&&&& RUNNING TensorRT.trtexec [TensorRT v8001] # trtexec --onnx=default_model.onnx --saveEngine=tmp.trt --verbose --int8
[12/29/2021-03:40:09] [I] === Model Options ===
[12/29/2021-03:40:09] [I] Format: ONNX
[12/29/2021-03:40:09] [I] Model: default_model.onnx
[12/29/2021-03:40:09] [I] Output:
[12/29/2021-03:40:09] [I] === Build Options ===
[12/29/2021-03:40:09] [I] Max batch: explicit
[12/29/2021-03:40:09] [I] Workspace: 16 MiB
[12/29/2021-03:40:09] [I] minTiming: 1
[12/29/2021-03:40:09] [I] avgTiming: 8
[12/29/2021-03:40:09] [I] Precision: FP32+INT8
[12/29/2021-03:40:09] [I] Calibration: Dynamic
[12/29/2021-03:40:09] [I] Refit: Disabled
[12/29/2021-03:40:09] [I] Sparsity: Disabled
[12/29/2021-03:40:09] [I] Safe mode: Disabled
[12/29/2021-03:40:09] [I] Restricted mode: Disabled
[12/29/2021-03:40:09] [I] Save engine: tmp.trt
[12/29/2021-03:40:09] [I] Load engine: 
[12/29/2021-03:40:09] [I] NVTX verbosity: 0
[12/29/2021-03:40:09] [I] Tactic sources: Using default tactic sources
[12/29/2021-03:40:09] [I] timingCacheMode: local
[12/29/2021-03:40:09] [I] timingCacheFile: 
[12/29/2021-03:40:09] [I] Input(s)s format: fp32:CHW
[12/29/2021-03:40:09] [I] Output(s)s format: fp32:CHW
[12/29/2021-03:40:09] [I] Input build shapes: model
[12/29/2021-03:40:09] [I] Input calibration shapes: model
[12/29/2021-03:40:09] [I] === System Options ===
[12/29/2021-03:40:09] [I] Device: 0
[12/29/2021-03:40:09] [I] DLACore: 
[12/29/2021-03:40:09] [I] Plugins:
[12/29/2021-03:40:09] [I] === Inference Options ===
[12/29/2021-03:40:09] [I] Batch: Explicit
[12/29/2021-03:40:09] [I] Input inference shapes: model
[12/29/2021-03:40:09] [I] Iterations: 10
[12/29/2021-03:40:09] [I] Duration: 3s (+ 200ms warm up)
[12/29/2021-03:40:09] [I] Sleep time: 0ms
[12/29/2021-03:40:09] [I] Streams: 1
[12/29/2021-03:40:09] [I] ExposeDMA: Disabled
[12/29/2021-03:40:09] [I] Data transfers: Enabled
[12/29/2021-03:40:09] [I] Spin-wait: Disabled
[12/29/2021-03:40:09] [I] Multithreading: Disabled
[12/29/2021-03:40:09] [I] CUDA Graph: Disabled
[12/29/2021-03:40:09] [I] Separate profiling: Disabled
[12/29/2021-03:40:09] [I] Time Deserialize: Disabled
[12/29/2021-03:40:09] [I] Time Refit: Disabled
[12/29/2021-03:40:09] [I] Skip inference: Disabled
[12/29/2021-03:40:09] [I] Inputs:
[12/29/2021-03:40:09] [I] === Reporting Options ===
[12/29/2021-03:40:09] [I] Verbose: Enabled
[12/29/2021-03:40:09] [I] Averages: 10 inferences
[12/29/2021-03:40:09] [I] Percentile: 99
[12/29/2021-03:40:09] [I] Dump refittable layers:Disabled
[12/29/2021-03:40:09] [I] Dump output: Disabled
[12/29/2021-03:40:09] [I] Profile: Disabled
[12/29/2021-03:40:09] [I] Export timing to JSON file: 
[12/29/2021-03:40:09] [I] Export output to JSON file: 
[12/29/2021-03:40:09] [I] Export profile to JSON file: 
[12/29/2021-03:40:09] [I] 
[12/29/2021-03:40:09] [I] === Device Information ===
[12/29/2021-03:40:09] [I] Selected Device: NVIDIA GeForce RTX 3090
[12/29/2021-03:40:09] [I] Compute Capability: 8.6
[12/29/2021-03:40:09] [I] SMs: 82
[12/29/2021-03:40:09] [I] Compute Clock Rate: 1.695 GHz
[12/29/2021-03:40:09] [I] Device Global Memory: 24260 MiB
[12/29/2021-03:40:09] [I] Shared Memory per SM: 100 KiB
[12/29/2021-03:40:09] [I] Memory Bus Width: 384 bits (ECC disabled)
[12/29/2021-03:40:09] [I] Memory Clock Rate: 9.751 GHz
[12/29/2021-03:40:09] [I] 
[12/29/2021-03:40:09] [I] TensorRT version: 8001
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::Region_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::Clip_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::ScatterND version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::CropAndResize version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::Proposal version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::Split version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1
[12/29/2021-03:40:09] [I] [TRT] [MemUsageChange] Init CUDA: CPU +534, GPU +0, now: CPU 541, GPU 3268 (MiB)
[12/29/2021-03:40:09] [I] Start parsing network model
[12/29/2021-03:40:09] [I] [TRT] ----------------------------------------------------------------
[12/29/2021-03:40:09] [I] [TRT] Input filename:   default_model.onnx
[12/29/2021-03:40:09] [I] [TRT] ONNX IR version:  0.0.6
[12/29/2021-03:40:09] [I] [TRT] Opset version:    9
[12/29/2021-03:40:09] [I] [TRT] Producer name:    pytorch
[12/29/2021-03:40:09] [I] [TRT] Producer version: 1.8
[12/29/2021-03:40:09] [I] [TRT] Domain:           
[12/29/2021-03:40:09] [I] [TRT] Model version:    0
[12/29/2021-03:40:09] [I] [TRT] Doc string:       
[12/29/2021-03:40:09] [I] [TRT] ----------------------------------------------------------------
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::Clip_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::ScatterND version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::Proposal version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::Split version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1
[12/29/2021-03:40:09] [V] [TRT] Adding network input: actual_input_1 with dtype: float32, dimensions: (32, 3, 32, 32)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: actual_input_1 for ONNX tensor: actual_input_1
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: fc.module.weight
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: fc.module.bias
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 271
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 272
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 274
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 275
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 277
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 278
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 280
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 281
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 283
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 284
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 286
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 287
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 289
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 290
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 292
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 293
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 295
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 296
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 298
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 299
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 301
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 302
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 304
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 305
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 307
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 308
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 310
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 311
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 313
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 314
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 316
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 317
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 319
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 320
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 322
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 323
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 325
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 326
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 328
[12/29/2021-03:40:09] [V] [TRT] Importing initializer: 329
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Conv_2 [Conv]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: actual_input_1
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 271
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 272
[12/29/2021-03:40:09] [V] [TRT] Conv_2 [Conv] inputs: [actual_input_1 -> (32, 3, 32, 32)[FLOAT]], [271 -> (64, 3, 7, 7)[FLOAT]], [272 -> (64)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Convolution input dimensions: (32, 3, 32, 32)
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Conv_2 for ONNX node: Conv_2
[12/29/2021-03:40:09] [V] [TRT] Using kernel: (7, 7), strides: (2, 2), prepadding: (3, 3), postpadding: (3, 3), dilations: (1, 1), numOutputs: 64
[12/29/2021-03:40:09] [V] [TRT] Convolution output dimensions: (32, 64, 16, 16)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 270 for ONNX tensor: 270
[12/29/2021-03:40:09] [V] [TRT] Conv_2 [Conv] outputs: [270 -> (32, 64, 16, 16)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Relu_5 [Relu]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 270
[12/29/2021-03:40:09] [V] [TRT] Relu_5 [Relu] inputs: [270 -> (32, 64, 16, 16)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Relu_5 for ONNX node: Relu_5
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 129 for ONNX tensor: 129
[12/29/2021-03:40:09] [V] [TRT] Relu_5 [Relu] outputs: [129 -> (32, 64, 16, 16)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: MaxPool_8 [MaxPool]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 129
[12/29/2021-03:40:09] [V] [TRT] MaxPool_8 [MaxPool] inputs: [129 -> (32, 64, 16, 16)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: MaxPool_8 for ONNX node: MaxPool_8
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 132 for ONNX tensor: 132
[12/29/2021-03:40:09] [V] [TRT] MaxPool_8 [MaxPool] outputs: [132 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Conv_11 [Conv]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 132
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 274
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 275
[12/29/2021-03:40:09] [V] [TRT] Conv_11 [Conv] inputs: [132 -> (32, 64, 8, 8)[FLOAT]], [274 -> (64, 64, 3, 3)[FLOAT]], [275 -> (64)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Convolution input dimensions: (32, 64, 8, 8)
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Conv_11 for ONNX node: Conv_11
[12/29/2021-03:40:09] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[12/29/2021-03:40:09] [V] [TRT] Convolution output dimensions: (32, 64, 8, 8)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 273 for ONNX tensor: 273
[12/29/2021-03:40:09] [V] [TRT] Conv_11 [Conv] outputs: [273 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Relu_14 [Relu]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 273
[12/29/2021-03:40:09] [V] [TRT] Relu_14 [Relu] inputs: [273 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Relu_14 for ONNX node: Relu_14
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 139 for ONNX tensor: 139
[12/29/2021-03:40:09] [V] [TRT] Relu_14 [Relu] outputs: [139 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Conv_17 [Conv]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 139
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 277
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 278
[12/29/2021-03:40:09] [V] [TRT] Conv_17 [Conv] inputs: [139 -> (32, 64, 8, 8)[FLOAT]], [277 -> (64, 64, 3, 3)[FLOAT]], [278 -> (64)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Convolution input dimensions: (32, 64, 8, 8)
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Conv_17 for ONNX node: Conv_17
[12/29/2021-03:40:09] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[12/29/2021-03:40:09] [V] [TRT] Convolution output dimensions: (32, 64, 8, 8)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 276 for ONNX tensor: 276
[12/29/2021-03:40:09] [V] [TRT] Conv_17 [Conv] outputs: [276 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Add_18 [Add]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 276
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 132
[12/29/2021-03:40:09] [V] [TRT] Add_18 [Add] inputs: [276 -> (32, 64, 8, 8)[FLOAT]], [132 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Add_18 for ONNX node: Add_18
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 144 for ONNX tensor: 144
[12/29/2021-03:40:09] [V] [TRT] Add_18 [Add] outputs: [144 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Relu_21 [Relu]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 144
[12/29/2021-03:40:09] [V] [TRT] Relu_21 [Relu] inputs: [144 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Relu_21 for ONNX node: Relu_21
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 147 for ONNX tensor: 147
[12/29/2021-03:40:09] [V] [TRT] Relu_21 [Relu] outputs: [147 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Conv_24 [Conv]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 147
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 280
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 281
[12/29/2021-03:40:09] [V] [TRT] Conv_24 [Conv] inputs: [147 -> (32, 64, 8, 8)[FLOAT]], [280 -> (64, 64, 3, 3)[FLOAT]], [281 -> (64)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Convolution input dimensions: (32, 64, 8, 8)
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Conv_24 for ONNX node: Conv_24
[12/29/2021-03:40:09] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[12/29/2021-03:40:09] [V] [TRT] Convolution output dimensions: (32, 64, 8, 8)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 279 for ONNX tensor: 279
[12/29/2021-03:40:09] [V] [TRT] Conv_24 [Conv] outputs: [279 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Relu_27 [Relu]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 279
[12/29/2021-03:40:09] [V] [TRT] Relu_27 [Relu] inputs: [279 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Relu_27 for ONNX node: Relu_27
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 154 for ONNX tensor: 154
[12/29/2021-03:40:09] [V] [TRT] Relu_27 [Relu] outputs: [154 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Conv_30 [Conv]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 154
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 283
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 284
[12/29/2021-03:40:09] [V] [TRT] Conv_30 [Conv] inputs: [154 -> (32, 64, 8, 8)[FLOAT]], [283 -> (64, 64, 3, 3)[FLOAT]], [284 -> (64)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Convolution input dimensions: (32, 64, 8, 8)
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Conv_30 for ONNX node: Conv_30
[12/29/2021-03:40:09] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[12/29/2021-03:40:09] [V] [TRT] Convolution output dimensions: (32, 64, 8, 8)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 282 for ONNX tensor: 282
[12/29/2021-03:40:09] [V] [TRT] Conv_30 [Conv] outputs: [282 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Add_31 [Add]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 282
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 147
[12/29/2021-03:40:09] [V] [TRT] Add_31 [Add] inputs: [282 -> (32, 64, 8, 8)[FLOAT]], [147 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Add_31 for ONNX node: Add_31
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 159 for ONNX tensor: 159
[12/29/2021-03:40:09] [V] [TRT] Add_31 [Add] outputs: [159 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Relu_34 [Relu]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 159
[12/29/2021-03:40:09] [V] [TRT] Relu_34 [Relu] inputs: [159 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Relu_34 for ONNX node: Relu_34
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 162 for ONNX tensor: 162
[12/29/2021-03:40:09] [V] [TRT] Relu_34 [Relu] outputs: [162 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Conv_37 [Conv]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 162
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 286
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 287
[12/29/2021-03:40:09] [V] [TRT] Conv_37 [Conv] inputs: [162 -> (32, 64, 8, 8)[FLOAT]], [286 -> (128, 64, 3, 3)[FLOAT]], [287 -> (128)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Convolution input dimensions: (32, 64, 8, 8)
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Conv_37 for ONNX node: Conv_37
[12/29/2021-03:40:09] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[12/29/2021-03:40:09] [V] [TRT] Convolution output dimensions: (32, 128, 4, 4)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 285 for ONNX tensor: 285
[12/29/2021-03:40:09] [V] [TRT] Conv_37 [Conv] outputs: [285 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Relu_40 [Relu]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 285
[12/29/2021-03:40:09] [V] [TRT] Relu_40 [Relu] inputs: [285 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Relu_40 for ONNX node: Relu_40
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 169 for ONNX tensor: 169
[12/29/2021-03:40:09] [V] [TRT] Relu_40 [Relu] outputs: [169 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Conv_43 [Conv]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 169
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 289
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 290
[12/29/2021-03:40:09] [V] [TRT] Conv_43 [Conv] inputs: [169 -> (32, 128, 4, 4)[FLOAT]], [289 -> (128, 128, 3, 3)[FLOAT]], [290 -> (128)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Convolution input dimensions: (32, 128, 4, 4)
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Conv_43 for ONNX node: Conv_43
[12/29/2021-03:40:09] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[12/29/2021-03:40:09] [V] [TRT] Convolution output dimensions: (32, 128, 4, 4)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 288 for ONNX tensor: 288
[12/29/2021-03:40:09] [V] [TRT] Conv_43 [Conv] outputs: [288 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Conv_46 [Conv]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 162
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 292
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 293
[12/29/2021-03:40:09] [V] [TRT] Conv_46 [Conv] inputs: [162 -> (32, 64, 8, 8)[FLOAT]], [292 -> (128, 64, 1, 1)[FLOAT]], [293 -> (128)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Convolution input dimensions: (32, 64, 8, 8)
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Conv_46 for ONNX node: Conv_46
[12/29/2021-03:40:09] [V] [TRT] Using kernel: (1, 1), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[12/29/2021-03:40:09] [V] [TRT] Convolution output dimensions: (32, 128, 4, 4)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 291 for ONNX tensor: 291
[12/29/2021-03:40:09] [V] [TRT] Conv_46 [Conv] outputs: [291 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Add_47 [Add]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 288
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 291
[12/29/2021-03:40:09] [V] [TRT] Add_47 [Add] inputs: [288 -> (32, 128, 4, 4)[FLOAT]], [291 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Add_47 for ONNX node: Add_47
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 178 for ONNX tensor: 178
[12/29/2021-03:40:09] [V] [TRT] Add_47 [Add] outputs: [178 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Relu_50 [Relu]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 178
[12/29/2021-03:40:09] [V] [TRT] Relu_50 [Relu] inputs: [178 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Relu_50 for ONNX node: Relu_50
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 181 for ONNX tensor: 181
[12/29/2021-03:40:09] [V] [TRT] Relu_50 [Relu] outputs: [181 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Conv_53 [Conv]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 181
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 295
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 296
[12/29/2021-03:40:09] [V] [TRT] Conv_53 [Conv] inputs: [181 -> (32, 128, 4, 4)[FLOAT]], [295 -> (128, 128, 3, 3)[FLOAT]], [296 -> (128)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Convolution input dimensions: (32, 128, 4, 4)
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Conv_53 for ONNX node: Conv_53
[12/29/2021-03:40:09] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[12/29/2021-03:40:09] [V] [TRT] Convolution output dimensions: (32, 128, 4, 4)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 294 for ONNX tensor: 294
[12/29/2021-03:40:09] [V] [TRT] Conv_53 [Conv] outputs: [294 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Relu_56 [Relu]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 294
[12/29/2021-03:40:09] [V] [TRT] Relu_56 [Relu] inputs: [294 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Relu_56 for ONNX node: Relu_56
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 188 for ONNX tensor: 188
[12/29/2021-03:40:09] [V] [TRT] Relu_56 [Relu] outputs: [188 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Conv_59 [Conv]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 188
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 298
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 299
[12/29/2021-03:40:09] [V] [TRT] Conv_59 [Conv] inputs: [188 -> (32, 128, 4, 4)[FLOAT]], [298 -> (128, 128, 3, 3)[FLOAT]], [299 -> (128)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Convolution input dimensions: (32, 128, 4, 4)
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Conv_59 for ONNX node: Conv_59
[12/29/2021-03:40:09] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[12/29/2021-03:40:09] [V] [TRT] Convolution output dimensions: (32, 128, 4, 4)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 297 for ONNX tensor: 297
[12/29/2021-03:40:09] [V] [TRT] Conv_59 [Conv] outputs: [297 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Add_60 [Add]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 297
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 181
[12/29/2021-03:40:09] [V] [TRT] Add_60 [Add] inputs: [297 -> (32, 128, 4, 4)[FLOAT]], [181 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Add_60 for ONNX node: Add_60
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 193 for ONNX tensor: 193
[12/29/2021-03:40:09] [V] [TRT] Add_60 [Add] outputs: [193 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Relu_63 [Relu]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 193
[12/29/2021-03:40:09] [V] [TRT] Relu_63 [Relu] inputs: [193 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Relu_63 for ONNX node: Relu_63
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 196 for ONNX tensor: 196
[12/29/2021-03:40:09] [V] [TRT] Relu_63 [Relu] outputs: [196 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Conv_66 [Conv]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 196
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 301
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 302
[12/29/2021-03:40:09] [V] [TRT] Conv_66 [Conv] inputs: [196 -> (32, 128, 4, 4)[FLOAT]], [301 -> (256, 128, 3, 3)[FLOAT]], [302 -> (256)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Convolution input dimensions: (32, 128, 4, 4)
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Conv_66 for ONNX node: Conv_66
[12/29/2021-03:40:09] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[12/29/2021-03:40:09] [V] [TRT] Convolution output dimensions: (32, 256, 2, 2)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 300 for ONNX tensor: 300
[12/29/2021-03:40:09] [V] [TRT] Conv_66 [Conv] outputs: [300 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Relu_69 [Relu]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 300
[12/29/2021-03:40:09] [V] [TRT] Relu_69 [Relu] inputs: [300 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Relu_69 for ONNX node: Relu_69
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 203 for ONNX tensor: 203
[12/29/2021-03:40:09] [V] [TRT] Relu_69 [Relu] outputs: [203 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Conv_72 [Conv]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 203
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 304
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 305
[12/29/2021-03:40:09] [V] [TRT] Conv_72 [Conv] inputs: [203 -> (32, 256, 2, 2)[FLOAT]], [304 -> (256, 256, 3, 3)[FLOAT]], [305 -> (256)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Convolution input dimensions: (32, 256, 2, 2)
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Conv_72 for ONNX node: Conv_72
[12/29/2021-03:40:09] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[12/29/2021-03:40:09] [V] [TRT] Convolution output dimensions: (32, 256, 2, 2)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 303 for ONNX tensor: 303
[12/29/2021-03:40:09] [V] [TRT] Conv_72 [Conv] outputs: [303 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Conv_75 [Conv]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 196
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 307
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 308
[12/29/2021-03:40:09] [V] [TRT] Conv_75 [Conv] inputs: [196 -> (32, 128, 4, 4)[FLOAT]], [307 -> (256, 128, 1, 1)[FLOAT]], [308 -> (256)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Convolution input dimensions: (32, 128, 4, 4)
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Conv_75 for ONNX node: Conv_75
[12/29/2021-03:40:09] [V] [TRT] Using kernel: (1, 1), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[12/29/2021-03:40:09] [V] [TRT] Convolution output dimensions: (32, 256, 2, 2)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 306 for ONNX tensor: 306
[12/29/2021-03:40:09] [V] [TRT] Conv_75 [Conv] outputs: [306 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Add_76 [Add]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 303
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 306
[12/29/2021-03:40:09] [V] [TRT] Add_76 [Add] inputs: [303 -> (32, 256, 2, 2)[FLOAT]], [306 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Add_76 for ONNX node: Add_76
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 212 for ONNX tensor: 212
[12/29/2021-03:40:09] [V] [TRT] Add_76 [Add] outputs: [212 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Relu_79 [Relu]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 212
[12/29/2021-03:40:09] [V] [TRT] Relu_79 [Relu] inputs: [212 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Relu_79 for ONNX node: Relu_79
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 215 for ONNX tensor: 215
[12/29/2021-03:40:09] [V] [TRT] Relu_79 [Relu] outputs: [215 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Conv_82 [Conv]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 215
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 310
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 311
[12/29/2021-03:40:09] [V] [TRT] Conv_82 [Conv] inputs: [215 -> (32, 256, 2, 2)[FLOAT]], [310 -> (256, 256, 3, 3)[FLOAT]], [311 -> (256)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Convolution input dimensions: (32, 256, 2, 2)
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Conv_82 for ONNX node: Conv_82
[12/29/2021-03:40:09] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[12/29/2021-03:40:09] [V] [TRT] Convolution output dimensions: (32, 256, 2, 2)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 309 for ONNX tensor: 309
[12/29/2021-03:40:09] [V] [TRT] Conv_82 [Conv] outputs: [309 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Relu_85 [Relu]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 309
[12/29/2021-03:40:09] [V] [TRT] Relu_85 [Relu] inputs: [309 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Relu_85 for ONNX node: Relu_85
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 222 for ONNX tensor: 222
[12/29/2021-03:40:09] [V] [TRT] Relu_85 [Relu] outputs: [222 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Conv_88 [Conv]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 222
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 313
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 314
[12/29/2021-03:40:09] [V] [TRT] Conv_88 [Conv] inputs: [222 -> (32, 256, 2, 2)[FLOAT]], [313 -> (256, 256, 3, 3)[FLOAT]], [314 -> (256)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Convolution input dimensions: (32, 256, 2, 2)
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Conv_88 for ONNX node: Conv_88
[12/29/2021-03:40:09] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[12/29/2021-03:40:09] [V] [TRT] Convolution output dimensions: (32, 256, 2, 2)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 312 for ONNX tensor: 312
[12/29/2021-03:40:09] [V] [TRT] Conv_88 [Conv] outputs: [312 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Add_89 [Add]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 312
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 215
[12/29/2021-03:40:09] [V] [TRT] Add_89 [Add] inputs: [312 -> (32, 256, 2, 2)[FLOAT]], [215 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Add_89 for ONNX node: Add_89
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 227 for ONNX tensor: 227
[12/29/2021-03:40:09] [V] [TRT] Add_89 [Add] outputs: [227 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Relu_92 [Relu]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 227
[12/29/2021-03:40:09] [V] [TRT] Relu_92 [Relu] inputs: [227 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Relu_92 for ONNX node: Relu_92
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 230 for ONNX tensor: 230
[12/29/2021-03:40:09] [V] [TRT] Relu_92 [Relu] outputs: [230 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Conv_95 [Conv]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 230
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 316
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 317
[12/29/2021-03:40:09] [V] [TRT] Conv_95 [Conv] inputs: [230 -> (32, 256, 2, 2)[FLOAT]], [316 -> (512, 256, 3, 3)[FLOAT]], [317 -> (512)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Convolution input dimensions: (32, 256, 2, 2)
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Conv_95 for ONNX node: Conv_95
[12/29/2021-03:40:09] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 512
[12/29/2021-03:40:09] [V] [TRT] Convolution output dimensions: (32, 512, 1, 1)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 315 for ONNX tensor: 315
[12/29/2021-03:40:09] [V] [TRT] Conv_95 [Conv] outputs: [315 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Relu_98 [Relu]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 315
[12/29/2021-03:40:09] [V] [TRT] Relu_98 [Relu] inputs: [315 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Relu_98 for ONNX node: Relu_98
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 237 for ONNX tensor: 237
[12/29/2021-03:40:09] [V] [TRT] Relu_98 [Relu] outputs: [237 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Conv_101 [Conv]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 237
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 319
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 320
[12/29/2021-03:40:09] [V] [TRT] Conv_101 [Conv] inputs: [237 -> (32, 512, 1, 1)[FLOAT]], [319 -> (512, 512, 3, 3)[FLOAT]], [320 -> (512)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Convolution input dimensions: (32, 512, 1, 1)
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Conv_101 for ONNX node: Conv_101
[12/29/2021-03:40:09] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 512
[12/29/2021-03:40:09] [V] [TRT] Convolution output dimensions: (32, 512, 1, 1)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 318 for ONNX tensor: 318
[12/29/2021-03:40:09] [V] [TRT] Conv_101 [Conv] outputs: [318 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Conv_104 [Conv]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 230
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 322
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 323
[12/29/2021-03:40:09] [V] [TRT] Conv_104 [Conv] inputs: [230 -> (32, 256, 2, 2)[FLOAT]], [322 -> (512, 256, 1, 1)[FLOAT]], [323 -> (512)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Convolution input dimensions: (32, 256, 2, 2)
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Conv_104 for ONNX node: Conv_104
[12/29/2021-03:40:09] [V] [TRT] Using kernel: (1, 1), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[12/29/2021-03:40:09] [V] [TRT] Convolution output dimensions: (32, 512, 1, 1)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 321 for ONNX tensor: 321
[12/29/2021-03:40:09] [V] [TRT] Conv_104 [Conv] outputs: [321 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Add_105 [Add]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 318
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 321
[12/29/2021-03:40:09] [V] [TRT] Add_105 [Add] inputs: [318 -> (32, 512, 1, 1)[FLOAT]], [321 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Add_105 for ONNX node: Add_105
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 246 for ONNX tensor: 246
[12/29/2021-03:40:09] [V] [TRT] Add_105 [Add] outputs: [246 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Relu_108 [Relu]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 246
[12/29/2021-03:40:09] [V] [TRT] Relu_108 [Relu] inputs: [246 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Relu_108 for ONNX node: Relu_108
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 249 for ONNX tensor: 249
[12/29/2021-03:40:09] [V] [TRT] Relu_108 [Relu] outputs: [249 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Conv_111 [Conv]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 249
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 325
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 326
[12/29/2021-03:40:09] [V] [TRT] Conv_111 [Conv] inputs: [249 -> (32, 512, 1, 1)[FLOAT]], [325 -> (512, 512, 3, 3)[FLOAT]], [326 -> (512)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Convolution input dimensions: (32, 512, 1, 1)
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Conv_111 for ONNX node: Conv_111
[12/29/2021-03:40:09] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 512
[12/29/2021-03:40:09] [V] [TRT] Convolution output dimensions: (32, 512, 1, 1)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 324 for ONNX tensor: 324
[12/29/2021-03:40:09] [V] [TRT] Conv_111 [Conv] outputs: [324 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Relu_114 [Relu]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 324
[12/29/2021-03:40:09] [V] [TRT] Relu_114 [Relu] inputs: [324 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Relu_114 for ONNX node: Relu_114
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 256 for ONNX tensor: 256
[12/29/2021-03:40:09] [V] [TRT] Relu_114 [Relu] outputs: [256 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Conv_117 [Conv]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 256
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 328
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 329
[12/29/2021-03:40:09] [V] [TRT] Conv_117 [Conv] inputs: [256 -> (32, 512, 1, 1)[FLOAT]], [328 -> (512, 512, 3, 3)[FLOAT]], [329 -> (512)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Convolution input dimensions: (32, 512, 1, 1)
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Conv_117 for ONNX node: Conv_117
[12/29/2021-03:40:09] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 512
[12/29/2021-03:40:09] [V] [TRT] Convolution output dimensions: (32, 512, 1, 1)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 327 for ONNX tensor: 327
[12/29/2021-03:40:09] [V] [TRT] Conv_117 [Conv] outputs: [327 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Add_118 [Add]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 327
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 249
[12/29/2021-03:40:09] [V] [TRT] Add_118 [Add] inputs: [327 -> (32, 512, 1, 1)[FLOAT]], [249 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Add_118 for ONNX node: Add_118
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 261 for ONNX tensor: 261
[12/29/2021-03:40:09] [V] [TRT] Add_118 [Add] outputs: [261 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Relu_121 [Relu]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 261
[12/29/2021-03:40:09] [V] [TRT] Relu_121 [Relu] inputs: [261 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Relu_121 for ONNX node: Relu_121
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 264 for ONNX tensor: 264
[12/29/2021-03:40:09] [V] [TRT] Relu_121 [Relu] outputs: [264 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: GlobalAveragePool_122 [GlobalAveragePool]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 264
[12/29/2021-03:40:09] [V] [TRT] GlobalAveragePool_122 [GlobalAveragePool] inputs: [264 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: GlobalAveragePool_122 for ONNX node: GlobalAveragePool_122
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 265 for ONNX tensor: 265
[12/29/2021-03:40:09] [V] [TRT] GlobalAveragePool_122 [GlobalAveragePool] outputs: [265 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Flatten_123 [Flatten]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 265
[12/29/2021-03:40:09] [V] [TRT] Flatten_123 [Flatten] inputs: [265 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Flatten_123 for ONNX node: Flatten_123
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: 266 for ONNX tensor: 266
[12/29/2021-03:40:09] [V] [TRT] Flatten_123 [Flatten] outputs: [266 -> (32, 512)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Parsing node: Gemm_126 [Gemm]
[12/29/2021-03:40:09] [V] [TRT] Searching for input: 266
[12/29/2021-03:40:09] [V] [TRT] Searching for input: fc.module.weight
[12/29/2021-03:40:09] [V] [TRT] Searching for input: fc.module.bias
[12/29/2021-03:40:09] [V] [TRT] Gemm_126 [Gemm] inputs: [266 -> (32, 512)[FLOAT]], [fc.module.weight -> (10, 512)[FLOAT]], [fc.module.bias -> (10)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] GEMM: using FC layer instead of MM because all criteria were met.
[12/29/2021-03:40:09] [V] [TRT] Original shape: (32, 512), unsqueezing to: (32, 512, 1, 1)
[12/29/2021-03:40:09] [V] [TRT] Registering layer: Gemm_126 for ONNX node: Gemm_126
[12/29/2021-03:40:09] [V] [TRT] Original shape: (32, 10, 1, 1), squeezing to: (32, 10)
[12/29/2021-03:40:09] [V] [TRT] Registering tensor: output1_0 for ONNX tensor: output1
[12/29/2021-03:40:09] [V] [TRT] Gemm_126 [Gemm] outputs: [output1 -> (32, 10)[FLOAT]], 
[12/29/2021-03:40:09] [V] [TRT] Marking output1_0 as output: output1
[12/29/2021-03:40:09] [I] Finish parsing network model
[12/29/2021-03:40:09] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 582, GPU 3268 (MiB)
[12/29/2021-03:40:09] [I] FP32 and INT8 precisions have been specified - more performance might be enabled by additionally specifying --fp16 or --best
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for actual_input_1 to [-2,2]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 270 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 129 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 132 to [-2,2]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 273 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 139 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 276 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 144 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 147 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 279 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 154 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 282 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 159 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 162 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 285 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 169 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 288 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 291 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 178 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 181 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 294 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 188 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 297 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 193 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 196 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 300 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 203 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 303 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 306 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 212 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 215 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 309 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 222 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 312 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 227 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 230 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 315 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 237 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 318 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 321 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 246 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 249 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 324 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 256 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 327 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 261 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 264 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 265 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for 266 to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for (Unnamed Layer* 48) [Shuffle]_output to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for (Unnamed Layer* 49) [Fully Connected]_output to [-4,4]
[12/29/2021-03:40:09] [V] [TRT] Setting dynamic range for output1 to [-4,4]
[12/29/2021-03:40:09] [I] [TRT] [MemUsageSnapshot] Builder begin: CPU 582 MiB, GPU 3268 MiB
[12/29/2021-03:40:09] [12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.015748,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.015748,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] User overriding scale with scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] Configuring builder for Int8 Mode completed in 0.000305039 seconds.
[12/29/2021-03:40:09] [V] [TRT] Applying generic optimizations to the graph for inference.
[12/29/2021-03:40:09] [V] [TRT] Original: 51 layers
[12/29/2021-03:40:09] [V] [TRT] After dead-layer removal: 51 layers
[12/29/2021-03:40:09] [V] [TRT] ShuffleShuffleFusion: Fusing Flatten_123 with (Unnamed Layer* 48) [Shuffle]
[12/29/2021-03:40:09] [V] [TRT] Removing Flatten_123 + (Unnamed Layer* 48) [Shuffle]
[12/29/2021-03:40:09] [V] [TRT] After Myelin optimization: 49 layers
[12/29/2021-03:40:09] [V] [TRT] Assigning shuffle_between_265_and_Gemm_126_out_tensor scale and zero-point 
[12/29/2021-03:40:09] [V] [TRT] using 265 scale and zero-point Quantization(scale: {0.0314961,}, zero-point: {0,})
[12/29/2021-03:40:09] [V] [TRT] Convert layer type of Gemm_126 from FULLY_CONNECTED to CONVOLUTION
[12/29/2021-03:40:09] [V] [TRT] Removing shuffle_between_265_and_Gemm_126
[12/29/2021-03:40:09] [V] [TRT] After scale fusion: 49 layers
[12/29/2021-03:40:09] [V] [TRT] ConvReluFusion: Fusing Conv_2 with Relu_5
[12/29/2021-03:40:09] [V] [TRT] ConvActPoolFusion: Fusing Conv_2 + Relu_5 with MaxPool_8
[12/29/2021-03:40:09] [V] [TRT] ConvReluFusion: Fusing Conv_11 with Relu_14
[12/29/2021-03:40:09] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_17 with Add_18
[12/29/2021-03:40:09] [V] [TRT] ConvReluFusion: Fusing Conv_17 + Add_18 with Relu_21
[12/29/2021-03:40:09] [V] [TRT] ConvReluFusion: Fusing Conv_24 with Relu_27
[12/29/2021-03:40:09] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_30 with Add_31
[12/29/2021-03:40:09] [V] [TRT] ConvReluFusion: Fusing Conv_30 + Add_31 with Relu_34
[12/29/2021-03:40:09] [V] [TRT] ConvReluFusion: Fusing Conv_37 with Relu_40
[12/29/2021-03:40:09] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_43 with Add_47
[12/29/2021-03:40:09] [V] [TRT] ConvReluFusion: Fusing Conv_43 + Add_47 with Relu_50
[12/29/2021-03:40:09] [V] [TRT] ConvReluFusion: Fusing Conv_53 with Relu_56
[12/29/2021-03:40:09] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_59 with Add_60
[12/29/2021-03:40:09] [V] [TRT] ConvReluFusion: Fusing Conv_59 + Add_60 with Relu_63
[12/29/2021-03:40:09] [V] [TRT] ConvReluFusion: Fusing Conv_66 with Relu_69
[12/29/2021-03:40:09] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_72 with Add_76
[12/29/2021-03:40:09] [V] [TRT] ConvReluFusion: Fusing Conv_72 + Add_76 with Relu_79
[12/29/2021-03:40:09] [V] [TRT] ConvReluFusion: Fusing Conv_82 with Relu_85
[12/29/2021-03:40:09] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_88 with Add_89
[12/29/2021-03:40:09] [V] [TRT] ConvReluFusion: Fusing Conv_88 + Add_89 with Relu_92
[12/29/2021-03:40:09] [V] [TRT] ConvReluFusion: Fusing Conv_95 with Relu_98
[12/29/2021-03:40:09] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_101 with Add_105
[12/29/2021-03:40:09] [V] [TRT] ConvReluFusion: Fusing Conv_101 + Add_105 with Relu_108
[12/29/2021-03:40:09] [V] [TRT] ConvReluFusion: Fusing Conv_111 with Relu_114
[12/29/2021-03:40:09] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_117 with Add_118
[12/29/2021-03:40:09] [V] [TRT] ConvReluFusion: Fusing Conv_117 + Add_118 with Relu_121
[12/29/2021-03:40:09] [V] [TRT] Swap the layer type of GlobalAveragePool_122 from REDUCE to POOLING
[12/29/2021-03:40:09] [V] [TRT] After vertical fusions: 23 layers
[12/29/2021-03:40:09] [V] [TRT] After dupe layer removal: 23 layers
[12/29/2021-03:40:09] [V] [TRT] After final dead-layer removal: 23 layers
[12/29/2021-03:40:09] [V] [TRT] After tensor merging: 23 layers
[12/29/2021-03:40:09] [V] [TRT] After concat removal: 23 layers
[12/29/2021-03:40:09] [V] [TRT] Graph construction and optimization completed in 0.0255313 seconds.
[12/29/2021-03:40:10] [V] [TRT] Using cublasLt a tactic source
[12/29/2021-03:40:10] [12/29/2021-03:40:10] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +637, GPU +266, now: CPU 1219, GPU 3534 (MiB)
[12/29/2021-03:40:10] [V] [TRT] Using cuDNN as a tactic source
[12/29/2021-03:40:11] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +358, GPU +260, now: CPU 1577, GPU 3794 (MiB)
[12/29/2021-03:40:11] [12/29/2021-03:40:11] [12/29/2021-03:40:11] [V] [TRT] Constructing optimization profile number 0 [1/1].
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Float(3072,1024,32,1) -> Int8(3072,1024,32,1) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.039976
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.005552
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.005552
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning format combination: Int8(3072,1024,32,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Conv_2 + Relu_5 + MaxPool_8 (ConvActPool)
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1000 Time: 0.014848
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1100 Time: 0.01472
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1110 Time: 0.015916
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1111 Time: 0.014628
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1112 Time: 0.018012
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1120 Time: 0.016044
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1121 Time: 0.014932
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1122 Time: 0.01824
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1130 Time: 0.015868
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1131 Time: 0.014656
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1132 Time: 0.018168
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1140 Time: 0.016176
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1141 Time: 0.014816
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1142 Time: 0.018248
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 1111 Time: 0.014628
[12/29/2021-03:40:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ConvActPool Tactic: 1111
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.007824
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.00622
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.00622
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.0077
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.00624
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.00624
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.008676
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.006552
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.006552
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.008096
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.009852
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 1002 Time: 0.008096
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.00742
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.004968
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1 Time: 0.0056
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.004968
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.008564
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.006408
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.006408
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.008532
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.00636
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.00636
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.007608
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.005104
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.005104
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.007672
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.007712
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 1002 Time: 0.007672
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.009048
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.006364
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.006364
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.007632
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.00598
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.00598
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.00772
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.00666
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.00666
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.007724
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.008404
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 1002 Time: 0.007724
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.008916
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.006472
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.006472
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.007604
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.006028
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.006028
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.008684
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.006704
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.006704
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.00866
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.00818
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.00818
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.008788
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.006292
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.006292
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.008528
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.005884
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.005884
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.007476
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.006392
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.006392
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.008056
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.006816
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.006816
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.008
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.008384
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 1002 Time: 0.008
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.008044
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.005428
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.005428
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.0084
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.006524
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.006524
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.00892
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.006876
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.006876
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.007552
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.005532
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.005532
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.00798
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.006472
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.006472
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.007848
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.006496
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.006496
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.00906
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.006676
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.006676
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1002 Time: 0.007324
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 0 Time: 0.00506
[12/29/2021-03:40:11] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:11] [V] [TRT] Tactic: 1 Time: 0.005532
[12/29/2021-03:40:11] [V] [TRT] Fastest Tactic: 0 Time: 0.00506
[12/29/2021-03:40:11] [V] [TRT] *************** Autotuning format combination: Float(4096,64,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CudaDepthwiseConvolution)
[12/29/2021-03:40:11] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:11] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (FusedConvActConvolution)
[12/29/2021-03:40:11] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:12] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CudnnConvolution)
[12/29/2021-03:40:12] [V] [TRT] Tactic: 0 Time: 0.035868
[12/29/2021-03:40:12] [V] [TRT] Tactic: 1 Time: 0.085108
[12/29/2021-03:40:12] [V] [TRT] Tactic: 2 Time: 0.067956
[12/29/2021-03:40:12] [V] [TRT] Tactic: 4 Time: 0.047696
[12/29/2021-03:40:12] [V] [TRT] Tactic: 5 skipped. Scratch requested: 35651584, available: 16777216
[12/29/2021-03:40:12] [V] [TRT] Tactic: 6 Time: 0.0274
[12/29/2021-03:40:12] [V] [TRT] Tactic: 56 Time: 0.035764
[12/29/2021-03:40:12] [V] [TRT] Tactic: 57 Time: 0.086912
[12/29/2021-03:40:12] [V] [TRT] Tactic: 58 Time: 0.0681
[12/29/2021-03:40:12] [V] [TRT] Tactic: 60 Time: 0.048012
[12/29/2021-03:40:12] [V] [TRT] Tactic: 61 skipped. Scratch requested: 35651584, available: 16777216
[12/29/2021-03:40:12] [V] [TRT] Tactic: 62 Time: 0.027392
[12/29/2021-03:40:12] [V] [TRT] Tactic: 112 Time: 0.035876
[12/29/2021-03:40:12] [V] [TRT] Tactic: 113 Time: 0.247448
[12/29/2021-03:40:12] [V] [TRT] Tactic: 114 Time: 0.067976
[12/29/2021-03:40:12] [V] [TRT] Tactic: 116 Time: 0.047792
[12/29/2021-03:40:12] [V] [TRT] Tactic: 117 skipped. Scratch requested: 35651584, available: 16777216
[12/29/2021-03:40:12] [V] [TRT] Tactic: 118 Time: 0.027416
[12/29/2021-03:40:12] [I] [TRT] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.
[12/29/2021-03:40:12] [V] [TRT] Fastest Tactic: 62 Time: 0.027392
[12/29/2021-03:40:12] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CaskConvolution)
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:40:12] [V] [TRT] Tactic: 4549827808004681195 Time: 0.063016
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:40:12] [V] [TRT] Tactic: 5779835512569528575 Time: 0.079764
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[12/29/2021-03:40:12] [V] [TRT] Tactic: 6053873026024413720 Time: 0.089516
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[12/29/2021-03:40:12] [V] [TRT] Tactic: 6767548733843469815 Time: 0.068348
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:40:12] [V] [TRT] Tactic: -6313876406580483184 Time: 0.075564
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:40:12] [V] [TRT] Tactic: -1123676555321336786 Time: 0.087764
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:40:12] [V] [TRT] Tactic: -701551393537224327 Time: 0.07692
[12/29/2021-03:40:12] [V] [TRT] Fastest Tactic: 4549827808004681195 Time: 0.063016
[12/29/2021-03:40:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 62
[12/29/2021-03:40:12] [V] [TRT] *************** Autotuning format combination: Float(4096,1,512,64) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:12] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CudnnConvolution)
[12/29/2021-03:40:12] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:12] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CaskConvolution)
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:12] [V] [TRT] Tactic: 2860655430572478466 Time: 0.04902
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:12] [V] [TRT] Tactic: 4474630279712975759 Time: 0.030424
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:12] [V] [TRT] Tactic: 4479823862704990365 Time: 0.029668
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:12] [V] [TRT] Tactic: 4696204239951173149 Time: 0.049668
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:12] [V] [TRT] Tactic: 5778138195697110003 Time: 0.078924
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:40:12] [V] [TRT] Tactic: 7155825427510256858 Time: 0.079356
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:12] [V] [TRT] Tactic: 8918020581761223752 Time: 0.077804
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:40:12] [V] [TRT] Tactic: -4756382386362004279 Time: 0.049036
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:40:12] [V] [TRT] Tactic: -3855385237722507464 Time: 0.080508
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:12] [V] [TRT] Tactic: -2809379259463049391 Time: 0.07904
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:12] [V] [TRT] Tactic: -504296718212024303 Time: 0.07678
[12/29/2021-03:40:12] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.029668
[12/29/2021-03:40:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:40:12] [V] [TRT] *************** Autotuning format combination: Float(1024,1:4,128,16) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:12] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CudnnConvolution)
[12/29/2021-03:40:12] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:12] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CaskConvolution)
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:12] [V] [TRT] Tactic: 2860655430572478466 Time: 0.049052
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:12] [V] [TRT] Tactic: 4474630279712975759 Time: 0.030552
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:12] [V] [TRT] Tactic: 4479823862704990365 Time: 0.02974
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:12] [V] [TRT] Tactic: 4696204239951173149 Time: 0.049784
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:12] [V] [TRT] Tactic: 5778138195697110003 Time: 0.079052
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:40:12] [V] [TRT] Tactic: 7155825427510256858 Time: 0.079492
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:40:12] [V] [TRT] Tactic: 7342025736444949634 Time: 0.054564
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:12] [V] [TRT] Tactic: 8918020581761223752 Time: 0.07786
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:40:12] [V] [TRT] Tactic: -7377458734869418330 Time: 0.053876
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:40:12] [V] [TRT] Tactic: -5457304872213719461 Time: 0.054588
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:40:12] [V] [TRT] Tactic: -4756382386362004279 Time: 0.049212
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:40:12] [V] [TRT] Tactic: -3855385237722507464 Time: 0.080528
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:12] [V] [TRT] Tactic: -2809379259463049391 Time: 0.079268
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:12] [V] [TRT] Tactic: -504296718212024303 Time: 0.076972
[12/29/2021-03:40:12] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.02974
[12/29/2021-03:40:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:40:12] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:12] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CudaDepthwiseConvolution)
[12/29/2021-03:40:12] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:12] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CaskConvolution)
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 1332468635798226953
[12/29/2021-03:40:12] [V] [TRT] Tactic: 1332468635798226953 Time: 0.035148
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:40:12] [V] [TRT] Tactic: 1508480131241957639 Time: 0.033272
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 1947019689364377201
[12/29/2021-03:40:12] [V] [TRT] Tactic: 1947019689364377201 Time: 0.025264
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:40:12] [V] [TRT] Tactic: 3239257003214966313 Time: 0.034804
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:40:12] [V] [TRT] Tactic: 5592640619112287921 Time: 0.022272
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:40:12] [V] [TRT] Tactic: 7621465827583909090 Time: 0.023336
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:40:12] [V] [TRT] Tactic: -5576936487443445631 Time: 0.02698
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:40:12] [V] [TRT] Tactic: -2297737319934264721 Time: 0.03074
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:40:12] [V] [TRT] Tactic: -1425085658556684465 Time: 0.02902
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:40:12] [V] [TRT] Tactic: -108011214168778087 Time: 0.02608
[12/29/2021-03:40:12] [V] [TRT] Fastest Tactic: 5592640619112287921 Time: 0.022272
[12/29/2021-03:40:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5592640619112287921
[12/29/2021-03:40:12] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:12] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CudaDepthwiseConvolution)
[12/29/2021-03:40:12] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:12] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (FusedConvActConvolution)
[12/29/2021-03:40:12] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:12] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CaskConvolution)
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:40:12] [V] [TRT] Tactic: 175853789719975416 Time: 0.028812
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:40:12] [V] [TRT] Tactic: 2171150287007712632 Time: 0.027084
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:40:12] [V] [TRT] Tactic: 2234457234705232274 Time: 0.021156
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:40:12] [V] [TRT] Tactic: 5834048089706882838 Time: 0.024976
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:40:12] [V] [TRT] Tactic: -8626990807754934295 Time: 0.024148
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:40:12] [V] [TRT] Tactic: -7303593854972602201 Time: 0.02044
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:40:12] [V] [TRT] Tactic: -6585664687867083638 Time: 0.03232
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: -3730012925709297561
[12/29/2021-03:40:12] [V] [TRT] Tactic: -3730012925709297561 Time: 0.022932
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: -2277259417488004546
[12/29/2021-03:40:12] [V] [TRT] Tactic: -2277259417488004546 Time: 0.032556
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:40:12] [V] [TRT] Tactic: -683636008127039856 Time: 0.030524
[12/29/2021-03:40:12] [V] [TRT] Fastest Tactic: -7303593854972602201 Time: 0.02044
[12/29/2021-03:40:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7303593854972602201
[12/29/2021-03:40:12] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:12] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CaskConvolution)
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 984309058095623735
[12/29/2021-03:40:12] [V] [TRT] Tactic: 984309058095623735 Time: 0.02274
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:40:12] [V] [TRT] Tactic: 1100922622480907544 Time: 0.023592
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 3238312825609165543
[12/29/2021-03:40:12] [V] [TRT] Tactic: 3238312825609165543 Time: 0.03212
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:40:12] [V] [TRT] Tactic: 3606311198834416176 Time: 0.024516
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:40:12] [V] [TRT] Tactic: 4325765560739862899 Time: 0.030344
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:40:12] [V] [TRT] Tactic: -4255737803793506479 Time: 0.031904
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:40:12] [V] [TRT] Tactic: -3958182351168863467 Time: 0.020088
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:40:12] [V] [TRT] Tactic: -3111968753064955248 Time: 0.02654
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:40:12] [V] [TRT] Tactic: -1492575840277333548 Time: 0.02832
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:40:12] [V] [TRT] Tactic: -868495160148524802 Time: 0.020816
[12/29/2021-03:40:12] [V] [TRT] Fastest Tactic: -3958182351168863467 Time: 0.020088
[12/29/2021-03:40:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3958182351168863467
[12/29/2021-03:40:12] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:12] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CaskConvolution)
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:40:12] [V] [TRT] Tactic: 1011019097971850911 Time: 0.015024
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:40:12] [V] [TRT] Tactic: 1071114551801767124 Time: 0.00984
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:40:12] [V] [TRT] Tactic: 2623576043214044314 Time: 0.009068
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:40:12] [V] [TRT] Tactic: 3281631721811475881 Time: 0.008796
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:40:12] [V] [TRT] Tactic: 4551754795416974366 Time: 0.008624
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:40:12] [V] [TRT] Tactic: 4925112190271421402 Time: 0.00916
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:40:12] [V] [TRT] Tactic: 5012796702462679112 Time: 0.02044
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:40:12] [V] [TRT] Tactic: 5041593333398049019 Time: 0.008524
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:40:12] [V] [TRT] Tactic: 5166018662410176512 Time: 0.02084
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:40:12] [V] [TRT] Tactic: 6191867932654611882 Time: 0.012752
[12/29/2021-03:40:12] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:40:13] [V] [TRT] Tactic: 6556170942941957134 Time: 0.015068
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:40:13] [V] [TRT] Tactic: 6852868042694587230 Time: 0.008848
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:40:13] [V] [TRT] Tactic: 8399092794516815300 Time: 0.019156
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:40:13] [V] [TRT] Tactic: -9132922677633967263 Time: 0.010036
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:40:13] [V] [TRT] Tactic: -7988637803896331454 Time: 0.014308
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: -7865001268126363229
[12/29/2021-03:40:13] [V] [TRT] Tactic: -7865001268126363229 Time: 0.017036
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:40:13] [V] [TRT] Tactic: -7606074703023778034 Time: 0.01466
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:40:13] [V] [TRT] Tactic: -7413564913826321357 Time: 0.015248
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:40:13] [V] [TRT] Tactic: -7282232519526877434 Time: 0.020116
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:40:13] [V] [TRT] Tactic: -5942379529065248478 Time: 0.01042
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:40:13] [V] [TRT] Tactic: -5603587790314027122 Time: 0.016196
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:40:13] [V] [TRT] Tactic: -5334776871777565833 Time: 0.021312
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:40:13] [V] [TRT] Tactic: -5157868397078537095 Time: 0.013204
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:40:13] [V] [TRT] Tactic: -5100834417027499764 Time: 0.008228
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:40:13] [V] [TRT] Tactic: -3365360067423513506 Time: 0.0086
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2194148180068068313
[12/29/2021-03:40:13] [V] [TRT] Tactic: -2194148180068068313 Time: 0.020388
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:40:13] [V] [TRT] Tactic: -1782593837177056527 Time: 0.010848
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:40:13] [V] [TRT] Tactic: -1610768292520086910 Time: 0.015372
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:40:13] [V] [TRT] Tactic: -1573035963956198975 Time: 0.018796
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -1558762241666006941
[12/29/2021-03:40:13] [V] [TRT] Tactic: -1558762241666006941 Time: 0.015516
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -1365353082499976145
[12/29/2021-03:40:13] [V] [TRT] Tactic: -1365353082499976145 Time: 0.016704
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:40:13] [V] [TRT] Tactic: -621838502160440068 Time: 0.016584
[12/29/2021-03:40:13] [V] [TRT] Fastest Tactic: -5100834417027499764 Time: 0.008228
[12/29/2021-03:40:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -5100834417027499764
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CudaGroupConvolution)
[12/29/2021-03:40:13] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:13] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CudaDepthwiseConvolution)
[12/29/2021-03:40:13] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:13] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (FusedConvActConvolution)
[12/29/2021-03:40:13] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:13] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CaskConvolution)
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 177040020707947851
[12/29/2021-03:40:13] [V] [TRT] Tactic: 177040020707947851 Time: 0.00828
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 1550399266192842845
[12/29/2021-03:40:13] [V] [TRT] Tactic: 1550399266192842845 Time: 0.008648
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 1572887561103143487
[12/29/2021-03:40:13] [V] [TRT] Tactic: 1572887561103143487 Time: 0.009652
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:40:13] [V] [TRT] Tactic: 2325023763229477890 Time: 0.012768
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 2985940154541537814
[12/29/2021-03:40:13] [V] [TRT] Tactic: 2985940154541537814 Time: 0.015052
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:40:13] [V] [TRT] Tactic: 3284282970967328046 Time: 0.008184
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:40:13] [V] [TRT] Tactic: 3401614690060226673 Time: 0.00786
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3512426920013359699
[12/29/2021-03:40:13] [V] [TRT] Tactic: 3512426920013359699 Time: 0.008044
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 3899284354987683408
[12/29/2021-03:40:13] [V] [TRT] Tactic: 3899284354987683408 Time: 0.021248
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:40:13] [V] [TRT] Tactic: 4042202769383439184 Time: 0.009712
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: 4182625619810185112
[12/29/2021-03:40:13] [V] [TRT] Tactic: 4182625619810185112 Time: 0.016912
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 4259547356717612415
[12/29/2021-03:40:13] [V] [TRT] Tactic: 4259547356717612415 Time: 0.010196
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: 4717285412741024953
[12/29/2021-03:40:13] [V] [TRT] Tactic: 4717285412741024953 Time: 0.01526
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:40:13] [V] [TRT] Tactic: 4734519122557206480 Time: 0.01896
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 5121596860264626879
[12/29/2021-03:40:13] [V] [TRT] Tactic: 5121596860264626879 Time: 0.018952
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:40:13] [V] [TRT] Tactic: 5136656982162849059 Time: 0.00822
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 5158259316594207439
[12/29/2021-03:40:13] [V] [TRT] Tactic: 5158259316594207439 Time: 0.009844
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 5966973378912044513
[12/29/2021-03:40:13] [V] [TRT] Tactic: 5966973378912044513 Time: 0.012732
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:40:13] [V] [TRT] Tactic: 6004789655466615912 Time: 0.009772
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:40:13] [V] [TRT] Tactic: 6146901278630392829 Time: 0.018516
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 6434020722187266170
[12/29/2021-03:40:13] [V] [TRT] Tactic: 6434020722187266170 Time: 0.019212
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:40:13] [V] [TRT] Tactic: 6781129591847482048 Time: 0.009876
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7191893591576074000
[12/29/2021-03:40:13] [V] [TRT] Tactic: 7191893591576074000 Time: 0.008328
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7438984192263206338
[12/29/2021-03:40:13] [V] [TRT] Tactic: 7438984192263206338 Time: 0.00928
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 7504901284678552178
[12/29/2021-03:40:13] [V] [TRT] Tactic: 7504901284678552178 Time: 0.012476
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:40:13] [V] [TRT] Tactic: 8096257414008860171 Time: 0.009424
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 9143438935315839085
[12/29/2021-03:40:13] [V] [TRT] Tactic: 9143438935315839085 Time: 0.008032
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:40:13] [V] [TRT] Tactic: -9165697322068360861 Time: 0.019148
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -9118785798277698619
[12/29/2021-03:40:13] [V] [TRT] Tactic: -9118785798277698619 Time: 0.014464
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:40:13] [V] [TRT] Tactic: -8263994888336646547 Time: 0.01256
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:40:13] [V] [TRT] Tactic: -8205948405243401049 Time: 0.008584
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -7992068592656168418
[12/29/2021-03:40:13] [V] [TRT] Tactic: -7992068592656168418 Time: 0.009408
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: -7842775553137511386
[12/29/2021-03:40:13] [V] [TRT] Tactic: -7842775553137511386 Time: 0.012844
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:40:13] [V] [TRT] Tactic: -7683887278997527517 Time: 0.008464
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -6400348606759295499
[12/29/2021-03:40:13] [V] [TRT] Tactic: -6400348606759295499 Time: 0.0144
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -5980889159865208399
[12/29/2021-03:40:13] [V] [TRT] Tactic: -5980889159865208399 Time: 0.020532
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5766140806760372989
[12/29/2021-03:40:13] [V] [TRT] Tactic: -5766140806760372989 Time: 0.016096
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5709079507616090666
[12/29/2021-03:40:13] [V] [TRT] Tactic: -5709079507616090666 Time: 0.012336
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5698636014239116282
[12/29/2021-03:40:13] [V] [TRT] Tactic: -5698636014239116282 Time: 0.018532
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:40:13] [V] [TRT] Tactic: -4933563390723451692 Time: 0.008056
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -4516822589357530549
[12/29/2021-03:40:13] [V] [TRT] Tactic: -4516822589357530549 Time: 0.016164
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -3413217501222406256
[12/29/2021-03:40:13] [V] [TRT] Tactic: -3413217501222406256 Time: 0.018768
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:40:13] [V] [TRT] Tactic: -3238475748440751107 Time: 0.009304
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:40:13] [V] [TRT] Tactic: -3182884991006484042 Time: 0.012692
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:40:13] [V] [TRT] Tactic: -3173468756112541306 Time: 0.008404
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2917455979290586480
[12/29/2021-03:40:13] [V] [TRT] Tactic: -2917455979290586480 Time: 0.020924
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -2571022005763160364
[12/29/2021-03:40:13] [V] [TRT] Tactic: -2571022005763160364 Time: 0.015492
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -2083778562631872334
[12/29/2021-03:40:13] [V] [TRT] Tactic: -2083778562631872334 Time: 0.009896
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:40:13] [V] [TRT] Tactic: -1546787387293556842 Time: 0.012372
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:40:13] [V] [TRT] Tactic: -1498626619443284096 Time: 0.010292
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:40:13] [V] [TRT] Tactic: -1283580231568512025 Time: 0.0085
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: -1173968681844185579
[12/29/2021-03:40:13] [V] [TRT] Tactic: -1173968681844185579 Time: 0.008464
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:40:13] [V] [TRT] Tactic: -762222380308749469 Time: 0.008392
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -556794153877490941
[12/29/2021-03:40:13] [V] [TRT] Tactic: -556794153877490941 Time: 0.008288
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:40:13] [V] [TRT] Tactic: -516725800067794372 Time: 0.018612
[12/29/2021-03:40:13] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -428104331444385564
[12/29/2021-03:40:13] [V] [TRT] Tactic: -428104331444385564 Time: 0.016528
[12/29/2021-03:40:13] [V] [TRT] Fastest Tactic: 3401614690060226673 Time: 0.00786
[12/29/2021-03:40:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3401614690060226673
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:13] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:13] [V] [TRT] Tactic: 1002 Time: 0.008276
[12/29/2021-03:40:13] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:13] [V] [TRT] Tactic: 0 Time: 0.009212
[12/29/2021-03:40:13] [V] [TRT] Fastest Tactic: 1002 Time: 0.008276
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:13] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:13] [V] [TRT] Tactic: 1002 Time: 0.008452
[12/29/2021-03:40:13] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:13] [V] [TRT] Tactic: 0 Time: 0.009668
[12/29/2021-03:40:13] [V] [TRT] Fastest Tactic: 1002 Time: 0.008452
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:13] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:13] [V] [TRT] Tactic: 1002 Time: 0.007264
[12/29/2021-03:40:13] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:13] [V] [TRT] Tactic: 0 Time: 0.009792
[12/29/2021-03:40:13] [V] [TRT] Fastest Tactic: 1002 Time: 0.007264
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:13] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:13] [V] [TRT] Tactic: 1002 Time: 0.008252
[12/29/2021-03:40:13] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:13] [V] [TRT] Tactic: 0 Time: 0.00966
[12/29/2021-03:40:13] [V] [TRT] Fastest Tactic: 1002 Time: 0.008252
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:13] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:13] [V] [TRT] Tactic: 1002 Time: 0.007924
[12/29/2021-03:40:13] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:13] [V] [TRT] Tactic: 0 Time: 0.009664
[12/29/2021-03:40:13] [V] [TRT] Fastest Tactic: 1002 Time: 0.007924
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning format combination: Float(4096,64,8,1), Float(4096,64,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:13] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CudaDepthwiseConvolution)
[12/29/2021-03:40:13] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:13] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (FusedConvActConvolution)
[12/29/2021-03:40:13] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:13] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CudnnConvolution)
[12/29/2021-03:40:13] [V] [TRT] Tactic: 0 Time: 0.038996
[12/29/2021-03:40:13] [V] [TRT] Tactic: 1 Time: 0.062744
[12/29/2021-03:40:13] [V] [TRT] Tactic: 2 Time: 0.078496
[12/29/2021-03:40:13] [V] [TRT] Tactic: 4 Time: 0.051268
[12/29/2021-03:40:13] [V] [TRT] Tactic: 5 skipped. Scratch requested: 35651584, available: 16777216
[12/29/2021-03:40:13] [V] [TRT] Tactic: 6 Time: 0.03012
[12/29/2021-03:40:13] [V] [TRT] Tactic: 56 Time: 0.038992
[12/29/2021-03:40:13] [V] [TRT] Tactic: 57 Time: 0.060184
[12/29/2021-03:40:13] [V] [TRT] Tactic: 58 Time: 0.078356
[12/29/2021-03:40:13] [V] [TRT] Tactic: 60 Time: 0.051148
[12/29/2021-03:40:13] [V] [TRT] Tactic: 61 skipped. Scratch requested: 35651584, available: 16777216
[12/29/2021-03:40:13] [V] [TRT] Tactic: 62 Time: 0.030112
[12/29/2021-03:40:13] [V] [TRT] Tactic: 112 Time: 0.038828
[12/29/2021-03:40:13] [V] [TRT] Tactic: 113 Time: 0.287556
[12/29/2021-03:40:13] [V] [TRT] Tactic: 114 Time: 0.07858
[12/29/2021-03:40:13] [V] [TRT] Tactic: 116 Time: 0.051072
[12/29/2021-03:40:13] [V] [TRT] Tactic: 117 skipped. Scratch requested: 35651584, available: 16777216
[12/29/2021-03:40:13] [V] [TRT] Tactic: 118 Time: 0.030112
[12/29/2021-03:40:13] [V] [TRT] Fastest Tactic: 62 Time: 0.030112
[12/29/2021-03:40:13] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CaskConvolution)
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:40:13] [V] [TRT] Tactic: 4549827808004681195 Time: 0.063948
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:40:13] [V] [TRT] Tactic: 5779835512569528575 Time: 0.080832
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[12/29/2021-03:40:13] [V] [TRT] Tactic: 6053873026024413720 Time: 0.090488
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[12/29/2021-03:40:13] [V] [TRT] Tactic: 6767548733843469815 Time: 0.06966
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:40:13] [V] [TRT] Tactic: -6313876406580483184 Time: 0.07646
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:40:13] [V] [TRT] Tactic: -1123676555321336786 Time: 0.088896
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:40:13] [V] [TRT] Tactic: -701551393537224327 Time: 0.077888
[12/29/2021-03:40:13] [V] [TRT] Fastest Tactic: 4549827808004681195 Time: 0.063948
[12/29/2021-03:40:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 62
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning format combination: Float(4096,1,512,64), Float(4096,1,512,64) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:13] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CudnnConvolution)
[12/29/2021-03:40:13] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:13] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CaskConvolution)
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:13] [V] [TRT] Tactic: 2860655430572478466 Time: 0.049936
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:13] [V] [TRT] Tactic: 4474630279712975759 Time: 0.031296
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:13] [V] [TRT] Tactic: 4479823862704990365 Time: 0.030656
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:13] [V] [TRT] Tactic: 4696204239951173149 Time: 0.050664
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:13] [V] [TRT] Tactic: 5778138195697110003 Time: 0.079596
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:40:13] [V] [TRT] Tactic: 7155825427510256858 Time: 0.07978
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:13] [V] [TRT] Tactic: 8918020581761223752 Time: 0.078268
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:40:13] [V] [TRT] Tactic: -4756382386362004279 Time: 0.04994
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:40:13] [V] [TRT] Tactic: -3855385237722507464 Time: 0.081012
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:13] [V] [TRT] Tactic: -2809379259463049391 Time: 0.079612
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:13] [V] [TRT] Tactic: -504296718212024303 Time: 0.077264
[12/29/2021-03:40:13] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.030656
[12/29/2021-03:40:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:40:13] [V] [TRT] *************** Autotuning format combination: Float(1024,1:4,128,16), Float(1024,1:4,128,16) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:13] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CudnnConvolution)
[12/29/2021-03:40:13] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:13] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CaskConvolution)
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:13] [V] [TRT] Tactic: 2860655430572478466 Time: 0.04982
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:13] [V] [TRT] Tactic: 4474630279712975759 Time: 0.03134
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:13] [V] [TRT] Tactic: 4479823862704990365 Time: 0.030648
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:13] [V] [TRT] Tactic: 4696204239951173149 Time: 0.05062
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:13] [V] [TRT] Tactic: 5778138195697110003 Time: 0.07946
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:40:13] [V] [TRT] Tactic: 7155825427510256858 Time: 0.079848
[12/29/2021-03:40:13] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:40:14] [V] [TRT] Tactic: 7342025736444949634 Time: 0.055756
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:14] [V] [TRT] Tactic: 8918020581761223752 Time: 0.078444
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:40:14] [V] [TRT] Tactic: -7377458734869418330 Time: 0.05496
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:40:14] [V] [TRT] Tactic: -5457304872213719461 Time: 0.05562
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:40:14] [V] [TRT] Tactic: -4756382386362004279 Time: 0.050012
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:40:14] [V] [TRT] Tactic: -3855385237722507464 Time: 0.080912
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:14] [V] [TRT] Tactic: -2809379259463049391 Time: 0.079652
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:14] [V] [TRT] Tactic: -504296718212024303 Time: 0.077312
[12/29/2021-03:40:14] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.030648
[12/29/2021-03:40:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:40:14] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1), Float(4096,64,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:14] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CudaDepthwiseConvolution)
[12/29/2021-03:40:14] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:14] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CaskConvolution)
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 1332468635798226953
[12/29/2021-03:40:14] [V] [TRT] Tactic: 1332468635798226953 Time: 0.03588
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:40:14] [V] [TRT] Tactic: 1508480131241957639 Time: 0.034172
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 1947019689364377201
[12/29/2021-03:40:14] [V] [TRT] Tactic: 1947019689364377201 Time: 0.026124
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:40:14] [V] [TRT] Tactic: 3239257003214966313 Time: 0.035716
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:40:14] [V] [TRT] Tactic: 5592640619112287921 Time: 0.023356
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:40:14] [V] [TRT] Tactic: 7621465827583909090 Time: 0.02442
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:40:14] [V] [TRT] Tactic: -5576936487443445631 Time: 0.02806
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:40:14] [V] [TRT] Tactic: -2297737319934264721 Time: 0.03184
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:40:14] [V] [TRT] Tactic: -1425085658556684465 Time: 0.029844
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:40:14] [V] [TRT] Tactic: -108011214168778087 Time: 0.027
[12/29/2021-03:40:14] [V] [TRT] Fastest Tactic: 5592640619112287921 Time: 0.023356
[12/29/2021-03:40:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5592640619112287921
[12/29/2021-03:40:14] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1), Int8(1024,64:4,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:14] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CudaDepthwiseConvolution)
[12/29/2021-03:40:14] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:14] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (FusedConvActConvolution)
[12/29/2021-03:40:14] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:14] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CaskConvolution)
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:40:14] [V] [TRT] Tactic: 175853789719975416 Time: 0.029952
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:40:14] [V] [TRT] Tactic: 2171150287007712632 Time: 0.02866
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:40:14] [V] [TRT] Tactic: 2234457234705232274 Time: 0.022516
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:40:14] [V] [TRT] Tactic: 5834048089706882838 Time: 0.026148
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:40:14] [V] [TRT] Tactic: -8626990807754934295 Time: 0.025276
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:40:14] [V] [TRT] Tactic: -7303593854972602201 Time: 0.021748
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:40:14] [V] [TRT] Tactic: -6585664687867083638 Time: 0.03366
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: -3730012925709297561
[12/29/2021-03:40:14] [V] [TRT] Tactic: -3730012925709297561 Time: 0.024192
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: -2277259417488004546
[12/29/2021-03:40:14] [V] [TRT] Tactic: -2277259417488004546 Time: 0.034
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:40:14] [V] [TRT] Tactic: -683636008127039856 Time: 0.032128
[12/29/2021-03:40:14] [V] [TRT] Fastest Tactic: -7303593854972602201 Time: 0.021748
[12/29/2021-03:40:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7303593854972602201
[12/29/2021-03:40:14] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1), Int8(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:14] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CaskConvolution)
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 984309058095623735
[12/29/2021-03:40:14] [V] [TRT] Tactic: 984309058095623735 Time: 0.024608
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:40:14] [V] [TRT] Tactic: 1100922622480907544 Time: 0.025284
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 3238312825609165543
[12/29/2021-03:40:14] [V] [TRT] Tactic: 3238312825609165543 Time: 0.033764
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:40:14] [V] [TRT] Tactic: 3606311198834416176 Time: 0.0262
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:40:14] [V] [TRT] Tactic: 4325765560739862899 Time: 0.031984
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:40:14] [V] [TRT] Tactic: -4255737803793506479 Time: 0.033584
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:40:14] [V] [TRT] Tactic: -3958182351168863467 Time: 0.021728
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:40:14] [V] [TRT] Tactic: -3111968753064955248 Time: 0.028268
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:40:14] [V] [TRT] Tactic: -1492575840277333548 Time: 0.029936
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:40:14] [V] [TRT] Tactic: -868495160148524802 Time: 0.022536
[12/29/2021-03:40:14] [V] [TRT] Fastest Tactic: -3958182351168863467 Time: 0.021728
[12/29/2021-03:40:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3958182351168863467
[12/29/2021-03:40:14] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1), Float(128,64:32,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:14] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CaskConvolution)
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:40:14] [V] [TRT] Tactic: 1011019097971850911 Time: 0.015784
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:40:14] [V] [TRT] Tactic: 1071114551801767124 Time: 0.010288
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:40:14] [V] [TRT] Tactic: 2623576043214044314 Time: 0.009052
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:40:14] [V] [TRT] Tactic: 3281631721811475881 Time: 0.00914
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:40:14] [V] [TRT] Tactic: 4551754795416974366 Time: 0.009132
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:40:14] [V] [TRT] Tactic: 4925112190271421402 Time: 0.008924
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:40:14] [V] [TRT] Tactic: 5012796702462679112 Time: 0.021836
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:40:14] [V] [TRT] Tactic: 5041593333398049019 Time: 0.008748
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:40:14] [V] [TRT] Tactic: 5166018662410176512 Time: 0.021572
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:40:14] [V] [TRT] Tactic: 6191867932654611882 Time: 0.014256
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:40:14] [V] [TRT] Tactic: 6556170942941957134 Time: 0.016008
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:40:14] [V] [TRT] Tactic: 6852868042694587230 Time: 0.009324
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:40:14] [V] [TRT] Tactic: 8399092794516815300 Time: 0.020912
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:40:14] [V] [TRT] Tactic: -9132922677633967263 Time: 0.010832
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:40:14] [V] [TRT] Tactic: -7988637803896331454 Time: 0.01512
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: -7865001268126363229
[12/29/2021-03:40:14] [V] [TRT] Tactic: -7865001268126363229 Time: 0.018408
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:40:14] [V] [TRT] Tactic: -7606074703023778034 Time: 0.016024
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:40:14] [V] [TRT] Tactic: -7413564913826321357 Time: 0.016068
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:40:14] [V] [TRT] Tactic: -7282232519526877434 Time: 0.021476
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:40:14] [V] [TRT] Tactic: -5942379529065248478 Time: 0.01118
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:40:14] [V] [TRT] Tactic: -5603587790314027122 Time: 0.017788
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:40:14] [V] [TRT] Tactic: -5334776871777565833 Time: 0.021972
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:40:14] [V] [TRT] Tactic: -5157868397078537095 Time: 0.014496
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:40:14] [V] [TRT] Tactic: -5100834417027499764 Time: 0.008684
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:40:14] [V] [TRT] Tactic: -3365360067423513506 Time: 0.008484
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2194148180068068313
[12/29/2021-03:40:14] [V] [TRT] Tactic: -2194148180068068313 Time: 0.021808
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:40:14] [V] [TRT] Tactic: -1782593837177056527 Time: 0.01156
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:40:14] [V] [TRT] Tactic: -1610768292520086910 Time: 0.016772
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:40:14] [V] [TRT] Tactic: -1573035963956198975 Time: 0.020352
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -1558762241666006941
[12/29/2021-03:40:14] [V] [TRT] Tactic: -1558762241666006941 Time: 0.016504
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -1365353082499976145
[12/29/2021-03:40:14] [V] [TRT] Tactic: -1365353082499976145 Time: 0.0181
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:40:14] [V] [TRT] Tactic: -621838502160440068 Time: 0.017996
[12/29/2021-03:40:14] [V] [TRT] Fastest Tactic: -3365360067423513506 Time: 0.008484
[12/29/2021-03:40:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3365360067423513506
[12/29/2021-03:40:14] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1), Int8(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:14] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CudaGroupConvolution)
[12/29/2021-03:40:14] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:14] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CudaDepthwiseConvolution)
[12/29/2021-03:40:14] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:14] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (FusedConvActConvolution)
[12/29/2021-03:40:14] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:14] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CaskConvolution)
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:40:14] [V] [TRT] Tactic: 2325023763229477890 Time: 0.013856
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 2985940154541537814
[12/29/2021-03:40:14] [V] [TRT] Tactic: 2985940154541537814 Time: 0.01626
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:40:14] [V] [TRT] Tactic: 3401614690060226673 Time: 0.008436
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 3899284354987683408
[12/29/2021-03:40:14] [V] [TRT] Tactic: 3899284354987683408 Time: 0.022756
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:40:14] [V] [TRT] Tactic: 4042202769383439184 Time: 0.010092
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: 4182625619810185112
[12/29/2021-03:40:14] [V] [TRT] Tactic: 4182625619810185112 Time: 0.018088
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: 4717285412741024953
[12/29/2021-03:40:14] [V] [TRT] Tactic: 4717285412741024953 Time: 0.016252
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:40:14] [V] [TRT] Tactic: 4734519122557206480 Time: 0.019732
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:40:14] [V] [TRT] Tactic: 5136656982162849059 Time: 0.008448
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:40:14] [V] [TRT] Tactic: 6004789655466615912 Time: 0.010464
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:40:14] [V] [TRT] Tactic: 6146901278630392829 Time: 0.01934
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:40:14] [V] [TRT] Tactic: 6781129591847482048 Time: 0.01064
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:40:14] [V] [TRT] Tactic: 8096257414008860171 Time: 0.010252
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:40:14] [V] [TRT] Tactic: -9165697322068360861 Time: 0.02028
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -9118785798277698619
[12/29/2021-03:40:14] [V] [TRT] Tactic: -9118785798277698619 Time: 0.015484
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:40:14] [V] [TRT] Tactic: -8263994888336646547 Time: 0.013292
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:40:14] [V] [TRT] Tactic: -8205948405243401049 Time: 0.00894
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:40:14] [V] [TRT] Tactic: -7683887278997527517 Time: 0.008904
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -6400348606759295499
[12/29/2021-03:40:14] [V] [TRT] Tactic: -6400348606759295499 Time: 0.015412
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -5980889159865208399
[12/29/2021-03:40:14] [V] [TRT] Tactic: -5980889159865208399 Time: 0.022424
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5766140806760372989
[12/29/2021-03:40:14] [V] [TRT] Tactic: -5766140806760372989 Time: 0.017184
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:40:14] [V] [TRT] Tactic: -4933563390723451692 Time: 0.008772
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -4516822589357530549
[12/29/2021-03:40:14] [V] [TRT] Tactic: -4516822589357530549 Time: 0.017436
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:40:14] [V] [TRT] Tactic: -3238475748440751107 Time: 0.009952
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:40:14] [V] [TRT] Tactic: -3182884991006484042 Time: 0.013736
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:40:14] [V] [TRT] Tactic: -3173468756112541306 Time: 0.008476
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2917455979290586480
[12/29/2021-03:40:14] [V] [TRT] Tactic: -2917455979290586480 Time: 0.02284
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -2571022005763160364
[12/29/2021-03:40:14] [V] [TRT] Tactic: -2571022005763160364 Time: 0.016692
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:40:14] [V] [TRT] Tactic: -1546787387293556842 Time: 0.013128
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:40:14] [V] [TRT] Tactic: -1498626619443284096 Time: 0.011144
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:40:14] [V] [TRT] Tactic: -1283580231568512025 Time: 0.008736
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:40:14] [V] [TRT] Tactic: -762222380308749469 Time: 0.008904
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:40:14] [V] [TRT] Tactic: -516725800067794372 Time: 0.01968
[12/29/2021-03:40:14] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -428104331444385564
[12/29/2021-03:40:14] [V] [TRT] Tactic: -428104331444385564 Time: 0.017488
[12/29/2021-03:40:14] [V] [TRT] Fastest Tactic: 3401614690060226673 Time: 0.008436
[12/29/2021-03:40:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3401614690060226673
[12/29/2021-03:40:14] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:14] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:14] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:14] [V] [TRT] Tactic: 1002 Time: 0.00818
[12/29/2021-03:40:14] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:14] [V] [TRT] Tactic: 0 Time: 0.006204
[12/29/2021-03:40:14] [V] [TRT] Fastest Tactic: 0 Time: 0.006204
[12/29/2021-03:40:14] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:14] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:14] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:14] [V] [TRT] Tactic: 1002 Time: 0.008168
[12/29/2021-03:40:14] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:14] [V] [TRT] Tactic: 0 Time: 0.006024
[12/29/2021-03:40:14] [V] [TRT] Fastest Tactic: 0 Time: 0.006024
[12/29/2021-03:40:14] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:14] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:14] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:14] [V] [TRT] Tactic: 1002 Time: 0.008236
[12/29/2021-03:40:14] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:14] [V] [TRT] Tactic: 0 Time: 0.009224
[12/29/2021-03:40:14] [V] [TRT] Fastest Tactic: 1002 Time: 0.008236
[12/29/2021-03:40:14] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:14] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:14] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:14] [V] [TRT] Tactic: 1002 Time: 0.00718
[12/29/2021-03:40:14] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:14] [V] [TRT] Tactic: 0 Time: 0.004752
[12/29/2021-03:40:14] [V] [TRT] Fastest Tactic: 0 Time: 0.004752
[12/29/2021-03:40:14] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:14] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:14] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:14] [V] [TRT] Tactic: 1002 Time: 0.007204
[12/29/2021-03:40:14] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:14] [V] [TRT] Tactic: 0 Time: 0.007308
[12/29/2021-03:40:14] [V] [TRT] Fastest Tactic: 1002 Time: 0.007204
[12/29/2021-03:40:14] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:14] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:14] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:14] [V] [TRT] Tactic: 1002 Time: 0.00852
[12/29/2021-03:40:14] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:14] [V] [TRT] Tactic: 0 Time: 0.006032
[12/29/2021-03:40:14] [V] [TRT] Fastest Tactic: 0 Time: 0.006032
[12/29/2021-03:40:14] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:14] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:14] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:14] [V] [TRT] Tactic: 1002 Time: 0.007272
[12/29/2021-03:40:14] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:14] [V] [TRT] Tactic: 0 Time: 0.00562
[12/29/2021-03:40:14] [V] [TRT] Fastest Tactic: 0 Time: 0.00562
[12/29/2021-03:40:14] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:14] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:14] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:14] [V] [TRT] Tactic: 1002 Time: 0.008168
[12/29/2021-03:40:14] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:14] [V] [TRT] Tactic: 0 Time: 0.009684
[12/29/2021-03:40:14] [V] [TRT] Fastest Tactic: 1002 Time: 0.008168
[12/29/2021-03:40:14] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:14] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:14] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:14] [V] [TRT] Tactic: 1002 Time: 0.007336
[12/29/2021-03:40:14] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:14] [V] [TRT] Tactic: 0 Time: 0.006264
[12/29/2021-03:40:14] [V] [TRT] Fastest Tactic: 0 Time: 0.006264
[12/29/2021-03:40:14] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:14] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:14] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1002 Time: 0.00766
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 0 Time: 0.008016
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: 1002 Time: 0.00766
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1002 Time: 0.008584
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 0 Time: 0.006076
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: 0 Time: 0.006076
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1002 Time: 0.007264
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 0 Time: 0.005776
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: 0 Time: 0.005776
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1002 Time: 0.007216
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 0 Time: 0.00982
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: 1002 Time: 0.007216
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1002 Time: 0.008476
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 0 Time: 0.006324
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: 0 Time: 0.006324
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1002 Time: 0.008388
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 0 Time: 0.008132
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: 0 Time: 0.008132
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1002 Time: 0.0085
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 0 Time: 0.006024
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: 0 Time: 0.006024
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1002 Time: 0.008252
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 0 Time: 0.00566
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: 0 Time: 0.00566
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1002 Time: 0.007176
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 0 Time: 0.0061
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: 0 Time: 0.0061
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1002 Time: 0.007756
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 0 Time: 0.006352
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: 0 Time: 0.006352
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1002 Time: 0.007732
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 0 Time: 0.00808
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: 1002 Time: 0.007732
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1002 Time: 0.007816
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 0 Time: 0.005016
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: 0 Time: 0.005016
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1002 Time: 0.007908
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 0 Time: 0.006156
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: 0 Time: 0.006156
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1002 Time: 0.008616
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 0 Time: 0.006612
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: 0 Time: 0.006612
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1002 Time: 0.008328
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 0 Time: 0.00962
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: 1002 Time: 0.008328
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1002 Time: 0.007192
[12/29/2021-03:40:15] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:15] [V] [TRT] Tactic: 0 Time: 0.005212
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: 0 Time: 0.005212
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Float(4096,64,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Float(4096,1,512,64) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Float(1024,1:4,128,16) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Float(4096,64,8,1), Float(4096,64,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Float(4096,1,512,64), Float(4096,1,512,64) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Float(1024,1:4,128,16), Float(1024,1:4,128,16) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1), Float(4096,64,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1), Int8(1024,64:4,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1), Int8(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1), Float(128,64:32,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1), Int8(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Float(4096,64,8,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CudaDepthwiseConvolution)
[12/29/2021-03:40:15] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (FusedConvActConvolution)
[12/29/2021-03:40:15] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CudnnConvolution)
[12/29/2021-03:40:15] [V] [TRT] Tactic: 0 Time: 0.033644
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1 Time: 0.032416
[12/29/2021-03:40:15] [V] [TRT] Tactic: 2 Time: 0.066828
[12/29/2021-03:40:15] [V] [TRT] Tactic: 5 skipped. Scratch requested: 62390272, available: 16777216
[12/29/2021-03:40:15] [V] [TRT] Tactic: 56 Time: 0.033696
[12/29/2021-03:40:15] [V] [TRT] Tactic: 57 Time: 0.0648
[12/29/2021-03:40:15] [V] [TRT] Tactic: 58 Time: 0.066648
[12/29/2021-03:40:15] [V] [TRT] Tactic: 61 skipped. Scratch requested: 62390272, available: 16777216
[12/29/2021-03:40:15] [V] [TRT] Tactic: 112 Time: 0.033636
[12/29/2021-03:40:15] [V] [TRT] Tactic: 113 Time: 0.145576
[12/29/2021-03:40:15] [V] [TRT] Tactic: 114 Time: 0.06684
[12/29/2021-03:40:15] [V] [TRT] Tactic: 117 skipped. Scratch requested: 62390272, available: 16777216
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: 1 Time: 0.032416
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CaskConvolution)
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:40:15] [V] [TRT] Tactic: 4549827808004681195 Time: 0.062992
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:40:15] [V] [TRT] Tactic: 5779835512569528575 Time: 0.080268
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[12/29/2021-03:40:15] [V] [TRT] Tactic: 6053873026024413720 Time: 0.084388
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[12/29/2021-03:40:15] [V] [TRT] Tactic: 6767548733843469815 Time: 0.065748
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:40:15] [V] [TRT] Tactic: -6313876406580483184 Time: 0.078212
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:40:15] [V] [TRT] Tactic: -1123676555321336786 Time: 0.08336
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:40:15] [V] [TRT] Tactic: -701551393537224327 Time: 0.071748
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: 4549827808004681195 Time: 0.062992
[12/29/2021-03:40:15] [V] [TRT] Setting workspace to 62390272enables more tactics for profiling
[12/29/2021-03:40:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Float(4096,1,512,64) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CudnnConvolution)
[12/29/2021-03:40:15] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CaskConvolution)
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:15] [V] [TRT] Tactic: 2860655430572478466 Time: 0.048944
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:15] [V] [TRT] Tactic: 4474630279712975759 Time: 0.030112
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:15] [V] [TRT] Tactic: 4479823862704990365 Time: 0.029556
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:15] [V] [TRT] Tactic: 4696204239951173149 Time: 0.05008
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:15] [V] [TRT] Tactic: 5778138195697110003 Time: 0.082384
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:40:15] [V] [TRT] Tactic: 7155825427510256858 Time: 0.078564
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:15] [V] [TRT] Tactic: 8918020581761223752 Time: 0.076744
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:40:15] [V] [TRT] Tactic: -4756382386362004279 Time: 0.048948
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:40:15] [V] [TRT] Tactic: -3855385237722507464 Time: 0.082772
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:15] [V] [TRT] Tactic: -2809379259463049391 Time: 0.081292
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:15] [V] [TRT] Tactic: -504296718212024303 Time: 0.076432
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.029556
[12/29/2021-03:40:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Float(1024,1:4,128,16) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CudnnConvolution)
[12/29/2021-03:40:15] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CaskConvolution)
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:15] [V] [TRT] Tactic: 2860655430572478466 Time: 0.04898
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:15] [V] [TRT] Tactic: 4474630279712975759 Time: 0.030012
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:15] [V] [TRT] Tactic: 4479823862704990365 Time: 0.029436
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:15] [V] [TRT] Tactic: 4696204239951173149 Time: 0.049956
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:15] [V] [TRT] Tactic: 5778138195697110003 Time: 0.082312
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:40:15] [V] [TRT] Tactic: 7155825427510256858 Time: 0.0784
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:40:15] [V] [TRT] Tactic: 7342025736444949634 Time: 0.054544
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:15] [V] [TRT] Tactic: 8918020581761223752 Time: 0.077084
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:40:15] [V] [TRT] Tactic: -7377458734869418330 Time: 0.053896
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:40:15] [V] [TRT] Tactic: -5457304872213719461 Time: 0.054548
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:40:15] [V] [TRT] Tactic: -4756382386362004279 Time: 0.049048
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:40:15] [V] [TRT] Tactic: -3855385237722507464 Time: 0.08276
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:15] [V] [TRT] Tactic: -2809379259463049391 Time: 0.081396
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:15] [V] [TRT] Tactic: -504296718212024303 Time: 0.076596
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.029436
[12/29/2021-03:40:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CudaDepthwiseConvolution)
[12/29/2021-03:40:15] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CaskConvolution)
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 1332468635798226953
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1332468635798226953 Time: 0.034376
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1508480131241957639 Time: 0.033144
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 1947019689364377201
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1947019689364377201 Time: 0.02428
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:40:15] [V] [TRT] Tactic: 3239257003214966313 Time: 0.034044
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:40:15] [V] [TRT] Tactic: 5592640619112287921 Time: 0.02234
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:40:15] [V] [TRT] Tactic: 7621465827583909090 Time: 0.023376
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:40:15] [V] [TRT] Tactic: -5576936487443445631 Time: 0.025808
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:40:15] [V] [TRT] Tactic: -2297737319934264721 Time: 0.029664
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:40:15] [V] [TRT] Tactic: -1425085658556684465 Time: 0.026928
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:40:15] [V] [TRT] Tactic: -108011214168778087 Time: 0.026724
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: 5592640619112287921 Time: 0.02234
[12/29/2021-03:40:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5592640619112287921
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CudaDepthwiseConvolution)
[12/29/2021-03:40:15] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (FusedConvActConvolution)
[12/29/2021-03:40:15] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CaskConvolution)
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:40:15] [V] [TRT] Tactic: 175853789719975416 Time: 0.0276
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:40:15] [V] [TRT] Tactic: 2171150287007712632 Time: 0.024348
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:40:15] [V] [TRT] Tactic: 2234457234705232274 Time: 0.020916
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:40:15] [V] [TRT] Tactic: 5834048089706882838 Time: 0.023324
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:40:15] [V] [TRT] Tactic: -8626990807754934295 Time: 0.024504
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:40:15] [V] [TRT] Tactic: -7303593854972602201 Time: 0.020168
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:40:15] [V] [TRT] Tactic: -6585664687867083638 Time: 0.03118
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: -3730012925709297561
[12/29/2021-03:40:15] [V] [TRT] Tactic: -3730012925709297561 Time: 0.021876
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: -2277259417488004546
[12/29/2021-03:40:15] [V] [TRT] Tactic: -2277259417488004546 Time: 0.031692
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:40:15] [V] [TRT] Tactic: -683636008127039856 Time: 0.0304
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: -7303593854972602201 Time: 0.020168
[12/29/2021-03:40:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7303593854972602201
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CaskConvolution)
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 984309058095623735
[12/29/2021-03:40:15] [V] [TRT] Tactic: 984309058095623735 Time: 0.021712
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1100922622480907544 Time: 0.024132
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 3238312825609165543
[12/29/2021-03:40:15] [V] [TRT] Tactic: 3238312825609165543 Time: 0.03158
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:40:15] [V] [TRT] Tactic: 3606311198834416176 Time: 0.023132
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:40:15] [V] [TRT] Tactic: 4325765560739862899 Time: 0.030348
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:40:15] [V] [TRT] Tactic: -4255737803793506479 Time: 0.031128
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:40:15] [V] [TRT] Tactic: -3958182351168863467 Time: 0.020024
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:40:15] [V] [TRT] Tactic: -3111968753064955248 Time: 0.024132
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:40:15] [V] [TRT] Tactic: -1492575840277333548 Time: 0.0273
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:40:15] [V] [TRT] Tactic: -868495160148524802 Time: 0.020812
[12/29/2021-03:40:15] [V] [TRT] Fastest Tactic: -3958182351168863467 Time: 0.020024
[12/29/2021-03:40:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3958182351168863467
[12/29/2021-03:40:15] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:15] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CaskConvolution)
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1011019097971850911 Time: 0.01506
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:40:15] [V] [TRT] Tactic: 1071114551801767124 Time: 0.01034
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:40:15] [V] [TRT] Tactic: 2623576043214044314 Time: 0.00792
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:40:15] [V] [TRT] Tactic: 3281631721811475881 Time: 0.00846
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:40:15] [V] [TRT] Tactic: 4551754795416974366 Time: 0.008396
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:40:15] [V] [TRT] Tactic: 4925112190271421402 Time: 0.007796
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:40:15] [V] [TRT] Tactic: 5012796702462679112 Time: 0.021844
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:40:15] [V] [TRT] Tactic: 5041593333398049019 Time: 0.007488
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:40:15] [V] [TRT] Tactic: 5166018662410176512 Time: 0.024068
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:40:15] [V] [TRT] Tactic: 6191867932654611882 Time: 0.014684
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:40:15] [V] [TRT] Tactic: 6556170942941957134 Time: 0.015184
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:40:15] [V] [TRT] Tactic: 6852868042694587230 Time: 0.008856
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:40:15] [V] [TRT] Tactic: 8399092794516815300 Time: 0.021264
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:40:15] [V] [TRT] Tactic: -9132922677633967263 Time: 0.011004
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:40:15] [V] [TRT] Tactic: -7988637803896331454 Time: 0.01444
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: -7865001268126363229
[12/29/2021-03:40:15] [V] [TRT] Tactic: -7865001268126363229 Time: 0.017032
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:40:15] [V] [TRT] Tactic: -7606074703023778034 Time: 0.014704
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:40:15] [V] [TRT] Tactic: -7413564913826321357 Time: 0.015388
[12/29/2021-03:40:15] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:40:16] [V] [TRT] Tactic: -7282232519526877434 Time: 0.021488
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:40:16] [V] [TRT] Tactic: -5942379529065248478 Time: 0.010544
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:40:16] [V] [TRT] Tactic: -5603587790314027122 Time: 0.016032
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:40:16] [V] [TRT] Tactic: -5334776871777565833 Time: 0.024652
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:40:16] [V] [TRT] Tactic: -5157868397078537095 Time: 0.015008
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:40:16] [V] [TRT] Tactic: -5100834417027499764 Time: 0.007932
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:40:16] [V] [TRT] Tactic: -3365360067423513506 Time: 0.0072
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2194148180068068313
[12/29/2021-03:40:16] [V] [TRT] Tactic: -2194148180068068313 Time: 0.022012
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:40:16] [V] [TRT] Tactic: -1782593837177056527 Time: 0.010804
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:40:16] [V] [TRT] Tactic: -1610768292520086910 Time: 0.015564
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:40:16] [V] [TRT] Tactic: -1573035963956198975 Time: 0.020796
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -1558762241666006941
[12/29/2021-03:40:16] [V] [TRT] Tactic: -1558762241666006941 Time: 0.016096
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -1365353082499976145
[12/29/2021-03:40:16] [V] [TRT] Tactic: -1365353082499976145 Time: 0.016508
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:40:16] [V] [TRT] Tactic: -621838502160440068 Time: 0.016668
[12/29/2021-03:40:16] [V] [TRT] Fastest Tactic: -3365360067423513506 Time: 0.0072
[12/29/2021-03:40:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3365360067423513506
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:16] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CudaGroupConvolution)
[12/29/2021-03:40:16] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:16] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CudaDepthwiseConvolution)
[12/29/2021-03:40:16] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:16] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (FusedConvActConvolution)
[12/29/2021-03:40:16] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:16] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CaskConvolution)
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 177040020707947851
[12/29/2021-03:40:16] [V] [TRT] Tactic: 177040020707947851 Time: 0.00818
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 1550399266192842845
[12/29/2021-03:40:16] [V] [TRT] Tactic: 1550399266192842845 Time: 0.007864
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 1572887561103143487
[12/29/2021-03:40:16] [V] [TRT] Tactic: 1572887561103143487 Time: 0.009852
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:40:16] [V] [TRT] Tactic: 2325023763229477890 Time: 0.013128
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 2985940154541537814
[12/29/2021-03:40:16] [V] [TRT] Tactic: 2985940154541537814 Time: 0.015096
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:40:16] [V] [TRT] Tactic: 3284282970967328046 Time: 0.00714
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:40:16] [V] [TRT] Tactic: 3401614690060226673 Time: 0.007936
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3512426920013359699
[12/29/2021-03:40:16] [V] [TRT] Tactic: 3512426920013359699 Time: 0.008108
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 3899284354987683408
[12/29/2021-03:40:16] [V] [TRT] Tactic: 3899284354987683408 Time: 0.02096
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:40:16] [V] [TRT] Tactic: 4042202769383439184 Time: 0.009628
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: 4182625619810185112
[12/29/2021-03:40:16] [V] [TRT] Tactic: 4182625619810185112 Time: 0.016812
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 4259547356717612415
[12/29/2021-03:40:16] [V] [TRT] Tactic: 4259547356717612415 Time: 0.010248
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: 4717285412741024953
[12/29/2021-03:40:16] [V] [TRT] Tactic: 4717285412741024953 Time: 0.015288
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:40:16] [V] [TRT] Tactic: 4734519122557206480 Time: 0.019044
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 5121596860264626879
[12/29/2021-03:40:16] [V] [TRT] Tactic: 5121596860264626879 Time: 0.019124
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:40:16] [V] [TRT] Tactic: 5136656982162849059 Time: 0.007128
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 5158259316594207439
[12/29/2021-03:40:16] [V] [TRT] Tactic: 5158259316594207439 Time: 0.009612
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 5966973378912044513
[12/29/2021-03:40:16] [V] [TRT] Tactic: 5966973378912044513 Time: 0.012696
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:40:16] [V] [TRT] Tactic: 6004789655466615912 Time: 0.009796
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:40:16] [V] [TRT] Tactic: 6146901278630392829 Time: 0.018632
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 6434020722187266170
[12/29/2021-03:40:16] [V] [TRT] Tactic: 6434020722187266170 Time: 0.019392
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:40:16] [V] [TRT] Tactic: 6781129591847482048 Time: 0.009784
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7191893591576074000
[12/29/2021-03:40:16] [V] [TRT] Tactic: 7191893591576074000 Time: 0.007516
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7438984192263206338
[12/29/2021-03:40:16] [V] [TRT] Tactic: 7438984192263206338 Time: 0.009272
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 7504901284678552178
[12/29/2021-03:40:16] [V] [TRT] Tactic: 7504901284678552178 Time: 0.012704
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:40:16] [V] [TRT] Tactic: 8096257414008860171 Time: 0.009416
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 9143438935315839085
[12/29/2021-03:40:16] [V] [TRT] Tactic: 9143438935315839085 Time: 0.007796
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:40:16] [V] [TRT] Tactic: -9165697322068360861 Time: 0.019532
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -9118785798277698619
[12/29/2021-03:40:16] [V] [TRT] Tactic: -9118785798277698619 Time: 0.014552
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:40:16] [V] [TRT] Tactic: -8263994888336646547 Time: 0.012656
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:40:16] [V] [TRT] Tactic: -8205948405243401049 Time: 0.007612
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -7992068592656168418
[12/29/2021-03:40:16] [V] [TRT] Tactic: -7992068592656168418 Time: 0.009388
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: -7842775553137511386
[12/29/2021-03:40:16] [V] [TRT] Tactic: -7842775553137511386 Time: 0.012924
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:40:16] [V] [TRT] Tactic: -7683887278997527517 Time: 0.008428
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -6400348606759295499
[12/29/2021-03:40:16] [V] [TRT] Tactic: -6400348606759295499 Time: 0.014208
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -5980889159865208399
[12/29/2021-03:40:16] [V] [TRT] Tactic: -5980889159865208399 Time: 0.02064
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5766140806760372989
[12/29/2021-03:40:16] [V] [TRT] Tactic: -5766140806760372989 Time: 0.015708
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5709079507616090666
[12/29/2021-03:40:16] [V] [TRT] Tactic: -5709079507616090666 Time: 0.012444
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5698636014239116282
[12/29/2021-03:40:16] [V] [TRT] Tactic: -5698636014239116282 Time: 0.018616
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:40:16] [V] [TRT] Tactic: -4933563390723451692 Time: 0.00824
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -4516822589357530549
[12/29/2021-03:40:16] [V] [TRT] Tactic: -4516822589357530549 Time: 0.016384
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -3413217501222406256
[12/29/2021-03:40:16] [V] [TRT] Tactic: -3413217501222406256 Time: 0.01898
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:40:16] [V] [TRT] Tactic: -3238475748440751107 Time: 0.009416
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:40:16] [V] [TRT] Tactic: -3182884991006484042 Time: 0.012672
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:40:16] [V] [TRT] Tactic: -3173468756112541306 Time: 0.007444
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2917455979290586480
[12/29/2021-03:40:16] [V] [TRT] Tactic: -2917455979290586480 Time: 0.020944
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -2571022005763160364
[12/29/2021-03:40:16] [V] [TRT] Tactic: -2571022005763160364 Time: 0.015872
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -2083778562631872334
[12/29/2021-03:40:16] [V] [TRT] Tactic: -2083778562631872334 Time: 0.00988
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:40:16] [V] [TRT] Tactic: -1546787387293556842 Time: 0.012256
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:40:16] [V] [TRT] Tactic: -1498626619443284096 Time: 0.010368
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:40:16] [V] [TRT] Tactic: -1283580231568512025 Time: 0.007644
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: -1173968681844185579
[12/29/2021-03:40:16] [V] [TRT] Tactic: -1173968681844185579 Time: 0.00756
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:40:16] [V] [TRT] Tactic: -762222380308749469 Time: 0.008356
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -556794153877490941
[12/29/2021-03:40:16] [V] [TRT] Tactic: -556794153877490941 Time: 0.008384
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:40:16] [V] [TRT] Tactic: -516725800067794372 Time: 0.019032
[12/29/2021-03:40:16] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -428104331444385564
[12/29/2021-03:40:16] [V] [TRT] Tactic: -428104331444385564 Time: 0.016324
[12/29/2021-03:40:16] [V] [TRT] Fastest Tactic: 5136656982162849059 Time: 0.007128
[12/29/2021-03:40:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5136656982162849059
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning format combination: Float(4096,64,8,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:16] [V] [TRT] --------------- Timing Runner: Conv_46 (CudaDepthwiseConvolution)
[12/29/2021-03:40:16] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:16] [V] [TRT] --------------- Timing Runner: Conv_46 (FusedConvActConvolution)
[12/29/2021-03:40:16] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:16] [V] [TRT] --------------- Timing Runner: Conv_46 (CudnnConvolution)
[12/29/2021-03:40:16] [V] [TRT] Tactic: 0 Time: 0.011288
[12/29/2021-03:40:16] [V] [TRT] Tactic: 1 Time: 0.011364
[12/29/2021-03:40:16] [V] [TRT] Tactic: 2 Time: 0.032436
[12/29/2021-03:40:16] [V] [TRT] Tactic: 56 Time: 0.01134
[12/29/2021-03:40:16] [V] [TRT] Tactic: 57 Time: 0.011252
[12/29/2021-03:40:16] [V] [TRT] Tactic: 58 Time: 0.032344
[12/29/2021-03:40:16] [V] [TRT] Tactic: 112 Time: 0.011372
[12/29/2021-03:40:16] [V] [TRT] Tactic: 113 Time: 0.011344
[12/29/2021-03:40:16] [V] [TRT] Tactic: 114 Time: 0.032272
[12/29/2021-03:40:16] [V] [TRT] Fastest Tactic: 57 Time: 0.011252
[12/29/2021-03:40:16] [V] [TRT] --------------- Timing Runner: Conv_46 (CaskConvolution)
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:40:16] [V] [TRT] Tactic: 4549827808004681195 Time: 0.015432
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:40:16] [V] [TRT] Tactic: 5779835512569528575 Time: 0.018308
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 9151672657204310840
[12/29/2021-03:40:16] [V] [TRT] Tactic: 9151672657204310840 Time: 0.028524
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: -7491730084094677098
[12/29/2021-03:40:16] [V] [TRT] Tactic: -7491730084094677098 Time: 0.016524
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:40:16] [V] [TRT] Tactic: -6313876406580483184 Time: 0.0169
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: -6273689210331812572
[12/29/2021-03:40:16] [V] [TRT] Tactic: -6273689210331812572 Time: 0.018164
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: -4337126844824617177
[12/29/2021-03:40:16] [V] [TRT] Tactic: -4337126844824617177 Time: 0.014948
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:40:16] [V] [TRT] Tactic: -1123676555321336786 Time: 0.01832
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:40:16] [V] [TRT] Tactic: -701551393537224327 Time: 0.015588
[12/29/2021-03:40:16] [V] [TRT] Fastest Tactic: -4337126844824617177 Time: 0.014948
[12/29/2021-03:40:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 57
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning format combination: Float(4096,1,512,64) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:16] [V] [TRT] --------------- Timing Runner: Conv_46 (CudnnConvolution)
[12/29/2021-03:40:16] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:16] [V] [TRT] --------------- Timing Runner: Conv_46 (CaskConvolution)
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 1663866669559596164
[12/29/2021-03:40:16] [V] [TRT] Tactic: 1663866669559596164 Time: 0.016968
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:16] [V] [TRT] Tactic: 2860655430572478466 Time: 0.013056
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:16] [V] [TRT] Tactic: 4474630279712975759 Time: 0.010856
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:16] [V] [TRT] Tactic: 4479823862704990365 Time: 0.010808
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:16] [V] [TRT] Tactic: 4696204239951173149 Time: 0.012932
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:16] [V] [TRT] Tactic: 5778138195697110003 Time: 0.01702
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:16] [V] [TRT] Tactic: 8918020581761223752 Time: 0.016288
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -5905193483742532701
[12/29/2021-03:40:16] [V] [TRT] Tactic: -5905193483742532701 Time: 0.012396
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -4035591156787122265
[12/29/2021-03:40:16] [V] [TRT] Tactic: -4035591156787122265 Time: 0.010736
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:16] [V] [TRT] Tactic: -2809379259463049391 Time: 0.0171
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -1985235291706575900
[12/29/2021-03:40:16] [V] [TRT] Tactic: -1985235291706575900 Time: 0.016232
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:16] [V] [TRT] Tactic: -504296718212024303 Time: 0.016236
[12/29/2021-03:40:16] [V] [TRT] Fastest Tactic: -4035591156787122265 Time: 0.010736
[12/29/2021-03:40:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4035591156787122265
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning format combination: Float(1024,1:4,128,16) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:16] [V] [TRT] --------------- Timing Runner: Conv_46 (CudnnConvolution)
[12/29/2021-03:40:16] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:16] [V] [TRT] --------------- Timing Runner: Conv_46 (CaskConvolution)
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 1373022415249282411
[12/29/2021-03:40:16] [V] [TRT] Tactic: 1373022415249282411 Time: 0.013256
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 1663866669559596164
[12/29/2021-03:40:16] [V] [TRT] Tactic: 1663866669559596164 Time: 0.016836
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:16] [V] [TRT] Tactic: 2860655430572478466 Time: 0.01316
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:16] [V] [TRT] Tactic: 4474630279712975759 Time: 0.010912
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:16] [V] [TRT] Tactic: 4479823862704990365 Time: 0.010772
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:16] [V] [TRT] Tactic: 4696204239951173149 Time: 0.012836
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:16] [V] [TRT] Tactic: 5778138195697110003 Time: 0.017092
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:40:16] [V] [TRT] Tactic: 7342025736444949634 Time: 0.013344
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:16] [V] [TRT] Tactic: 8918020581761223752 Time: 0.016284
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -5905193483742532701
[12/29/2021-03:40:16] [V] [TRT] Tactic: -5905193483742532701 Time: 0.012404
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:40:16] [V] [TRT] Tactic: -5457304872213719461 Time: 0.013808
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -4035591156787122265
[12/29/2021-03:40:16] [V] [TRT] Tactic: -4035591156787122265 Time: 0.010712
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:16] [V] [TRT] Tactic: -2809379259463049391 Time: 0.016976
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -1985235291706575900
[12/29/2021-03:40:16] [V] [TRT] Tactic: -1985235291706575900 Time: 0.0162
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:16] [V] [TRT] Tactic: -504296718212024303 Time: 0.016396
[12/29/2021-03:40:16] [V] [TRT] Fastest Tactic: -4035591156787122265 Time: 0.010712
[12/29/2021-03:40:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4035591156787122265
[12/29/2021-03:40:16] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:16] [V] [TRT] --------------- Timing Runner: Conv_46 (CudaDepthwiseConvolution)
[12/29/2021-03:40:16] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:16] [V] [TRT] --------------- Timing Runner: Conv_46 (CaskConvolution)
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:40:16] [V] [TRT] Tactic: 1508480131241957639 Time: 0.013164
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 2141154648944475104
[12/29/2021-03:40:16] [V] [TRT] Tactic: 2141154648944475104 Time: 0.013084
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:40:16] [V] [TRT] Tactic: 3239257003214966313 Time: 0.0132
[12/29/2021-03:40:16] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:40:17] [V] [TRT] Tactic: 5592640619112287921 Time: 0.01086
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:40:17] [V] [TRT] Tactic: 7621465827583909090 Time: 0.011428
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: -6580271968881459581
[12/29/2021-03:40:17] [V] [TRT] Tactic: -6580271968881459581 Time: 0.011116
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:40:17] [V] [TRT] Tactic: -5576936487443445631 Time: 0.011344
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: -4443833619060044580
[12/29/2021-03:40:17] [V] [TRT] Tactic: -4443833619060044580 Time: 0.010844
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:40:17] [V] [TRT] Tactic: -2297737319934264721 Time: 0.011436
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:40:17] [V] [TRT] Tactic: -1425085658556684465 Time: 0.011196
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:40:17] [V] [TRT] Tactic: -108011214168778087 Time: 0.011208
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: -42427192380281294
[12/29/2021-03:40:17] [V] [TRT] Tactic: -42427192380281294 Time: 0.011328
[12/29/2021-03:40:17] [V] [TRT] Fastest Tactic: -4443833619060044580 Time: 0.010844
[12/29/2021-03:40:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4443833619060044580
[12/29/2021-03:40:17] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:17] [V] [TRT] --------------- Timing Runner: Conv_46 (CudaDepthwiseConvolution)
[12/29/2021-03:40:17] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:17] [V] [TRT] --------------- Timing Runner: Conv_46 (FusedConvActConvolution)
[12/29/2021-03:40:17] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:17] [V] [TRT] --------------- Timing Runner: Conv_46 (CaskConvolution)
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:40:17] [V] [TRT] Tactic: 175853789719975416 Time: 0.009292
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:40:17] [V] [TRT] Tactic: 2171150287007712632 Time: 0.009116
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:40:17] [V] [TRT] Tactic: 2234457234705232274 Time: 0.008884
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:40:17] [V] [TRT] Tactic: 5834048089706882838 Time: 0.009132
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 6299962968199310600
[12/29/2021-03:40:17] [V] [TRT] Tactic: 6299962968199310600 Time: 0.010372
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 6341572697076960911
[12/29/2021-03:40:17] [V] [TRT] Tactic: 6341572697076960911 Time: 0.008844
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:40:17] [V] [TRT] Tactic: -8626990807754934295 Time: 0.009052
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: -8498217049614706532
[12/29/2021-03:40:17] [V] [TRT] Tactic: -8498217049614706532 Time: 0.009
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:40:17] [V] [TRT] Tactic: -7303593854972602201 Time: 0.008836
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:40:17] [V] [TRT] Tactic: -6585664687867083638 Time: 0.01066
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: -3326139578711341011
[12/29/2021-03:40:17] [V] [TRT] Tactic: -3326139578711341011 Time: 0.008996
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:40:17] [V] [TRT] Tactic: -683636008127039856 Time: 0.010464
[12/29/2021-03:40:17] [V] [TRT] Fastest Tactic: -7303593854972602201 Time: 0.008836
[12/29/2021-03:40:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7303593854972602201
[12/29/2021-03:40:17] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:17] [V] [TRT] --------------- Timing Runner: Conv_46 (CaskConvolution)
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:40:17] [V] [TRT] Tactic: 1100922622480907544 Time: 0.009092
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_c32_nn_v1 Tactic: 2855900226702061782
[12/29/2021-03:40:17] [V] [TRT] Tactic: 2855900226702061782 Time: 0.010432
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:40:17] [V] [TRT] Tactic: 3606311198834416176 Time: 0.008964
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:40:17] [V] [TRT] Tactic: 4325765560739862899 Time: 0.010512
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 8803458114157674373
[12/29/2021-03:40:17] [V] [TRT] Tactic: 8803458114157674373 Time: 0.008672
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: -6934773036503365000
[12/29/2021-03:40:17] [V] [TRT] Tactic: -6934773036503365000 Time: 0.008836
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: -4431642509665791294
[12/29/2021-03:40:17] [V] [TRT] Tactic: -4431642509665791294 Time: 0.008616
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:40:17] [V] [TRT] Tactic: -4255737803793506479 Time: 0.010496
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:40:17] [V] [TRT] Tactic: -3958182351168863467 Time: 0.00852
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:40:17] [V] [TRT] Tactic: -3111968753064955248 Time: 0.009168
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:40:17] [V] [TRT] Tactic: -1492575840277333548 Time: 0.009096
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:40:17] [V] [TRT] Tactic: -868495160148524802 Time: 0.008696
[12/29/2021-03:40:17] [V] [TRT] Fastest Tactic: -3958182351168863467 Time: 0.00852
[12/29/2021-03:40:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3958182351168863467
[12/29/2021-03:40:17] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:17] [V] [TRT] --------------- Timing Runner: Conv_46 (CaskConvolution)
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:40:17] [V] [TRT] Tactic: 2623576043214044314 Time: 0.00624
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 2818014835119698671
[12/29/2021-03:40:17] [V] [TRT] Tactic: 2818014835119698671 Time: 0.007792
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 3721599319722771137
[12/29/2021-03:40:17] [V] [TRT] Tactic: 3721599319722771137 Time: 0.006056
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_interior_nt_v1 Tactic: 4178917718361232468
[12/29/2021-03:40:17] [V] [TRT] Tactic: 4178917718361232468 Time: 0.00886
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:40:17] [V] [TRT] Tactic: 4551754795416974366 Time: 0.006332
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:40:17] [V] [TRT] Tactic: 4925112190271421402 Time: 0.006028
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:40:17] [V] [TRT] Tactic: 5012796702462679112 Time: 0.011332
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:40:17] [V] [TRT] Tactic: 6556170942941957134 Time: 0.008648
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 6618077155362058131
[12/29/2021-03:40:17] [V] [TRT] Tactic: 6618077155362058131 Time: 0.005892
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:40:17] [V] [TRT] Tactic: 6852868042694587230 Time: 0.006812
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 6969462133921577484
[12/29/2021-03:40:17] [V] [TRT] Tactic: 6969462133921577484 Time: 0.010824
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:40:17] [V] [TRT] Tactic: 8399092794516815300 Time: 0.01072
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:40:17] [V] [TRT] Tactic: -9132922677633967263 Time: 0.00776
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -8912999970161746151
[12/29/2021-03:40:17] [V] [TRT] Tactic: -8912999970161746151 Time: 0.007576
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -8893439100868426414
[12/29/2021-03:40:17] [V] [TRT] Tactic: -8893439100868426414 Time: 0.010208
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:40:17] [V] [TRT] Tactic: -7988637803896331454 Time: 0.008568
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_interior_nt_v1 Tactic: -7904635102498369361
[12/29/2021-03:40:17] [V] [TRT] Tactic: -7904635102498369361 Time: 0.011232
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:40:17] [V] [TRT] Tactic: -7606074703023778034 Time: 0.008804
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:40:17] [V] [TRT] Tactic: -7413564913826321357 Time: 0.010156
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:40:17] [V] [TRT] Tactic: -7282232519526877434 Time: 0.011328
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -6406011580107094428
[12/29/2021-03:40:17] [V] [TRT] Tactic: -6406011580107094428 Time: 0.006572
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:40:17] [V] [TRT] Tactic: -5603587790314027122 Time: 0.008932
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_interior_nt_v1 Tactic: -5416590980288859834
[12/29/2021-03:40:17] [V] [TRT] Tactic: -5416590980288859834 Time: 0.008664
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:40:17] [V] [TRT] Tactic: -5334776871777565833 Time: 0.014296
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:40:17] [V] [TRT] Tactic: -5157868397078537095 Time: 0.009672
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -3665201838779845683
[12/29/2021-03:40:17] [V] [TRT] Tactic: -3665201838779845683 Time: 0.014048
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_interior_nt_v1 Tactic: -3644377136375731441
[12/29/2021-03:40:17] [V] [TRT] Tactic: -3644377136375731441 Time: 0.008828
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -3502495740607894730
[12/29/2021-03:40:17] [V] [TRT] Tactic: -3502495740607894730 Time: 0.006092
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -2342404147487779225
[12/29/2021-03:40:17] [V] [TRT] Tactic: -2342404147487779225 Time: 0.009772
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:40:17] [V] [TRT] Tactic: -1782593837177056527 Time: 0.00786
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:40:17] [V] [TRT] Tactic: -1610768292520086910 Time: 0.008904
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:40:17] [V] [TRT] Tactic: -621838502160440068 Time: 0.009
[12/29/2021-03:40:17] [V] [TRT] Fastest Tactic: 6618077155362058131 Time: 0.005892
[12/29/2021-03:40:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6618077155362058131
[12/29/2021-03:40:17] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:17] [V] [TRT] --------------- Timing Runner: Conv_46 (CudaGroupConvolution)
[12/29/2021-03:40:17] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:17] [V] [TRT] --------------- Timing Runner: Conv_46 (CudaDepthwiseConvolution)
[12/29/2021-03:40:17] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:17] [V] [TRT] --------------- Timing Runner: Conv_46 (FusedConvActConvolution)
[12/29/2021-03:40:17] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:17] [V] [TRT] --------------- Timing Runner: Conv_46 (CaskConvolution)
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 177040020707947851
[12/29/2021-03:40:17] [V] [TRT] Tactic: 177040020707947851 Time: 0.006312
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_interior_nt_v1 Tactic: 434957160407688216
[12/29/2021-03:40:17] [V] [TRT] Tactic: 434957160407688216 Time: 0.01032
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 805889586762897346
[12/29/2021-03:40:17] [V] [TRT] Tactic: 805889586762897346 Time: 0.009016
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 1550399266192842845
[12/29/2021-03:40:17] [V] [TRT] Tactic: 1550399266192842845 Time: 0.006048
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:40:17] [V] [TRT] Tactic: 2325023763229477890 Time: 0.007936
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_interior_nt_v1 Tactic: 2346437292116182513
[12/29/2021-03:40:17] [V] [TRT] Tactic: 2346437292116182513 Time: 0.008568
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_interior_nt_v1 Tactic: 2522133112320625287
[12/29/2021-03:40:17] [V] [TRT] Tactic: 2522133112320625287 Time: 0.008768
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 2985940154541537814
[12/29/2021-03:40:17] [V] [TRT] Tactic: 2985940154541537814 Time: 0.00854
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 3538565962642681625
[12/29/2021-03:40:17] [V] [TRT] Tactic: 3538565962642681625 Time: 0.00608
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 3899284354987683408
[12/29/2021-03:40:17] [V] [TRT] Tactic: 3899284354987683408 Time: 0.010476
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:40:17] [V] [TRT] Tactic: 4042202769383439184 Time: 0.006768
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 4259547356717612415
[12/29/2021-03:40:17] [V] [TRT] Tactic: 4259547356717612415 Time: 0.007272
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: 4717285412741024953
[12/29/2021-03:40:17] [V] [TRT] Tactic: 4717285412741024953 Time: 0.008768
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:40:17] [V] [TRT] Tactic: 4734519122557206480 Time: 0.009168
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 5121596860264626879
[12/29/2021-03:40:17] [V] [TRT] Tactic: 5121596860264626879 Time: 0.009068
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_interior_nt_v1 Tactic: 5126565865931538390
[12/29/2021-03:40:17] [V] [TRT] Tactic: 5126565865931538390 Time: 0.0088
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 5158259316594207439
[12/29/2021-03:40:17] [V] [TRT] Tactic: 5158259316594207439 Time: 0.006904
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 5375256703210220108
[12/29/2021-03:40:17] [V] [TRT] Tactic: 5375256703210220108 Time: 0.00672
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 6433368103202497147
[12/29/2021-03:40:17] [V] [TRT] Tactic: 6433368103202497147 Time: 0.007704
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 6434020722187266170
[12/29/2021-03:40:17] [V] [TRT] Tactic: 6434020722187266170 Time: 0.009488
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 6441948709525127755
[12/29/2021-03:40:17] [V] [TRT] Tactic: 6441948709525127755 Time: 0.006036
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 6457435868048963632
[12/29/2021-03:40:17] [V] [TRT] Tactic: 6457435868048963632 Time: 0.006688
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:40:17] [V] [TRT] Tactic: 6781129591847482048 Time: 0.006932
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 6925201228918187099
[12/29/2021-03:40:17] [V] [TRT] Tactic: 6925201228918187099 Time: 0.007588
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 7504901284678552178
[12/29/2021-03:40:17] [V] [TRT] Tactic: 7504901284678552178 Time: 0.0077
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 7731430299029542276
[12/29/2021-03:40:17] [V] [TRT] Tactic: 7731430299029542276 Time: 0.00752
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 7738495016763012180
[12/29/2021-03:40:17] [V] [TRT] Tactic: 7738495016763012180 Time: 0.00898
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 8234775147403903473
[12/29/2021-03:40:17] [V] [TRT] Tactic: 8234775147403903473 Time: 0.009132
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:40:17] [V] [TRT] Tactic: -9165697322068360861 Time: 0.009488
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -9118785798277698619
[12/29/2021-03:40:17] [V] [TRT] Tactic: -9118785798277698619 Time: 0.008836
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -8556775352640313933
[12/29/2021-03:40:17] [V] [TRT] Tactic: -8556775352640313933 Time: 0.007684
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:40:17] [V] [TRT] Tactic: -8263994888336646547 Time: 0.007676
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:40:17] [V] [TRT] Tactic: -8205948405243401049 Time: 0.006228
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: -7842775553137511386
[12/29/2021-03:40:17] [V] [TRT] Tactic: -7842775553137511386 Time: 0.007824
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:40:17] [V] [TRT] Tactic: -7683887278997527517 Time: 0.006384
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -6527178416855951297
[12/29/2021-03:40:17] [V] [TRT] Tactic: -6527178416855951297 Time: 0.006168
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -6510232214299595844
[12/29/2021-03:40:17] [V] [TRT] Tactic: -6510232214299595844 Time: 0.00616
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -6400348606759295499
[12/29/2021-03:40:17] [V] [TRT] Tactic: -6400348606759295499 Time: 0.008716
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -5980889159865208399
[12/29/2021-03:40:17] [V] [TRT] Tactic: -5980889159865208399 Time: 0.010668
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5766140806760372989
[12/29/2021-03:40:17] [V] [TRT] Tactic: -5766140806760372989 Time: 0.008984
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -5170003087447722174
[12/29/2021-03:40:17] [V] [TRT] Tactic: -5170003087447722174 Time: 0.00606
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -4849712423393454704
[12/29/2021-03:40:17] [V] [TRT] Tactic: -4849712423393454704 Time: 0.006664
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -4516822589357530549
[12/29/2021-03:40:17] [V] [TRT] Tactic: -4516822589357530549 Time: 0.009088
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -3613322253849278738
[12/29/2021-03:40:17] [V] [TRT] Tactic: -3613322253849278738 Time: 0.006036
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -3577322188448771475
[12/29/2021-03:40:17] [V] [TRT] Tactic: -3577322188448771475 Time: 0.006948
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -2754311112012636251
[12/29/2021-03:40:17] [V] [TRT] Tactic: -2754311112012636251 Time: 0.007184
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: -2315453944962430928
[12/29/2021-03:40:17] [V] [TRT] Tactic: -2315453944962430928 Time: 0.009104
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -2083778562631872334
[12/29/2021-03:40:17] [V] [TRT] Tactic: -2083778562631872334 Time: 0.00696
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -1499578657823798783
[12/29/2021-03:40:17] [V] [TRT] Tactic: -1499578657823798783 Time: 0.00612
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:40:17] [V] [TRT] Tactic: -1498626619443284096 Time: 0.007356
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:40:17] [V] [TRT] Tactic: -1283580231568512025 Time: 0.0062
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: -1173968681844185579
[12/29/2021-03:40:17] [V] [TRT] Tactic: -1173968681844185579 Time: 0.006176
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:40:17] [V] [TRT] Tactic: -762222380308749469 Time: 0.00636
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -713022856474991236
[12/29/2021-03:40:17] [V] [TRT] Tactic: -713022856474991236 Time: 0.006032
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -556794153877490941
[12/29/2021-03:40:17] [V] [TRT] Tactic: -556794153877490941 Time: 0.006328
[12/29/2021-03:40:17] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -375949437730908730
[12/29/2021-03:40:17] [V] [TRT] Tactic: -375949437730908730 Time: 0.006756
[12/29/2021-03:40:17] [V] [TRT] Fastest Tactic: -713022856474991236 Time: 0.006032
[12/29/2021-03:40:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -713022856474991236
[12/29/2021-03:40:17] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:17] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:17] [V] [TRT] Tactic: 1002 Time: 0.008624
[12/29/2021-03:40:17] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:17] [V] [TRT] Tactic: 0 Time: 0.005636
[12/29/2021-03:40:17] [V] [TRT] Fastest Tactic: 0 Time: 0.005636
[12/29/2021-03:40:17] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:17] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.008536
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.005536
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.005536
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.007608
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.0046
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.0046
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.007656
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.005336
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.005336
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.008744
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.005384
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.005384
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.007032
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.005184
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.005184
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.007812
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.005316
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.005316
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.007668
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.005528
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.005528
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.008676
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.005204
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.005204
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.00716
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.005148
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.005148
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.008672
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.005356
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.005356
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.00866
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.005492
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.005492
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.008756
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.005236
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.005236
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.009028
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.005144
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.005144
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.007096
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.00544
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.00544
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.008132
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.005368
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.005368
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.007932
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.0054
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.0054
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.00744
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.004644
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.004644
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.00864
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.005616
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.005616
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.008744
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.005708
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.005708
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.007332
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.004784
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.004784
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.007444
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.005428
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.005428
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.007684
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.00568
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.00568
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.00868
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.005712
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.005712
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.007132
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.004544
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1 Time: 0.004832
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.004544
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.008608
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.00544
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.00544
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.00898
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.005492
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.005492
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.007052
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.005556
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.005556
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.009132
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.005684
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.005684
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1002 Time: 0.008284
[12/29/2021-03:40:18] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.005708
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 0 Time: 0.005708
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning format combination: Float(2048,16,4,1), Float(2048,16,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CudaDepthwiseConvolution)
[12/29/2021-03:40:18] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (FusedConvActConvolution)
[12/29/2021-03:40:18] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CudnnConvolution)
[12/29/2021-03:40:18] [V] [TRT] Tactic: 0 Time: 0.058316
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1 Time: 0.061212
[12/29/2021-03:40:18] [V] [TRT] Tactic: 2 Time: 0.080788
[12/29/2021-03:40:18] [V] [TRT] Tactic: 4 skipped. Scratch requested: 47775744, available: 16777216
[12/29/2021-03:40:18] [V] [TRT] Tactic: 5 skipped. Scratch requested: 106954752, available: 16777216
[12/29/2021-03:40:18] [V] [TRT] Tactic: 6 Time: 0.040052
[12/29/2021-03:40:18] [V] [TRT] Tactic: 56 Time: 0.05826
[12/29/2021-03:40:18] [V] [TRT] Tactic: 57 Time: 0.0654
[12/29/2021-03:40:18] [V] [TRT] Tactic: 58 Time: 0.0806
[12/29/2021-03:40:18] [V] [TRT] Tactic: 60 skipped. Scratch requested: 47775744, available: 16777216
[12/29/2021-03:40:18] [V] [TRT] Tactic: 61 skipped. Scratch requested: 106954752, available: 16777216
[12/29/2021-03:40:18] [V] [TRT] Tactic: 62 Time: 0.039976
[12/29/2021-03:40:18] [V] [TRT] Tactic: 112 Time: 0.058376
[12/29/2021-03:40:18] [V] [TRT] Tactic: 113 Time: 0.31382
[12/29/2021-03:40:18] [V] [TRT] Tactic: 114 Time: 0.08076
[12/29/2021-03:40:18] [V] [TRT] Tactic: 116 skipped. Scratch requested: 47775744, available: 16777216
[12/29/2021-03:40:18] [V] [TRT] Tactic: 117 skipped. Scratch requested: 106954752, available: 16777216
[12/29/2021-03:40:18] [V] [TRT] Tactic: 118 Time: 0.040048
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 62 Time: 0.039976
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CaskConvolution)
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:40:18] [V] [TRT] Tactic: 4549827808004681195 Time: 0.117568
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:40:18] [V] [TRT] Tactic: 5779835512569528575 Time: 0.150532
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[12/29/2021-03:40:18] [V] [TRT] Tactic: 6053873026024413720 Time: 0.18342
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[12/29/2021-03:40:18] [V] [TRT] Tactic: 6767548733843469815 Time: 0.139384
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:40:18] [V] [TRT] Tactic: -6313876406580483184 Time: 0.14018
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:40:18] [V] [TRT] Tactic: -1123676555321336786 Time: 0.178436
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:40:18] [V] [TRT] Tactic: -701551393537224327 Time: 0.161408
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 4549827808004681195 Time: 0.117568
[12/29/2021-03:40:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 62
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning format combination: Float(2048,1,512,128), Float(2048,1,512,128) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CudnnConvolution)
[12/29/2021-03:40:18] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CaskConvolution)
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:18] [V] [TRT] Tactic: 2860655430572478466 Time: 0.090116
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:18] [V] [TRT] Tactic: 4474630279712975759 Time: 0.053624
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:18] [V] [TRT] Tactic: 4479823862704990365 Time: 0.051108
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:18] [V] [TRT] Tactic: 4696204239951173149 Time: 0.09568
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:18] [V] [TRT] Tactic: 5778138195697110003 Time: 0.151252
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:40:18] [V] [TRT] Tactic: 7155825427510256858 Time: 0.154536
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:18] [V] [TRT] Tactic: 8918020581761223752 Time: 0.151208
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:40:18] [V] [TRT] Tactic: -4756382386362004279 Time: 0.093972
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:40:18] [V] [TRT] Tactic: -3855385237722507464 Time: 0.155408
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:18] [V] [TRT] Tactic: -2809379259463049391 Time: 0.152764
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:18] [V] [TRT] Tactic: -504296718212024303 Time: 0.145236
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.051108
[12/29/2021-03:40:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning format combination: Float(512,1:4,128,32), Float(512,1:4,128,32) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CudnnConvolution)
[12/29/2021-03:40:18] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CaskConvolution)
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:18] [V] [TRT] Tactic: 2860655430572478466 Time: 0.089876
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:18] [V] [TRT] Tactic: 4474630279712975759 Time: 0.053616
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:18] [V] [TRT] Tactic: 4479823862704990365 Time: 0.05128
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:18] [V] [TRT] Tactic: 4696204239951173149 Time: 0.095588
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:18] [V] [TRT] Tactic: 5778138195697110003 Time: 0.151484
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:40:18] [V] [TRT] Tactic: 7155825427510256858 Time: 0.154604
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:40:18] [V] [TRT] Tactic: 7342025736444949634 Time: 0.102532
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:18] [V] [TRT] Tactic: 8918020581761223752 Time: 0.151584
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:40:18] [V] [TRT] Tactic: -7377458734869418330 Time: 0.101316
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:40:18] [V] [TRT] Tactic: -5457304872213719461 Time: 0.10218
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:40:18] [V] [TRT] Tactic: -4756382386362004279 Time: 0.094136
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:40:18] [V] [TRT] Tactic: -3855385237722507464 Time: 0.155504
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:18] [V] [TRT] Tactic: -2809379259463049391 Time: 0.152836
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:18] [V] [TRT] Tactic: -504296718212024303 Time: 0.145216
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.05128
[12/29/2021-03:40:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1), Float(2048,16,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CudaDepthwiseConvolution)
[12/29/2021-03:40:18] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CaskConvolution)
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 1332468635798226953
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1332468635798226953 Time: 0.061872
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1508480131241957639 Time: 0.05672
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 1947019689364377201
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1947019689364377201 Time: 0.044476
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:40:18] [V] [TRT] Tactic: 3239257003214966313 Time: 0.061428
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:40:18] [V] [TRT] Tactic: 5592640619112287921 Time: 0.036064
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:40:18] [V] [TRT] Tactic: 7621465827583909090 Time: 0.037868
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:40:18] [V] [TRT] Tactic: -5576936487443445631 Time: 0.049112
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:40:18] [V] [TRT] Tactic: -2297737319934264721 Time: 0.056644
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:40:18] [V] [TRT] Tactic: -1425085658556684465 Time: 0.054708
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:40:18] [V] [TRT] Tactic: -108011214168778087 Time: 0.04284
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: 5592640619112287921 Time: 0.036064
[12/29/2021-03:40:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5592640619112287921
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1), Int8(512,16:4,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CudaDepthwiseConvolution)
[12/29/2021-03:40:18] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (FusedConvActConvolution)
[12/29/2021-03:40:18] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CaskConvolution)
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:40:18] [V] [TRT] Tactic: 175853789719975416 Time: 0.054952
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:40:18] [V] [TRT] Tactic: 2171150287007712632 Time: 0.05292
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:40:18] [V] [TRT] Tactic: 2234457234705232274 Time: 0.036104
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:40:18] [V] [TRT] Tactic: 5834048089706882838 Time: 0.047224
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:40:18] [V] [TRT] Tactic: -8626990807754934295 Time: 0.041348
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:40:18] [V] [TRT] Tactic: -7303593854972602201 Time: 0.03444
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:40:18] [V] [TRT] Tactic: -6585664687867083638 Time: 0.059368
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: -3730012925709297561
[12/29/2021-03:40:18] [V] [TRT] Tactic: -3730012925709297561 Time: 0.042124
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: -2277259417488004546
[12/29/2021-03:40:18] [V] [TRT] Tactic: -2277259417488004546 Time: 0.059648
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:40:18] [V] [TRT] Tactic: -683636008127039856 Time: 0.054576
[12/29/2021-03:40:18] [V] [TRT] Fastest Tactic: -7303593854972602201 Time: 0.03444
[12/29/2021-03:40:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7303593854972602201
[12/29/2021-03:40:18] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1), Int8(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:18] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CaskConvolution)
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 984309058095623735
[12/29/2021-03:40:18] [V] [TRT] Tactic: 984309058095623735 Time: 0.042412
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:40:18] [V] [TRT] Tactic: 1100922622480907544 Time: 0.041176
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 3238312825609165543
[12/29/2021-03:40:18] [V] [TRT] Tactic: 3238312825609165543 Time: 0.059832
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:40:18] [V] [TRT] Tactic: 3606311198834416176 Time: 0.047268
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:40:18] [V] [TRT] Tactic: 4325765560739862899 Time: 0.055116
[12/29/2021-03:40:18] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:40:19] [V] [TRT] Tactic: -4255737803793506479 Time: 0.059596
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:40:19] [V] [TRT] Tactic: -3958182351168863467 Time: 0.034272
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:40:19] [V] [TRT] Tactic: -3111968753064955248 Time: 0.052592
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:40:19] [V] [TRT] Tactic: -1492575840277333548 Time: 0.054836
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:40:19] [V] [TRT] Tactic: -868495160148524802 Time: 0.035948
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: -3958182351168863467 Time: 0.034272
[12/29/2021-03:40:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3958182351168863467
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning format combination: Int8(64,16:32,4,1), Float(64,16:32,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CaskConvolution)
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1011019097971850911 Time: 0.021268
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1071114551801767124 Time: 0.01358
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:40:19] [V] [TRT] Tactic: 2623576043214044314 Time: 0.009592
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:40:19] [V] [TRT] Tactic: 3281631721811475881 Time: 0.01084
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:40:19] [V] [TRT] Tactic: 4551754795416974366 Time: 0.0107
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:40:19] [V] [TRT] Tactic: 4925112190271421402 Time: 0.009348
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:40:19] [V] [TRT] Tactic: 5012796702462679112 Time: 0.0379
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:40:19] [V] [TRT] Tactic: 5041593333398049019 Time: 0.009192
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:40:19] [V] [TRT] Tactic: 5166018662410176512 Time: 0.035564
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:40:19] [V] [TRT] Tactic: 6191867932654611882 Time: 0.020628
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:40:19] [V] [TRT] Tactic: 6556170942941957134 Time: 0.024728
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:40:19] [V] [TRT] Tactic: 6852868042694587230 Time: 0.010944
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:40:19] [V] [TRT] Tactic: 8399092794516815300 Time: 0.032424
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:40:19] [V] [TRT] Tactic: -9132922677633967263 Time: 0.014124
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:40:19] [V] [TRT] Tactic: -7988637803896331454 Time: 0.022056
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: -7865001268126363229
[12/29/2021-03:40:19] [V] [TRT] Tactic: -7865001268126363229 Time: 0.030088
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:40:19] [V] [TRT] Tactic: -7606074703023778034 Time: 0.022536
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:40:19] [V] [TRT] Tactic: -7413564913826321357 Time: 0.021624
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:40:19] [V] [TRT] Tactic: -7282232519526877434 Time: 0.03656
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:40:19] [V] [TRT] Tactic: -5942379529065248478 Time: 0.013828
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:40:19] [V] [TRT] Tactic: -5603587790314027122 Time: 0.028584
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:40:19] [V] [TRT] Tactic: -5334776871777565833 Time: 0.0361
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:40:19] [V] [TRT] Tactic: -5157868397078537095 Time: 0.020964
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:40:19] [V] [TRT] Tactic: -5100834417027499764 Time: 0.01002
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:40:19] [V] [TRT] Tactic: -3365360067423513506 Time: 0.008496
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2194148180068068313
[12/29/2021-03:40:19] [V] [TRT] Tactic: -2194148180068068313 Time: 0.037548
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:40:19] [V] [TRT] Tactic: -1782593837177056527 Time: 0.01412
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:40:19] [V] [TRT] Tactic: -1610768292520086910 Time: 0.023844
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:40:19] [V] [TRT] Tactic: -1573035963956198975 Time: 0.031896
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -1558762241666006941
[12/29/2021-03:40:19] [V] [TRT] Tactic: -1558762241666006941 Time: 0.026124
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -1365353082499976145
[12/29/2021-03:40:19] [V] [TRT] Tactic: -1365353082499976145 Time: 0.0292
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:40:19] [V] [TRT] Tactic: -621838502160440068 Time: 0.029264
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: -3365360067423513506 Time: 0.008496
[12/29/2021-03:40:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3365360067423513506
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning format combination: Int8(64,16:32,4,1), Int8(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CudaGroupConvolution)
[12/29/2021-03:40:19] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CudaDepthwiseConvolution)
[12/29/2021-03:40:19] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (FusedConvActConvolution)
[12/29/2021-03:40:19] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CaskConvolution)
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:40:19] [V] [TRT] Tactic: 2325023763229477890 Time: 0.019516
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 2985940154541537814
[12/29/2021-03:40:19] [V] [TRT] Tactic: 2985940154541537814 Time: 0.02456
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:40:19] [V] [TRT] Tactic: 3401614690060226673 Time: 0.009636
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 3899284354987683408
[12/29/2021-03:40:19] [V] [TRT] Tactic: 3899284354987683408 Time: 0.034884
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:40:19] [V] [TRT] Tactic: 4042202769383439184 Time: 0.012912
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: 4182625619810185112
[12/29/2021-03:40:19] [V] [TRT] Tactic: 4182625619810185112 Time: 0.029736
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: 4717285412741024953
[12/29/2021-03:40:19] [V] [TRT] Tactic: 4717285412741024953 Time: 0.023536
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:40:19] [V] [TRT] Tactic: 4734519122557206480 Time: 0.030956
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:40:19] [V] [TRT] Tactic: 5136656982162849059 Time: 0.008336
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:40:19] [V] [TRT] Tactic: 6004789655466615912 Time: 0.013484
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:40:19] [V] [TRT] Tactic: 6146901278630392829 Time: 0.030424
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:40:19] [V] [TRT] Tactic: 6781129591847482048 Time: 0.013284
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:40:19] [V] [TRT] Tactic: 8096257414008860171 Time: 0.013096
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:40:19] [V] [TRT] Tactic: -9165697322068360861 Time: 0.031472
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -9118785798277698619
[12/29/2021-03:40:19] [V] [TRT] Tactic: -9118785798277698619 Time: 0.021948
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:40:19] [V] [TRT] Tactic: -8263994888336646547 Time: 0.019088
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:40:19] [V] [TRT] Tactic: -8205948405243401049 Time: 0.009148
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:40:19] [V] [TRT] Tactic: -7683887278997527517 Time: 0.010332
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -6400348606759295499
[12/29/2021-03:40:19] [V] [TRT] Tactic: -6400348606759295499 Time: 0.021848
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -5980889159865208399
[12/29/2021-03:40:19] [V] [TRT] Tactic: -5980889159865208399 Time: 0.033788
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5766140806760372989
[12/29/2021-03:40:19] [V] [TRT] Tactic: -5766140806760372989 Time: 0.028104
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:40:19] [V] [TRT] Tactic: -4933563390723451692 Time: 0.010436
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -4516822589357530549
[12/29/2021-03:40:19] [V] [TRT] Tactic: -4516822589357530549 Time: 0.02866
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:40:19] [V] [TRT] Tactic: -3238475748440751107 Time: 0.012456
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:40:19] [V] [TRT] Tactic: -3182884991006484042 Time: 0.0194
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:40:19] [V] [TRT] Tactic: -3173468756112541306 Time: 0.008812
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2917455979290586480
[12/29/2021-03:40:19] [V] [TRT] Tactic: -2917455979290586480 Time: 0.034636
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -2571022005763160364
[12/29/2021-03:40:19] [V] [TRT] Tactic: -2571022005763160364 Time: 0.025756
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:40:19] [V] [TRT] Tactic: -1546787387293556842 Time: 0.01896
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:40:19] [V] [TRT] Tactic: -1498626619443284096 Time: 0.014332
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:40:19] [V] [TRT] Tactic: -1283580231568512025 Time: 0.00898
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:40:19] [V] [TRT] Tactic: -762222380308749469 Time: 0.010396
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:40:19] [V] [TRT] Tactic: -516725800067794372 Time: 0.030872
[12/29/2021-03:40:19] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -428104331444385564
[12/29/2021-03:40:19] [V] [TRT] Tactic: -428104331444385564 Time: 0.028804
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 5136656982162849059 Time: 0.008336
[12/29/2021-03:40:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5136656982162849059
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.008616
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.005524
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.005524
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.008632
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.00556
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.00556
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.008492
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.005448
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.005448
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.007584
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.004528
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.004528
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.007544
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.005396
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.005396
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.008808
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.005136
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.005136
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.007072
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.005204
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.005204
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.00896
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.00546
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.00546
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.007768
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.00536
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.00536
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.007796
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.005416
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.005416
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.009028
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.005252
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.005252
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.00708
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.005272
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.005272
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.007076
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.005556
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.005556
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.008712
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.005364
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.005364
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.00866
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.005424
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.005424
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.00878
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.005192
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.005192
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.008852
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.005128
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.005128
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.007052
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.005276
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.005276
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.008036
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.005408
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.005408
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.00794
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.005388
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.005388
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.007492
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.00474
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.00474
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.008688
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.00564
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.00564
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.00874
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.005672
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.005672
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.00912
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.005716
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.005716
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.007292
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.004852
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.004852
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 1002 Time: 0.007468
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:19] [V] [TRT] Tactic: 0 Time: 0.005448
[12/29/2021-03:40:19] [V] [TRT] Fastest Tactic: 0 Time: 0.005448
[12/29/2021-03:40:19] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:19] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:20] [V] [TRT] Tactic: 1002 Time: 0.00772
[12/29/2021-03:40:20] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:20] [V] [TRT] Tactic: 0 Time: 0.005744
[12/29/2021-03:40:20] [V] [TRT] Fastest Tactic: 0 Time: 0.005744
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:20] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:20] [V] [TRT] Tactic: 1002 Time: 0.008788
[12/29/2021-03:40:20] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:20] [V] [TRT] Tactic: 0 Time: 0.005688
[12/29/2021-03:40:20] [V] [TRT] Fastest Tactic: 0 Time: 0.005688
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:20] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:20] [V] [TRT] Tactic: 1002 Time: 0.008172
[12/29/2021-03:40:20] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:20] [V] [TRT] Tactic: 0 Time: 0.00572
[12/29/2021-03:40:20] [V] [TRT] Fastest Tactic: 0 Time: 0.00572
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:20] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:20] [V] [TRT] Tactic: 1002 Time: 0.007096
[12/29/2021-03:40:20] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:20] [V] [TRT] Tactic: 0 Time: 0.004528
[12/29/2021-03:40:20] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:20] [V] [TRT] Tactic: 1 Time: 0.0048
[12/29/2021-03:40:20] [V] [TRT] Fastest Tactic: 0 Time: 0.004528
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning format combination: Float(2048,16,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CudaDepthwiseConvolution)
[12/29/2021-03:40:20] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (FusedConvActConvolution)
[12/29/2021-03:40:20] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CudnnConvolution)
[12/29/2021-03:40:20] [V] [TRT] Tactic: 0 Time: 0.055764
[12/29/2021-03:40:20] [V] [TRT] Tactic: 1 Time: 0.078496
[12/29/2021-03:40:20] [V] [TRT] Tactic: 2 Time: 0.078084
[12/29/2021-03:40:20] [V] [TRT] Tactic: 4 skipped. Scratch requested: 47775744, available: 16777216
[12/29/2021-03:40:20] [V] [TRT] Tactic: 5 skipped. Scratch requested: 106954752, available: 16777216
[12/29/2021-03:40:20] [V] [TRT] Tactic: 6 Time: 0.037416
[12/29/2021-03:40:20] [V] [TRT] Tactic: 56 Time: 0.055776
[12/29/2021-03:40:20] [V] [TRT] Tactic: 57 Time: 0.083152
[12/29/2021-03:40:20] [V] [TRT] Tactic: 58 Time: 0.077992
[12/29/2021-03:40:20] [V] [TRT] Tactic: 60 skipped. Scratch requested: 47775744, available: 16777216
[12/29/2021-03:40:20] [V] [TRT] Tactic: 61 skipped. Scratch requested: 106954752, available: 16777216
[12/29/2021-03:40:20] [V] [TRT] Tactic: 62 Time: 0.037592
[12/29/2021-03:40:20] [V] [TRT] Tactic: 112 Time: 0.055752
[12/29/2021-03:40:20] [V] [TRT] Tactic: 113 Time: 0.315092
[12/29/2021-03:40:20] [V] [TRT] Tactic: 114 Time: 0.07796
[12/29/2021-03:40:20] [V] [TRT] Tactic: 116 skipped. Scratch requested: 47775744, available: 16777216
[12/29/2021-03:40:20] [V] [TRT] Tactic: 117 skipped. Scratch requested: 106954752, available: 16777216
[12/29/2021-03:40:20] [V] [TRT] Tactic: 118 Time: 0.037524
[12/29/2021-03:40:20] [V] [TRT] Fastest Tactic: 6 Time: 0.037416
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CaskConvolution)
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:40:20] [V] [TRT] Tactic: 4549827808004681195 Time: 0.116616
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:40:20] [V] [TRT] Tactic: 5779835512569528575 Time: 0.14954
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[12/29/2021-03:40:20] [V] [TRT] Tactic: 6053873026024413720 Time: 0.182224
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[12/29/2021-03:40:20] [V] [TRT] Tactic: 6767548733843469815 Time: 0.138804
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:40:20] [V] [TRT] Tactic: -6313876406580483184 Time: 0.139252
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:40:20] [V] [TRT] Tactic: -1123676555321336786 Time: 0.177332
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:40:20] [V] [TRT] Tactic: -701551393537224327 Time: 0.160376
[12/29/2021-03:40:20] [V] [TRT] Fastest Tactic: 4549827808004681195 Time: 0.116616
[12/29/2021-03:40:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning format combination: Float(2048,1,512,128) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CudnnConvolution)
[12/29/2021-03:40:20] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CaskConvolution)
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:20] [V] [TRT] Tactic: 2860655430572478466 Time: 0.089276
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:20] [V] [TRT] Tactic: 4474630279712975759 Time: 0.052736
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:20] [V] [TRT] Tactic: 4479823862704990365 Time: 0.050412
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:20] [V] [TRT] Tactic: 4696204239951173149 Time: 0.094504
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:20] [V] [TRT] Tactic: 5778138195697110003 Time: 0.151084
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:40:20] [V] [TRT] Tactic: 7155825427510256858 Time: 0.153612
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:20] [V] [TRT] Tactic: 8918020581761223752 Time: 0.150296
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:40:20] [V] [TRT] Tactic: -4756382386362004279 Time: 0.093276
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:40:20] [V] [TRT] Tactic: -3855385237722507464 Time: 0.154756
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:20] [V] [TRT] Tactic: -2809379259463049391 Time: 0.152328
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:20] [V] [TRT] Tactic: -504296718212024303 Time: 0.14418
[12/29/2021-03:40:20] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.050412
[12/29/2021-03:40:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning format combination: Float(512,1:4,128,32) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CudnnConvolution)
[12/29/2021-03:40:20] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CaskConvolution)
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:20] [V] [TRT] Tactic: 2860655430572478466 Time: 0.089112
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:20] [V] [TRT] Tactic: 4474630279712975759 Time: 0.05272
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:20] [V] [TRT] Tactic: 4479823862704990365 Time: 0.050448
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:20] [V] [TRT] Tactic: 4696204239951173149 Time: 0.094592
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:20] [V] [TRT] Tactic: 5778138195697110003 Time: 0.151104
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:40:20] [V] [TRT] Tactic: 7155825427510256858 Time: 0.153656
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:40:20] [V] [TRT] Tactic: 7342025736444949634 Time: 0.100728
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:20] [V] [TRT] Tactic: 8918020581761223752 Time: 0.150344
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:40:20] [V] [TRT] Tactic: -7377458734869418330 Time: 0.099556
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:40:20] [V] [TRT] Tactic: -5457304872213719461 Time: 0.100436
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:40:20] [V] [TRT] Tactic: -4756382386362004279 Time: 0.093216
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:40:20] [V] [TRT] Tactic: -3855385237722507464 Time: 0.154708
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:20] [V] [TRT] Tactic: -2809379259463049391 Time: 0.152092
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:20] [V] [TRT] Tactic: -504296718212024303 Time: 0.144164
[12/29/2021-03:40:20] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.050448
[12/29/2021-03:40:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CudaDepthwiseConvolution)
[12/29/2021-03:40:20] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CaskConvolution)
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 1332468635798226953
[12/29/2021-03:40:20] [V] [TRT] Tactic: 1332468635798226953 Time: 0.06078
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:40:20] [V] [TRT] Tactic: 1508480131241957639 Time: 0.05568
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 1947019689364377201
[12/29/2021-03:40:20] [V] [TRT] Tactic: 1947019689364377201 Time: 0.042996
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:40:20] [V] [TRT] Tactic: 3239257003214966313 Time: 0.06048
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:40:20] [V] [TRT] Tactic: 5592640619112287921 Time: 0.034852
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:40:20] [V] [TRT] Tactic: 7621465827583909090 Time: 0.036632
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:40:20] [V] [TRT] Tactic: -5576936487443445631 Time: 0.048044
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:40:20] [V] [TRT] Tactic: -2297737319934264721 Time: 0.055484
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:40:20] [V] [TRT] Tactic: -1425085658556684465 Time: 0.053644
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:40:20] [V] [TRT] Tactic: -108011214168778087 Time: 0.041756
[12/29/2021-03:40:20] [V] [TRT] Fastest Tactic: 5592640619112287921 Time: 0.034852
[12/29/2021-03:40:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5592640619112287921
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CudaDepthwiseConvolution)
[12/29/2021-03:40:20] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (FusedConvActConvolution)
[12/29/2021-03:40:20] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CaskConvolution)
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:40:20] [V] [TRT] Tactic: 175853789719975416 Time: 0.053504
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:40:20] [V] [TRT] Tactic: 2171150287007712632 Time: 0.051444
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:40:20] [V] [TRT] Tactic: 2234457234705232274 Time: 0.034284
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:40:20] [V] [TRT] Tactic: 5834048089706882838 Time: 0.045544
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:40:20] [V] [TRT] Tactic: -8626990807754934295 Time: 0.03978
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:40:20] [V] [TRT] Tactic: -7303593854972602201 Time: 0.032804
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:40:20] [V] [TRT] Tactic: -6585664687867083638 Time: 0.057864
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: -3730012925709297561
[12/29/2021-03:40:20] [V] [TRT] Tactic: -3730012925709297561 Time: 0.0405
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: -2277259417488004546
[12/29/2021-03:40:20] [V] [TRT] Tactic: -2277259417488004546 Time: 0.057924
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:40:20] [V] [TRT] Tactic: -683636008127039856 Time: 0.052936
[12/29/2021-03:40:20] [V] [TRT] Fastest Tactic: -7303593854972602201 Time: 0.032804
[12/29/2021-03:40:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7303593854972602201
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CaskConvolution)
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 984309058095623735
[12/29/2021-03:40:20] [V] [TRT] Tactic: 984309058095623735 Time: 0.04036
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:40:20] [V] [TRT] Tactic: 1100922622480907544 Time: 0.03954
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 3238312825609165543
[12/29/2021-03:40:20] [V] [TRT] Tactic: 3238312825609165543 Time: 0.05786
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:40:20] [V] [TRT] Tactic: 3606311198834416176 Time: 0.045452
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:40:20] [V] [TRT] Tactic: 4325765560739862899 Time: 0.052928
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:40:20] [V] [TRT] Tactic: -4255737803793506479 Time: 0.057584
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:40:20] [V] [TRT] Tactic: -3958182351168863467 Time: 0.032556
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:40:20] [V] [TRT] Tactic: -3111968753064955248 Time: 0.0511
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:40:20] [V] [TRT] Tactic: -1492575840277333548 Time: 0.053468
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:40:20] [V] [TRT] Tactic: -868495160148524802 Time: 0.034208
[12/29/2021-03:40:20] [V] [TRT] Fastest Tactic: -3958182351168863467 Time: 0.032556
[12/29/2021-03:40:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3958182351168863467
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning format combination: Int8(64,16:32,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CaskConvolution)
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:40:20] [V] [TRT] Tactic: 1011019097971850911 Time: 0.020328
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:40:20] [V] [TRT] Tactic: 1071114551801767124 Time: 0.013016
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:40:20] [V] [TRT] Tactic: 2623576043214044314 Time: 0.009352
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:40:20] [V] [TRT] Tactic: 3281631721811475881 Time: 0.01044
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:40:20] [V] [TRT] Tactic: 4551754795416974366 Time: 0.010252
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:40:20] [V] [TRT] Tactic: 4925112190271421402 Time: 0.00918
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:40:20] [V] [TRT] Tactic: 5012796702462679112 Time: 0.03402
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:40:20] [V] [TRT] Tactic: 5041593333398049019 Time: 0.008692
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:40:20] [V] [TRT] Tactic: 5166018662410176512 Time: 0.034744
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:40:20] [V] [TRT] Tactic: 6191867932654611882 Time: 0.02012
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:40:20] [V] [TRT] Tactic: 6556170942941957134 Time: 0.023376
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:40:20] [V] [TRT] Tactic: 6852868042694587230 Time: 0.01048
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:40:20] [V] [TRT] Tactic: 8399092794516815300 Time: 0.032032
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:40:20] [V] [TRT] Tactic: -9132922677633967263 Time: 0.013584
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:40:20] [V] [TRT] Tactic: -7988637803896331454 Time: 0.0207
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: -7865001268126363229
[12/29/2021-03:40:20] [V] [TRT] Tactic: -7865001268126363229 Time: 0.028616
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:40:20] [V] [TRT] Tactic: -7606074703023778034 Time: 0.021144
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:40:20] [V] [TRT] Tactic: -7413564913826321357 Time: 0.02062
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:40:20] [V] [TRT] Tactic: -7282232519526877434 Time: 0.032892
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:40:20] [V] [TRT] Tactic: -5942379529065248478 Time: 0.013108
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:40:20] [V] [TRT] Tactic: -5603587790314027122 Time: 0.027216
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:40:20] [V] [TRT] Tactic: -5334776871777565833 Time: 0.035312
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:40:20] [V] [TRT] Tactic: -5157868397078537095 Time: 0.020336
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:40:20] [V] [TRT] Tactic: -5100834417027499764 Time: 0.009476
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:40:20] [V] [TRT] Tactic: -3365360067423513506 Time: 0.008292
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2194148180068068313
[12/29/2021-03:40:20] [V] [TRT] Tactic: -2194148180068068313 Time: 0.033804
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:40:20] [V] [TRT] Tactic: -1782593837177056527 Time: 0.013584
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:40:20] [V] [TRT] Tactic: -1610768292520086910 Time: 0.022424
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:40:20] [V] [TRT] Tactic: -1573035963956198975 Time: 0.031576
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -1558762241666006941
[12/29/2021-03:40:20] [V] [TRT] Tactic: -1558762241666006941 Time: 0.02478
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -1365353082499976145
[12/29/2021-03:40:20] [V] [TRT] Tactic: -1365353082499976145 Time: 0.0279
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:40:20] [V] [TRT] Tactic: -621838502160440068 Time: 0.027944
[12/29/2021-03:40:20] [V] [TRT] Fastest Tactic: -3365360067423513506 Time: 0.008292
[12/29/2021-03:40:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3365360067423513506
[12/29/2021-03:40:20] [V] [TRT] *************** Autotuning format combination: Int8(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CudaGroupConvolution)
[12/29/2021-03:40:20] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CudaDepthwiseConvolution)
[12/29/2021-03:40:20] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (FusedConvActConvolution)
[12/29/2021-03:40:20] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:20] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CaskConvolution)
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 177040020707947851
[12/29/2021-03:40:20] [V] [TRT] Tactic: 177040020707947851 Time: 0.009936
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 1550399266192842845
[12/29/2021-03:40:20] [V] [TRT] Tactic: 1550399266192842845 Time: 0.00896
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 1572887561103143487
[12/29/2021-03:40:20] [V] [TRT] Tactic: 1572887561103143487 Time: 0.0125
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:40:20] [V] [TRT] Tactic: 2325023763229477890 Time: 0.018248
[12/29/2021-03:40:20] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 2985940154541537814
[12/29/2021-03:40:21] [V] [TRT] Tactic: 2985940154541537814 Time: 0.0233
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:40:21] [V] [TRT] Tactic: 3284282970967328046 Time: 0.00834
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:40:21] [V] [TRT] Tactic: 3401614690060226673 Time: 0.009332
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3512426920013359699
[12/29/2021-03:40:21] [V] [TRT] Tactic: 3512426920013359699 Time: 0.010056
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 3899284354987683408
[12/29/2021-03:40:21] [V] [TRT] Tactic: 3899284354987683408 Time: 0.033248
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:40:21] [V] [TRT] Tactic: 4042202769383439184 Time: 0.0123
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: 4182625619810185112
[12/29/2021-03:40:21] [V] [TRT] Tactic: 4182625619810185112 Time: 0.028508
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 4259547356717612415
[12/29/2021-03:40:21] [V] [TRT] Tactic: 4259547356717612415 Time: 0.013084
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: 4717285412741024953
[12/29/2021-03:40:21] [V] [TRT] Tactic: 4717285412741024953 Time: 0.022316
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:40:21] [V] [TRT] Tactic: 4734519122557206480 Time: 0.02996
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 5121596860264626879
[12/29/2021-03:40:21] [V] [TRT] Tactic: 5121596860264626879 Time: 0.030048
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:40:21] [V] [TRT] Tactic: 5136656982162849059 Time: 0.008224
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 5158259316594207439
[12/29/2021-03:40:21] [V] [TRT] Tactic: 5158259316594207439 Time: 0.012496
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 5966973378912044513
[12/29/2021-03:40:21] [V] [TRT] Tactic: 5966973378912044513 Time: 0.018224
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:40:21] [V] [TRT] Tactic: 6004789655466615912 Time: 0.012524
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:40:21] [V] [TRT] Tactic: 6146901278630392829 Time: 0.029444
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 6434020722187266170
[12/29/2021-03:40:21] [V] [TRT] Tactic: 6434020722187266170 Time: 0.030036
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:40:21] [V] [TRT] Tactic: 6781129591847482048 Time: 0.012488
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7191893591576074000
[12/29/2021-03:40:21] [V] [TRT] Tactic: 7191893591576074000 Time: 0.00858
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7438984192263206338
[12/29/2021-03:40:21] [V] [TRT] Tactic: 7438984192263206338 Time: 0.012116
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 7504901284678552178
[12/29/2021-03:40:21] [V] [TRT] Tactic: 7504901284678552178 Time: 0.017992
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:40:21] [V] [TRT] Tactic: 8096257414008860171 Time: 0.012388
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 9143438935315839085
[12/29/2021-03:40:21] [V] [TRT] Tactic: 9143438935315839085 Time: 0.009444
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:40:21] [V] [TRT] Tactic: -9165697322068360861 Time: 0.030156
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -9118785798277698619
[12/29/2021-03:40:21] [V] [TRT] Tactic: -9118785798277698619 Time: 0.020856
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:40:21] [V] [TRT] Tactic: -8263994888336646547 Time: 0.017928
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:40:21] [V] [TRT] Tactic: -8205948405243401049 Time: 0.008928
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -7992068592656168418
[12/29/2021-03:40:21] [V] [TRT] Tactic: -7992068592656168418 Time: 0.012208
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: -7842775553137511386
[12/29/2021-03:40:21] [V] [TRT] Tactic: -7842775553137511386 Time: 0.018336
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:40:21] [V] [TRT] Tactic: -7683887278997527517 Time: 0.009912
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -6400348606759295499
[12/29/2021-03:40:21] [V] [TRT] Tactic: -6400348606759295499 Time: 0.020636
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -5980889159865208399
[12/29/2021-03:40:21] [V] [TRT] Tactic: -5980889159865208399 Time: 0.032064
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5766140806760372989
[12/29/2021-03:40:21] [V] [TRT] Tactic: -5766140806760372989 Time: 0.027012
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5709079507616090666
[12/29/2021-03:40:21] [V] [TRT] Tactic: -5709079507616090666 Time: 0.01782
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5698636014239116282
[12/29/2021-03:40:21] [V] [TRT] Tactic: -5698636014239116282 Time: 0.029528
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:40:21] [V] [TRT] Tactic: -4933563390723451692 Time: 0.010052
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -4516822589357530549
[12/29/2021-03:40:21] [V] [TRT] Tactic: -4516822589357530549 Time: 0.027612
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -3413217501222406256
[12/29/2021-03:40:21] [V] [TRT] Tactic: -3413217501222406256 Time: 0.029756
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:40:21] [V] [TRT] Tactic: -3238475748440751107 Time: 0.012136
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:40:21] [V] [TRT] Tactic: -3182884991006484042 Time: 0.018084
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:40:21] [V] [TRT] Tactic: -3173468756112541306 Time: 0.008776
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2917455979290586480
[12/29/2021-03:40:21] [V] [TRT] Tactic: -2917455979290586480 Time: 0.032968
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -2571022005763160364
[12/29/2021-03:40:21] [V] [TRT] Tactic: -2571022005763160364 Time: 0.02468
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -2083778562631872334
[12/29/2021-03:40:21] [V] [TRT] Tactic: -2083778562631872334 Time: 0.012568
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:40:21] [V] [TRT] Tactic: -1546787387293556842 Time: 0.017788
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:40:21] [V] [TRT] Tactic: -1498626619443284096 Time: 0.013508
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:40:21] [V] [TRT] Tactic: -1283580231568512025 Time: 0.008892
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: -1173968681844185579
[12/29/2021-03:40:21] [V] [TRT] Tactic: -1173968681844185579 Time: 0.008836
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:40:21] [V] [TRT] Tactic: -762222380308749469 Time: 0.010076
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -556794153877490941
[12/29/2021-03:40:21] [V] [TRT] Tactic: -556794153877490941 Time: 0.010116
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:40:21] [V] [TRT] Tactic: -516725800067794372 Time: 0.029528
[12/29/2021-03:40:21] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -428104331444385564
[12/29/2021-03:40:21] [V] [TRT] Tactic: -428104331444385564 Time: 0.027688
[12/29/2021-03:40:21] [V] [TRT] Fastest Tactic: 5136656982162849059 Time: 0.008224
[12/29/2021-03:40:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5136656982162849059
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning format combination: Float(2048,16,4,1), Float(2048,16,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning format combination: Float(2048,1,512,128), Float(2048,1,512,128) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning format combination: Float(512,1:4,128,32), Float(512,1:4,128,32) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1), Float(2048,16,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1), Int8(512,16:4,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1), Int8(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning format combination: Int8(64,16:32,4,1), Float(64,16:32,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning format combination: Int8(64,16:32,4,1), Int8(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning format combination: Float(2048,16,4,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:21] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CudaDepthwiseConvolution)
[12/29/2021-03:40:21] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:21] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (FusedConvActConvolution)
[12/29/2021-03:40:21] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:21] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CudnnConvolution)
[12/29/2021-03:40:21] [V] [TRT] Tactic: 0 Time: 0.057956
[12/29/2021-03:40:21] [V] [TRT] Tactic: 1 Time: 0.047364
[12/29/2021-03:40:21] [V] [TRT] Tactic: 2 Time: 0.077604
[12/29/2021-03:40:21] [V] [TRT] Tactic: 5 skipped. Scratch requested: 196083712, available: 16777216
[12/29/2021-03:40:21] [V] [TRT] Tactic: 56 Time: 0.05804
[12/29/2021-03:40:21] [V] [TRT] Tactic: 57 Time: 0.04642
[12/29/2021-03:40:21] [V] [TRT] Tactic: 58 Time: 0.077304
[12/29/2021-03:40:21] [V] [TRT] Tactic: 61 skipped. Scratch requested: 196083712, available: 16777216
[12/29/2021-03:40:21] [V] [TRT] Tactic: 112 Time: 0.057968
[12/29/2021-03:40:21] [V] [TRT] Tactic: 113 Time: 0.28616
[12/29/2021-03:40:21] [V] [TRT] Tactic: 114 Time: 0.07736
[12/29/2021-03:40:21] [V] [TRT] Tactic: 117 skipped. Scratch requested: 196083712, available: 16777216
[12/29/2021-03:40:21] [V] [TRT] Fastest Tactic: 57 Time: 0.04642
[12/29/2021-03:40:21] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CaskConvolution)
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:40:21] [V] [TRT] Tactic: 4549827808004681195 Time: 0.116576
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:40:21] [V] [TRT] Tactic: 5779835512569528575 Time: 0.154232
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[12/29/2021-03:40:21] [V] [TRT] Tactic: 6053873026024413720 Time: 0.16098
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[12/29/2021-03:40:21] [V] [TRT] Tactic: 6767548733843469815 Time: 0.12174
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:40:21] [V] [TRT] Tactic: -6313876406580483184 Time: 0.147344
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:40:21] [V] [TRT] Tactic: -1123676555321336786 Time: 0.15936
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:40:21] [V] [TRT] Tactic: -701551393537224327 Time: 0.134752
[12/29/2021-03:40:21] [V] [TRT] Fastest Tactic: 4549827808004681195 Time: 0.116576
[12/29/2021-03:40:21] [V] [TRT] Setting workspace to 196083712enables more tactics for profiling
[12/29/2021-03:40:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 57
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning format combination: Float(2048,1,512,128) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:21] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CudnnConvolution)
[12/29/2021-03:40:21] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:21] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CaskConvolution)
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:21] [V] [TRT] Tactic: 2860655430572478466 Time: 0.088872
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:21] [V] [TRT] Tactic: 4474630279712975759 Time: 0.05386
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:21] [V] [TRT] Tactic: 4479823862704990365 Time: 0.050256
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:21] [V] [TRT] Tactic: 4696204239951173149 Time: 0.092416
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:21] [V] [TRT] Tactic: 5778138195697110003 Time: 0.153284
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:40:21] [V] [TRT] Tactic: 7155825427510256858 Time: 0.147636
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:21] [V] [TRT] Tactic: 8918020581761223752 Time: 0.14448
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:40:21] [V] [TRT] Tactic: -4756382386362004279 Time: 0.090064
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:40:21] [V] [TRT] Tactic: -3855385237722507464 Time: 0.160244
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:21] [V] [TRT] Tactic: -2809379259463049391 Time: 0.157176
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:21] [V] [TRT] Tactic: -504296718212024303 Time: 0.143888
[12/29/2021-03:40:21] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.050256
[12/29/2021-03:40:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning format combination: Float(512,1:4,128,32) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:21] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CudnnConvolution)
[12/29/2021-03:40:21] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:21] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CaskConvolution)
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:21] [V] [TRT] Tactic: 2860655430572478466 Time: 0.089076
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:21] [V] [TRT] Tactic: 4474630279712975759 Time: 0.053864
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:21] [V] [TRT] Tactic: 4479823862704990365 Time: 0.050276
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:21] [V] [TRT] Tactic: 4696204239951173149 Time: 0.092476
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:21] [V] [TRT] Tactic: 5778138195697110003 Time: 0.153336
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:40:21] [V] [TRT] Tactic: 7155825427510256858 Time: 0.147484
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:40:21] [V] [TRT] Tactic: 7342025736444949634 Time: 0.100812
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:21] [V] [TRT] Tactic: 8918020581761223752 Time: 0.14442
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:40:21] [V] [TRT] Tactic: -7377458734869418330 Time: 0.099224
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:40:21] [V] [TRT] Tactic: -5457304872213719461 Time: 0.10036
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:40:21] [V] [TRT] Tactic: -4756382386362004279 Time: 0.090308
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:40:21] [V] [TRT] Tactic: -3855385237722507464 Time: 0.160336
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:21] [V] [TRT] Tactic: -2809379259463049391 Time: 0.157184
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:21] [V] [TRT] Tactic: -504296718212024303 Time: 0.144116
[12/29/2021-03:40:21] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.050276
[12/29/2021-03:40:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:21] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CudaDepthwiseConvolution)
[12/29/2021-03:40:21] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:21] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CaskConvolution)
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 1332468635798226953
[12/29/2021-03:40:21] [V] [TRT] Tactic: 1332468635798226953 Time: 0.059572
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:40:21] [V] [TRT] Tactic: 1508480131241957639 Time: 0.0576
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 1947019689364377201
[12/29/2021-03:40:21] [V] [TRT] Tactic: 1947019689364377201 Time: 0.038356
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:40:21] [V] [TRT] Tactic: 3239257003214966313 Time: 0.058924
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:40:21] [V] [TRT] Tactic: 5592640619112287921 Time: 0.035024
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:40:21] [V] [TRT] Tactic: 7621465827583909090 Time: 0.036672
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:40:21] [V] [TRT] Tactic: -5576936487443445631 Time: 0.041404
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:40:21] [V] [TRT] Tactic: -2297737319934264721 Time: 0.049588
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:40:21] [V] [TRT] Tactic: -1425085658556684465 Time: 0.042988
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:40:21] [V] [TRT] Tactic: -108011214168778087 Time: 0.043868
[12/29/2021-03:40:21] [V] [TRT] Fastest Tactic: 5592640619112287921 Time: 0.035024
[12/29/2021-03:40:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5592640619112287921
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:21] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CudaDepthwiseConvolution)
[12/29/2021-03:40:21] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:21] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (FusedConvActConvolution)
[12/29/2021-03:40:21] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:21] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CaskConvolution)
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:40:21] [V] [TRT] Tactic: 175853789719975416 Time: 0.047456
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:40:21] [V] [TRT] Tactic: 2171150287007712632 Time: 0.040828
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:40:21] [V] [TRT] Tactic: 2234457234705232274 Time: 0.034304
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:40:21] [V] [TRT] Tactic: 5834048089706882838 Time: 0.039032
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:40:21] [V] [TRT] Tactic: -8626990807754934295 Time: 0.041856
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:40:21] [V] [TRT] Tactic: -7303593854972602201 Time: 0.032816
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:40:21] [V] [TRT] Tactic: -6585664687867083638 Time: 0.054584
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: -3730012925709297561
[12/29/2021-03:40:21] [V] [TRT] Tactic: -3730012925709297561 Time: 0.035864
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: -2277259417488004546
[12/29/2021-03:40:21] [V] [TRT] Tactic: -2277259417488004546 Time: 0.055284
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:40:21] [V] [TRT] Tactic: -683636008127039856 Time: 0.053332
[12/29/2021-03:40:21] [V] [TRT] Fastest Tactic: -7303593854972602201 Time: 0.032816
[12/29/2021-03:40:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7303593854972602201
[12/29/2021-03:40:21] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:21] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CaskConvolution)
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 984309058095623735
[12/29/2021-03:40:21] [V] [TRT] Tactic: 984309058095623735 Time: 0.035604
[12/29/2021-03:40:21] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:40:22] [V] [TRT] Tactic: 1100922622480907544 Time: 0.041616
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 3238312825609165543
[12/29/2021-03:40:22] [V] [TRT] Tactic: 3238312825609165543 Time: 0.054776
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:40:22] [V] [TRT] Tactic: 3606311198834416176 Time: 0.038752
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:40:22] [V] [TRT] Tactic: 4325765560739862899 Time: 0.052756
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:40:22] [V] [TRT] Tactic: -4255737803793506479 Time: 0.05408
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:40:22] [V] [TRT] Tactic: -3958182351168863467 Time: 0.03266
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:40:22] [V] [TRT] Tactic: -3111968753064955248 Time: 0.040528
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:40:22] [V] [TRT] Tactic: -1492575840277333548 Time: 0.047264
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:40:22] [V] [TRT] Tactic: -868495160148524802 Time: 0.03416
[12/29/2021-03:40:22] [V] [TRT] Fastest Tactic: -3958182351168863467 Time: 0.03266
[12/29/2021-03:40:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3958182351168863467
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning format combination: Int8(64,16:32,4,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:22] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CaskConvolution)
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:40:22] [V] [TRT] Tactic: 1011019097971850911 Time: 0.0193
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:40:22] [V] [TRT] Tactic: 1071114551801767124 Time: 0.013084
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:40:22] [V] [TRT] Tactic: 2623576043214044314 Time: 0.00926
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:40:22] [V] [TRT] Tactic: 3281631721811475881 Time: 0.010292
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:40:22] [V] [TRT] Tactic: 4551754795416974366 Time: 0.010072
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:40:22] [V] [TRT] Tactic: 4925112190271421402 Time: 0.008984
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:40:22] [V] [TRT] Tactic: 5012796702462679112 Time: 0.031912
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:40:22] [V] [TRT] Tactic: 5041593333398049019 Time: 0.008612
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:40:22] [V] [TRT] Tactic: 5166018662410176512 Time: 0.031872
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:40:22] [V] [TRT] Tactic: 6191867932654611882 Time: 0.02002
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:40:22] [V] [TRT] Tactic: 6556170942941957134 Time: 0.02192
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:40:22] [V] [TRT] Tactic: 6852868042694587230 Time: 0.010432
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:40:22] [V] [TRT] Tactic: 8399092794516815300 Time: 0.035128
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:40:22] [V] [TRT] Tactic: -9132922677633967263 Time: 0.013552
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:40:22] [V] [TRT] Tactic: -7988637803896331454 Time: 0.020584
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: -7865001268126363229
[12/29/2021-03:40:22] [V] [TRT] Tactic: -7865001268126363229 Time: 0.023916
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:40:22] [V] [TRT] Tactic: -7606074703023778034 Time: 0.020856
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:40:22] [V] [TRT] Tactic: -7413564913826321357 Time: 0.01942
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:40:22] [V] [TRT] Tactic: -7282232519526877434 Time: 0.031256
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:40:22] [V] [TRT] Tactic: -5942379529065248478 Time: 0.012972
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:40:22] [V] [TRT] Tactic: -5603587790314027122 Time: 0.02224
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:40:22] [V] [TRT] Tactic: -5334776871777565833 Time: 0.03248
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:40:22] [V] [TRT] Tactic: -5157868397078537095 Time: 0.020116
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:40:22] [V] [TRT] Tactic: -5100834417027499764 Time: 0.009492
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:40:22] [V] [TRT] Tactic: -3365360067423513506 Time: 0.008136
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2194148180068068313
[12/29/2021-03:40:22] [V] [TRT] Tactic: -2194148180068068313 Time: 0.031552
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:40:22] [V] [TRT] Tactic: -1782593837177056527 Time: 0.013588
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:40:22] [V] [TRT] Tactic: -1610768292520086910 Time: 0.022216
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:40:22] [V] [TRT] Tactic: -1573035963956198975 Time: 0.034772
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -1558762241666006941
[12/29/2021-03:40:22] [V] [TRT] Tactic: -1558762241666006941 Time: 0.023716
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -1365353082499976145
[12/29/2021-03:40:22] [V] [TRT] Tactic: -1365353082499976145 Time: 0.023228
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:40:22] [V] [TRT] Tactic: -621838502160440068 Time: 0.023156
[12/29/2021-03:40:22] [V] [TRT] Fastest Tactic: -3365360067423513506 Time: 0.008136
[12/29/2021-03:40:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3365360067423513506
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning format combination: Int8(64,16:32,4,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:22] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CudaGroupConvolution)
[12/29/2021-03:40:22] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:22] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CudaDepthwiseConvolution)
[12/29/2021-03:40:22] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:22] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (FusedConvActConvolution)
[12/29/2021-03:40:22] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:22] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CaskConvolution)
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 177040020707947851
[12/29/2021-03:40:22] [V] [TRT] Tactic: 177040020707947851 Time: 0.009848
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 1550399266192842845
[12/29/2021-03:40:22] [V] [TRT] Tactic: 1550399266192842845 Time: 0.009032
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 1572887561103143487
[12/29/2021-03:40:22] [V] [TRT] Tactic: 1572887561103143487 Time: 0.012736
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:40:22] [V] [TRT] Tactic: 2325023763229477890 Time: 0.01866
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 2985940154541537814
[12/29/2021-03:40:22] [V] [TRT] Tactic: 2985940154541537814 Time: 0.021928
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:40:22] [V] [TRT] Tactic: 3284282970967328046 Time: 0.008264
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:40:22] [V] [TRT] Tactic: 3401614690060226673 Time: 0.009336
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3512426920013359699
[12/29/2021-03:40:22] [V] [TRT] Tactic: 3512426920013359699 Time: 0.0098
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 3899284354987683408
[12/29/2021-03:40:22] [V] [TRT] Tactic: 3899284354987683408 Time: 0.032588
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:40:22] [V] [TRT] Tactic: 4042202769383439184 Time: 0.012276
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: 4182625619810185112
[12/29/2021-03:40:22] [V] [TRT] Tactic: 4182625619810185112 Time: 0.023912
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 4259547356717612415
[12/29/2021-03:40:22] [V] [TRT] Tactic: 4259547356717612415 Time: 0.013248
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: 4717285412741024953
[12/29/2021-03:40:22] [V] [TRT] Tactic: 4717285412741024953 Time: 0.022216
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:40:22] [V] [TRT] Tactic: 4734519122557206480 Time: 0.029828
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 5121596860264626879
[12/29/2021-03:40:22] [V] [TRT] Tactic: 5121596860264626879 Time: 0.030016
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:40:22] [V] [TRT] Tactic: 5136656982162849059 Time: 0.008092
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 5158259316594207439
[12/29/2021-03:40:22] [V] [TRT] Tactic: 5158259316594207439 Time: 0.01248
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 5966973378912044513
[12/29/2021-03:40:22] [V] [TRT] Tactic: 5966973378912044513 Time: 0.018244
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:40:22] [V] [TRT] Tactic: 6004789655466615912 Time: 0.01274
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:40:22] [V] [TRT] Tactic: 6146901278630392829 Time: 0.029488
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 6434020722187266170
[12/29/2021-03:40:22] [V] [TRT] Tactic: 6434020722187266170 Time: 0.030164
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:40:22] [V] [TRT] Tactic: 6781129591847482048 Time: 0.012544
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7191893591576074000
[12/29/2021-03:40:22] [V] [TRT] Tactic: 7191893591576074000 Time: 0.008596
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7438984192263206338
[12/29/2021-03:40:22] [V] [TRT] Tactic: 7438984192263206338 Time: 0.01202
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 7504901284678552178
[12/29/2021-03:40:22] [V] [TRT] Tactic: 7504901284678552178 Time: 0.018
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:40:22] [V] [TRT] Tactic: 8096257414008860171 Time: 0.012212
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 9143438935315839085
[12/29/2021-03:40:22] [V] [TRT] Tactic: 9143438935315839085 Time: 0.009604
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:40:22] [V] [TRT] Tactic: -9165697322068360861 Time: 0.030176
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -9118785798277698619
[12/29/2021-03:40:22] [V] [TRT] Tactic: -9118785798277698619 Time: 0.0209
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:40:22] [V] [TRT] Tactic: -8263994888336646547 Time: 0.018148
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:40:22] [V] [TRT] Tactic: -8205948405243401049 Time: 0.0089
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -7992068592656168418
[12/29/2021-03:40:22] [V] [TRT] Tactic: -7992068592656168418 Time: 0.012268
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: -7842775553137511386
[12/29/2021-03:40:22] [V] [TRT] Tactic: -7842775553137511386 Time: 0.01842
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:40:22] [V] [TRT] Tactic: -7683887278997527517 Time: 0.010008
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -6400348606759295499
[12/29/2021-03:40:22] [V] [TRT] Tactic: -6400348606759295499 Time: 0.020536
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -5980889159865208399
[12/29/2021-03:40:22] [V] [TRT] Tactic: -5980889159865208399 Time: 0.031952
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5766140806760372989
[12/29/2021-03:40:22] [V] [TRT] Tactic: -5766140806760372989 Time: 0.022256
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5709079507616090666
[12/29/2021-03:40:22] [V] [TRT] Tactic: -5709079507616090666 Time: 0.0178
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5698636014239116282
[12/29/2021-03:40:22] [V] [TRT] Tactic: -5698636014239116282 Time: 0.029524
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:40:22] [V] [TRT] Tactic: -4933563390723451692 Time: 0.009876
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -4516822589357530549
[12/29/2021-03:40:22] [V] [TRT] Tactic: -4516822589357530549 Time: 0.0233
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -3413217501222406256
[12/29/2021-03:40:22] [V] [TRT] Tactic: -3413217501222406256 Time: 0.029796
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:40:22] [V] [TRT] Tactic: -3238475748440751107 Time: 0.012112
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:40:22] [V] [TRT] Tactic: -3182884991006484042 Time: 0.018252
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:40:22] [V] [TRT] Tactic: -3173468756112541306 Time: 0.008536
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2917455979290586480
[12/29/2021-03:40:22] [V] [TRT] Tactic: -2917455979290586480 Time: 0.03208
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -2571022005763160364
[12/29/2021-03:40:22] [V] [TRT] Tactic: -2571022005763160364 Time: 0.023544
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -2083778562631872334
[12/29/2021-03:40:22] [V] [TRT] Tactic: -2083778562631872334 Time: 0.012428
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:40:22] [V] [TRT] Tactic: -1546787387293556842 Time: 0.017712
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:40:22] [V] [TRT] Tactic: -1498626619443284096 Time: 0.013468
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:40:22] [V] [TRT] Tactic: -1283580231568512025 Time: 0.008732
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: -1173968681844185579
[12/29/2021-03:40:22] [V] [TRT] Tactic: -1173968681844185579 Time: 0.008592
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:40:22] [V] [TRT] Tactic: -762222380308749469 Time: 0.009988
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -556794153877490941
[12/29/2021-03:40:22] [V] [TRT] Tactic: -556794153877490941 Time: 0.010016
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:40:22] [V] [TRT] Tactic: -516725800067794372 Time: 0.02956
[12/29/2021-03:40:22] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -428104331444385564
[12/29/2021-03:40:22] [V] [TRT] Tactic: -428104331444385564 Time: 0.023316
[12/29/2021-03:40:22] [V] [TRT] Fastest Tactic: 5136656982162849059 Time: 0.008092
[12/29/2021-03:40:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5136656982162849059
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:40:22] [V] [TRT] *************** Autotuning format combination: Float(2048,16,4,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:22] [V] [TRT] --------------- Timing Runner: Conv_75 (CudaDepthwiseConvolution)
[12/29/2021-03:40:22] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:22] [V] [TRT] --------------- Timing Runner: Conv_75 (FusedConvActConvolution)
[12/29/2021-03:40:22] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:22] [V] [TRT] --------------- Timing Runner: Conv_75 (CudnnConvolution)
[12/29/2021-03:40:22] [V] [TRT] Tactic: 0 Time: 0.014272
[12/29/2021-03:40:22] [V] [TRT] Tactic: 1 Time: 0.01432
[12/29/2021-03:40:22] [V] [TRT] Tactic: 2 Time: 0.05098
[12/29/2021-03:40:22] [V] [TRT] Tactic: 56 Time: 0.014344
[12/29/2021-03:40:22] [V] [TRT] Tactic: 57 Time: 0.014288
[12/29/2021-03:40:22] [V] [TRT] Tactic: 58 Time: 0.050952
[12/29/2021-03:40:22] [V] [TRT] Tactic: 112 Time: 0.014292
[12/29/2021-03:40:22] [V] [TRT] Tactic: 113 Time: 0.014244
[12/29/2021-03:40:22] [V] [TRT] Tactic: 114 Time: 0.050996
[12/29/2021-03:40:22] [V] [TRT] Fastest Tactic: 113 Time: 0.014244
[12/29/2021-03:40:22] [V] [TRT] --------------- Timing Runner: Conv_75 (CaskConvolution)
[12/29/2021-03:40:22] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:40:22] [V] [TRT] Tactic: 4549827808004681195 Time: 0.022016
[12/29/2021-03:40:22] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:40:22] [V] [TRT] Tactic: 5779835512569528575 Time: 0.030884
[12/29/2021-03:40:22] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 9151672657204310840
[12/29/2021-03:40:22] [V] [TRT] Tactic: 9151672657204310840 Time: 0.036988
[12/29/2021-03:40:22] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: -7491730084094677098
[12/29/2021-03:40:22] [V] [TRT] Tactic: -7491730084094677098 Time: 0.025348
[12/29/2021-03:40:22] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:40:22] [V] [TRT] Tactic: -6313876406580483184 Time: 0.026552
[12/29/2021-03:40:22] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: -6273689210331812572
[12/29/2021-03:40:22] [V] [TRT] Tactic: -6273689210331812572 Time: 0.03068
[12/29/2021-03:40:22] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: -4337126844824617177
[12/29/2021-03:40:22] [V] [TRT] Tactic: -4337126844824617177 Time: 0.020984
[12/29/2021-03:40:22] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:40:23] [V] [TRT] Tactic: -1123676555321336786 Time: 0.030908
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:40:23] [V] [TRT] Tactic: -701551393537224327 Time: 0.022296
[12/29/2021-03:40:23] [V] [TRT] Fastest Tactic: -4337126844824617177 Time: 0.020984
[12/29/2021-03:40:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 113
[12/29/2021-03:40:23] [V] [TRT] *************** Autotuning format combination: Float(2048,1,512,128) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:23] [V] [TRT] --------------- Timing Runner: Conv_75 (CudnnConvolution)
[12/29/2021-03:40:23] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:23] [V] [TRT] --------------- Timing Runner: Conv_75 (CaskConvolution)
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 1663866669559596164
[12/29/2021-03:40:23] [V] [TRT] Tactic: 1663866669559596164 Time: 0.025012
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:23] [V] [TRT] Tactic: 2860655430572478466 Time: 0.017572
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:23] [V] [TRT] Tactic: 4474630279712975759 Time: 0.013348
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:23] [V] [TRT] Tactic: 4479823862704990365 Time: 0.013324
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:23] [V] [TRT] Tactic: 4696204239951173149 Time: 0.017436
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:23] [V] [TRT] Tactic: 5778138195697110003 Time: 0.025572
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:23] [V] [TRT] Tactic: 8918020581761223752 Time: 0.023892
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -5905193483742532701
[12/29/2021-03:40:23] [V] [TRT] Tactic: -5905193483742532701 Time: 0.016404
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -4035591156787122265
[12/29/2021-03:40:23] [V] [TRT] Tactic: -4035591156787122265 Time: 0.013064
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:23] [V] [TRT] Tactic: -2809379259463049391 Time: 0.025392
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -1985235291706575900
[12/29/2021-03:40:23] [V] [TRT] Tactic: -1985235291706575900 Time: 0.02386
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:23] [V] [TRT] Tactic: -504296718212024303 Time: 0.02406
[12/29/2021-03:40:23] [V] [TRT] Fastest Tactic: -4035591156787122265 Time: 0.013064
[12/29/2021-03:40:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4035591156787122265
[12/29/2021-03:40:23] [V] [TRT] *************** Autotuning format combination: Float(512,1:4,128,32) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:23] [V] [TRT] --------------- Timing Runner: Conv_75 (CudnnConvolution)
[12/29/2021-03:40:23] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:23] [V] [TRT] --------------- Timing Runner: Conv_75 (CaskConvolution)
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 1373022415249282411
[12/29/2021-03:40:23] [V] [TRT] Tactic: 1373022415249282411 Time: 0.018396
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 1663866669559596164
[12/29/2021-03:40:23] [V] [TRT] Tactic: 1663866669559596164 Time: 0.025168
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:23] [V] [TRT] Tactic: 2860655430572478466 Time: 0.0177
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:23] [V] [TRT] Tactic: 4474630279712975759 Time: 0.013556
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:23] [V] [TRT] Tactic: 4479823862704990365 Time: 0.013372
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:23] [V] [TRT] Tactic: 4696204239951173149 Time: 0.01752
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:23] [V] [TRT] Tactic: 5778138195697110003 Time: 0.025336
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:40:23] [V] [TRT] Tactic: 7342025736444949634 Time: 0.018616
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:23] [V] [TRT] Tactic: 8918020581761223752 Time: 0.02374
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -5905193483742532701
[12/29/2021-03:40:23] [V] [TRT] Tactic: -5905193483742532701 Time: 0.016256
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:40:23] [V] [TRT] Tactic: -5457304872213719461 Time: 0.018944
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -4035591156787122265
[12/29/2021-03:40:23] [V] [TRT] Tactic: -4035591156787122265 Time: 0.013016
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:23] [V] [TRT] Tactic: -2809379259463049391 Time: 0.025128
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -1985235291706575900
[12/29/2021-03:40:23] [V] [TRT] Tactic: -1985235291706575900 Time: 0.02362
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:23] [V] [TRT] Tactic: -504296718212024303 Time: 0.023824
[12/29/2021-03:40:23] [V] [TRT] Fastest Tactic: -4035591156787122265 Time: 0.013016
[12/29/2021-03:40:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4035591156787122265
[12/29/2021-03:40:23] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:23] [V] [TRT] --------------- Timing Runner: Conv_75 (CudaDepthwiseConvolution)
[12/29/2021-03:40:23] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:23] [V] [TRT] --------------- Timing Runner: Conv_75 (CaskConvolution)
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:40:23] [V] [TRT] Tactic: 1508480131241957639 Time: 0.018292
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 2141154648944475104
[12/29/2021-03:40:23] [V] [TRT] Tactic: 2141154648944475104 Time: 0.018156
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:40:23] [V] [TRT] Tactic: 3239257003214966313 Time: 0.01824
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:40:23] [V] [TRT] Tactic: 5592640619112287921 Time: 0.012388
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:40:23] [V] [TRT] Tactic: 7621465827583909090 Time: 0.013108
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: -6580271968881459581
[12/29/2021-03:40:23] [V] [TRT] Tactic: -6580271968881459581 Time: 0.013284
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:40:23] [V] [TRT] Tactic: -5576936487443445631 Time: 0.013216
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: -4443833619060044580
[12/29/2021-03:40:23] [V] [TRT] Tactic: -4443833619060044580 Time: 0.012232
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:40:23] [V] [TRT] Tactic: -2297737319934264721 Time: 0.014036
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:40:23] [V] [TRT] Tactic: -1425085658556684465 Time: 0.012924
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:40:23] [V] [TRT] Tactic: -108011214168778087 Time: 0.013532
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: -42427192380281294
[12/29/2021-03:40:23] [V] [TRT] Tactic: -42427192380281294 Time: 0.0129
[12/29/2021-03:40:23] [V] [TRT] Fastest Tactic: -4443833619060044580 Time: 0.012232
[12/29/2021-03:40:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4443833619060044580
[12/29/2021-03:40:23] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:23] [V] [TRT] --------------- Timing Runner: Conv_75 (CudaDepthwiseConvolution)
[12/29/2021-03:40:23] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:23] [V] [TRT] --------------- Timing Runner: Conv_75 (FusedConvActConvolution)
[12/29/2021-03:40:23] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:23] [V] [TRT] --------------- Timing Runner: Conv_75 (CaskConvolution)
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:40:23] [V] [TRT] Tactic: 175853789719975416 Time: 0.01186
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:40:23] [V] [TRT] Tactic: 2171150287007712632 Time: 0.011032
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:40:23] [V] [TRT] Tactic: 2234457234705232274 Time: 0.010728
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:40:23] [V] [TRT] Tactic: 5834048089706882838 Time: 0.010872
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 6299962968199310600
[12/29/2021-03:40:23] [V] [TRT] Tactic: 6299962968199310600 Time: 0.013936
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 6341572697076960911
[12/29/2021-03:40:23] [V] [TRT] Tactic: 6341572697076960911 Time: 0.010464
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:40:23] [V] [TRT] Tactic: -8626990807754934295 Time: 0.011532
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: -8498217049614706532
[12/29/2021-03:40:23] [V] [TRT] Tactic: -8498217049614706532 Time: 0.010432
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:40:23] [V] [TRT] Tactic: -7303593854972602201 Time: 0.01042
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:40:23] [V] [TRT] Tactic: -6585664687867083638 Time: 0.013976
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: -3326139578711341011
[12/29/2021-03:40:23] [V] [TRT] Tactic: -3326139578711341011 Time: 0.011452
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:40:23] [V] [TRT] Tactic: -683636008127039856 Time: 0.013952
[12/29/2021-03:40:23] [V] [TRT] Fastest Tactic: -7303593854972602201 Time: 0.01042
[12/29/2021-03:40:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7303593854972602201
[12/29/2021-03:40:23] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:23] [V] [TRT] --------------- Timing Runner: Conv_75 (CaskConvolution)
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:40:23] [V] [TRT] Tactic: 1100922622480907544 Time: 0.011256
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_c32_nn_v1 Tactic: 2855900226702061782
[12/29/2021-03:40:23] [V] [TRT] Tactic: 2855900226702061782 Time: 0.013268
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:40:23] [V] [TRT] Tactic: 3606311198834416176 Time: 0.010428
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:40:23] [V] [TRT] Tactic: 4325765560739862899 Time: 0.013488
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 8803458114157674373
[12/29/2021-03:40:23] [V] [TRT] Tactic: 8803458114157674373 Time: 0.010244
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: -6934773036503365000
[12/29/2021-03:40:23] [V] [TRT] Tactic: -6934773036503365000 Time: 0.011332
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: -4431642509665791294
[12/29/2021-03:40:23] [V] [TRT] Tactic: -4431642509665791294 Time: 0.010216
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:40:23] [V] [TRT] Tactic: -4255737803793506479 Time: 0.013484
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:40:23] [V] [TRT] Tactic: -3958182351168863467 Time: 0.010148
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:40:23] [V] [TRT] Tactic: -3111968753064955248 Time: 0.010848
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:40:23] [V] [TRT] Tactic: -1492575840277333548 Time: 0.011728
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:40:23] [V] [TRT] Tactic: -868495160148524802 Time: 0.010548
[12/29/2021-03:40:23] [V] [TRT] Fastest Tactic: -3958182351168863467 Time: 0.010148
[12/29/2021-03:40:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3958182351168863467
[12/29/2021-03:40:23] [V] [TRT] *************** Autotuning format combination: Int8(64,16:32,4,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:23] [V] [TRT] --------------- Timing Runner: Conv_75 (CaskConvolution)
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:40:23] [V] [TRT] Tactic: 2623576043214044314 Time: 0.006376
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 2818014835119698671
[12/29/2021-03:40:23] [V] [TRT] Tactic: 2818014835119698671 Time: 0.008092
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 3721599319722771137
[12/29/2021-03:40:23] [V] [TRT] Tactic: 3721599319722771137 Time: 0.00618
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_interior_nt_v1 Tactic: 4178917718361232468
[12/29/2021-03:40:23] [V] [TRT] Tactic: 4178917718361232468 Time: 0.009308
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:40:23] [V] [TRT] Tactic: 4551754795416974366 Time: 0.006576
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:40:23] [V] [TRT] Tactic: 4925112190271421402 Time: 0.006296
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:40:23] [V] [TRT] Tactic: 5012796702462679112 Time: 0.011036
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:40:23] [V] [TRT] Tactic: 6556170942941957134 Time: 0.009468
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 6618077155362058131
[12/29/2021-03:40:23] [V] [TRT] Tactic: 6618077155362058131 Time: 0.006036
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:40:23] [V] [TRT] Tactic: 6852868042694587230 Time: 0.007072
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 6969462133921577484
[12/29/2021-03:40:23] [V] [TRT] Tactic: 6969462133921577484 Time: 0.01524
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:40:23] [V] [TRT] Tactic: 8399092794516815300 Time: 0.015536
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:40:23] [V] [TRT] Tactic: -9132922677633967263 Time: 0.008044
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -8912999970161746151
[12/29/2021-03:40:23] [V] [TRT] Tactic: -8912999970161746151 Time: 0.007996
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -8893439100868426414
[12/29/2021-03:40:23] [V] [TRT] Tactic: -8893439100868426414 Time: 0.009128
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:40:23] [V] [TRT] Tactic: -7988637803896331454 Time: 0.009504
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_interior_nt_v1 Tactic: -7904635102498369361
[12/29/2021-03:40:23] [V] [TRT] Tactic: -7904635102498369361 Time: 0.010912
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:40:23] [V] [TRT] Tactic: -7606074703023778034 Time: 0.009352
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:40:23] [V] [TRT] Tactic: -7413564913826321357 Time: 0.00932
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:40:23] [V] [TRT] Tactic: -7282232519526877434 Time: 0.010984
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -6406011580107094428
[12/29/2021-03:40:23] [V] [TRT] Tactic: -6406011580107094428 Time: 0.006776
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:40:23] [V] [TRT] Tactic: -5603587790314027122 Time: 0.009512
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_interior_nt_v1 Tactic: -5416590980288859834
[12/29/2021-03:40:23] [V] [TRT] Tactic: -5416590980288859834 Time: 0.009508
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:40:23] [V] [TRT] Tactic: -5334776871777565833 Time: 0.012764
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:40:23] [V] [TRT] Tactic: -5157868397078537095 Time: 0.010584
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -3665201838779845683
[12/29/2021-03:40:23] [V] [TRT] Tactic: -3665201838779845683 Time: 0.012344
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_interior_nt_v1 Tactic: -3644377136375731441
[12/29/2021-03:40:23] [V] [TRT] Tactic: -3644377136375731441 Time: 0.009364
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -3502495740607894730
[12/29/2021-03:40:23] [V] [TRT] Tactic: -3502495740607894730 Time: 0.00604
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -2342404147487779225
[12/29/2021-03:40:23] [V] [TRT] Tactic: -2342404147487779225 Time: 0.010596
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:40:23] [V] [TRT] Tactic: -1782593837177056527 Time: 0.008272
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:40:23] [V] [TRT] Tactic: -1610768292520086910 Time: 0.009428
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:40:23] [V] [TRT] Tactic: -621838502160440068 Time: 0.009464
[12/29/2021-03:40:23] [V] [TRT] Fastest Tactic: 6618077155362058131 Time: 0.006036
[12/29/2021-03:40:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6618077155362058131
[12/29/2021-03:40:23] [V] [TRT] *************** Autotuning format combination: Int8(64,16:32,4,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:23] [V] [TRT] --------------- Timing Runner: Conv_75 (CudaGroupConvolution)
[12/29/2021-03:40:23] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:23] [V] [TRT] --------------- Timing Runner: Conv_75 (CudaDepthwiseConvolution)
[12/29/2021-03:40:23] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:23] [V] [TRT] --------------- Timing Runner: Conv_75 (FusedConvActConvolution)
[12/29/2021-03:40:23] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:23] [V] [TRT] --------------- Timing Runner: Conv_75 (CaskConvolution)
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 177040020707947851
[12/29/2021-03:40:23] [V] [TRT] Tactic: 177040020707947851 Time: 0.006596
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_interior_nt_v1 Tactic: 434957160407688216
[12/29/2021-03:40:23] [V] [TRT] Tactic: 434957160407688216 Time: 0.011384
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 805889586762897346
[12/29/2021-03:40:23] [V] [TRT] Tactic: 805889586762897346 Time: 0.010352
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 1550399266192842845
[12/29/2021-03:40:23] [V] [TRT] Tactic: 1550399266192842845 Time: 0.006288
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:40:23] [V] [TRT] Tactic: 2325023763229477890 Time: 0.008308
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_interior_nt_v1 Tactic: 2346437292116182513
[12/29/2021-03:40:23] [V] [TRT] Tactic: 2346437292116182513 Time: 0.009344
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_interior_nt_v1 Tactic: 2522133112320625287
[12/29/2021-03:40:23] [V] [TRT] Tactic: 2522133112320625287 Time: 0.009392
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 2985940154541537814
[12/29/2021-03:40:23] [V] [TRT] Tactic: 2985940154541537814 Time: 0.009392
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 3538565962642681625
[12/29/2021-03:40:23] [V] [TRT] Tactic: 3538565962642681625 Time: 0.006232
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 3899284354987683408
[12/29/2021-03:40:23] [V] [TRT] Tactic: 3899284354987683408 Time: 0.011712
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:40:23] [V] [TRT] Tactic: 4042202769383439184 Time: 0.007184
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 4259547356717612415
[12/29/2021-03:40:23] [V] [TRT] Tactic: 4259547356717612415 Time: 0.007488
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: 4717285412741024953
[12/29/2021-03:40:23] [V] [TRT] Tactic: 4717285412741024953 Time: 0.009528
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:40:23] [V] [TRT] Tactic: 4734519122557206480 Time: 0.010644
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 5121596860264626879
[12/29/2021-03:40:23] [V] [TRT] Tactic: 5121596860264626879 Time: 0.01058
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_interior_nt_v1 Tactic: 5126565865931538390
[12/29/2021-03:40:23] [V] [TRT] Tactic: 5126565865931538390 Time: 0.009428
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 5158259316594207439
[12/29/2021-03:40:23] [V] [TRT] Tactic: 5158259316594207439 Time: 0.007148
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 5375256703210220108
[12/29/2021-03:40:23] [V] [TRT] Tactic: 5375256703210220108 Time: 0.007124
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 6433368103202497147
[12/29/2021-03:40:23] [V] [TRT] Tactic: 6433368103202497147 Time: 0.008164
[12/29/2021-03:40:23] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 6434020722187266170
[12/29/2021-03:40:24] [V] [TRT] Tactic: 6434020722187266170 Time: 0.01066
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 6441948709525127755
[12/29/2021-03:40:24] [V] [TRT] Tactic: 6441948709525127755 Time: 0.005884
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 6457435868048963632
[12/29/2021-03:40:24] [V] [TRT] Tactic: 6457435868048963632 Time: 0.006896
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:40:24] [V] [TRT] Tactic: 6781129591847482048 Time: 0.007252
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 6925201228918187099
[12/29/2021-03:40:24] [V] [TRT] Tactic: 6925201228918187099 Time: 0.008292
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 7504901284678552178
[12/29/2021-03:40:24] [V] [TRT] Tactic: 7504901284678552178 Time: 0.008268
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 7731430299029542276
[12/29/2021-03:40:24] [V] [TRT] Tactic: 7731430299029542276 Time: 0.008136
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 7738495016763012180
[12/29/2021-03:40:24] [V] [TRT] Tactic: 7738495016763012180 Time: 0.010408
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 8234775147403903473
[12/29/2021-03:40:24] [V] [TRT] Tactic: 8234775147403903473 Time: 0.010248
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:40:24] [V] [TRT] Tactic: -9165697322068360861 Time: 0.010576
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -9118785798277698619
[12/29/2021-03:40:24] [V] [TRT] Tactic: -9118785798277698619 Time: 0.009348
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -8556775352640313933
[12/29/2021-03:40:24] [V] [TRT] Tactic: -8556775352640313933 Time: 0.00808
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:40:24] [V] [TRT] Tactic: -8263994888336646547 Time: 0.008244
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:40:24] [V] [TRT] Tactic: -8205948405243401049 Time: 0.006252
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: -7842775553137511386
[12/29/2021-03:40:24] [V] [TRT] Tactic: -7842775553137511386 Time: 0.008308
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:40:24] [V] [TRT] Tactic: -7683887278997527517 Time: 0.006664
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -6527178416855951297
[12/29/2021-03:40:24] [V] [TRT] Tactic: -6527178416855951297 Time: 0.006204
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -6510232214299595844
[12/29/2021-03:40:24] [V] [TRT] Tactic: -6510232214299595844 Time: 0.006204
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -6400348606759295499
[12/29/2021-03:40:24] [V] [TRT] Tactic: -6400348606759295499 Time: 0.009216
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -5980889159865208399
[12/29/2021-03:40:24] [V] [TRT] Tactic: -5980889159865208399 Time: 0.01154
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5766140806760372989
[12/29/2021-03:40:24] [V] [TRT] Tactic: -5766140806760372989 Time: 0.009432
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -5170003087447722174
[12/29/2021-03:40:24] [V] [TRT] Tactic: -5170003087447722174 Time: 0.006024
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -4849712423393454704
[12/29/2021-03:40:24] [V] [TRT] Tactic: -4849712423393454704 Time: 0.006892
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -4516822589357530549
[12/29/2021-03:40:24] [V] [TRT] Tactic: -4516822589357530549 Time: 0.009636
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -3613322253849278738
[12/29/2021-03:40:24] [V] [TRT] Tactic: -3613322253849278738 Time: 0.005844
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -3577322188448771475
[12/29/2021-03:40:24] [V] [TRT] Tactic: -3577322188448771475 Time: 0.00714
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -2754311112012636251
[12/29/2021-03:40:24] [V] [TRT] Tactic: -2754311112012636251 Time: 0.007292
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: -2315453944962430928
[12/29/2021-03:40:24] [V] [TRT] Tactic: -2315453944962430928 Time: 0.010316
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -2083778562631872334
[12/29/2021-03:40:24] [V] [TRT] Tactic: -2083778562631872334 Time: 0.007128
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -1499578657823798783
[12/29/2021-03:40:24] [V] [TRT] Tactic: -1499578657823798783 Time: 0.006284
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:40:24] [V] [TRT] Tactic: -1498626619443284096 Time: 0.007368
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:40:24] [V] [TRT] Tactic: -1283580231568512025 Time: 0.00618
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: -1173968681844185579
[12/29/2021-03:40:24] [V] [TRT] Tactic: -1173968681844185579 Time: 0.006084
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:40:24] [V] [TRT] Tactic: -762222380308749469 Time: 0.00656
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -713022856474991236
[12/29/2021-03:40:24] [V] [TRT] Tactic: -713022856474991236 Time: 0.0058
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -556794153877490941
[12/29/2021-03:40:24] [V] [TRT] Tactic: -556794153877490941 Time: 0.0065
[12/29/2021-03:40:24] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -375949437730908730
[12/29/2021-03:40:24] [V] [TRT] Tactic: -375949437730908730 Time: 0.007016
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: -713022856474991236 Time: 0.0058
[12/29/2021-03:40:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -713022856474991236
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.009484
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.005096
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.005096
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.009556
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.005052
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.005052
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.00826
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.00466
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.00466
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.008184
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.005184
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.005184
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.009912
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.004784
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.004784
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.008304
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.005052
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.005052
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.008648
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.005152
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.005152
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.00836
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.005172
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.005172
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.009744
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.005024
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.005024
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.008268
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.004908
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.004908
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.009348
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.005268
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.005268
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.009352
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.005176
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.005176
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.009712
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.004984
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.004984
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.010004
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.005016
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.005016
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.008296
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.004984
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.004984
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.00906
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.005224
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.005224
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.008904
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.005192
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.005192
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.006956
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.004532
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.004532
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.009448
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.0058
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.0058
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.009688
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.005904
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.005904
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.00778
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.00494
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.00494
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.007052
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.005192
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.005192
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.008724
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.0059
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.0059
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.00964
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.006024
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.006024
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.00762
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.004632
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1 Time: 0.005012
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.004632
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.009492
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.004996
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.004996
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.010064
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.005004
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.005004
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.008476
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.004956
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.004956
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.00974
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.005356
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.005356
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1002 Time: 0.009144
[12/29/2021-03:40:24] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.00526
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 0 Time: 0.00526
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning format combination: Float(1024,4,2,1), Float(1024,4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CudaDepthwiseConvolution)
[12/29/2021-03:40:24] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (FusedConvActConvolution)
[12/29/2021-03:40:24] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CudnnConvolution)
[12/29/2021-03:40:24] [V] [TRT] Tactic: 0 Time: 0.1069
[12/29/2021-03:40:24] [V] [TRT] Tactic: 1 Time: 0.097508
[12/29/2021-03:40:24] [V] [TRT] Tactic: 2 Time: 0.110636
[12/29/2021-03:40:24] [V] [TRT] Tactic: 4 skipped. Scratch requested: 172228608, available: 16777216
[12/29/2021-03:40:24] [V] [TRT] Tactic: 5 skipped. Scratch requested: 356515840, available: 16777216
[12/29/2021-03:40:24] [V] [TRT] Tactic: 6 Time: 0.066716
[12/29/2021-03:40:24] [V] [TRT] Tactic: 56 Time: 0.106804
[12/29/2021-03:40:24] [V] [TRT] Tactic: 57 Time: 0.137292
[12/29/2021-03:40:24] [V] [TRT] Tactic: 58 Time: 0.110632
[12/29/2021-03:40:24] [V] [TRT] Tactic: 60 skipped. Scratch requested: 172228608, available: 16777216
[12/29/2021-03:40:24] [V] [TRT] Tactic: 61 skipped. Scratch requested: 356515840, available: 16777216
[12/29/2021-03:40:24] [V] [TRT] Tactic: 62 Time: 0.066708
[12/29/2021-03:40:24] [V] [TRT] Tactic: 112 Time: 0.10706
[12/29/2021-03:40:24] [V] [TRT] Tactic: 113 Time: 0.277356
[12/29/2021-03:40:24] [V] [TRT] Tactic: 114 Time: 0.110708
[12/29/2021-03:40:24] [V] [TRT] Tactic: 116 skipped. Scratch requested: 172228608, available: 16777216
[12/29/2021-03:40:24] [V] [TRT] Tactic: 117 skipped. Scratch requested: 356515840, available: 16777216
[12/29/2021-03:40:24] [V] [TRT] Tactic: 118 Time: 0.066628
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 118 Time: 0.066628
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CaskConvolution)
[12/29/2021-03:40:24] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:40:24] [V] [TRT] Tactic: 4549827808004681195 Time: 0.227576
[12/29/2021-03:40:24] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:40:24] [V] [TRT] Tactic: 5779835512569528575 Time: 0.303932
[12/29/2021-03:40:24] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[12/29/2021-03:40:24] [V] [TRT] Tactic: 6053873026024413720 Time: 0.318224
[12/29/2021-03:40:24] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[12/29/2021-03:40:24] [V] [TRT] Tactic: 6767548733843469815 Time: 0.234256
[12/29/2021-03:40:24] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:40:24] [V] [TRT] Tactic: -6313876406580483184 Time: 0.271312
[12/29/2021-03:40:24] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:40:24] [V] [TRT] Tactic: -1123676555321336786 Time: 0.311288
[12/29/2021-03:40:24] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:40:24] [V] [TRT] Tactic: -701551393537224327 Time: 0.261656
[12/29/2021-03:40:24] [V] [TRT] Fastest Tactic: 4549827808004681195 Time: 0.227576
[12/29/2021-03:40:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 118
[12/29/2021-03:40:24] [V] [TRT] *************** Autotuning format combination: Float(1024,1,512,256), Float(1024,1,512,256) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CudnnConvolution)
[12/29/2021-03:40:24] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:24] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CaskConvolution)
[12/29/2021-03:40:24] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:24] [V] [TRT] Tactic: 2860655430572478466 Time: 0.169956
[12/29/2021-03:40:24] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:24] [V] [TRT] Tactic: 4474630279712975759 Time: 0.100028
[12/29/2021-03:40:24] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:24] [V] [TRT] Tactic: 4479823862704990365 Time: 0.092808
[12/29/2021-03:40:24] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:24] [V] [TRT] Tactic: 4696204239951173149 Time: 0.176976
[12/29/2021-03:40:24] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:24] [V] [TRT] Tactic: 5778138195697110003 Time: 0.2911
[12/29/2021-03:40:24] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:40:24] [V] [TRT] Tactic: 7155825427510256858 Time: 0.286244
[12/29/2021-03:40:24] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:24] [V] [TRT] Tactic: 8918020581761223752 Time: 0.279864
[12/29/2021-03:40:24] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:40:24] [V] [TRT] Tactic: -4756382386362004279 Time: 0.172224
[12/29/2021-03:40:24] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:40:24] [V] [TRT] Tactic: -3855385237722507464 Time: 0.308104
[12/29/2021-03:40:24] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:25] [V] [TRT] Tactic: -2809379259463049391 Time: 0.30398
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:25] [V] [TRT] Tactic: -504296718212024303 Time: 0.279788
[12/29/2021-03:40:25] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.092808
[12/29/2021-03:40:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:40:25] [V] [TRT] *************** Autotuning format combination: Float(256,1:4,128,64), Float(256,1:4,128,64) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:25] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CudnnConvolution)
[12/29/2021-03:40:25] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:25] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CaskConvolution)
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:25] [V] [TRT] Tactic: 2860655430572478466 Time: 0.17028
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:25] [V] [TRT] Tactic: 4474630279712975759 Time: 0.100012
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:25] [V] [TRT] Tactic: 4479823862704990365 Time: 0.092808
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:25] [V] [TRT] Tactic: 4696204239951173149 Time: 0.176932
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:25] [V] [TRT] Tactic: 5778138195697110003 Time: 0.291268
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:40:25] [V] [TRT] Tactic: 7155825427510256858 Time: 0.286248
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:40:25] [V] [TRT] Tactic: 7342025736444949634 Time: 0.194932
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:25] [V] [TRT] Tactic: 8918020581761223752 Time: 0.280268
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:40:25] [V] [TRT] Tactic: -7377458734869418330 Time: 0.19188
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:40:25] [V] [TRT] Tactic: -5457304872213719461 Time: 0.1935
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:40:25] [V] [TRT] Tactic: -4756382386362004279 Time: 0.172384
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:40:25] [V] [TRT] Tactic: -3855385237722507464 Time: 0.308276
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:25] [V] [TRT] Tactic: -2809379259463049391 Time: 0.303808
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:25] [V] [TRT] Tactic: -504296718212024303 Time: 0.279792
[12/29/2021-03:40:25] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.092808
[12/29/2021-03:40:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:40:25] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1), Float(1024,4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:25] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CudaDepthwiseConvolution)
[12/29/2021-03:40:25] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:25] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CaskConvolution)
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 1332468635798226953
[12/29/2021-03:40:25] [V] [TRT] Tactic: 1332468635798226953 Time: 0.108164
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:40:25] [V] [TRT] Tactic: 1508480131241957639 Time: 0.105176
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 1947019689364377201
[12/29/2021-03:40:25] [V] [TRT] Tactic: 1947019689364377201 Time: 0.067416
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:40:25] [V] [TRT] Tactic: 3239257003214966313 Time: 0.107868
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:40:25] [V] [TRT] Tactic: 5592640619112287921 Time: 0.061792
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:40:25] [V] [TRT] Tactic: 7621465827583909090 Time: 0.065488
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:40:25] [V] [TRT] Tactic: -5576936487443445631 Time: 0.074068
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:40:25] [V] [TRT] Tactic: -2297737319934264721 Time: 0.08746
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:40:25] [V] [TRT] Tactic: -1425085658556684465 Time: 0.07804
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:40:25] [V] [TRT] Tactic: -108011214168778087 Time: 0.07582
[12/29/2021-03:40:25] [V] [TRT] Fastest Tactic: 5592640619112287921 Time: 0.061792
[12/29/2021-03:40:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5592640619112287921
[12/29/2021-03:40:25] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1), Int8(256,4:4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:25] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CudaDepthwiseConvolution)
[12/29/2021-03:40:25] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:25] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (FusedConvActConvolution)
[12/29/2021-03:40:25] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:25] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CaskConvolution)
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:40:25] [V] [TRT] Tactic: 175853789719975416 Time: 0.085996
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:40:25] [V] [TRT] Tactic: 2171150287007712632 Time: 0.075672
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:40:25] [V] [TRT] Tactic: 2234457234705232274 Time: 0.063556
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:40:25] [V] [TRT] Tactic: 5834048089706882838 Time: 0.07202
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:40:25] [V] [TRT] Tactic: -8626990807754934295 Time: 0.074072
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:40:25] [V] [TRT] Tactic: -7303593854972602201 Time: 0.060236
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:40:25] [V] [TRT] Tactic: -6585664687867083638 Time: 0.10316
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: -3730012925709297561
[12/29/2021-03:40:25] [V] [TRT] Tactic: -3730012925709297561 Time: 0.065716
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: -2277259417488004546
[12/29/2021-03:40:25] [V] [TRT] Tactic: -2277259417488004546 Time: 0.10414
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:40:25] [V] [TRT] Tactic: -683636008127039856 Time: 0.100628
[12/29/2021-03:40:25] [V] [TRT] Fastest Tactic: -7303593854972602201 Time: 0.060236
[12/29/2021-03:40:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7303593854972602201
[12/29/2021-03:40:25] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1), Int8(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:25] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CaskConvolution)
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 984309058095623735
[12/29/2021-03:40:25] [V] [TRT] Tactic: 984309058095623735 Time: 0.065308
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:40:25] [V] [TRT] Tactic: 1100922622480907544 Time: 0.074136
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 3238312825609165543
[12/29/2021-03:40:25] [V] [TRT] Tactic: 3238312825609165543 Time: 0.103404
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:40:25] [V] [TRT] Tactic: 3606311198834416176 Time: 0.071808
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:40:25] [V] [TRT] Tactic: 4325765560739862899 Time: 0.099936
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:40:25] [V] [TRT] Tactic: -4255737803793506479 Time: 0.102456
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:40:25] [V] [TRT] Tactic: -3958182351168863467 Time: 0.060136
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:40:25] [V] [TRT] Tactic: -3111968753064955248 Time: 0.075496
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:40:25] [V] [TRT] Tactic: -1492575840277333548 Time: 0.085888
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:40:25] [V] [TRT] Tactic: -868495160148524802 Time: 0.063496
[12/29/2021-03:40:25] [V] [TRT] Fastest Tactic: -3958182351168863467 Time: 0.060136
[12/29/2021-03:40:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3958182351168863467
[12/29/2021-03:40:25] [V] [TRT] *************** Autotuning format combination: Int8(32,4:32,2,1), Float(32,4:32,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:25] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CaskConvolution)
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:40:25] [V] [TRT] Tactic: 1011019097971850911 Time: 0.03124
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:40:25] [V] [TRT] Tactic: 1071114551801767124 Time: 0.018952
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:40:25] [V] [TRT] Tactic: 2623576043214044314 Time: 0.012388
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:40:25] [V] [TRT] Tactic: 3281631721811475881 Time: 0.014788
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:40:25] [V] [TRT] Tactic: 4551754795416974366 Time: 0.013924
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:40:25] [V] [TRT] Tactic: 4925112190271421402 Time: 0.011852
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:40:25] [V] [TRT] Tactic: 5012796702462679112 Time: 0.056904
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:40:25] [V] [TRT] Tactic: 5041593333398049019 Time: 0.011736
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:40:25] [V] [TRT] Tactic: 5166018662410176512 Time: 0.054684
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:40:25] [V] [TRT] Tactic: 6191867932654611882 Time: 0.031512
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:40:25] [V] [TRT] Tactic: 6556170942941957134 Time: 0.037208
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:40:25] [V] [TRT] Tactic: 6852868042694587230 Time: 0.014268
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:40:25] [V] [TRT] Tactic: 8399092794516815300 Time: 0.057968
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:40:25] [V] [TRT] Tactic: -9132922677633967263 Time: 0.019508
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:40:25] [V] [TRT] Tactic: -7988637803896331454 Time: 0.03484
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: -7865001268126363229
[12/29/2021-03:40:25] [V] [TRT] Tactic: -7865001268126363229 Time: 0.040236
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:40:25] [V] [TRT] Tactic: -7606074703023778034 Time: 0.03428
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:40:25] [V] [TRT] Tactic: -7413564913826321357 Time: 0.031536
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:40:25] [V] [TRT] Tactic: -7282232519526877434 Time: 0.055612
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:40:25] [V] [TRT] Tactic: -5942379529065248478 Time: 0.019244
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:40:25] [V] [TRT] Tactic: -5603587790314027122 Time: 0.037288
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:40:25] [V] [TRT] Tactic: -5334776871777565833 Time: 0.055364
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:40:25] [V] [TRT] Tactic: -5157868397078537095 Time: 0.031868
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:40:25] [V] [TRT] Tactic: -5100834417027499764 Time: 0.013092
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:40:25] [V] [TRT] Tactic: -3365360067423513506 Time: 0.010624
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2194148180068068313
[12/29/2021-03:40:25] [V] [TRT] Tactic: -2194148180068068313 Time: 0.055824
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:40:25] [V] [TRT] Tactic: -1782593837177056527 Time: 0.019488
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:40:25] [V] [TRT] Tactic: -1610768292520086910 Time: 0.036796
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:40:25] [V] [TRT] Tactic: -1573035963956198975 Time: 0.057404
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -1558762241666006941
[12/29/2021-03:40:25] [V] [TRT] Tactic: -1558762241666006941 Time: 0.039956
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -1365353082499976145
[12/29/2021-03:40:25] [V] [TRT] Tactic: -1365353082499976145 Time: 0.039052
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:40:25] [V] [TRT] Tactic: -621838502160440068 Time: 0.038996
[12/29/2021-03:40:25] [V] [TRT] Fastest Tactic: -3365360067423513506 Time: 0.010624
[12/29/2021-03:40:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3365360067423513506
[12/29/2021-03:40:25] [V] [TRT] *************** Autotuning format combination: Int8(32,4:32,2,1), Int8(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:25] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CudaGroupConvolution)
[12/29/2021-03:40:25] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:25] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CudaDepthwiseConvolution)
[12/29/2021-03:40:25] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:25] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (FusedConvActConvolution)
[12/29/2021-03:40:25] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:25] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CaskConvolution)
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:40:25] [V] [TRT] Tactic: 2325023763229477890 Time: 0.0303
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:40:25] [V] [TRT] Tactic: 3401614690060226673 Time: 0.012756
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:40:25] [V] [TRT] Tactic: 4042202769383439184 Time: 0.01838
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:40:25] [V] [TRT] Tactic: 4734519122557206480 Time: 0.053108
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:40:25] [V] [TRT] Tactic: 5136656982162849059 Time: 0.010536
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:40:25] [V] [TRT] Tactic: 6004789655466615912 Time: 0.01916
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:40:25] [V] [TRT] Tactic: 6146901278630392829 Time: 0.052912
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:40:25] [V] [TRT] Tactic: 6781129591847482048 Time: 0.01896
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:40:25] [V] [TRT] Tactic: 8096257414008860171 Time: 0.01854
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:40:25] [V] [TRT] Tactic: -9165697322068360861 Time: 0.053344
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:40:25] [V] [TRT] Tactic: -8263994888336646547 Time: 0.030188
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:40:25] [V] [TRT] Tactic: -8205948405243401049 Time: 0.011656
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:40:25] [V] [TRT] Tactic: -7683887278997527517 Time: 0.013688
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:40:25] [V] [TRT] Tactic: -4933563390723451692 Time: 0.014428
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:40:25] [V] [TRT] Tactic: -3238475748440751107 Time: 0.017996
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:40:25] [V] [TRT] Tactic: -3182884991006484042 Time: 0.030244
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:40:25] [V] [TRT] Tactic: -3173468756112541306 Time: 0.011584
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:40:25] [V] [TRT] Tactic: -1546787387293556842 Time: 0.029928
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:40:25] [V] [TRT] Tactic: -1498626619443284096 Time: 0.0207
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:40:25] [V] [TRT] Tactic: -1283580231568512025 Time: 0.011492
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:40:25] [V] [TRT] Tactic: -762222380308749469 Time: 0.013992
[12/29/2021-03:40:25] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:40:25] [V] [TRT] Tactic: -516725800067794372 Time: 0.052484
[12/29/2021-03:40:25] [V] [TRT] Fastest Tactic: 5136656982162849059 Time: 0.010536
[12/29/2021-03:40:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5136656982162849059
[12/29/2021-03:40:25] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:25] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:25] [V] [TRT] Tactic: 1002 Time: 0.009428
[12/29/2021-03:40:25] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:25] [V] [TRT] Tactic: 0 Time: 0.005036
[12/29/2021-03:40:25] [V] [TRT] Fastest Tactic: 0 Time: 0.005036
[12/29/2021-03:40:25] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:25] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:25] [V] [TRT] Tactic: 1002 Time: 0.009524
[12/29/2021-03:40:25] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:25] [V] [TRT] Tactic: 0 Time: 0.005188
[12/29/2021-03:40:25] [V] [TRT] Fastest Tactic: 0 Time: 0.005188
[12/29/2021-03:40:25] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:25] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:25] [V] [TRT] Tactic: 1002 Time: 0.009444
[12/29/2021-03:40:25] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:25] [V] [TRT] Tactic: 0 Time: 0.005072
[12/29/2021-03:40:25] [V] [TRT] Fastest Tactic: 0 Time: 0.005072
[12/29/2021-03:40:25] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:25] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:25] [V] [TRT] Tactic: 1002 Time: 0.008316
[12/29/2021-03:40:25] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.004708
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.004708
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.00828
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.005224
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.005224
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.00978
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.004864
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.004864
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.008308
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.004992
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.004992
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.010096
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.004972
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.004972
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.008484
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.005176
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.005176
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.008364
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.00518
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.00518
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.009716
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.00504
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.00504
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.008348
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.005016
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.005016
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.008208
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.00506
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.00506
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.009472
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.005196
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.005196
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.00948
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.005276
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.005276
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.009892
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.004988
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.004988
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.01004
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.00512
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.00512
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.008348
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.005172
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.005172
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.009068
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.005264
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.005264
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.009096
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.005256
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.005256
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.006932
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.00458
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.00458
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.0094
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.005904
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.005904
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.009696
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.005836
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.005836
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.009772
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.005416
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.005416
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.007748
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.004896
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.004896
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.00684
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.005244
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.005244
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.00868
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.005796
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.005796
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.009592
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.005912
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.005912
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.009
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.005332
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.005332
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1002 Time: 0.00756
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.004528
[12/29/2021-03:40:26] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1 Time: 0.004884
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 0 Time: 0.004528
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning format combination: Float(1024,4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CudaDepthwiseConvolution)
[12/29/2021-03:40:26] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (FusedConvActConvolution)
[12/29/2021-03:40:26] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CudnnConvolution)
[12/29/2021-03:40:26] [V] [TRT] Tactic: 0 Time: 0.104352
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1 Time: 0.09442
[12/29/2021-03:40:26] [V] [TRT] Tactic: 2 Time: 0.10802
[12/29/2021-03:40:26] [V] [TRT] Tactic: 4 skipped. Scratch requested: 172228608, available: 16777216
[12/29/2021-03:40:26] [V] [TRT] Tactic: 5 skipped. Scratch requested: 356515840, available: 16777216
[12/29/2021-03:40:26] [V] [TRT] Tactic: 6 Time: 0.06392
[12/29/2021-03:40:26] [V] [TRT] Tactic: 56 Time: 0.104444
[12/29/2021-03:40:26] [V] [TRT] Tactic: 57 Time: 0.10362
[12/29/2021-03:40:26] [V] [TRT] Tactic: 58 Time: 0.108172
[12/29/2021-03:40:26] [V] [TRT] Tactic: 60 skipped. Scratch requested: 172228608, available: 16777216
[12/29/2021-03:40:26] [V] [TRT] Tactic: 61 skipped. Scratch requested: 356515840, available: 16777216
[12/29/2021-03:40:26] [V] [TRT] Tactic: 62 Time: 0.063696
[12/29/2021-03:40:26] [V] [TRT] Tactic: 112 Time: 0.10426
[12/29/2021-03:40:26] [V] [TRT] Tactic: 113 Time: 0.23034
[12/29/2021-03:40:26] [V] [TRT] Tactic: 114 Time: 0.108332
[12/29/2021-03:40:26] [V] [TRT] Tactic: 116 skipped. Scratch requested: 172228608, available: 16777216
[12/29/2021-03:40:26] [V] [TRT] Tactic: 117 skipped. Scratch requested: 356515840, available: 16777216
[12/29/2021-03:40:26] [V] [TRT] Tactic: 118 Time: 0.063664
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 118 Time: 0.063664
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CaskConvolution)
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:40:26] [V] [TRT] Tactic: 4549827808004681195 Time: 0.2264
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:40:26] [V] [TRT] Tactic: 5779835512569528575 Time: 0.301832
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[12/29/2021-03:40:26] [V] [TRT] Tactic: 6053873026024413720 Time: 0.316044
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[12/29/2021-03:40:26] [V] [TRT] Tactic: 6767548733843469815 Time: 0.233116
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:40:26] [V] [TRT] Tactic: -6313876406580483184 Time: 0.2702
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:40:26] [V] [TRT] Tactic: -1123676555321336786 Time: 0.308732
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:40:26] [V] [TRT] Tactic: -701551393537224327 Time: 0.260244
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 4549827808004681195 Time: 0.2264
[12/29/2021-03:40:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 118
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning format combination: Float(1024,1,512,256) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CudnnConvolution)
[12/29/2021-03:40:26] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CaskConvolution)
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:26] [V] [TRT] Tactic: 2860655430572478466 Time: 0.168908
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:26] [V] [TRT] Tactic: 4474630279712975759 Time: 0.099188
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:26] [V] [TRT] Tactic: 4479823862704990365 Time: 0.091968
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:26] [V] [TRT] Tactic: 4696204239951173149 Time: 0.176212
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:26] [V] [TRT] Tactic: 5778138195697110003 Time: 0.290328
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:40:26] [V] [TRT] Tactic: 7155825427510256858 Time: 0.28558
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:26] [V] [TRT] Tactic: 8918020581761223752 Time: 0.279084
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:40:26] [V] [TRT] Tactic: -4756382386362004279 Time: 0.171696
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:40:26] [V] [TRT] Tactic: -3855385237722507464 Time: 0.307396
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:26] [V] [TRT] Tactic: -2809379259463049391 Time: 0.302964
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:26] [V] [TRT] Tactic: -504296718212024303 Time: 0.278884
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.091968
[12/29/2021-03:40:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning format combination: Float(256,1:4,128,64) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CudnnConvolution)
[12/29/2021-03:40:26] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CaskConvolution)
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:26] [V] [TRT] Tactic: 2860655430572478466 Time: 0.169316
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:26] [V] [TRT] Tactic: 4474630279712975759 Time: 0.09932
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:26] [V] [TRT] Tactic: 4479823862704990365 Time: 0.092044
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:26] [V] [TRT] Tactic: 4696204239951173149 Time: 0.176152
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:26] [V] [TRT] Tactic: 5778138195697110003 Time: 0.290088
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:40:26] [V] [TRT] Tactic: 7155825427510256858 Time: 0.28548
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:40:26] [V] [TRT] Tactic: 7342025736444949634 Time: 0.193428
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:26] [V] [TRT] Tactic: 8918020581761223752 Time: 0.279028
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:40:26] [V] [TRT] Tactic: -7377458734869418330 Time: 0.190488
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:40:26] [V] [TRT] Tactic: -5457304872213719461 Time: 0.192016
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:40:26] [V] [TRT] Tactic: -4756382386362004279 Time: 0.17162
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:40:26] [V] [TRT] Tactic: -3855385237722507464 Time: 0.307264
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:26] [V] [TRT] Tactic: -2809379259463049391 Time: 0.30286
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:26] [V] [TRT] Tactic: -504296718212024303 Time: 0.27856
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.092044
[12/29/2021-03:40:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CudaDepthwiseConvolution)
[12/29/2021-03:40:26] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CaskConvolution)
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 1332468635798226953
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1332468635798226953 Time: 0.106016
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1508480131241957639 Time: 0.102376
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 1947019689364377201
[12/29/2021-03:40:26] [V] [TRT] Tactic: 1947019689364377201 Time: 0.066356
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:40:26] [V] [TRT] Tactic: 3239257003214966313 Time: 0.105168
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:40:26] [V] [TRT] Tactic: 5592640619112287921 Time: 0.060664
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:40:26] [V] [TRT] Tactic: 7621465827583909090 Time: 0.064148
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:40:26] [V] [TRT] Tactic: -5576936487443445631 Time: 0.072764
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:40:26] [V] [TRT] Tactic: -2297737319934264721 Time: 0.086616
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:40:26] [V] [TRT] Tactic: -1425085658556684465 Time: 0.076444
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:40:26] [V] [TRT] Tactic: -108011214168778087 Time: 0.074568
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: 5592640619112287921 Time: 0.060664
[12/29/2021-03:40:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5592640619112287921
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CudaDepthwiseConvolution)
[12/29/2021-03:40:26] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (FusedConvActConvolution)
[12/29/2021-03:40:26] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:26] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CaskConvolution)
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:40:26] [V] [TRT] Tactic: 175853789719975416 Time: 0.08446
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:40:26] [V] [TRT] Tactic: 2171150287007712632 Time: 0.074108
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:40:26] [V] [TRT] Tactic: 2234457234705232274 Time: 0.061844
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:40:26] [V] [TRT] Tactic: 5834048089706882838 Time: 0.07038
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:40:26] [V] [TRT] Tactic: -8626990807754934295 Time: 0.072628
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:40:26] [V] [TRT] Tactic: -7303593854972602201 Time: 0.058676
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:40:26] [V] [TRT] Tactic: -6585664687867083638 Time: 0.101036
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: -3730012925709297561
[12/29/2021-03:40:26] [V] [TRT] Tactic: -3730012925709297561 Time: 0.063756
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: -2277259417488004546
[12/29/2021-03:40:26] [V] [TRT] Tactic: -2277259417488004546 Time: 0.102192
[12/29/2021-03:40:26] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:40:26] [V] [TRT] Tactic: -683636008127039856 Time: 0.098124
[12/29/2021-03:40:26] [V] [TRT] Fastest Tactic: -7303593854972602201 Time: 0.058676
[12/29/2021-03:40:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7303593854972602201
[12/29/2021-03:40:26] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CaskConvolution)
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 984309058095623735
[12/29/2021-03:40:27] [V] [TRT] Tactic: 984309058095623735 Time: 0.06352
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:40:27] [V] [TRT] Tactic: 1100922622480907544 Time: 0.07246
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 3238312825609165543
[12/29/2021-03:40:27] [V] [TRT] Tactic: 3238312825609165543 Time: 0.101524
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:40:27] [V] [TRT] Tactic: 3606311198834416176 Time: 0.070212
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:40:27] [V] [TRT] Tactic: 4325765560739862899 Time: 0.097716
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:40:27] [V] [TRT] Tactic: -4255737803793506479 Time: 0.100492
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:40:27] [V] [TRT] Tactic: -3958182351168863467 Time: 0.058496
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:40:27] [V] [TRT] Tactic: -3111968753064955248 Time: 0.074296
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:40:27] [V] [TRT] Tactic: -1492575840277333548 Time: 0.084404
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:40:27] [V] [TRT] Tactic: -868495160148524802 Time: 0.061728
[12/29/2021-03:40:27] [V] [TRT] Fastest Tactic: -3958182351168863467 Time: 0.058496
[12/29/2021-03:40:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3958182351168863467
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning format combination: Int8(32,4:32,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CaskConvolution)
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:40:27] [V] [TRT] Tactic: 1011019097971850911 Time: 0.030464
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:40:27] [V] [TRT] Tactic: 1071114551801767124 Time: 0.018604
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:40:27] [V] [TRT] Tactic: 2623576043214044314 Time: 0.0123
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:40:27] [V] [TRT] Tactic: 3281631721811475881 Time: 0.01446
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:40:27] [V] [TRT] Tactic: 4551754795416974366 Time: 0.013376
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:40:27] [V] [TRT] Tactic: 4925112190271421402 Time: 0.011628
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:40:27] [V] [TRT] Tactic: 5012796702462679112 Time: 0.055584
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:40:27] [V] [TRT] Tactic: 5041593333398049019 Time: 0.0114
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:40:27] [V] [TRT] Tactic: 5166018662410176512 Time: 0.053848
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:40:27] [V] [TRT] Tactic: 6191867932654611882 Time: 0.030972
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:40:27] [V] [TRT] Tactic: 6556170942941957134 Time: 0.03584
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:40:27] [V] [TRT] Tactic: 6852868042694587230 Time: 0.013988
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:40:27] [V] [TRT] Tactic: 8399092794516815300 Time: 0.057128
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:40:27] [V] [TRT] Tactic: -9132922677633967263 Time: 0.01902
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:40:27] [V] [TRT] Tactic: -7988637803896331454 Time: 0.033316
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: -7865001268126363229
[12/29/2021-03:40:27] [V] [TRT] Tactic: -7865001268126363229 Time: 0.039496
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:40:27] [V] [TRT] Tactic: -7606074703023778034 Time: 0.03368
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:40:27] [V] [TRT] Tactic: -7413564913826321357 Time: 0.030732
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:40:27] [V] [TRT] Tactic: -7282232519526877434 Time: 0.054364
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:40:27] [V] [TRT] Tactic: -5942379529065248478 Time: 0.01876
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:40:27] [V] [TRT] Tactic: -5603587790314027122 Time: 0.03656
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:40:27] [V] [TRT] Tactic: -5334776871777565833 Time: 0.054584
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:40:27] [V] [TRT] Tactic: -5157868397078537095 Time: 0.031312
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:40:27] [V] [TRT] Tactic: -5100834417027499764 Time: 0.012616
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:40:27] [V] [TRT] Tactic: -3365360067423513506 Time: 0.010452
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2194148180068068313
[12/29/2021-03:40:27] [V] [TRT] Tactic: -2194148180068068313 Time: 0.05456
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:40:27] [V] [TRT] Tactic: -1782593837177056527 Time: 0.0192
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:40:27] [V] [TRT] Tactic: -1610768292520086910 Time: 0.03618
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:40:27] [V] [TRT] Tactic: -1573035963956198975 Time: 0.056812
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -1558762241666006941
[12/29/2021-03:40:27] [V] [TRT] Tactic: -1558762241666006941 Time: 0.038776
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -1365353082499976145
[12/29/2021-03:40:27] [V] [TRT] Tactic: -1365353082499976145 Time: 0.038588
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:40:27] [V] [TRT] Tactic: -621838502160440068 Time: 0.038396
[12/29/2021-03:40:27] [V] [TRT] Fastest Tactic: -3365360067423513506 Time: 0.010452
[12/29/2021-03:40:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3365360067423513506
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning format combination: Int8(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CudaGroupConvolution)
[12/29/2021-03:40:27] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:27] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CudaDepthwiseConvolution)
[12/29/2021-03:40:27] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:27] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (FusedConvActConvolution)
[12/29/2021-03:40:27] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:27] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CaskConvolution)
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 177040020707947851
[12/29/2021-03:40:27] [V] [TRT] Tactic: 177040020707947851 Time: 0.013024
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 1550399266192842845
[12/29/2021-03:40:27] [V] [TRT] Tactic: 1550399266192842845 Time: 0.011708
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 1572887561103143487
[12/29/2021-03:40:27] [V] [TRT] Tactic: 1572887561103143487 Time: 0.018692
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:40:27] [V] [TRT] Tactic: 2325023763229477890 Time: 0.029536
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:40:27] [V] [TRT] Tactic: 3284282970967328046 Time: 0.010336
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:40:27] [V] [TRT] Tactic: 3401614690060226673 Time: 0.012564
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3512426920013359699
[12/29/2021-03:40:27] [V] [TRT] Tactic: 3512426920013359699 Time: 0.01384
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:40:27] [V] [TRT] Tactic: 4042202769383439184 Time: 0.017836
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 4259547356717612415
[12/29/2021-03:40:27] [V] [TRT] Tactic: 4259547356717612415 Time: 0.0194
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:40:27] [V] [TRT] Tactic: 4734519122557206480 Time: 0.051776
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 5121596860264626879
[12/29/2021-03:40:27] [V] [TRT] Tactic: 5121596860264626879 Time: 0.051884
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:40:27] [V] [TRT] Tactic: 5136656982162849059 Time: 0.010356
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 5158259316594207439
[12/29/2021-03:40:27] [V] [TRT] Tactic: 5158259316594207439 Time: 0.017968
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 5966973378912044513
[12/29/2021-03:40:27] [V] [TRT] Tactic: 5966973378912044513 Time: 0.02912
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:40:27] [V] [TRT] Tactic: 6004789655466615912 Time: 0.018604
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:40:27] [V] [TRT] Tactic: 6146901278630392829 Time: 0.051352
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 6434020722187266170
[12/29/2021-03:40:27] [V] [TRT] Tactic: 6434020722187266170 Time: 0.052012
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:40:27] [V] [TRT] Tactic: 6781129591847482048 Time: 0.018124
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7191893591576074000
[12/29/2021-03:40:27] [V] [TRT] Tactic: 7191893591576074000 Time: 0.011464
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7438984192263206338
[12/29/2021-03:40:27] [V] [TRT] Tactic: 7438984192263206338 Time: 0.017516
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 7504901284678552178
[12/29/2021-03:40:27] [V] [TRT] Tactic: 7504901284678552178 Time: 0.028892
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:40:27] [V] [TRT] Tactic: 8096257414008860171 Time: 0.017592
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 9143438935315839085
[12/29/2021-03:40:27] [V] [TRT] Tactic: 9143438935315839085 Time: 0.01266
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:40:27] [V] [TRT] Tactic: -9165697322068360861 Time: 0.05214
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:40:27] [V] [TRT] Tactic: -8263994888336646547 Time: 0.02892
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:40:27] [V] [TRT] Tactic: -8205948405243401049 Time: 0.011596
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -7992068592656168418
[12/29/2021-03:40:27] [V] [TRT] Tactic: -7992068592656168418 Time: 0.01772
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: -7842775553137511386
[12/29/2021-03:40:27] [V] [TRT] Tactic: -7842775553137511386 Time: 0.02946
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:40:27] [V] [TRT] Tactic: -7683887278997527517 Time: 0.013392
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5709079507616090666
[12/29/2021-03:40:27] [V] [TRT] Tactic: -5709079507616090666 Time: 0.028832
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5698636014239116282
[12/29/2021-03:40:27] [V] [TRT] Tactic: -5698636014239116282 Time: 0.051424
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:40:27] [V] [TRT] Tactic: -4933563390723451692 Time: 0.013916
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -3413217501222406256
[12/29/2021-03:40:27] [V] [TRT] Tactic: -3413217501222406256 Time: 0.051636
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:40:27] [V] [TRT] Tactic: -3238475748440751107 Time: 0.01738
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:40:27] [V] [TRT] Tactic: -3182884991006484042 Time: 0.029344
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:40:27] [V] [TRT] Tactic: -3173468756112541306 Time: 0.011452
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -2083778562631872334
[12/29/2021-03:40:27] [V] [TRT] Tactic: -2083778562631872334 Time: 0.018064
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:40:27] [V] [TRT] Tactic: -1546787387293556842 Time: 0.028616
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:40:27] [V] [TRT] Tactic: -1498626619443284096 Time: 0.019984
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:40:27] [V] [TRT] Tactic: -1283580231568512025 Time: 0.011212
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: -1173968681844185579
[12/29/2021-03:40:27] [V] [TRT] Tactic: -1173968681844185579 Time: 0.01104
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:40:27] [V] [TRT] Tactic: -762222380308749469 Time: 0.013536
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -556794153877490941
[12/29/2021-03:40:27] [V] [TRT] Tactic: -556794153877490941 Time: 0.013532
[12/29/2021-03:40:27] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:40:27] [V] [TRT] Tactic: -516725800067794372 Time: 0.051452
[12/29/2021-03:40:27] [V] [TRT] Fastest Tactic: 3284282970967328046 Time: 0.010336
[12/29/2021-03:40:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3284282970967328046
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning format combination: Float(1024,4,2,1), Float(1024,4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning format combination: Float(1024,1,512,256), Float(1024,1,512,256) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning format combination: Float(256,1:4,128,64), Float(256,1:4,128,64) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1), Float(1024,4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1), Int8(256,4:4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1), Int8(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning format combination: Int8(32,4:32,2,1), Float(32,4:32,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning format combination: Int8(32,4:32,2,1), Int8(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning format combination: Float(1024,4,2,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:27] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CudaDepthwiseConvolution)
[12/29/2021-03:40:27] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:27] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (FusedConvActConvolution)
[12/29/2021-03:40:27] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:27] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CudnnConvolution)
[12/29/2021-03:40:27] [V] [TRT] Tactic: 0 Time: 0.113296
[12/29/2021-03:40:27] [V] [TRT] Tactic: 1 Time: 0.079304
[12/29/2021-03:40:27] [V] [TRT] Tactic: 2 Time: 0.10946
[12/29/2021-03:40:27] [V] [TRT] Tactic: 5 skipped. Scratch requested: 677380096, available: 16777216
[12/29/2021-03:40:27] [V] [TRT] Tactic: 56 Time: 0.1132
[12/29/2021-03:40:27] [V] [TRT] Tactic: 57 Time: 0.082972
[12/29/2021-03:40:27] [V] [TRT] Tactic: 58 Time: 0.109348
[12/29/2021-03:40:27] [V] [TRT] Tactic: 61 skipped. Scratch requested: 677380096, available: 16777216
[12/29/2021-03:40:27] [V] [TRT] Tactic: 112 Time: 0.11338
[12/29/2021-03:40:27] [V] [TRT] Tactic: 113 Time: 0.327088
[12/29/2021-03:40:27] [V] [TRT] Tactic: 114 Time: 0.109348
[12/29/2021-03:40:27] [V] [TRT] Tactic: 117 skipped. Scratch requested: 677380096, available: 16777216
[12/29/2021-03:40:27] [V] [TRT] Fastest Tactic: 1 Time: 0.079304
[12/29/2021-03:40:27] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CaskConvolution)
[12/29/2021-03:40:27] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:27] [V] [TRT] Setting workspace to 677380096enables more tactics for profiling
[12/29/2021-03:40:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning format combination: Float(1024,1,512,256) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:27] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CudnnConvolution)
[12/29/2021-03:40:27] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:27] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CaskConvolution)
[12/29/2021-03:40:27] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning format combination: Float(256,1:4,128,64) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:27] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CudnnConvolution)
[12/29/2021-03:40:27] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:27] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CaskConvolution)
[12/29/2021-03:40:27] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:40:27] [V] [TRT] Tactic: 7342025736444949634 Time: 0.19312
[12/29/2021-03:40:27] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:40:27] [V] [TRT] Tactic: -7377458734869418330 Time: 0.190212
[12/29/2021-03:40:27] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:40:27] [V] [TRT] Tactic: -5457304872213719461 Time: 0.191704
[12/29/2021-03:40:27] [V] [TRT] Fastest Tactic: -7377458734869418330 Time: 0.190212
[12/29/2021-03:40:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7377458734869418330
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:27] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CudaDepthwiseConvolution)
[12/29/2021-03:40:27] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:27] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CaskConvolution)
[12/29/2021-03:40:27] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:27] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CudaDepthwiseConvolution)
[12/29/2021-03:40:27] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:27] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (FusedConvActConvolution)
[12/29/2021-03:40:27] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:27] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CaskConvolution)
[12/29/2021-03:40:27] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:27] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CaskConvolution)
[12/29/2021-03:40:27] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:27] [V] [TRT] *************** Autotuning format combination: Int8(32,4:32,2,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:40:28] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CaskConvolution)
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:40:28] [V] [TRT] Tactic: 1011019097971850911 Time: 0.02994
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:40:28] [V] [TRT] Tactic: 1071114551801767124 Time: 0.017664
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:40:28] [V] [TRT] Tactic: 2623576043214044314 Time: 0.012272
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:40:28] [V] [TRT] Tactic: 3281631721811475881 Time: 0.014276
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:40:28] [V] [TRT] Tactic: 4551754795416974366 Time: 0.013316
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:40:28] [V] [TRT] Tactic: 4925112190271421402 Time: 0.011508
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:40:28] [V] [TRT] Tactic: 5041593333398049019 Time: 0.011392
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:40:28] [V] [TRT] Tactic: 5166018662410176512 Time: 0.05162
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:40:28] [V] [TRT] Tactic: 6191867932654611882 Time: 0.029576
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:40:28] [V] [TRT] Tactic: 6852868042694587230 Time: 0.014212
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:40:28] [V] [TRT] Tactic: 8399092794516815300 Time: 0.05294
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:40:28] [V] [TRT] Tactic: -9132922677633967263 Time: 0.018308
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:40:28] [V] [TRT] Tactic: -7413564913826321357 Time: 0.031512
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:40:28] [V] [TRT] Tactic: -5942379529065248478 Time: 0.018
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:40:28] [V] [TRT] Tactic: -5334776871777565833 Time: 0.052064
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:40:28] [V] [TRT] Tactic: -5157868397078537095 Time: 0.029492
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:40:28] [V] [TRT] Tactic: -5100834417027499764 Time: 0.012504
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:40:28] [V] [TRT] Tactic: -3365360067423513506 Time: 0.010292
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:40:28] [V] [TRT] Tactic: -1782593837177056527 Time: 0.018292
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:40:28] [V] [TRT] Tactic: -1573035963956198975 Time: 0.052228
[12/29/2021-03:40:28] [V] [TRT] Fastest Tactic: -3365360067423513506 Time: 0.010292
[12/29/2021-03:40:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3365360067423513506
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning format combination: Int8(32,4:32,2,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:28] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CudaGroupConvolution)
[12/29/2021-03:40:28] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:28] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CudaDepthwiseConvolution)
[12/29/2021-03:40:28] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:28] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (FusedConvActConvolution)
[12/29/2021-03:40:28] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:28] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CaskConvolution)
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 177040020707947851
[12/29/2021-03:40:28] [V] [TRT] Tactic: 177040020707947851 Time: 0.012956
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 1550399266192842845
[12/29/2021-03:40:28] [V] [TRT] Tactic: 1550399266192842845 Time: 0.011812
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 1572887561103143487
[12/29/2021-03:40:28] [V] [TRT] Tactic: 1572887561103143487 Time: 0.020952
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:40:28] [V] [TRT] Tactic: 2325023763229477890 Time: 0.030196
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:40:28] [V] [TRT] Tactic: 3284282970967328046 Time: 0.010112
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:40:28] [V] [TRT] Tactic: 3401614690060226673 Time: 0.012276
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3512426920013359699
[12/29/2021-03:40:28] [V] [TRT] Tactic: 3512426920013359699 Time: 0.01414
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:40:28] [V] [TRT] Tactic: 4042202769383439184 Time: 0.017808
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 4259547356717612415
[12/29/2021-03:40:28] [V] [TRT] Tactic: 4259547356717612415 Time: 0.021904
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:40:28] [V] [TRT] Tactic: 4734519122557206480 Time: 0.051636
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 5121596860264626879
[12/29/2021-03:40:28] [V] [TRT] Tactic: 5121596860264626879 Time: 0.05162
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:40:28] [V] [TRT] Tactic: 5136656982162849059 Time: 0.010136
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 5158259316594207439
[12/29/2021-03:40:28] [V] [TRT] Tactic: 5158259316594207439 Time: 0.018032
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 5966973378912044513
[12/29/2021-03:40:28] [V] [TRT] Tactic: 5966973378912044513 Time: 0.029544
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:40:28] [V] [TRT] Tactic: 6004789655466615912 Time: 0.021184
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:40:28] [V] [TRT] Tactic: 6146901278630392829 Time: 0.051212
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 6434020722187266170
[12/29/2021-03:40:28] [V] [TRT] Tactic: 6434020722187266170 Time: 0.052368
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:40:28] [V] [TRT] Tactic: 6781129591847482048 Time: 0.018248
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7191893591576074000
[12/29/2021-03:40:28] [V] [TRT] Tactic: 7191893591576074000 Time: 0.011416
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7438984192263206338
[12/29/2021-03:40:28] [V] [TRT] Tactic: 7438984192263206338 Time: 0.017408
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 7504901284678552178
[12/29/2021-03:40:28] [V] [TRT] Tactic: 7504901284678552178 Time: 0.029076
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:40:28] [V] [TRT] Tactic: 8096257414008860171 Time: 0.01812
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 9143438935315839085
[12/29/2021-03:40:28] [V] [TRT] Tactic: 9143438935315839085 Time: 0.01252
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:40:28] [V] [TRT] Tactic: -9165697322068360861 Time: 0.05224
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:40:28] [V] [TRT] Tactic: -8263994888336646547 Time: 0.029164
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:40:28] [V] [TRT] Tactic: -8205948405243401049 Time: 0.011524
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -7992068592656168418
[12/29/2021-03:40:28] [V] [TRT] Tactic: -7992068592656168418 Time: 0.018092
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: -7842775553137511386
[12/29/2021-03:40:28] [V] [TRT] Tactic: -7842775553137511386 Time: 0.030284
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:40:28] [V] [TRT] Tactic: -7683887278997527517 Time: 0.0133
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5709079507616090666
[12/29/2021-03:40:28] [V] [TRT] Tactic: -5709079507616090666 Time: 0.029028
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5698636014239116282
[12/29/2021-03:40:28] [V] [TRT] Tactic: -5698636014239116282 Time: 0.051348
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:40:28] [V] [TRT] Tactic: -4933563390723451692 Time: 0.01422
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -3413217501222406256
[12/29/2021-03:40:28] [V] [TRT] Tactic: -3413217501222406256 Time: 0.051544
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:40:28] [V] [TRT] Tactic: -3238475748440751107 Time: 0.017432
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:40:28] [V] [TRT] Tactic: -3182884991006484042 Time: 0.029924
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:40:28] [V] [TRT] Tactic: -3173468756112541306 Time: 0.011428
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -2083778562631872334
[12/29/2021-03:40:28] [V] [TRT] Tactic: -2083778562631872334 Time: 0.018216
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:40:28] [V] [TRT] Tactic: -1546787387293556842 Time: 0.029152
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:40:28] [V] [TRT] Tactic: -1498626619443284096 Time: 0.022212
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:40:28] [V] [TRT] Tactic: -1283580231568512025 Time: 0.011196
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: -1173968681844185579
[12/29/2021-03:40:28] [V] [TRT] Tactic: -1173968681844185579 Time: 0.01078
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:40:28] [V] [TRT] Tactic: -762222380308749469 Time: 0.014048
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -556794153877490941
[12/29/2021-03:40:28] [V] [TRT] Tactic: -556794153877490941 Time: 0.01398
[12/29/2021-03:40:28] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:40:28] [V] [TRT] Tactic: -516725800067794372 Time: 0.051472
[12/29/2021-03:40:28] [V] [TRT] Fastest Tactic: 3284282970967328046 Time: 0.010112
[12/29/2021-03:40:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3284282970967328046
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning format combination: Float(1024,4,2,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:28] [V] [TRT] --------------- Timing Runner: Conv_104 (CudaDepthwiseConvolution)
[12/29/2021-03:40:28] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:28] [V] [TRT] --------------- Timing Runner: Conv_104 (FusedConvActConvolution)
[12/29/2021-03:40:28] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:28] [V] [TRT] --------------- Timing Runner: Conv_104 (CudnnConvolution)
[12/29/2021-03:40:28] [V] [TRT] Tactic: 0 Time: 0.04804
[12/29/2021-03:40:28] [V] [TRT] Tactic: 1 Time: 0.033536
[12/29/2021-03:40:28] [V] [TRT] Tactic: 2 Time: 0.110824
[12/29/2021-03:40:28] [V] [TRT] Tactic: 56 Time: 0.04796
[12/29/2021-03:40:28] [V] [TRT] Tactic: 57 Time: 0.154644
[12/29/2021-03:40:28] [V] [TRT] Tactic: 58 Time: 0.110732
[12/29/2021-03:40:28] [V] [TRT] Tactic: 112 Time: 0.04786
[12/29/2021-03:40:28] [V] [TRT] Tactic: 113 Time: 0.184828
[12/29/2021-03:40:28] [V] [TRT] Tactic: 114 Time: 0.110628
[12/29/2021-03:40:28] [V] [TRT] Fastest Tactic: 1 Time: 0.033536
[12/29/2021-03:40:28] [V] [TRT] --------------- Timing Runner: Conv_104 (CaskConvolution)
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:40:28] [V] [TRT] Tactic: 4549827808004681195 Time: 0.033684
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:40:28] [V] [TRT] Tactic: 5779835512569528575 Time: 0.043844
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 9151672657204310840
[12/29/2021-03:40:28] [V] [TRT] Tactic: 9151672657204310840 Time: 0.045568
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: -7491730084094677098
[12/29/2021-03:40:28] [V] [TRT] Tactic: -7491730084094677098 Time: 0.040748
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:40:28] [V] [TRT] Tactic: -6313876406580483184 Time: 0.042632
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: -6273689210331812572
[12/29/2021-03:40:28] [V] [TRT] Tactic: -6273689210331812572 Time: 0.04318
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: -4337126844824617177
[12/29/2021-03:40:28] [V] [TRT] Tactic: -4337126844824617177 Time: 0.031524
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:40:28] [V] [TRT] Tactic: -1123676555321336786 Time: 0.043424
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:40:28] [V] [TRT] Tactic: -701551393537224327 Time: 0.034696
[12/29/2021-03:40:28] [V] [TRT] Fastest Tactic: -4337126844824617177 Time: 0.031524
[12/29/2021-03:40:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4337126844824617177
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning format combination: Float(1024,1,512,256) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:28] [V] [TRT] --------------- Timing Runner: Conv_104 (CudnnConvolution)
[12/29/2021-03:40:28] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:28] [V] [TRT] --------------- Timing Runner: Conv_104 (CaskConvolution)
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 1663866669559596164
[12/29/2021-03:40:28] [V] [TRT] Tactic: 1663866669559596164 Time: 0.039344
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:28] [V] [TRT] Tactic: 2860655430572478466 Time: 0.026292
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:28] [V] [TRT] Tactic: 4474630279712975759 Time: 0.017844
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:28] [V] [TRT] Tactic: 4479823862704990365 Time: 0.017652
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:28] [V] [TRT] Tactic: 4696204239951173149 Time: 0.025992
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:28] [V] [TRT] Tactic: 5778138195697110003 Time: 0.039744
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:28] [V] [TRT] Tactic: 8918020581761223752 Time: 0.038288
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -5905193483742532701
[12/29/2021-03:40:28] [V] [TRT] Tactic: -5905193483742532701 Time: 0.023992
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -4035591156787122265
[12/29/2021-03:40:28] [V] [TRT] Tactic: -4035591156787122265 Time: 0.017376
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:28] [V] [TRT] Tactic: -2809379259463049391 Time: 0.039456
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -1985235291706575900
[12/29/2021-03:40:28] [V] [TRT] Tactic: -1985235291706575900 Time: 0.038168
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:28] [V] [TRT] Tactic: -504296718212024303 Time: 0.038592
[12/29/2021-03:40:28] [V] [TRT] Fastest Tactic: -4035591156787122265 Time: 0.017376
[12/29/2021-03:40:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4035591156787122265
[12/29/2021-03:40:28] [V] [TRT] *************** Autotuning format combination: Float(256,1:4,128,64) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:28] [V] [TRT] --------------- Timing Runner: Conv_104 (CudnnConvolution)
[12/29/2021-03:40:28] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:28] [V] [TRT] --------------- Timing Runner: Conv_104 (CaskConvolution)
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 1373022415249282411
[12/29/2021-03:40:28] [V] [TRT] Tactic: 1373022415249282411 Time: 0.027816
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 1663866669559596164
[12/29/2021-03:40:28] [V] [TRT] Tactic: 1663866669559596164 Time: 0.039232
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:28] [V] [TRT] Tactic: 2860655430572478466 Time: 0.026292
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:28] [V] [TRT] Tactic: 4474630279712975759 Time: 0.017772
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:28] [V] [TRT] Tactic: 4479823862704990365 Time: 0.01768
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:28] [V] [TRT] Tactic: 4696204239951173149 Time: 0.026056
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:28] [V] [TRT] Tactic: 5778138195697110003 Time: 0.039748
[12/29/2021-03:40:28] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:40:29] [V] [TRT] Tactic: 7342025736444949634 Time: 0.028176
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:29] [V] [TRT] Tactic: 8918020581761223752 Time: 0.038236
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -5905193483742532701
[12/29/2021-03:40:29] [V] [TRT] Tactic: -5905193483742532701 Time: 0.023976
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:40:29] [V] [TRT] Tactic: -5457304872213719461 Time: 0.028428
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -4035591156787122265
[12/29/2021-03:40:29] [V] [TRT] Tactic: -4035591156787122265 Time: 0.017476
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:29] [V] [TRT] Tactic: -2809379259463049391 Time: 0.039404
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -1985235291706575900
[12/29/2021-03:40:29] [V] [TRT] Tactic: -1985235291706575900 Time: 0.038184
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:29] [V] [TRT] Tactic: -504296718212024303 Time: 0.038472
[12/29/2021-03:40:29] [V] [TRT] Fastest Tactic: -4035591156787122265 Time: 0.017476
[12/29/2021-03:40:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4035591156787122265
[12/29/2021-03:40:29] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:29] [V] [TRT] --------------- Timing Runner: Conv_104 (CudaDepthwiseConvolution)
[12/29/2021-03:40:29] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:29] [V] [TRT] --------------- Timing Runner: Conv_104 (CaskConvolution)
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:40:29] [V] [TRT] Tactic: 1508480131241957639 Time: 0.022048
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 2141154648944475104
[12/29/2021-03:40:29] [V] [TRT] Tactic: 2141154648944475104 Time: 0.021716
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:40:29] [V] [TRT] Tactic: 3239257003214966313 Time: 0.0219
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:40:29] [V] [TRT] Tactic: 5592640619112287921 Time: 0.015068
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:40:29] [V] [TRT] Tactic: 7621465827583909090 Time: 0.015848
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: -6580271968881459581
[12/29/2021-03:40:29] [V] [TRT] Tactic: -6580271968881459581 Time: 0.017092
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:40:29] [V] [TRT] Tactic: -5576936487443445631 Time: 0.016156
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: -4443833619060044580
[12/29/2021-03:40:29] [V] [TRT] Tactic: -4443833619060044580 Time: 0.015
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:40:29] [V] [TRT] Tactic: -2297737319934264721 Time: 0.017964
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:40:29] [V] [TRT] Tactic: -1425085658556684465 Time: 0.016012
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:40:29] [V] [TRT] Tactic: -108011214168778087 Time: 0.017512
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: -42427192380281294
[12/29/2021-03:40:29] [V] [TRT] Tactic: -42427192380281294 Time: 0.015372
[12/29/2021-03:40:29] [V] [TRT] Fastest Tactic: -4443833619060044580 Time: 0.015
[12/29/2021-03:40:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4443833619060044580
[12/29/2021-03:40:29] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:29] [V] [TRT] --------------- Timing Runner: Conv_104 (CudaDepthwiseConvolution)
[12/29/2021-03:40:29] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:29] [V] [TRT] --------------- Timing Runner: Conv_104 (FusedConvActConvolution)
[12/29/2021-03:40:29] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:29] [V] [TRT] --------------- Timing Runner: Conv_104 (CaskConvolution)
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:40:29] [V] [TRT] Tactic: 175853789719975416 Time: 0.015996
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:40:29] [V] [TRT] Tactic: 2171150287007712632 Time: 0.014232
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:40:29] [V] [TRT] Tactic: 2234457234705232274 Time: 0.013596
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:40:29] [V] [TRT] Tactic: 5834048089706882838 Time: 0.01394
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 6299962968199310600
[12/29/2021-03:40:29] [V] [TRT] Tactic: 6299962968199310600 Time: 0.018368
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 6341572697076960911
[12/29/2021-03:40:29] [V] [TRT] Tactic: 6341572697076960911 Time: 0.013072
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:40:29] [V] [TRT] Tactic: -8626990807754934295 Time: 0.0155
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: -8498217049614706532
[12/29/2021-03:40:29] [V] [TRT] Tactic: -8498217049614706532 Time: 0.01304
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:40:29] [V] [TRT] Tactic: -7303593854972602201 Time: 0.012996
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:40:29] [V] [TRT] Tactic: -6585664687867083638 Time: 0.018536
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: -3326139578711341011
[12/29/2021-03:40:29] [V] [TRT] Tactic: -3326139578711341011 Time: 0.014964
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:40:29] [V] [TRT] Tactic: -683636008127039856 Time: 0.018476
[12/29/2021-03:40:29] [V] [TRT] Fastest Tactic: -7303593854972602201 Time: 0.012996
[12/29/2021-03:40:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7303593854972602201
[12/29/2021-03:40:29] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:29] [V] [TRT] --------------- Timing Runner: Conv_104 (CaskConvolution)
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:40:29] [V] [TRT] Tactic: 1100922622480907544 Time: 0.015432
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_c32_nn_v1 Tactic: 2855900226702061782
[12/29/2021-03:40:29] [V] [TRT] Tactic: 2855900226702061782 Time: 0.017888
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:40:29] [V] [TRT] Tactic: 3606311198834416176 Time: 0.013792
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:40:29] [V] [TRT] Tactic: 4325765560739862899 Time: 0.018048
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 8803458114157674373
[12/29/2021-03:40:29] [V] [TRT] Tactic: 8803458114157674373 Time: 0.012772
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: -6934773036503365000
[12/29/2021-03:40:29] [V] [TRT] Tactic: -6934773036503365000 Time: 0.014788
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: -4431642509665791294
[12/29/2021-03:40:29] [V] [TRT] Tactic: -4431642509665791294 Time: 0.01288
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:40:29] [V] [TRT] Tactic: -4255737803793506479 Time: 0.018012
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:40:29] [V] [TRT] Tactic: -3958182351168863467 Time: 0.012888
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:40:29] [V] [TRT] Tactic: -3111968753064955248 Time: 0.01398
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:40:29] [V] [TRT] Tactic: -1492575840277333548 Time: 0.015712
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:40:29] [V] [TRT] Tactic: -868495160148524802 Time: 0.013336
[12/29/2021-03:40:29] [V] [TRT] Fastest Tactic: 8803458114157674373 Time: 0.012772
[12/29/2021-03:40:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8803458114157674373
[12/29/2021-03:40:29] [V] [TRT] *************** Autotuning format combination: Int8(32,4:32,2,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:40:29] [V] [TRT] --------------- Timing Runner: Conv_104 (CaskConvolution)
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:40:29] [V] [TRT] Tactic: 2623576043214044314 Time: 0.00678
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 2818014835119698671
[12/29/2021-03:40:29] [V] [TRT] Tactic: 2818014835119698671 Time: 0.007756
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 3721599319722771137
[12/29/2021-03:40:29] [V] [TRT] Tactic: 3721599319722771137 Time: 0.006552
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_interior_nt_v1 Tactic: 4178917718361232468
[12/29/2021-03:40:29] [V] [TRT] Tactic: 4178917718361232468 Time: 0.010792
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:40:29] [V] [TRT] Tactic: 4551754795416974366 Time: 0.00692
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:40:29] [V] [TRT] Tactic: 4925112190271421402 Time: 0.006468
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:40:29] [V] [TRT] Tactic: 5012796702462679112 Time: 0.01352
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:40:29] [V] [TRT] Tactic: 6556170942941957134 Time: 0.010688
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 6618077155362058131
[12/29/2021-03:40:29] [V] [TRT] Tactic: 6618077155362058131 Time: 0.006224
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:40:29] [V] [TRT] Tactic: 6852868042694587230 Time: 0.007104
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 6969462133921577484
[12/29/2021-03:40:29] [V] [TRT] Tactic: 6969462133921577484 Time: 0.013232
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:40:29] [V] [TRT] Tactic: 8399092794516815300 Time: 0.013504
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:40:29] [V] [TRT] Tactic: -9132922677633967263 Time: 0.007848
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -8912999970161746151
[12/29/2021-03:40:29] [V] [TRT] Tactic: -8912999970161746151 Time: 0.007676
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -8893439100868426414
[12/29/2021-03:40:29] [V] [TRT] Tactic: -8893439100868426414 Time: 0.009192
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:40:29] [V] [TRT] Tactic: -7988637803896331454 Time: 0.010496
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_interior_nt_v1 Tactic: -7904635102498369361
[12/29/2021-03:40:29] [V] [TRT] Tactic: -7904635102498369361 Time: 0.013264
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:40:29] [V] [TRT] Tactic: -7606074703023778034 Time: 0.010636
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:40:29] [V] [TRT] Tactic: -7413564913826321357 Time: 0.010148
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:40:29] [V] [TRT] Tactic: -7282232519526877434 Time: 0.013328
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -6406011580107094428
[12/29/2021-03:40:29] [V] [TRT] Tactic: -6406011580107094428 Time: 0.006676
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:40:29] [V] [TRT] Tactic: -5603587790314027122 Time: 0.010804
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_interior_nt_v1 Tactic: -5416590980288859834
[12/29/2021-03:40:29] [V] [TRT] Tactic: -5416590980288859834 Time: 0.010624
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:40:29] [V] [TRT] Tactic: -5334776871777565833 Time: 0.013164
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:40:29] [V] [TRT] Tactic: -5157868397078537095 Time: 0.009892
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -3665201838779845683
[12/29/2021-03:40:29] [V] [TRT] Tactic: -3665201838779845683 Time: 0.012392
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_interior_nt_v1 Tactic: -3644377136375731441
[12/29/2021-03:40:29] [V] [TRT] Tactic: -3644377136375731441 Time: 0.010664
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -3502495740607894730
[12/29/2021-03:40:29] [V] [TRT] Tactic: -3502495740607894730 Time: 0.006348
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -2342404147487779225
[12/29/2021-03:40:29] [V] [TRT] Tactic: -2342404147487779225 Time: 0.00936
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:40:29] [V] [TRT] Tactic: -1782593837177056527 Time: 0.008024
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:40:29] [V] [TRT] Tactic: -1610768292520086910 Time: 0.010984
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:40:29] [V] [TRT] Tactic: -621838502160440068 Time: 0.011192
[12/29/2021-03:40:29] [V] [TRT] Fastest Tactic: 6618077155362058131 Time: 0.006224
[12/29/2021-03:40:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6618077155362058131
[12/29/2021-03:40:29] [V] [TRT] *************** Autotuning format combination: Int8(32,4:32,2,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:29] [V] [TRT] --------------- Timing Runner: Conv_104 (CudaGroupConvolution)
[12/29/2021-03:40:29] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:29] [V] [TRT] --------------- Timing Runner: Conv_104 (CudaDepthwiseConvolution)
[12/29/2021-03:40:29] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:29] [V] [TRT] --------------- Timing Runner: Conv_104 (FusedConvActConvolution)
[12/29/2021-03:40:29] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:29] [V] [TRT] --------------- Timing Runner: Conv_104 (CaskConvolution)
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 177040020707947851
[12/29/2021-03:40:29] [V] [TRT] Tactic: 177040020707947851 Time: 0.006936
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_interior_nt_v1 Tactic: 434957160407688216
[12/29/2021-03:40:29] [V] [TRT] Tactic: 434957160407688216 Time: 0.013948
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 805889586762897346
[12/29/2021-03:40:29] [V] [TRT] Tactic: 805889586762897346 Time: 0.012536
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 1550399266192842845
[12/29/2021-03:40:29] [V] [TRT] Tactic: 1550399266192842845 Time: 0.006568
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:40:29] [V] [TRT] Tactic: 2325023763229477890 Time: 0.010336
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_interior_nt_v1 Tactic: 2346437292116182513
[12/29/2021-03:40:29] [V] [TRT] Tactic: 2346437292116182513 Time: 0.010936
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_interior_nt_v1 Tactic: 2522133112320625287
[12/29/2021-03:40:29] [V] [TRT] Tactic: 2522133112320625287 Time: 0.010828
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 2985940154541537814
[12/29/2021-03:40:29] [V] [TRT] Tactic: 2985940154541537814 Time: 0.010892
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 3538565962642681625
[12/29/2021-03:40:29] [V] [TRT] Tactic: 3538565962642681625 Time: 0.006768
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 3899284354987683408
[12/29/2021-03:40:29] [V] [TRT] Tactic: 3899284354987683408 Time: 0.014308
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:40:29] [V] [TRT] Tactic: 4042202769383439184 Time: 0.007872
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 4259547356717612415
[12/29/2021-03:40:29] [V] [TRT] Tactic: 4259547356717612415 Time: 0.00864
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: 4717285412741024953
[12/29/2021-03:40:29] [V] [TRT] Tactic: 4717285412741024953 Time: 0.011144
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:40:29] [V] [TRT] Tactic: 4734519122557206480 Time: 0.013004
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 5121596860264626879
[12/29/2021-03:40:29] [V] [TRT] Tactic: 5121596860264626879 Time: 0.012948
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_interior_nt_v1 Tactic: 5126565865931538390
[12/29/2021-03:40:29] [V] [TRT] Tactic: 5126565865931538390 Time: 0.010932
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 5158259316594207439
[12/29/2021-03:40:29] [V] [TRT] Tactic: 5158259316594207439 Time: 0.007732
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 5375256703210220108
[12/29/2021-03:40:29] [V] [TRT] Tactic: 5375256703210220108 Time: 0.007636
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 6433368103202497147
[12/29/2021-03:40:29] [V] [TRT] Tactic: 6433368103202497147 Time: 0.009208
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 6434020722187266170
[12/29/2021-03:40:29] [V] [TRT] Tactic: 6434020722187266170 Time: 0.013264
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 6441948709525127755
[12/29/2021-03:40:29] [V] [TRT] Tactic: 6441948709525127755 Time: 0.006312
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 6457435868048963632
[12/29/2021-03:40:29] [V] [TRT] Tactic: 6457435868048963632 Time: 0.00746
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:40:29] [V] [TRT] Tactic: 6781129591847482048 Time: 0.008104
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 6925201228918187099
[12/29/2021-03:40:29] [V] [TRT] Tactic: 6925201228918187099 Time: 0.009236
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 7504901284678552178
[12/29/2021-03:40:29] [V] [TRT] Tactic: 7504901284678552178 Time: 0.009652
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 7731430299029542276
[12/29/2021-03:40:29] [V] [TRT] Tactic: 7731430299029542276 Time: 0.009224
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 7738495016763012180
[12/29/2021-03:40:29] [V] [TRT] Tactic: 7738495016763012180 Time: 0.012656
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 8234775147403903473
[12/29/2021-03:40:29] [V] [TRT] Tactic: 8234775147403903473 Time: 0.012496
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:40:29] [V] [TRT] Tactic: -9165697322068360861 Time: 0.013348
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -9118785798277698619
[12/29/2021-03:40:29] [V] [TRT] Tactic: -9118785798277698619 Time: 0.01078
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -8556775352640313933
[12/29/2021-03:40:29] [V] [TRT] Tactic: -8556775352640313933 Time: 0.009348
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:40:29] [V] [TRT] Tactic: -8263994888336646547 Time: 0.009492
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:40:29] [V] [TRT] Tactic: -8205948405243401049 Time: 0.006516
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: -7842775553137511386
[12/29/2021-03:40:29] [V] [TRT] Tactic: -7842775553137511386 Time: 0.010168
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:40:29] [V] [TRT] Tactic: -7683887278997527517 Time: 0.006924
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -6527178416855951297
[12/29/2021-03:40:29] [V] [TRT] Tactic: -6527178416855951297 Time: 0.006528
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -6510232214299595844
[12/29/2021-03:40:29] [V] [TRT] Tactic: -6510232214299595844 Time: 0.0066
[12/29/2021-03:40:29] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -6400348606759295499
[12/29/2021-03:40:30] [V] [TRT] Tactic: -6400348606759295499 Time: 0.010688
[12/29/2021-03:40:30] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -5980889159865208399
[12/29/2021-03:40:30] [V] [TRT] Tactic: -5980889159865208399 Time: 0.014012
[12/29/2021-03:40:30] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5766140806760372989
[12/29/2021-03:40:30] [V] [TRT] Tactic: -5766140806760372989 Time: 0.010956
[12/29/2021-03:40:30] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -5170003087447722174
[12/29/2021-03:40:30] [V] [TRT] Tactic: -5170003087447722174 Time: 0.006244
[12/29/2021-03:40:30] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -4849712423393454704
[12/29/2021-03:40:30] [V] [TRT] Tactic: -4849712423393454704 Time: 0.00744
[12/29/2021-03:40:30] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -4516822589357530549
[12/29/2021-03:40:30] [V] [TRT] Tactic: -4516822589357530549 Time: 0.011356
[12/29/2021-03:40:30] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -3613322253849278738
[12/29/2021-03:40:30] [V] [TRT] Tactic: -3613322253849278738 Time: 0.005972
[12/29/2021-03:40:30] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -3577322188448771475
[12/29/2021-03:40:30] [V] [TRT] Tactic: -3577322188448771475 Time: 0.0078
[12/29/2021-03:40:30] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -2754311112012636251
[12/29/2021-03:40:30] [V] [TRT] Tactic: -2754311112012636251 Time: 0.007792
[12/29/2021-03:40:30] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: -2315453944962430928
[12/29/2021-03:40:30] [V] [TRT] Tactic: -2315453944962430928 Time: 0.012592
[12/29/2021-03:40:30] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -2083778562631872334
[12/29/2021-03:40:30] [V] [TRT] Tactic: -2083778562631872334 Time: 0.00794
[12/29/2021-03:40:30] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -1499578657823798783
[12/29/2021-03:40:30] [V] [TRT] Tactic: -1499578657823798783 Time: 0.006728
[12/29/2021-03:40:30] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:40:30] [V] [TRT] Tactic: -1498626619443284096 Time: 0.008672
[12/29/2021-03:40:30] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:40:30] [V] [TRT] Tactic: -1283580231568512025 Time: 0.00638
[12/29/2021-03:40:30] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: -1173968681844185579
[12/29/2021-03:40:30] [V] [TRT] Tactic: -1173968681844185579 Time: 0.00642
[12/29/2021-03:40:30] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:40:30] [V] [TRT] Tactic: -762222380308749469 Time: 0.006856
[12/29/2021-03:40:30] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -713022856474991236
[12/29/2021-03:40:30] [V] [TRT] Tactic: -713022856474991236 Time: 0.006232
[12/29/2021-03:40:30] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -556794153877490941
[12/29/2021-03:40:30] [V] [TRT] Tactic: -556794153877490941 Time: 0.0069
[12/29/2021-03:40:30] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -375949437730908730
[12/29/2021-03:40:30] [V] [TRT] Tactic: -375949437730908730 Time: 0.007592
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: -3613322253849278738 Time: 0.005972
[12/29/2021-03:40:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3613322253849278738
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.005644
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.00476
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.00476
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.006556
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.004876
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.004876
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.010632
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.004592
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.004592
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.010464
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.005156
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.005156
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.005616
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.004688
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.004688
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.006472
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.004964
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.004964
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.010636
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.005192
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.005192
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.010464
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.00508
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.00508
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.010032
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.00474
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.00474
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.006536
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.004812
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.004812
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.011596
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.005128
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.005128
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.011696
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.005164
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.005164
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.012816
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.00478
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.00478
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.006548
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.004732
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.004732
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.006504
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.004804
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.004804
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.011268
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.005168
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.005168
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.011124
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.0052
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.0052
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.011024
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.00458
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.00458
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.008152
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.00518
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.00518
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.008092
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.005288
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.005288
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.008552
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.00448
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.00448
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.010648
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.005132
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.005132
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.008068
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.005208
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.005208
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.008164
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.00528
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.00528
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.008372
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.004576
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1 Time: 0.004508
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 1 Time: 0.004508
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.012612
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.004768
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.004768
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.012564
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.004728
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.004728
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.010048
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.00476
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.00476
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.01152
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.005172
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.005172
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1002 Time: 0.011104
[12/29/2021-03:40:30] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.005136
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 0 Time: 0.005136
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning format combination: Float(512,1,1,1), Float(512,1,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CudaDepthwiseConvolution)
[12/29/2021-03:40:30] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (FusedConvActConvolution)
[12/29/2021-03:40:30] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CudnnConvolution)
[12/29/2021-03:40:30] [V] [TRT] Tactic: 0 Time: 0.64108
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1 Time: 0.264144
[12/29/2021-03:40:30] [V] [TRT] Tactic: 2 Time: 0.29406
[12/29/2021-03:40:30] [V] [TRT] Tactic: 4 skipped. Scratch requested: 651165696, available: 16777216
[12/29/2021-03:40:30] [V] [TRT] Tactic: 5 skipped. Scratch requested: 1283457024, available: 16777216
[12/29/2021-03:40:30] [V] [TRT] Tactic: 6 skipped. Scratch requested: 26216448, available: 16777216
[12/29/2021-03:40:30] [V] [TRT] Tactic: 56 Time: 0.640732
[12/29/2021-03:40:30] [V] [TRT] Tactic: 57 Time: 0.263352
[12/29/2021-03:40:30] [V] [TRT] Tactic: 58 Time: 0.294668
[12/29/2021-03:40:30] [V] [TRT] Tactic: 60 skipped. Scratch requested: 651165696, available: 16777216
[12/29/2021-03:40:30] [V] [TRT] Tactic: 61 skipped. Scratch requested: 1283457024, available: 16777216
[12/29/2021-03:40:30] [V] [TRT] Tactic: 62 skipped. Scratch requested: 26216448, available: 16777216
[12/29/2021-03:40:30] [V] [TRT] Tactic: 112 Time: 0.640784
[12/29/2021-03:40:30] [V] [TRT] Tactic: 113 Time: 0.895432
[12/29/2021-03:40:30] [V] [TRT] Tactic: 114 Time: 0.29424
[12/29/2021-03:40:30] [V] [TRT] Tactic: 116 skipped. Scratch requested: 651165696, available: 16777216
[12/29/2021-03:40:30] [V] [TRT] Tactic: 117 skipped. Scratch requested: 1283457024, available: 16777216
[12/29/2021-03:40:30] [V] [TRT] Tactic: 118 skipped. Scratch requested: 26216448, available: 16777216
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: 57 Time: 0.263352
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CaskConvolution)
[12/29/2021-03:40:30] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:30] [V] [TRT] Setting workspace to 26216448enables more tactics for profiling
[12/29/2021-03:40:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 57
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning format combination: Float(512,1,512,512), Float(512,1,512,512) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CudnnConvolution)
[12/29/2021-03:40:30] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CaskConvolution)
[12/29/2021-03:40:30] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning format combination: Float(128,1:4,128,128), Float(128,1:4,128,128) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CudnnConvolution)
[12/29/2021-03:40:30] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CaskConvolution)
[12/29/2021-03:40:30] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:40:30] [V] [TRT] Tactic: 7342025736444949634 Time: 0.379352
[12/29/2021-03:40:30] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:40:30] [V] [TRT] Tactic: -7377458734869418330 Time: 0.37366
[12/29/2021-03:40:30] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:40:30] [V] [TRT] Tactic: -5457304872213719461 Time: 0.376808
[12/29/2021-03:40:30] [V] [TRT] Fastest Tactic: -7377458734869418330 Time: 0.37366
[12/29/2021-03:40:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7377458734869418330
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning format combination: Int8(128,1:4,1,1), Float(512,1,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CudaDepthwiseConvolution)
[12/29/2021-03:40:30] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CaskConvolution)
[12/29/2021-03:40:30] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning format combination: Int8(128,1:4,1,1), Int8(128,1:4,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CudaDepthwiseConvolution)
[12/29/2021-03:40:30] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (FusedConvActConvolution)
[12/29/2021-03:40:30] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CaskConvolution)
[12/29/2021-03:40:30] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning format combination: Int8(128,1:4,1,1), Int8(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CaskConvolution)
[12/29/2021-03:40:30] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:30] [V] [TRT] *************** Autotuning format combination: Int8(16,1:32,1,1), Float(16,1:32,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:40:30] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CaskConvolution)
[12/29/2021-03:40:30] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1011019097971850911 Time: 0.05256
[12/29/2021-03:40:30] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:40:30] [V] [TRT] Tactic: 1071114551801767124 Time: 0.02908
[12/29/2021-03:40:30] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:40:30] [V] [TRT] Tactic: 2623576043214044314 Time: 0.017972
[12/29/2021-03:40:30] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:40:30] [V] [TRT] Tactic: 3281631721811475881 Time: 0.022284
[12/29/2021-03:40:30] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:40:30] [V] [TRT] Tactic: 4551754795416974366 Time: 0.02
[12/29/2021-03:40:30] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:40:30] [V] [TRT] Tactic: 4925112190271421402 Time: 0.016816
[12/29/2021-03:40:30] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:40:30] [V] [TRT] Tactic: 5041593333398049019 Time: 0.016676
[12/29/2021-03:40:30] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:40:30] [V] [TRT] Tactic: 5166018662410176512 Time: 0.096764
[12/29/2021-03:40:30] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:40:31] [V] [TRT] Tactic: 6191867932654611882 Time: 0.052244
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:40:31] [V] [TRT] Tactic: 6852868042694587230 Time: 0.020704
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:40:31] [V] [TRT] Tactic: 8399092794516815300 Time: 0.09704
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:40:31] [V] [TRT] Tactic: -9132922677633967263 Time: 0.02988
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:40:31] [V] [TRT] Tactic: -7413564913826321357 Time: 0.054012
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:40:31] [V] [TRT] Tactic: -5942379529065248478 Time: 0.029432
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:40:31] [V] [TRT] Tactic: -5334776871777565833 Time: 0.09762
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:40:31] [V] [TRT] Tactic: -5157868397078537095 Time: 0.052376
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:40:31] [V] [TRT] Tactic: -5100834417027499764 Time: 0.01904
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:40:31] [V] [TRT] Tactic: -3365360067423513506 Time: 0.01496
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:40:31] [V] [TRT] Tactic: -1782593837177056527 Time: 0.029696
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:40:31] [V] [TRT] Tactic: -1573035963956198975 Time: 0.096476
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: -3365360067423513506 Time: 0.01496
[12/29/2021-03:40:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3365360067423513506
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning format combination: Int8(16,1:32,1,1), Int8(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CudaGroupConvolution)
[12/29/2021-03:40:31] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CudaDepthwiseConvolution)
[12/29/2021-03:40:31] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (FusedConvActConvolution)
[12/29/2021-03:40:31] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CaskConvolution)
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:40:31] [V] [TRT] Tactic: 2325023763229477890 Time: 0.053068
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:40:31] [V] [TRT] Tactic: 3401614690060226673 Time: 0.018748
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:40:31] [V] [TRT] Tactic: 4042202769383439184 Time: 0.029252
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:40:31] [V] [TRT] Tactic: 4734519122557206480 Time: 0.096444
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:40:31] [V] [TRT] Tactic: 5136656982162849059 Time: 0.014612
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:40:31] [V] [TRT] Tactic: 6004789655466615912 Time: 0.032024
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:40:31] [V] [TRT] Tactic: 6146901278630392829 Time: 0.096152
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:40:31] [V] [TRT] Tactic: 6781129591847482048 Time: 0.029568
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:40:31] [V] [TRT] Tactic: 8096257414008860171 Time: 0.029308
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:40:31] [V] [TRT] Tactic: -9165697322068360861 Time: 0.097496
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:40:31] [V] [TRT] Tactic: -8263994888336646547 Time: 0.051848
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:40:31] [V] [TRT] Tactic: -8205948405243401049 Time: 0.01682
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:40:31] [V] [TRT] Tactic: -7683887278997527517 Time: 0.020096
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:40:31] [V] [TRT] Tactic: -4933563390723451692 Time: 0.02218
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:40:31] [V] [TRT] Tactic: -3238475748440751107 Time: 0.028888
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:40:31] [V] [TRT] Tactic: -3182884991006484042 Time: 0.052644
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:40:31] [V] [TRT] Tactic: -3173468756112541306 Time: 0.016756
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:40:31] [V] [TRT] Tactic: -1546787387293556842 Time: 0.051716
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:40:31] [V] [TRT] Tactic: -1498626619443284096 Time: 0.034372
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:40:31] [V] [TRT] Tactic: -1283580231568512025 Time: 0.016224
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:40:31] [V] [TRT] Tactic: -762222380308749469 Time: 0.020516
[12/29/2021-03:40:31] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:40:31] [V] [TRT] Tactic: -516725800067794372 Time: 0.096332
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 5136656982162849059 Time: 0.014612
[12/29/2021-03:40:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5136656982162849059
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.005668
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.005
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.005
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.006684
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.0051
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.0051
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.012928
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.005016
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.005016
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.010884
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.004948
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.004948
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.010784
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.0054
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.0054
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.005856
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.004856
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.004856
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.00662
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.004968
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.004968
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.012716
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.004904
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.004904
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.01068
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.005152
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.005152
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.010516
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.005108
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.005108
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.010152
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.004868
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.004868
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.006628
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.00486
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.00486
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.010048
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.00478
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.00478
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.01166
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.005156
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.005156
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.01168
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.005276
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.005276
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.012864
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.004776
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.004776
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.006568
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.0048
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.0048
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.006444
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.004772
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.004772
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.011412
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.005212
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.005212
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.011124
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.005164
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.005164
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.010896
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.004504
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.004504
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.008172
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.005156
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.005156
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.008232
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.005124
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.005124
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.011456
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.005128
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.005128
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.008496
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.004488
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.004488
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.010532
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.005196
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.005196
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.008108
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.005144
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.005144
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.008132
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.005096
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.005096
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.011256
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.00522
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 0 Time: 0.00522
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1002 Time: 0.00846
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.004572
[12/29/2021-03:40:31] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1 Time: 0.004484
[12/29/2021-03:40:31] [V] [TRT] Fastest Tactic: 1 Time: 0.004484
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] *************** Autotuning format combination: Float(512,1,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CudaDepthwiseConvolution)
[12/29/2021-03:40:31] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (FusedConvActConvolution)
[12/29/2021-03:40:31] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:31] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CudnnConvolution)
[12/29/2021-03:40:31] [V] [TRT] Tactic: 0 Time: 0.638428
[12/29/2021-03:40:31] [V] [TRT] Tactic: 1 Time: 0.239912
[12/29/2021-03:40:31] [V] [TRT] Tactic: 2 Time: 0.29212
[12/29/2021-03:40:31] [V] [TRT] Tactic: 4 skipped. Scratch requested: 651165696, available: 16777216
[12/29/2021-03:40:31] [V] [TRT] Tactic: 5 skipped. Scratch requested: 1283457024, available: 16777216
[12/29/2021-03:40:31] [V] [TRT] Tactic: 6 skipped. Scratch requested: 26216448, available: 16777216
[12/29/2021-03:40:31] [V] [TRT] Tactic: 56 Time: 0.638348
[12/29/2021-03:40:32] [V] [TRT] Tactic: 57 Time: 0.202576
[12/29/2021-03:40:32] [V] [TRT] Tactic: 58 Time: 0.292072
[12/29/2021-03:40:32] [V] [TRT] Tactic: 60 skipped. Scratch requested: 651165696, available: 16777216
[12/29/2021-03:40:32] [V] [TRT] Tactic: 61 skipped. Scratch requested: 1283457024, available: 16777216
[12/29/2021-03:40:32] [V] [TRT] Tactic: 62 skipped. Scratch requested: 26216448, available: 16777216
[12/29/2021-03:40:32] [V] [TRT] Tactic: 112 Time: 0.638664
[12/29/2021-03:40:32] [V] [TRT] Tactic: 113 Time: 0.885024
[12/29/2021-03:40:32] [V] [TRT] Tactic: 114 Time: 0.29184
[12/29/2021-03:40:32] [V] [TRT] Tactic: 116 skipped. Scratch requested: 651165696, available: 16777216
[12/29/2021-03:40:32] [V] [TRT] Tactic: 117 skipped. Scratch requested: 1283457024, available: 16777216
[12/29/2021-03:40:32] [V] [TRT] Tactic: 118 skipped. Scratch requested: 26216448, available: 16777216
[12/29/2021-03:40:32] [V] [TRT] Fastest Tactic: 57 Time: 0.202576
[12/29/2021-03:40:32] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CaskConvolution)
[12/29/2021-03:40:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:32] [V] [TRT] Setting workspace to 26216448enables more tactics for profiling
[12/29/2021-03:40:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 57
[12/29/2021-03:40:32] [V] [TRT] *************** Autotuning format combination: Float(512,1,512,512) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:32] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CudnnConvolution)
[12/29/2021-03:40:32] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:32] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CaskConvolution)
[12/29/2021-03:40:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:32] [V] [TRT] *************** Autotuning format combination: Float(128,1:4,128,128) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:32] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CudnnConvolution)
[12/29/2021-03:40:32] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:32] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CaskConvolution)
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:40:32] [V] [TRT] Tactic: 7342025736444949634 Time: 0.378244
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:40:32] [V] [TRT] Tactic: -7377458734869418330 Time: 0.372428
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:40:32] [V] [TRT] Tactic: -5457304872213719461 Time: 0.375476
[12/29/2021-03:40:32] [V] [TRT] Fastest Tactic: -7377458734869418330 Time: 0.372428
[12/29/2021-03:40:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7377458734869418330
[12/29/2021-03:40:32] [V] [TRT] *************** Autotuning format combination: Int8(128,1:4,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:32] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CudaDepthwiseConvolution)
[12/29/2021-03:40:32] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:32] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CaskConvolution)
[12/29/2021-03:40:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:32] [V] [TRT] *************** Autotuning format combination: Int8(128,1:4,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:32] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CudaDepthwiseConvolution)
[12/29/2021-03:40:32] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:32] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (FusedConvActConvolution)
[12/29/2021-03:40:32] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:32] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CaskConvolution)
[12/29/2021-03:40:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:32] [V] [TRT] *************** Autotuning format combination: Int8(128,1:4,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:32] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CaskConvolution)
[12/29/2021-03:40:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:32] [V] [TRT] *************** Autotuning format combination: Int8(16,1:32,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:40:32] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CaskConvolution)
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:40:32] [V] [TRT] Tactic: 1011019097971850911 Time: 0.051412
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:40:32] [V] [TRT] Tactic: 1071114551801767124 Time: 0.028568
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:40:32] [V] [TRT] Tactic: 2623576043214044314 Time: 0.017672
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:40:32] [V] [TRT] Tactic: 3281631721811475881 Time: 0.022008
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:40:32] [V] [TRT] Tactic: 4551754795416974366 Time: 0.019792
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:40:32] [V] [TRT] Tactic: 4925112190271421402 Time: 0.016428
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:40:32] [V] [TRT] Tactic: 5041593333398049019 Time: 0.016356
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:40:32] [V] [TRT] Tactic: 5166018662410176512 Time: 0.0951
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:40:32] [V] [TRT] Tactic: 6191867932654611882 Time: 0.051592
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:40:32] [V] [TRT] Tactic: 6852868042694587230 Time: 0.020208
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:40:32] [V] [TRT] Tactic: 8399092794516815300 Time: 0.096472
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:40:32] [V] [TRT] Tactic: -9132922677633967263 Time: 0.029248
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:40:32] [V] [TRT] Tactic: -7413564913826321357 Time: 0.052908
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:40:32] [V] [TRT] Tactic: -5942379529065248478 Time: 0.028724
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:40:32] [V] [TRT] Tactic: -5334776871777565833 Time: 0.095928
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:40:32] [V] [TRT] Tactic: -5157868397078537095 Time: 0.051536
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:40:32] [V] [TRT] Tactic: -5100834417027499764 Time: 0.018484
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:40:32] [V] [TRT] Tactic: -3365360067423513506 Time: 0.014588
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:40:32] [V] [TRT] Tactic: -1782593837177056527 Time: 0.029044
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:40:32] [V] [TRT] Tactic: -1573035963956198975 Time: 0.095948
[12/29/2021-03:40:32] [V] [TRT] Fastest Tactic: -3365360067423513506 Time: 0.014588
[12/29/2021-03:40:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3365360067423513506
[12/29/2021-03:40:32] [V] [TRT] *************** Autotuning format combination: Int8(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:32] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CudaGroupConvolution)
[12/29/2021-03:40:32] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:32] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CudaDepthwiseConvolution)
[12/29/2021-03:40:32] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:32] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (FusedConvActConvolution)
[12/29/2021-03:40:32] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:32] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CaskConvolution)
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 177040020707947851
[12/29/2021-03:40:32] [V] [TRT] Tactic: 177040020707947851 Time: 0.019456
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 1550399266192842845
[12/29/2021-03:40:32] [V] [TRT] Tactic: 1550399266192842845 Time: 0.016568
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 1572887561103143487
[12/29/2021-03:40:32] [V] [TRT] Tactic: 1572887561103143487 Time: 0.031128
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:40:32] [V] [TRT] Tactic: 2325023763229477890 Time: 0.052044
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:40:32] [V] [TRT] Tactic: 3284282970967328046 Time: 0.01436
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:40:32] [V] [TRT] Tactic: 3401614690060226673 Time: 0.018544
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3512426920013359699
[12/29/2021-03:40:32] [V] [TRT] Tactic: 3512426920013359699 Time: 0.021828
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:40:32] [V] [TRT] Tactic: 4042202769383439184 Time: 0.028908
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 4259547356717612415
[12/29/2021-03:40:32] [V] [TRT] Tactic: 4259547356717612415 Time: 0.032856
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:40:32] [V] [TRT] Tactic: 4734519122557206480 Time: 0.095344
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 5121596860264626879
[12/29/2021-03:40:32] [V] [TRT] Tactic: 5121596860264626879 Time: 0.095296
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:40:32] [V] [TRT] Tactic: 5136656982162849059 Time: 0.014508
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 5158259316594207439
[12/29/2021-03:40:32] [V] [TRT] Tactic: 5158259316594207439 Time: 0.028876
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 5966973378912044513
[12/29/2021-03:40:32] [V] [TRT] Tactic: 5966973378912044513 Time: 0.0511
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:40:32] [V] [TRT] Tactic: 6004789655466615912 Time: 0.031192
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:40:32] [V] [TRT] Tactic: 6146901278630392829 Time: 0.095048
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 6434020722187266170
[12/29/2021-03:40:32] [V] [TRT] Tactic: 6434020722187266170 Time: 0.09592
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:40:32] [V] [TRT] Tactic: 6781129591847482048 Time: 0.029116
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7191893591576074000
[12/29/2021-03:40:32] [V] [TRT] Tactic: 7191893591576074000 Time: 0.016464
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7438984192263206338
[12/29/2021-03:40:32] [V] [TRT] Tactic: 7438984192263206338 Time: 0.028276
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 7504901284678552178
[12/29/2021-03:40:32] [V] [TRT] Tactic: 7504901284678552178 Time: 0.051208
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:40:32] [V] [TRT] Tactic: 8096257414008860171 Time: 0.02882
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 9143438935315839085
[12/29/2021-03:40:32] [V] [TRT] Tactic: 9143438935315839085 Time: 0.018824
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:40:32] [V] [TRT] Tactic: -9165697322068360861 Time: 0.095948
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:40:32] [V] [TRT] Tactic: -8263994888336646547 Time: 0.050976
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:40:32] [V] [TRT] Tactic: -8205948405243401049 Time: 0.016564
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -7992068592656168418
[12/29/2021-03:40:32] [V] [TRT] Tactic: -7992068592656168418 Time: 0.028756
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: -7842775553137511386
[12/29/2021-03:40:32] [V] [TRT] Tactic: -7842775553137511386 Time: 0.052112
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:40:32] [V] [TRT] Tactic: -7683887278997527517 Time: 0.019888
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5709079507616090666
[12/29/2021-03:40:32] [V] [TRT] Tactic: -5709079507616090666 Time: 0.051044
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5698636014239116282
[12/29/2021-03:40:32] [V] [TRT] Tactic: -5698636014239116282 Time: 0.09516
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:40:32] [V] [TRT] Tactic: -4933563390723451692 Time: 0.021872
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -3413217501222406256
[12/29/2021-03:40:32] [V] [TRT] Tactic: -3413217501222406256 Time: 0.095124
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:40:32] [V] [TRT] Tactic: -3238475748440751107 Time: 0.02838
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:40:32] [V] [TRT] Tactic: -3182884991006484042 Time: 0.051472
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:40:32] [V] [TRT] Tactic: -3173468756112541306 Time: 0.016448
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -2083778562631872334
[12/29/2021-03:40:32] [V] [TRT] Tactic: -2083778562631872334 Time: 0.029092
[12/29/2021-03:40:32] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:40:33] [V] [TRT] Tactic: -1546787387293556842 Time: 0.051024
[12/29/2021-03:40:33] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:40:33] [V] [TRT] Tactic: -1498626619443284096 Time: 0.033596
[12/29/2021-03:40:33] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:40:33] [V] [TRT] Tactic: -1283580231568512025 Time: 0.015992
[12/29/2021-03:40:33] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: -1173968681844185579
[12/29/2021-03:40:33] [V] [TRT] Tactic: -1173968681844185579 Time: 0.015656
[12/29/2021-03:40:33] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:40:33] [V] [TRT] Tactic: -762222380308749469 Time: 0.020204
[12/29/2021-03:40:33] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -556794153877490941
[12/29/2021-03:40:33] [V] [TRT] Tactic: -556794153877490941 Time: 0.020224
[12/29/2021-03:40:33] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:40:33] [V] [TRT] Tactic: -516725800067794372 Time: 0.09496
[12/29/2021-03:40:33] [V] [TRT] Fastest Tactic: 3284282970967328046 Time: 0.01436
[12/29/2021-03:40:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3284282970967328046
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning format combination: Float(512,1,1,1), Float(512,1,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning format combination: Float(512,1,512,512), Float(512,1,512,512) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Conv_117 + Add_118 + Relu_121 (CudnnConvolution)
[12/29/2021-03:40:33] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Conv_117 + Add_118 + Relu_121 (CaskConvolution)
[12/29/2021-03:40:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning format combination: Float(128,1:4,128,128), Float(128,1:4,128,128) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning format combination: Int8(128,1:4,1,1), Float(512,1,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Conv_117 + Add_118 + Relu_121 (CudaDepthwiseConvolution)
[12/29/2021-03:40:33] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Conv_117 + Add_118 + Relu_121 (CaskConvolution)
[12/29/2021-03:40:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning format combination: Int8(128,1:4,1,1), Int8(128,1:4,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Conv_117 + Add_118 + Relu_121 (CudaDepthwiseConvolution)
[12/29/2021-03:40:33] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Conv_117 + Add_118 + Relu_121 (FusedConvActConvolution)
[12/29/2021-03:40:33] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Conv_117 + Add_118 + Relu_121 (CaskConvolution)
[12/29/2021-03:40:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning format combination: Int8(128,1:4,1,1), Int8(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Conv_117 + Add_118 + Relu_121 (CaskConvolution)
[12/29/2021-03:40:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning format combination: Int8(16,1:32,1,1), Float(16,1:32,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning format combination: Int8(16,1:32,1,1), Int8(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning format combination: Float(512,1,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_122 (TiledPooling)
[12/29/2021-03:40:33] [V] [TRT] Tactic: 7209217 Time: 0.016096
[12/29/2021-03:40:33] [V] [TRT] Fastest Tactic: 7209217 Time: 0.016096
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_122 (CudnnPooling)
[12/29/2021-03:40:33] [V] [TRT] Tactic: -1 Time: 0.005312
[12/29/2021-03:40:33] [V] [TRT] Fastest Tactic: -1 Time: 0.005312
[12/29/2021-03:40:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning format combination: Int8(128,1:4,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_122 (TiledPooling)
[12/29/2021-03:40:33] [V] [TRT] Tactic: 7209217 Time: 0.007884
[12/29/2021-03:40:33] [V] [TRT] Fastest Tactic: 7209217 Time: 0.007884
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_122 (CudaPooling)
[12/29/2021-03:40:33] [V] [TRT] Tactic: -3 Time: 0.004632
[12/29/2021-03:40:33] [V] [TRT] Fastest Tactic: -3 Time: 0.004632
[12/29/2021-03:40:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaPooling Tactic: -3
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning format combination: Int8(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_122 (TiledPooling)
[12/29/2021-03:40:33] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_122 (CudaPooling)
[12/29/2021-03:40:33] [V] [TRT] Tactic: -4 Time: 0.004632
[12/29/2021-03:40:33] [V] [TRT] Fastest Tactic: -4 Time: 0.004632
[12/29/2021-03:40:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaPooling Tactic: -4
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning format combination: Float(512,1,1,1) -> Float(10,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Gemm_126 (CudaDepthwiseConvolution)
[12/29/2021-03:40:33] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Gemm_126 (FusedConvActConvolution)
[12/29/2021-03:40:33] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Gemm_126 (CudnnConvolution)
[12/29/2021-03:40:33] [V] [TRT] Tactic: 0 Time: 0.0705
[12/29/2021-03:40:33] [V] [TRT] Tactic: 1 Time: 0.092576
[12/29/2021-03:40:33] [V] [TRT] Tactic: 2 Time: 0.099992
[12/29/2021-03:40:33] [V] [TRT] Tactic: 4 skipped. Scratch requested: 49565696, available: 16777216
[12/29/2021-03:40:33] [V] [TRT] Tactic: 5 Time: 0.055788
[12/29/2021-03:40:33] [V] [TRT] Tactic: 56 Time: 0.070416
[12/29/2021-03:40:33] [V] [TRT] Tactic: 57 Time: 0.082376
[12/29/2021-03:40:33] [V] [TRT] Tactic: 58 Time: 0.100108
[12/29/2021-03:40:33] [V] [TRT] Tactic: 60 skipped. Scratch requested: 49565696, available: 16777216
[12/29/2021-03:40:33] [V] [TRT] Tactic: 61 Time: 0.055884
[12/29/2021-03:40:33] [V] [TRT] Tactic: 112 Time: 0.070512
[12/29/2021-03:40:33] [V] [TRT] Tactic: 113 Time: 0.23224
[12/29/2021-03:40:33] [V] [TRT] Tactic: 114 Time: 0.099992
[12/29/2021-03:40:33] [V] [TRT] Tactic: 116 skipped. Scratch requested: 49565696, available: 16777216
[12/29/2021-03:40:33] [V] [TRT] Tactic: 117 Time: 0.056228
[12/29/2021-03:40:33] [V] [TRT] Fastest Tactic: 5 Time: 0.055788
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Gemm_126 (CublasConvolution)
[12/29/2021-03:40:33] [V] [TRT] Tactic: 0 Time: 0.012528
[12/29/2021-03:40:33] [V] [TRT] Tactic: 1 Time: 0.01652
[12/29/2021-03:40:33] [V] [TRT] Tactic: 2 Time: 0.013696
[12/29/2021-03:40:33] [V] [TRT] Tactic: 3 Time: 0.014144
[12/29/2021-03:40:33] [V] [TRT] Fastest Tactic: 0 Time: 0.012528
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Gemm_126 (CaskConvolution)
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:40:33] [V] [TRT] Tactic: 4549827808004681195 Time: 0.057
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:40:33] [V] [TRT] Tactic: 5779835512569528575 Time: 0.072588
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 9151672657204310840
[12/29/2021-03:40:33] [V] [TRT] Tactic: 9151672657204310840 Time: 0.066092
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: -7491730084094677098
[12/29/2021-03:40:33] [V] [TRT] Tactic: -7491730084094677098 Time: 0.064628
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: -6622064180404051845
[12/29/2021-03:40:33] [V] [TRT] Tactic: -6622064180404051845 Time: 0.062436
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:40:33] [V] [TRT] Tactic: -6313876406580483184 Time: 0.065372
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: -6273689210331812572
[12/29/2021-03:40:33] [V] [TRT] Tactic: -6273689210331812572 Time: 0.07138
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: -4337126844824617177
[12/29/2021-03:40:33] [V] [TRT] Tactic: -4337126844824617177 Time: 0.052964
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:40:33] [V] [TRT] Tactic: -1123676555321336786 Time: 0.071636
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:40:33] [V] [TRT] Tactic: -701551393537224327 Time: 0.062044
[12/29/2021-03:40:33] [V] [TRT] Fastest Tactic: -4337126844824617177 Time: 0.052964
[12/29/2021-03:40:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning format combination: Float(512,1,512,512) -> Float(10,1,10,10) ***************
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Gemm_126 (CudnnConvolution)
[12/29/2021-03:40:33] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Gemm_126 (CublasConvolution)
[12/29/2021-03:40:33] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Gemm_126 (CaskConvolution)
[12/29/2021-03:40:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning format combination: Float(128,1:4,128,128) -> Float(3,1:4,3,3) ***************
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Gemm_126 (CudnnConvolution)
[12/29/2021-03:40:33] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Gemm_126 (CublasConvolution)
[12/29/2021-03:40:33] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Gemm_126 (CaskConvolution)
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 1373022415249282411
[12/29/2021-03:40:33] [V] [TRT] Tactic: 1373022415249282411 Time: 0.047616
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 1663866669559596164
[12/29/2021-03:40:33] [V] [TRT] Tactic: 1663866669559596164 Time: 0.069704
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:40:33] [V] [TRT] Tactic: 2860655430572478466 Time: 0.043984
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:40:33] [V] [TRT] Tactic: 4474630279712975759 Time: 0.027084
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:40:33] [V] [TRT] Tactic: 4479823862704990365 Time: 0.02658
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:40:33] [V] [TRT] Tactic: 4696204239951173149 Time: 0.04324
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:40:33] [V] [TRT] Tactic: 5778138195697110003 Time: 0.070612
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:40:33] [V] [TRT] Tactic: 8918020581761223752 Time: 0.06692
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: -7067026478815706014
[12/29/2021-03:40:33] [V] [TRT] Tactic: -7067026478815706014 Time: 0.04752
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -5905193483742532701
[12/29/2021-03:40:33] [V] [TRT] Tactic: -5905193483742532701 Time: 0.039356
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -4035591156787122265
[12/29/2021-03:40:33] [V] [TRT] Tactic: -4035591156787122265 Time: 0.026244
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:40:33] [V] [TRT] Tactic: -2809379259463049391 Time: 0.069944
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -1985235291706575900
[12/29/2021-03:40:33] [V] [TRT] Tactic: -1985235291706575900 Time: 0.067364
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:40:33] [V] [TRT] Tactic: -504296718212024303 Time: 0.068416
[12/29/2021-03:40:33] [V] [TRT] Fastest Tactic: -4035591156787122265 Time: 0.026244
[12/29/2021-03:40:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4035591156787122265
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning format combination: Int8(128,1:4,1,1) -> Float(10,1,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Gemm_126 (CudaDepthwiseConvolution)
[12/29/2021-03:40:33] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Gemm_126 (CaskConvolution)
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:40:33] [V] [TRT] Tactic: 1508480131241957639 Time: 0.030204
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 2141154648944475104
[12/29/2021-03:40:33] [V] [TRT] Tactic: 2141154648944475104 Time: 0.03
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:40:33] [V] [TRT] Tactic: 3239257003214966313 Time: 0.030196
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:40:33] [V] [TRT] Tactic: 5592640619112287921 Time: 0.020612
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:40:33] [V] [TRT] Tactic: 7621465827583909090 Time: 0.021484
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: -6580271968881459581
[12/29/2021-03:40:33] [V] [TRT] Tactic: -6580271968881459581 Time: 0.023116
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:40:33] [V] [TRT] Tactic: -5576936487443445631 Time: 0.022672
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: -4443833619060044580
[12/29/2021-03:40:33] [V] [TRT] Tactic: -4443833619060044580 Time: 0.020664
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:40:33] [V] [TRT] Tactic: -2297737319934264721 Time: 0.024588
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:40:33] [V] [TRT] Tactic: -1425085658556684465 Time: 0.022012
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:40:33] [V] [TRT] Tactic: -108011214168778087 Time: 0.023184
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: -42427192380281294
[12/29/2021-03:40:33] [V] [TRT] Tactic: -42427192380281294 Time: 0.020488
[12/29/2021-03:40:33] [V] [TRT] Fastest Tactic: -42427192380281294 Time: 0.020488
[12/29/2021-03:40:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -42427192380281294
[12/29/2021-03:40:33] [V] [TRT] *************** Autotuning format combination: Int8(16,1:32,1,1) -> Float(1,1:32,1,1) ***************
[12/29/2021-03:40:33] [V] [TRT] --------------- Timing Runner: Gemm_126 (CaskConvolution)
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 2185926646498217601
[12/29/2021-03:40:33] [V] [TRT] Tactic: 2185926646498217601 Time: 0.011336
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 2818014835119698671
[12/29/2021-03:40:33] [V] [TRT] Tactic: 2818014835119698671 Time: 0.008724
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 3721599319722771137
[12/29/2021-03:40:33] [V] [TRT] Tactic: 3721599319722771137 Time: 0.007268
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_interior_nt_v1 Tactic: 4178917718361232468
[12/29/2021-03:40:33] [V] [TRT] Tactic: 4178917718361232468 Time: 0.01326
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:40:33] [V] [TRT] Tactic: 5012796702462679112 Time: 0.018656
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:40:33] [V] [TRT] Tactic: 6556170942941957134 Time: 0.0135
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 6618077155362058131
[12/29/2021-03:40:33] [V] [TRT] Tactic: 6618077155362058131 Time: 0.00672
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 6969462133921577484
[12/29/2021-03:40:33] [V] [TRT] Tactic: 6969462133921577484 Time: 0.017028
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 7348718297764976805
[12/29/2021-03:40:33] [V] [TRT] Tactic: 7348718297764976805 Time: 0.006776
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 7869897696365535632
[12/29/2021-03:40:33] [V] [TRT] Tactic: 7869897696365535632 Time: 0.006672
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 7970271430402365872
[12/29/2021-03:40:33] [V] [TRT] Tactic: 7970271430402365872 Time: 0.008508
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 8584126525867982141
[12/29/2021-03:40:33] [V] [TRT] Tactic: 8584126525867982141 Time: 0.008556
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -8912999970161746151
[12/29/2021-03:40:33] [V] [TRT] Tactic: -8912999970161746151 Time: 0.008616
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -8893439100868426414
[12/29/2021-03:40:33] [V] [TRT] Tactic: -8893439100868426414 Time: 0.011628
[12/29/2021-03:40:33] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: -8069335661823714580
[12/29/2021-03:40:34] [V] [TRT] Tactic: -8069335661823714580 Time: 0.01688
[12/29/2021-03:40:34] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:40:34] [V] [TRT] Tactic: -7988637803896331454 Time: 0.013296
[12/29/2021-03:40:34] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: -7957004747664952265
[12/29/2021-03:40:34] [V] [TRT] Tactic: -7957004747664952265 Time: 0.016932
[12/29/2021-03:40:34] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_interior_nt_v1 Tactic: -7904635102498369361
[12/29/2021-03:40:34] [V] [TRT] Tactic: -7904635102498369361 Time: 0.018316
[12/29/2021-03:40:34] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: -7633993163187901093
[12/29/2021-03:40:34] [V] [TRT] Tactic: -7633993163187901093 Time: 0.007244
[12/29/2021-03:40:34] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:40:34] [V] [TRT] Tactic: -7606074703023778034 Time: 0.013384
[12/29/2021-03:40:34] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:40:34] [V] [TRT] Tactic: -7282232519526877434 Time: 0.018564
[12/29/2021-03:40:34] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: -7007036200777870226
[12/29/2021-03:40:34] [V] [TRT] Tactic: -7007036200777870226 Time: 0.00712
[12/29/2021-03:40:34] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -6406011580107094428
[12/29/2021-03:40:34] [V] [TRT] Tactic: -6406011580107094428 Time: 0.007372
[12/29/2021-03:40:34] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:40:34] [V] [TRT] Tactic: -5603587790314027122 Time: 0.013844
[12/29/2021-03:40:34] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_interior_nt_v1 Tactic: -5416590980288859834
[12/29/2021-03:40:34] [V] [TRT] Tactic: -5416590980288859834 Time: 0.013204
[12/29/2021-03:40:34] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: -4704615512436071369
[12/29/2021-03:40:34] [V] [TRT] Tactic: -4704615512436071369 Time: 0.011132
[12/29/2021-03:40:34] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -3665201838779845683
[12/29/2021-03:40:34] [V] [TRT] Tactic: -3665201838779845683 Time: 0.01708
[12/29/2021-03:40:34] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_interior_nt_v1 Tactic: -3644377136375731441
[12/29/2021-03:40:34] [V] [TRT] Tactic: -3644377136375731441 Time: 0.013608
[12/29/2021-03:40:34] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -3502495740607894730
[12/29/2021-03:40:34] [V] [TRT] Tactic: -3502495740607894730 Time: 0.006748
[12/29/2021-03:40:34] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -2342404147487779225
[12/29/2021-03:40:34] [V] [TRT] Tactic: -2342404147487779225 Time: 0.011404
[12/29/2021-03:40:34] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:40:34] [V] [TRT] Tactic: -1610768292520086910 Time: 0.013876
[12/29/2021-03:40:34] [V] [TRT] Gemm_126 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:40:34] [V] [TRT] Tactic: -621838502160440068 Time: 0.014212
[12/29/2021-03:40:34] [V] [TRT] Fastest Tactic: 7869897696365535632 Time: 0.006672
[12/29/2021-03:40:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 7869897696365535632
[12/29/2021-03:40:34] [V] [TRT] *************** Autotuning Reformat:Float(10,1,10,10) -> Float(10,1,1,1) ***************
[12/29/2021-03:40:34] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:34] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:34] [V] [TRT] Tactic: 1002 Time: 0.006228
[12/29/2021-03:40:34] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:34] [V] [TRT] Tactic: 0 Time: 0.004588
[12/29/2021-03:40:34] [V] [TRT] Fastest Tactic: 0 Time: 0.004588
[12/29/2021-03:40:34] [V] [TRT] *************** Autotuning Reformat:Float(3,1:4,3,3) -> Float(10,1,1,1) ***************
[12/29/2021-03:40:34] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:34] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:34] [V] [TRT] Tactic: 1002 Time: 0.006232
[12/29/2021-03:40:34] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:34] [V] [TRT] Tactic: 0 Time: 0.00462
[12/29/2021-03:40:34] [V] [TRT] Fastest Tactic: 0 Time: 0.00462
[12/29/2021-03:40:34] [V] [TRT] *************** Autotuning Reformat:Float(1,1:32,1,1) -> Float(10,1,1,1) ***************
[12/29/2021-03:40:34] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:40:34] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:34] [V] [TRT] Tactic: 1002 Time: 0.008412
[12/29/2021-03:40:34] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:40:34] [V] [TRT] Tactic: 0 Time: 0.00464
[12/29/2021-03:40:34] [V] [TRT] Fastest Tactic: 0 Time: 0.00464
[12/29/2021-03:40:34] [V] [TRT] *************** Autotuning format combination: Float(10,1,1,1) -> Float(10,1) ***************
[12/29/2021-03:40:34] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 50) [Shuffle] (Shuffle)
[12/29/2021-03:40:34] [V] [TRT] Tactic: 0 Time: 0.00412
[12/29/2021-03:40:34] [V] [TRT] Tactic: 1 Time: 0.008616
[12/29/2021-03:40:34] [V] [TRT] Fastest Tactic: 0 Time: 0.00412
[12/29/2021-03:40:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0
[12/29/2021-03:40:34] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_2 + Relu_5 + MaxPool_8 (actual_input_1) from Float(3072,1024,32,1) to Int8(3072,1024,32,1)
[12/29/2021-03:40:34] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to (Unnamed Layer* 50) [Shuffle] ((Unnamed Layer* 49) [Fully Connected]_output) from Float(1,1:32,1,1) to Float(10,1,1,1)
[12/29/2021-03:40:34] [V] [TRT] Formats and tactics selection completed in 23.1929 seconds.
[12/29/2021-03:40:34] [V] [TRT] After reformat layers: 25 layers
[12/29/2021-03:40:34] [V] [TRT] Block size 16777216
[12/29/2021-03:40:34] [V] [TRT] Block size 131072
[12/29/2021-03:40:34] [V] [TRT] Block size 131072
[12/29/2021-03:40:34] [V] [TRT] Block size 131072
[12/29/2021-03:40:34] [V] [TRT] Total Activation Memory: 17170432
[12/29/2021-03:40:34] [I] [TRT] Detected 1 inputs and 1 output network tensors.
[12/29/2021-03:40:34] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:40:34] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:40:34] [V] [TRT] Conv_24 + Relu_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:40:34] [V] [TRT] Conv_30 + Add_31 + Relu_34 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:40:34] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:40:34] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -713022856474991236
[12/29/2021-03:40:34] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:40:34] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:40:34] [V] [TRT] Conv_59 + Add_60 + Relu_63 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:40:34] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:40:34] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -713022856474991236
[12/29/2021-03:40:34] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:40:34] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:40:34] [V] [TRT] Conv_88 + Add_89 + Relu_92 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:40:34] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:40:34] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -3613322253849278738
[12/29/2021-03:40:34] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:40:34] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:40:34] [V] [TRT] Conv_117 + Add_118 + Relu_121 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:40:34] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_simple_t1r1s1 Tactic: 7869897696365535632
[12/29/2021-03:40:34] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_2 + Relu_5 + MaxPool_8 HostPersistent: 0 DevicePersistent: 0
[12/29/2021-03:40:34] [V] [TRT] Layer: Conv_2 + Relu_5 + MaxPool_8 HostPersistent: 0 DevicePersistent: 0
[12/29/2021-03:40:34] [V] [TRT] Layer: Conv_11 + Relu_14 HostPersistent: 2976 DevicePersistent: 37888
[12/29/2021-03:40:34] [V] [TRT] Layer: Conv_17 + Add_18 + Relu_21 HostPersistent: 2976 DevicePersistent: 37888
[12/29/2021-03:40:34] [V] [TRT] Layer: Conv_24 + Relu_27 HostPersistent: 2976 DevicePersistent: 37888
[12/29/2021-03:40:34] [V] [TRT] Layer: Conv_30 + Add_31 + Relu_34 HostPersistent: 2976 DevicePersistent: 37888
[12/29/2021-03:40:34] [V] [TRT] Layer: Conv_37 + Relu_40 HostPersistent: 2976 DevicePersistent: 75264
[12/29/2021-03:40:34] [V] [TRT] Layer: Conv_46 HostPersistent: 2976 DevicePersistent: 9728
[12/29/2021-03:40:34] [V] [TRT] Layer: Conv_43 + Add_47 + Relu_50 HostPersistent: 2976 DevicePersistent: 148992
[12/29/2021-03:40:34] [V] [TRT] Layer: Conv_53 + Relu_56 HostPersistent: 2976 DevicePersistent: 148992
[12/29/2021-03:40:34] [V] [TRT] Layer: Conv_59 + Add_60 + Relu_63 HostPersistent: 2976 DevicePersistent: 148992
[12/29/2021-03:40:34] [V] [TRT] Layer: Conv_66 + Relu_69 HostPersistent: 2976 DevicePersistent: 297984
[12/29/2021-03:40:34] [V] [TRT] Layer: Conv_75 HostPersistent: 2976 DevicePersistent: 35840
[12/29/2021-03:40:34] [V] [TRT] Layer: Conv_72 + Add_76 + Relu_79 HostPersistent: 2976 DevicePersistent: 592896
[12/29/2021-03:40:34] [V] [TRT] Layer: Conv_82 + Relu_85 HostPersistent: 2976 DevicePersistent: 592896
[12/29/2021-03:40:34] [V] [TRT] Layer: Conv_88 + Add_89 + Relu_92 HostPersistent: 2976 DevicePersistent: 592896
[12/29/2021-03:40:34] [V] [TRT] Layer: Conv_95 + Relu_98 HostPersistent: 2976 DevicePersistent: 1185792
[12/29/2021-03:40:34] [V] [TRT] Layer: Conv_104 HostPersistent: 2976 DevicePersistent: 137216
[12/29/2021-03:40:34] [V] [TRT] Layer: Conv_101 + Add_105 + Relu_108 HostPersistent: 2976 DevicePersistent: 2365440
[12/29/2021-03:40:34] [V] [TRT] Layer: Conv_111 + Relu_114 HostPersistent: 2976 DevicePersistent: 2365440
[12/29/2021-03:40:34] [V] [TRT] Layer: Conv_117 + Add_118 + Relu_121 HostPersistent: 2976 DevicePersistent: 2365440
[12/29/2021-03:40:34] [V] [TRT] Layer: GlobalAveragePool_122 HostPersistent: 0 DevicePersistent: 0
[12/29/2021-03:40:34] [V] [TRT] Layer: Gemm_126 HostPersistent: 2976 DevicePersistent: 16896
[12/29/2021-03:40:34] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 50) [Shuffle] HostPersistent: 0 DevicePersistent: 0
[12/29/2021-03:40:34] [I] [TRT] Total Host Persistent Memory: 59520
[12/29/2021-03:40:34] [I] [TRT] Total Device Persistent Memory: 11232256
[12/29/2021-03:40:34] [I] [TRT] Total Scratch Memory: 0
[12/29/2021-03:40:34] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 13 MiB, GPU 4 MiB
[12/29/2021-03:40:34] [V] [TRT] Using cublasLt a tactic source
[12/29/2021-03:40:34] [12/29/2021-03:40:34] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2078, GPU 4032 (MiB)
[12/29/2021-03:40:34] [V] [TRT] Using cuDNN as a tactic source
[12/29/2021-03:40:34] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +8, now: CPU 2079, GPU 4040 (MiB)
[12/29/2021-03:40:34] [12/29/2021-03:40:34] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 2078, GPU 4024 (MiB)
[12/29/2021-03:40:34] [V] [TRT] Engine generation completed in 24.3533 seconds.
[12/29/2021-03:40:34] [V] [TRT] Deleting timing cache: 351 entries, 761 hits
[12/29/2021-03:40:34] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 2078, GPU 4006 (MiB)
[12/29/2021-03:40:34] [V] [TRT] Engine Layer Information:
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv_2 + Relu_5 + MaxPool_8, Tactic: 0, actual_input_1[Float(32,3,32,32)] -> Reformatted Input Tensor 0 to Conv_2 + Relu_5 + MaxPool_8[Int8(32,3,32,32)]
Layer(ConvActPool): Conv_2 + Relu_5 + MaxPool_8, Tactic: 1111, Reformatted Input Tensor 0 to Conv_2 + Relu_5 + MaxPool_8[Int8(32,3,32,32)] -> 132[Int8(32,64,8,8)]
Layer(CaskConvolution): Conv_11 + Relu_14, Tactic: 3401614690060226673, 132[Int8(32,64,8,8)] -> 139[Int8(32,64,8,8)]
Layer(CaskConvolution): Conv_17 + Add_18 + Relu_21, Tactic: 3401614690060226673, 139[Int8(32,64,8,8)], 132[Int8(32,64,8,8)] -> 147[Int8(32,64,8,8)]
Layer(CaskConvolution): Conv_24 + Relu_27, Tactic: 3401614690060226673, 147[Int8(32,64,8,8)] -> 154[Int8(32,64,8,8)]
Layer(CaskConvolution): Conv_30 + Add_31 + Relu_34, Tactic: 3401614690060226673, 154[Int8(32,64,8,8)], 147[Int8(32,64,8,8)] -> 162[Int8(32,64,8,8)]
Layer(CaskConvolution): Conv_37 + Relu_40, Tactic: 5136656982162849059, 162[Int8(32,64,8,8)] -> 169[Int8(32,128,4,4)]
Layer(CaskConvolution): Conv_46, Tactic: -713022856474991236, 162[Int8(32,64,8,8)] -> 291[Int8(32,128,4,4)]
Layer(CaskConvolution): Conv_43 + Add_47 + Relu_50, Tactic: 5136656982162849059, 169[Int8(32,128,4,4)], 291[Int8(32,128,4,4)] -> 181[Int8(32,128,4,4)]
Layer(CaskConvolution): Conv_53 + Relu_56, Tactic: 5136656982162849059, 181[Int8(32,128,4,4)] -> 188[Int8(32,128,4,4)]
Layer(CaskConvolution): Conv_59 + Add_60 + Relu_63, Tactic: 5136656982162849059, 188[Int8(32,128,4,4)], 181[Int8(32,128,4,4)] -> 196[Int8(32,128,4,4)]
Layer(CaskConvolution): Conv_66 + Relu_69, Tactic: 5136656982162849059, 196[Int8(32,128,4,4)] -> 203[Int8(32,256,2,2)]
Layer(CaskConvolution): Conv_75, Tactic: -713022856474991236, 196[Int8(32,128,4,4)] -> 306[Int8(32,256,2,2)]
Layer(CaskConvolution): Conv_72 + Add_76 + Relu_79, Tactic: 5136656982162849059, 203[Int8(32,256,2,2)], 306[Int8(32,256,2,2)] -> 215[Int8(32,256,2,2)]
Layer(CaskConvolution): Conv_82 + Relu_85, Tactic: 3284282970967328046, 215[Int8(32,256,2,2)] -> 222[Int8(32,256,2,2)]
Layer(CaskConvolution): Conv_88 + Add_89 + Relu_92, Tactic: 5136656982162849059, 222[Int8(32,256,2,2)], 215[Int8(32,256,2,2)] -> 230[Int8(32,256,2,2)]
Layer(CaskConvolution): Conv_95 + Relu_98, Tactic: 3284282970967328046, 230[Int8(32,256,2,2)] -> 237[Int8(32,512,1,1)]
Layer(CaskConvolution): Conv_104, Tactic: -3613322253849278738, 230[Int8(32,256,2,2)] -> 321[Int8(32,512,1,1)]
Layer(CaskConvolution): Conv_101 + Add_105 + Relu_108, Tactic: 5136656982162849059, 237[Int8(32,512,1,1)], 321[Int8(32,512,1,1)] -> 249[Int8(32,512,1,1)]
Layer(CaskConvolution): Conv_111 + Relu_114, Tactic: 3284282970967328046, 249[Int8(32,512,1,1)] -> 256[Int8(32,512,1,1)]
Layer(CaskConvolution): Conv_117 + Add_118 + Relu_121, Tactic: 5136656982162849059, 256[Int8(32,512,1,1)], 249[Int8(32,512,1,1)] -> 264[Int8(32,512,1,1)]
Layer(CudaPooling): GlobalAveragePool_122, Tactic: -4, 264[Int8(32,512,1,1)] -> 265[Int8(32,512,1,1)]
Layer(CaskConvolution): Gemm_126, Tactic: 7869897696365535632, 265[Int8(32,512,1,1)] -> (Unnamed Layer* 49) [Fully Connected]_output[Float(32,10,1,1)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 50) [Shuffle], Tactic: 0, (Unnamed Layer* 49) [Fully Connected]_output[Float(32,10,1,1)] -> Reformatted Input Tensor 0 to (Unnamed Layer* 50) [Shuffle][Float(32,10,1,1)]
[12/29/2021-03:40:34] [I] [TRT] [MemUsageSnapshot] Builder end: CPU 2078 MiB, GPU 4006 MiB
[12/29/2021-03:40:34] [I] [TRT] Loaded engine size: 10 MB
[12/29/2021-03:40:34] [I] [TRT] [MemUsageSnapshot] deserializeCudaEngine begin: CPU 2086 MiB, GPU 3994 MiB
[12/29/2021-03:40:34] [V] [TRT] Using cublasLt a tactic source
[12/29/2021-03:40:34] [12/29/2021-03:40:34] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2087, GPU 4016 (MiB)
[12/29/2021-03:40:34] [V] [TRT] Using cuDNN as a tactic source
[12/29/2021-03:40:34] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2087, GPU 4024 (MiB)
[12/29/2021-03:40:34] [12/29/2021-03:40:34] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 2087, GPU 4006 (MiB)
[12/29/2021-03:40:34] [V] [TRT] Deserialization required 30606 microseconds.
[12/29/2021-03:40:34] [I] [TRT] [MemUsageSnapshot] deserializeCudaEngine end: CPU 2087 MiB, GPU 4006 MiB
[12/29/2021-03:40:34] [I] Engine built in 25.1098 sec.
[12/29/2021-03:40:34] [I] [TRT] [MemUsageSnapshot] ExecutionContext creation begin: CPU 2050 MiB, GPU 4006 MiB
[12/29/2021-03:40:34] [V] [TRT] Using cublasLt a tactic source
[12/29/2021-03:40:34] [12/29/2021-03:40:34] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2050, GPU 4016 (MiB)
[12/29/2021-03:40:34] [V] [TRT] Using cuDNN as a tactic source
[12/29/2021-03:40:34] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +8, now: CPU 2051, GPU 4024 (MiB)
[12/29/2021-03:40:34] [12/29/2021-03:40:34] [V] [TRT] Total per-runner device memory is 11232256
[12/29/2021-03:40:34] [V] [TRT] Total per-runner host memory is 59520
[12/29/2021-03:40:34] [V] [TRT] Allocated activation device memory of size 393216
[12/29/2021-03:40:34] [I] [TRT] [MemUsageSnapshot] ExecutionContext creation end: CPU 2051 MiB, GPU 4036 MiB
[12/29/2021-03:40:34] [I] Created input binding for actual_input_1 with dimensions 32x3x32x32
[12/29/2021-03:40:34] [I] Created output binding for output1 with dimensions 32x10
[12/29/2021-03:40:34] [I] Starting inference
[12/29/2021-03:40:37] [I] Warmup completed 1088 queries over 200 ms
[12/29/2021-03:40:37] [I] Timing trace has 18070 queries over 3.00025 s
[12/29/2021-03:40:37] [I] 
[12/29/2021-03:40:37] [I] === Trace details ===
[12/29/2021-03:40:37] [I] Trace averages of 10 runs:
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.194124 ms - Host latency: 0.23895 ms (end to end 0.246828 ms, enqueue 0.220772 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.19352 ms - Host latency: 0.239104 ms (end to end 0.247057 ms, enqueue 0.218806 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153058 ms - Host latency: 0.198155 ms (end to end 0.214828 ms, enqueue 0.147754 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152689 ms - Host latency: 0.200427 ms (end to end 0.216965 ms, enqueue 0.150764 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153297 ms - Host latency: 0.199727 ms (end to end 0.216191 ms, enqueue 0.14839 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153551 ms - Host latency: 0.198578 ms (end to end 0.215919 ms, enqueue 0.148445 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154497 ms - Host latency: 0.200427 ms (end to end 0.218153 ms, enqueue 0.149709 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151248 ms - Host latency: 0.19593 ms (end to end 0.214282 ms, enqueue 0.138922 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148424 ms - Host latency: 0.19081 ms (end to end 0.273363 ms, enqueue 0.105353 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148944 ms - Host latency: 0.190941 ms (end to end 0.279303 ms, enqueue 0.105823 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149033 ms - Host latency: 0.191948 ms (end to end 0.277992 ms, enqueue 0.106473 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149495 ms - Host latency: 0.192252 ms (end to end 0.277882 ms, enqueue 0.105019 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149614 ms - Host latency: 0.192564 ms (end to end 0.277016 ms, enqueue 0.104517 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14874 ms - Host latency: 0.191217 ms (end to end 0.277539 ms, enqueue 0.104556 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148593 ms - Host latency: 0.190504 ms (end to end 0.277934 ms, enqueue 0.0905319 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149304 ms - Host latency: 0.19099 ms (end to end 0.276743 ms, enqueue 0.0792419 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149066 ms - Host latency: 0.191925 ms (end to end 0.259341 ms, enqueue 0.0796295 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14838 ms - Host latency: 0.189909 ms (end to end 0.278232 ms, enqueue 0.0782166 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148114 ms - Host latency: 0.19006 ms (end to end 0.277611 ms, enqueue 0.0792557 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148784 ms - Host latency: 0.190683 ms (end to end 0.274248 ms, enqueue 0.0901932 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14866 ms - Host latency: 0.19097 ms (end to end 0.275806 ms, enqueue 0.0903625 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148232 ms - Host latency: 0.189944 ms (end to end 0.276401 ms, enqueue 0.0904465 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148734 ms - Host latency: 0.190823 ms (end to end 0.276303 ms, enqueue 0.0907471 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148453 ms - Host latency: 0.190271 ms (end to end 0.276762 ms, enqueue 0.0901978 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.1487 ms - Host latency: 0.190706 ms (end to end 0.276527 ms, enqueue 0.0902527 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148619 ms - Host latency: 0.190515 ms (end to end 0.276308 ms, enqueue 0.0880676 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14825 ms - Host latency: 0.18938 ms (end to end 0.276927 ms, enqueue 0.0792633 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148067 ms - Host latency: 0.189926 ms (end to end 0.276801 ms, enqueue 0.0793259 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14819 ms - Host latency: 0.189687 ms (end to end 0.276607 ms, enqueue 0.0795151 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149463 ms - Host latency: 0.191026 ms (end to end 0.271275 ms, enqueue 0.0760605 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149081 ms - Host latency: 0.190544 ms (end to end 0.269826 ms, enqueue 0.0741928 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149257 ms - Host latency: 0.1905 ms (end to end 0.271521 ms, enqueue 0.0743072 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149371 ms - Host latency: 0.190996 ms (end to end 0.267944 ms, enqueue 0.0729553 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149002 ms - Host latency: 0.190475 ms (end to end 0.269733 ms, enqueue 0.0724335 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149017 ms - Host latency: 0.190521 ms (end to end 0.269397 ms, enqueue 0.0723816 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.162274 ms - Host latency: 0.205533 ms (end to end 0.280167 ms, enqueue 0.0970062 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.202621 ms - Host latency: 0.250995 ms (end to end 0.259668 ms, enqueue 0.228076 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.200192 ms - Host latency: 0.24682 ms (end to end 0.254623 ms, enqueue 0.224673 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.203137 ms - Host latency: 0.249548 ms (end to end 0.258447 ms, enqueue 0.227802 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.18475 ms - Host latency: 0.230212 ms (end to end 0.248807 ms, enqueue 0.183649 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.157455 ms - Host latency: 0.200543 ms (end to end 0.270776 ms, enqueue 0.12114 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.202823 ms - Host latency: 0.248792 ms (end to end 0.25722 ms, enqueue 0.227502 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.159726 ms - Host latency: 0.202747 ms (end to end 0.210089 ms, enqueue 0.185229 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.157889 ms - Host latency: 0.199207 ms (end to end 0.206375 ms, enqueue 0.184152 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156125 ms - Host latency: 0.197122 ms (end to end 0.20423 ms, enqueue 0.181561 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155585 ms - Host latency: 0.198209 ms (end to end 0.242389 ms, enqueue 0.130951 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148978 ms - Host latency: 0.191071 ms (end to end 0.275668 ms, enqueue 0.109424 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149905 ms - Host latency: 0.192337 ms (end to end 0.274359 ms, enqueue 0.0981445 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150314 ms - Host latency: 0.192963 ms (end to end 0.259598 ms, enqueue 0.0830902 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149832 ms - Host latency: 0.191202 ms (end to end 0.262527 ms, enqueue 0.0823578 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15163 ms - Host latency: 0.197617 ms (end to end 0.24516 ms, enqueue 0.122287 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154175 ms - Host latency: 0.202695 ms (end to end 0.217413 ms, enqueue 0.15022 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152985 ms - Host latency: 0.201834 ms (end to end 0.217133 ms, enqueue 0.150543 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.165384 ms - Host latency: 0.210767 ms (end to end 0.222168 ms, enqueue 0.184177 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.171445 ms - Host latency: 0.215836 ms (end to end 0.224713 ms, enqueue 0.200256 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.170865 ms - Host latency: 0.215237 ms (end to end 0.22373 ms, enqueue 0.199414 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.171371 ms - Host latency: 0.215912 ms (end to end 0.224313 ms, enqueue 0.200073 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.166379 ms - Host latency: 0.211292 ms (end to end 0.220044 ms, enqueue 0.179883 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155035 ms - Host latency: 0.197455 ms (end to end 0.206619 ms, enqueue 0.13476 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155209 ms - Host latency: 0.198221 ms (end to end 0.208603 ms, enqueue 0.137128 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154861 ms - Host latency: 0.197351 ms (end to end 0.208182 ms, enqueue 0.135767 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156 ms - Host latency: 0.198968 ms (end to end 0.208487 ms, enqueue 0.135797 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156329 ms - Host latency: 0.198386 ms (end to end 0.208325 ms, enqueue 0.136252 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154929 ms - Host latency: 0.196716 ms (end to end 0.207947 ms, enqueue 0.132455 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149332 ms - Host latency: 0.191504 ms (end to end 0.267673 ms, enqueue 0.0957397 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14939 ms - Host latency: 0.19133 ms (end to end 0.272043 ms, enqueue 0.0980957 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149115 ms - Host latency: 0.191074 ms (end to end 0.274878 ms, enqueue 0.0960846 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150101 ms - Host latency: 0.192316 ms (end to end 0.272791 ms, enqueue 0.0964142 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149677 ms - Host latency: 0.191931 ms (end to end 0.271561 ms, enqueue 0.096283 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149872 ms - Host latency: 0.192236 ms (end to end 0.272055 ms, enqueue 0.0963104 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150211 ms - Host latency: 0.192557 ms (end to end 0.269052 ms, enqueue 0.089801 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150543 ms - Host latency: 0.192181 ms (end to end 0.263785 ms, enqueue 0.079718 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150302 ms - Host latency: 0.192218 ms (end to end 0.263205 ms, enqueue 0.0799835 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150165 ms - Host latency: 0.191678 ms (end to end 0.264395 ms, enqueue 0.0804535 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149936 ms - Host latency: 0.191412 ms (end to end 0.263107 ms, enqueue 0.079892 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.160016 ms - Host latency: 0.204413 ms (end to end 0.272189 ms, enqueue 0.100821 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.16871 ms - Host latency: 0.216287 ms (end to end 0.226779 ms, enqueue 0.191513 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.200864 ms - Host latency: 0.246088 ms (end to end 0.255112 ms, enqueue 0.227136 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.197418 ms - Host latency: 0.242542 ms (end to end 0.251004 ms, enqueue 0.223361 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.196448 ms - Host latency: 0.241565 ms (end to end 0.250381 ms, enqueue 0.223203 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.185867 ms - Host latency: 0.232443 ms (end to end 0.242224 ms, enqueue 0.203601 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155261 ms - Host latency: 0.20069 ms (end to end 0.215741 ms, enqueue 0.147711 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154993 ms - Host latency: 0.201788 ms (end to end 0.216553 ms, enqueue 0.148441 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154388 ms - Host latency: 0.200342 ms (end to end 0.215555 ms, enqueue 0.147372 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154205 ms - Host latency: 0.201517 ms (end to end 0.215628 ms, enqueue 0.148126 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154428 ms - Host latency: 0.199527 ms (end to end 0.215057 ms, enqueue 0.146896 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151587 ms - Host latency: 0.195816 ms (end to end 0.23461 ms, enqueue 0.123135 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151282 ms - Host latency: 0.193704 ms (end to end 0.278073 ms, enqueue 0.107748 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148984 ms - Host latency: 0.190891 ms (end to end 0.272122 ms, enqueue 0.105316 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149246 ms - Host latency: 0.191321 ms (end to end 0.27063 ms, enqueue 0.104242 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14931 ms - Host latency: 0.191467 ms (end to end 0.27316 ms, enqueue 0.105359 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149548 ms - Host latency: 0.19191 ms (end to end 0.267712 ms, enqueue 0.104807 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149664 ms - Host latency: 0.191156 ms (end to end 0.272595 ms, enqueue 0.104724 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150107 ms - Host latency: 0.191528 ms (end to end 0.265778 ms, enqueue 0.0875977 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150751 ms - Host latency: 0.192657 ms (end to end 0.262903 ms, enqueue 0.0816437 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149957 ms - Host latency: 0.191956 ms (end to end 0.263437 ms, enqueue 0.0826385 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150125 ms - Host latency: 0.191467 ms (end to end 0.259805 ms, enqueue 0.0822174 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150043 ms - Host latency: 0.191727 ms (end to end 0.253543 ms, enqueue 0.0824738 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149927 ms - Host latency: 0.191568 ms (end to end 0.264301 ms, enqueue 0.0808868 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149527 ms - Host latency: 0.191165 ms (end to end 0.265482 ms, enqueue 0.0823975 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149518 ms - Host latency: 0.191245 ms (end to end 0.26384 ms, enqueue 0.0797546 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150616 ms - Host latency: 0.192224 ms (end to end 0.266696 ms, enqueue 0.0803497 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150223 ms - Host latency: 0.192249 ms (end to end 0.268372 ms, enqueue 0.0786438 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149185 ms - Host latency: 0.190808 ms (end to end 0.264777 ms, enqueue 0.0793732 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150299 ms - Host latency: 0.192209 ms (end to end 0.266183 ms, enqueue 0.0790619 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14964 ms - Host latency: 0.191586 ms (end to end 0.265604 ms, enqueue 0.0794525 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149033 ms - Host latency: 0.1909 ms (end to end 0.265137 ms, enqueue 0.0793884 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148944 ms - Host latency: 0.19068 ms (end to end 0.266489 ms, enqueue 0.0796692 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150885 ms - Host latency: 0.193832 ms (end to end 0.26452 ms, enqueue 0.0800476 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149094 ms - Host latency: 0.19064 ms (end to end 0.265933 ms, enqueue 0.0783905 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149146 ms - Host latency: 0.191104 ms (end to end 0.266037 ms, enqueue 0.0780243 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149484 ms - Host latency: 0.191028 ms (end to end 0.268219 ms, enqueue 0.0793213 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149469 ms - Host latency: 0.191473 ms (end to end 0.266132 ms, enqueue 0.0780212 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14913 ms - Host latency: 0.191116 ms (end to end 0.268149 ms, enqueue 0.0760773 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149567 ms - Host latency: 0.191299 ms (end to end 0.270071 ms, enqueue 0.0728638 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148715 ms - Host latency: 0.190033 ms (end to end 0.269296 ms, enqueue 0.0718597 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149094 ms - Host latency: 0.190353 ms (end to end 0.269 ms, enqueue 0.0725281 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14924 ms - Host latency: 0.190936 ms (end to end 0.268723 ms, enqueue 0.0720886 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148904 ms - Host latency: 0.190369 ms (end to end 0.269836 ms, enqueue 0.0719086 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149533 ms - Host latency: 0.191757 ms (end to end 0.265076 ms, enqueue 0.0772186 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148935 ms - Host latency: 0.190353 ms (end to end 0.2668 ms, enqueue 0.0783752 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149792 ms - Host latency: 0.191641 ms (end to end 0.273752 ms, enqueue 0.0959045 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148795 ms - Host latency: 0.190292 ms (end to end 0.269479 ms, enqueue 0.0929687 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149509 ms - Host latency: 0.19169 ms (end to end 0.271164 ms, enqueue 0.098764 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149496 ms - Host latency: 0.191391 ms (end to end 0.263437 ms, enqueue 0.0994537 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149957 ms - Host latency: 0.192123 ms (end to end 0.269525 ms, enqueue 0.101459 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149643 ms - Host latency: 0.191855 ms (end to end 0.270325 ms, enqueue 0.0966949 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148404 ms - Host latency: 0.190106 ms (end to end 0.269144 ms, enqueue 0.0966309 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149274 ms - Host latency: 0.190616 ms (end to end 0.269635 ms, enqueue 0.0971893 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148923 ms - Host latency: 0.19126 ms (end to end 0.267908 ms, enqueue 0.0949402 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148859 ms - Host latency: 0.190286 ms (end to end 0.26781 ms, enqueue 0.0906311 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148566 ms - Host latency: 0.189761 ms (end to end 0.268936 ms, enqueue 0.0875519 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149277 ms - Host latency: 0.191479 ms (end to end 0.270746 ms, enqueue 0.0855926 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148996 ms - Host latency: 0.190826 ms (end to end 0.261661 ms, enqueue 0.0720001 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148782 ms - Host latency: 0.19014 ms (end to end 0.268692 ms, enqueue 0.0734802 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149106 ms - Host latency: 0.190866 ms (end to end 0.272437 ms, enqueue 0.0804626 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.190884 ms (end to end 0.269174 ms, enqueue 0.0728912 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153091 ms - Host latency: 0.198871 ms (end to end 0.243558 ms, enqueue 0.110873 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155072 ms - Host latency: 0.199521 ms (end to end 0.211414 ms, enqueue 0.143698 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153278 ms - Host latency: 0.204477 ms (end to end 0.218619 ms, enqueue 0.155496 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153171 ms - Host latency: 0.205109 ms (end to end 0.21796 ms, enqueue 0.153079 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155087 ms - Host latency: 0.20296 ms (end to end 0.218918 ms, enqueue 0.152621 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154657 ms - Host latency: 0.20343 ms (end to end 0.218292 ms, enqueue 0.152194 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154016 ms - Host latency: 0.202838 ms (end to end 0.21803 ms, enqueue 0.152283 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151035 ms - Host latency: 0.199323 ms (end to end 0.219193 ms, enqueue 0.139841 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14863 ms - Host latency: 0.190399 ms (end to end 0.274072 ms, enqueue 0.11304 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148651 ms - Host latency: 0.190332 ms (end to end 0.277997 ms, enqueue 0.112857 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148929 ms - Host latency: 0.191357 ms (end to end 0.277823 ms, enqueue 0.112354 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148312 ms - Host latency: 0.190442 ms (end to end 0.275763 ms, enqueue 0.111691 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148621 ms - Host latency: 0.190567 ms (end to end 0.280429 ms, enqueue 0.112537 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149326 ms - Host latency: 0.191022 ms (end to end 0.269113 ms, enqueue 0.113788 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149255 ms - Host latency: 0.191415 ms (end to end 0.275381 ms, enqueue 0.101944 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148938 ms - Host latency: 0.190094 ms (end to end 0.272165 ms, enqueue 0.0908295 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148663 ms - Host latency: 0.190289 ms (end to end 0.269788 ms, enqueue 0.089151 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.160886 ms - Host latency: 0.204489 ms (end to end 0.268399 ms, enqueue 0.130878 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.169559 ms - Host latency: 0.214044 ms (end to end 0.222537 ms, enqueue 0.197812 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.169446 ms - Host latency: 0.213849 ms (end to end 0.222229 ms, enqueue 0.197729 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.168231 ms - Host latency: 0.212479 ms (end to end 0.220908 ms, enqueue 0.196533 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.168921 ms - Host latency: 0.213354 ms (end to end 0.221539 ms, enqueue 0.196484 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.167938 ms - Host latency: 0.212357 ms (end to end 0.220679 ms, enqueue 0.196259 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.167703 ms - Host latency: 0.211694 ms (end to end 0.220621 ms, enqueue 0.196149 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.159299 ms - Host latency: 0.201456 ms (end to end 0.212463 ms, enqueue 0.15282 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153195 ms - Host latency: 0.194937 ms (end to end 0.204657 ms, enqueue 0.133005 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155118 ms - Host latency: 0.197144 ms (end to end 0.209799 ms, enqueue 0.134769 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154666 ms - Host latency: 0.196466 ms (end to end 0.204465 ms, enqueue 0.133191 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151199 ms - Host latency: 0.192545 ms (end to end 0.204395 ms, enqueue 0.133032 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153488 ms - Host latency: 0.195197 ms (end to end 0.206116 ms, enqueue 0.133441 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152356 ms - Host latency: 0.194485 ms (end to end 0.223413 ms, enqueue 0.116733 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149081 ms - Host latency: 0.190335 ms (end to end 0.272153 ms, enqueue 0.0945007 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149454 ms - Host latency: 0.191257 ms (end to end 0.272522 ms, enqueue 0.0953766 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149741 ms - Host latency: 0.191492 ms (end to end 0.273715 ms, enqueue 0.0952179 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149493 ms - Host latency: 0.191644 ms (end to end 0.273331 ms, enqueue 0.095047 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150238 ms - Host latency: 0.19238 ms (end to end 0.273474 ms, enqueue 0.0949341 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149182 ms - Host latency: 0.191132 ms (end to end 0.274203 ms, enqueue 0.0950378 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149622 ms - Host latency: 0.191525 ms (end to end 0.269492 ms, enqueue 0.085083 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15 ms - Host latency: 0.191922 ms (end to end 0.26839 ms, enqueue 0.0784302 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149817 ms - Host latency: 0.192075 ms (end to end 0.267236 ms, enqueue 0.0789307 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149951 ms - Host latency: 0.191803 ms (end to end 0.267963 ms, enqueue 0.0785767 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149051 ms - Host latency: 0.190781 ms (end to end 0.267392 ms, enqueue 0.078183 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149399 ms - Host latency: 0.190945 ms (end to end 0.267709 ms, enqueue 0.078775 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149423 ms - Host latency: 0.190903 ms (end to end 0.268036 ms, enqueue 0.0779663 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149612 ms - Host latency: 0.191821 ms (end to end 0.269562 ms, enqueue 0.0735382 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149084 ms - Host latency: 0.190582 ms (end to end 0.270627 ms, enqueue 0.0743225 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149329 ms - Host latency: 0.190948 ms (end to end 0.26864 ms, enqueue 0.0736328 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149365 ms - Host latency: 0.191046 ms (end to end 0.268707 ms, enqueue 0.0737488 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149084 ms - Host latency: 0.190759 ms (end to end 0.268927 ms, enqueue 0.0742493 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149957 ms - Host latency: 0.191888 ms (end to end 0.266669 ms, enqueue 0.073822 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149365 ms - Host latency: 0.191174 ms (end to end 0.267297 ms, enqueue 0.0746338 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149078 ms - Host latency: 0.190546 ms (end to end 0.270013 ms, enqueue 0.0738403 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149475 ms - Host latency: 0.191455 ms (end to end 0.269342 ms, enqueue 0.073877 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14903 ms - Host latency: 0.190674 ms (end to end 0.270441 ms, enqueue 0.0740417 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149115 ms - Host latency: 0.19101 ms (end to end 0.267352 ms, enqueue 0.0753784 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149652 ms - Host latency: 0.19129 ms (end to end 0.27121 ms, enqueue 0.0744324 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149457 ms - Host latency: 0.191156 ms (end to end 0.269714 ms, enqueue 0.0731751 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149249 ms - Host latency: 0.191278 ms (end to end 0.266711 ms, enqueue 0.0737122 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149213 ms - Host latency: 0.190924 ms (end to end 0.269067 ms, enqueue 0.0737854 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149542 ms - Host latency: 0.19129 ms (end to end 0.269605 ms, enqueue 0.0737427 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149292 ms - Host latency: 0.190833 ms (end to end 0.268359 ms, enqueue 0.0738403 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.190894 ms (end to end 0.268866 ms, enqueue 0.0740967 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14939 ms - Host latency: 0.19093 ms (end to end 0.269678 ms, enqueue 0.0744263 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148981 ms - Host latency: 0.190955 ms (end to end 0.267792 ms, enqueue 0.0738709 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149133 ms - Host latency: 0.190576 ms (end to end 0.269806 ms, enqueue 0.0739014 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149304 ms - Host latency: 0.191125 ms (end to end 0.268384 ms, enqueue 0.0736145 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149237 ms - Host latency: 0.190729 ms (end to end 0.268475 ms, enqueue 0.0737 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149103 ms - Host latency: 0.190265 ms (end to end 0.269879 ms, enqueue 0.0736633 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149341 ms - Host latency: 0.191473 ms (end to end 0.269501 ms, enqueue 0.0738586 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149567 ms - Host latency: 0.191223 ms (end to end 0.269495 ms, enqueue 0.0742065 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148993 ms - Host latency: 0.190338 ms (end to end 0.268756 ms, enqueue 0.0739929 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149371 ms - Host latency: 0.191052 ms (end to end 0.269336 ms, enqueue 0.0743469 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149451 ms - Host latency: 0.190631 ms (end to end 0.270581 ms, enqueue 0.0736938 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149371 ms - Host latency: 0.191022 ms (end to end 0.271411 ms, enqueue 0.0739136 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149207 ms - Host latency: 0.190894 ms (end to end 0.268781 ms, enqueue 0.0744263 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.180164 ms - Host latency: 0.225269 ms (end to end 0.266791 ms, enqueue 0.169043 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.191711 ms - Host latency: 0.237134 ms (end to end 0.246948 ms, enqueue 0.219501 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.178656 ms - Host latency: 0.228375 ms (end to end 0.239758 ms, enqueue 0.203918 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155811 ms - Host latency: 0.199518 ms (end to end 0.21192 ms, enqueue 0.144244 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155475 ms - Host latency: 0.198737 ms (end to end 0.211255 ms, enqueue 0.143665 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155487 ms - Host latency: 0.199438 ms (end to end 0.212787 ms, enqueue 0.144775 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155981 ms - Host latency: 0.198669 ms (end to end 0.212463 ms, enqueue 0.144086 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152692 ms - Host latency: 0.194806 ms (end to end 0.232874 ms, enqueue 0.109479 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149988 ms - Host latency: 0.191956 ms (end to end 0.26601 ms, enqueue 0.072168 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149017 ms - Host latency: 0.190497 ms (end to end 0.265387 ms, enqueue 0.0727051 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149652 ms - Host latency: 0.191479 ms (end to end 0.264569 ms, enqueue 0.0726929 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149829 ms - Host latency: 0.192169 ms (end to end 0.266632 ms, enqueue 0.072345 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149628 ms - Host latency: 0.191461 ms (end to end 0.265863 ms, enqueue 0.0728271 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149603 ms - Host latency: 0.191589 ms (end to end 0.26759 ms, enqueue 0.0722046 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148865 ms - Host latency: 0.19046 ms (end to end 0.269299 ms, enqueue 0.0723755 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149561 ms - Host latency: 0.191205 ms (end to end 0.269586 ms, enqueue 0.071875 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.190533 ms (end to end 0.269855 ms, enqueue 0.0719727 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148682 ms - Host latency: 0.190472 ms (end to end 0.268903 ms, enqueue 0.072699 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148669 ms - Host latency: 0.190381 ms (end to end 0.268066 ms, enqueue 0.0722351 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149164 ms - Host latency: 0.190784 ms (end to end 0.269427 ms, enqueue 0.0721985 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148926 ms - Host latency: 0.190259 ms (end to end 0.269275 ms, enqueue 0.0751953 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148993 ms - Host latency: 0.190143 ms (end to end 0.271265 ms, enqueue 0.0740723 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149622 ms - Host latency: 0.191632 ms (end to end 0.270844 ms, enqueue 0.0738037 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148773 ms - Host latency: 0.190283 ms (end to end 0.271875 ms, enqueue 0.0742188 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149304 ms - Host latency: 0.190771 ms (end to end 0.271484 ms, enqueue 0.0738709 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149365 ms - Host latency: 0.190967 ms (end to end 0.27157 ms, enqueue 0.0736694 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148987 ms - Host latency: 0.190546 ms (end to end 0.272797 ms, enqueue 0.0741028 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148853 ms - Host latency: 0.190198 ms (end to end 0.270593 ms, enqueue 0.0738709 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148871 ms - Host latency: 0.190491 ms (end to end 0.272003 ms, enqueue 0.0738342 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148706 ms - Host latency: 0.190424 ms (end to end 0.272662 ms, enqueue 0.0733276 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148535 ms - Host latency: 0.190167 ms (end to end 0.271515 ms, enqueue 0.0742615 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148627 ms - Host latency: 0.190094 ms (end to end 0.2716 ms, enqueue 0.0740051 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148755 ms - Host latency: 0.19024 ms (end to end 0.271637 ms, enqueue 0.0735168 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149493 ms - Host latency: 0.191321 ms (end to end 0.272479 ms, enqueue 0.074115 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14881 ms - Host latency: 0.190057 ms (end to end 0.271112 ms, enqueue 0.0737915 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14884 ms - Host latency: 0.190112 ms (end to end 0.270496 ms, enqueue 0.0737793 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149133 ms - Host latency: 0.190625 ms (end to end 0.27276 ms, enqueue 0.0746948 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148956 ms - Host latency: 0.190192 ms (end to end 0.271722 ms, enqueue 0.0739563 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148822 ms - Host latency: 0.190411 ms (end to end 0.271906 ms, enqueue 0.0737183 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149408 ms - Host latency: 0.19126 ms (end to end 0.270648 ms, enqueue 0.073938 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149237 ms - Host latency: 0.191199 ms (end to end 0.272266 ms, enqueue 0.074054 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148975 ms - Host latency: 0.190308 ms (end to end 0.269934 ms, enqueue 0.0740173 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149475 ms - Host latency: 0.19104 ms (end to end 0.271313 ms, enqueue 0.074353 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148999 ms - Host latency: 0.190625 ms (end to end 0.27027 ms, enqueue 0.0737915 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149255 ms - Host latency: 0.190656 ms (end to end 0.271942 ms, enqueue 0.0741455 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148718 ms - Host latency: 0.190045 ms (end to end 0.2698 ms, enqueue 0.0734985 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148962 ms - Host latency: 0.19021 ms (end to end 0.271429 ms, enqueue 0.0739929 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148578 ms - Host latency: 0.190472 ms (end to end 0.269867 ms, enqueue 0.0741211 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149335 ms - Host latency: 0.19071 ms (end to end 0.271851 ms, enqueue 0.0740051 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149066 ms - Host latency: 0.190741 ms (end to end 0.271454 ms, enqueue 0.0743835 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149255 ms - Host latency: 0.190796 ms (end to end 0.270294 ms, enqueue 0.0742981 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14906 ms - Host latency: 0.190375 ms (end to end 0.270923 ms, enqueue 0.0737427 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.190955 ms (end to end 0.270398 ms, enqueue 0.0741516 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149615 ms - Host latency: 0.191016 ms (end to end 0.270361 ms, enqueue 0.0743408 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148914 ms - Host latency: 0.19071 ms (end to end 0.268414 ms, enqueue 0.0741028 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149481 ms - Host latency: 0.191229 ms (end to end 0.269171 ms, enqueue 0.0747437 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148938 ms - Host latency: 0.190454 ms (end to end 0.267914 ms, enqueue 0.0738159 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149292 ms - Host latency: 0.190833 ms (end to end 0.270721 ms, enqueue 0.0744568 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149268 ms - Host latency: 0.190808 ms (end to end 0.26958 ms, enqueue 0.0737793 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148889 ms - Host latency: 0.190619 ms (end to end 0.269189 ms, enqueue 0.0743897 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149481 ms - Host latency: 0.191028 ms (end to end 0.269666 ms, enqueue 0.0746033 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149341 ms - Host latency: 0.191107 ms (end to end 0.270264 ms, enqueue 0.0738342 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149121 ms - Host latency: 0.190979 ms (end to end 0.269592 ms, enqueue 0.0737793 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149402 ms - Host latency: 0.191193 ms (end to end 0.270819 ms, enqueue 0.0740906 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149463 ms - Host latency: 0.191254 ms (end to end 0.272046 ms, enqueue 0.0746155 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149359 ms - Host latency: 0.191034 ms (end to end 0.268805 ms, enqueue 0.0750061 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14917 ms - Host latency: 0.190906 ms (end to end 0.270978 ms, enqueue 0.0733704 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148834 ms - Host latency: 0.19032 ms (end to end 0.268317 ms, enqueue 0.0731445 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149329 ms - Host latency: 0.190814 ms (end to end 0.269952 ms, enqueue 0.0750305 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149243 ms - Host latency: 0.191046 ms (end to end 0.270886 ms, enqueue 0.0739319 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149573 ms - Host latency: 0.191498 ms (end to end 0.269153 ms, enqueue 0.0738403 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149042 ms - Host latency: 0.190314 ms (end to end 0.270044 ms, enqueue 0.0737671 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149316 ms - Host latency: 0.191003 ms (end to end 0.269946 ms, enqueue 0.0736328 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149103 ms - Host latency: 0.191046 ms (end to end 0.269055 ms, enqueue 0.0741333 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149365 ms - Host latency: 0.190942 ms (end to end 0.27005 ms, enqueue 0.0736084 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149274 ms - Host latency: 0.190759 ms (end to end 0.270728 ms, enqueue 0.0737793 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149323 ms - Host latency: 0.191235 ms (end to end 0.269684 ms, enqueue 0.0750488 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149207 ms - Host latency: 0.190533 ms (end to end 0.269763 ms, enqueue 0.0737 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149329 ms - Host latency: 0.190753 ms (end to end 0.270892 ms, enqueue 0.073468 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14856 ms - Host latency: 0.190204 ms (end to end 0.269128 ms, enqueue 0.0739563 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.190857 ms (end to end 0.269806 ms, enqueue 0.0743042 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149359 ms - Host latency: 0.190778 ms (end to end 0.269672 ms, enqueue 0.0743835 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149329 ms - Host latency: 0.191193 ms (end to end 0.269183 ms, enqueue 0.0739563 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149542 ms - Host latency: 0.191455 ms (end to end 0.271631 ms, enqueue 0.0741577 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149719 ms - Host latency: 0.191675 ms (end to end 0.267633 ms, enqueue 0.0746826 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14895 ms - Host latency: 0.190369 ms (end to end 0.270471 ms, enqueue 0.073645 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149243 ms - Host latency: 0.191034 ms (end to end 0.27085 ms, enqueue 0.0739746 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149329 ms - Host latency: 0.19068 ms (end to end 0.270105 ms, enqueue 0.0735474 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149408 ms - Host latency: 0.191565 ms (end to end 0.270374 ms, enqueue 0.0739685 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149335 ms - Host latency: 0.190948 ms (end to end 0.262335 ms, enqueue 0.0749878 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149268 ms - Host latency: 0.190771 ms (end to end 0.270148 ms, enqueue 0.0741272 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148987 ms - Host latency: 0.190472 ms (end to end 0.269672 ms, enqueue 0.0736328 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149341 ms - Host latency: 0.190906 ms (end to end 0.270612 ms, enqueue 0.0740356 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148987 ms - Host latency: 0.190466 ms (end to end 0.270544 ms, enqueue 0.0739014 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149335 ms - Host latency: 0.191418 ms (end to end 0.270575 ms, enqueue 0.0742493 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149274 ms - Host latency: 0.190674 ms (end to end 0.268921 ms, enqueue 0.0739746 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14942 ms - Host latency: 0.191333 ms (end to end 0.268207 ms, enqueue 0.0743164 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149426 ms - Host latency: 0.191211 ms (end to end 0.269586 ms, enqueue 0.0740051 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149164 ms - Host latency: 0.190851 ms (end to end 0.268695 ms, enqueue 0.0738098 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149603 ms - Host latency: 0.190997 ms (end to end 0.269867 ms, enqueue 0.0735596 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149542 ms - Host latency: 0.19118 ms (end to end 0.269415 ms, enqueue 0.0744324 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14931 ms - Host latency: 0.19104 ms (end to end 0.270862 ms, enqueue 0.0737183 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149261 ms - Host latency: 0.191132 ms (end to end 0.268976 ms, enqueue 0.0733459 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149304 ms - Host latency: 0.191003 ms (end to end 0.270282 ms, enqueue 0.0738953 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148987 ms - Host latency: 0.19046 ms (end to end 0.269818 ms, enqueue 0.0740173 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14903 ms - Host latency: 0.190826 ms (end to end 0.269794 ms, enqueue 0.0737915 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149506 ms - Host latency: 0.191144 ms (end to end 0.269055 ms, enqueue 0.0737 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149152 ms - Host latency: 0.190619 ms (end to end 0.269312 ms, enqueue 0.0744629 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.221741 ms - Host latency: 0.270917 ms (end to end 0.283801 ms, enqueue 0.248956 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.21795 ms - Host latency: 0.266132 ms (end to end 0.277258 ms, enqueue 0.245258 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.19325 ms - Host latency: 0.23866 ms (end to end 0.249286 ms, enqueue 0.222235 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.179846 ms - Host latency: 0.227771 ms (end to end 0.242188 ms, enqueue 0.183185 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154901 ms - Host latency: 0.202704 ms (end to end 0.217407 ms, enqueue 0.149249 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155133 ms - Host latency: 0.200739 ms (end to end 0.217767 ms, enqueue 0.148181 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154456 ms - Host latency: 0.201337 ms (end to end 0.216785 ms, enqueue 0.148199 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155286 ms - Host latency: 0.20249 ms (end to end 0.216791 ms, enqueue 0.147583 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152649 ms - Host latency: 0.200543 ms (end to end 0.215387 ms, enqueue 0.149994 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148669 ms - Host latency: 0.190393 ms (end to end 0.25304 ms, enqueue 0.105475 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149426 ms - Host latency: 0.19118 ms (end to end 0.25072 ms, enqueue 0.107495 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149188 ms - Host latency: 0.190491 ms (end to end 0.269702 ms, enqueue 0.108698 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149048 ms - Host latency: 0.190979 ms (end to end 0.268799 ms, enqueue 0.105115 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149274 ms - Host latency: 0.19162 ms (end to end 0.268604 ms, enqueue 0.104248 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149628 ms - Host latency: 0.191486 ms (end to end 0.273706 ms, enqueue 0.106415 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149933 ms - Host latency: 0.191644 ms (end to end 0.268579 ms, enqueue 0.0894836 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149335 ms - Host latency: 0.191034 ms (end to end 0.265881 ms, enqueue 0.0844177 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150397 ms - Host latency: 0.192273 ms (end to end 0.262604 ms, enqueue 0.0849487 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150543 ms - Host latency: 0.192078 ms (end to end 0.262207 ms, enqueue 0.0839844 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14978 ms - Host latency: 0.191876 ms (end to end 0.263342 ms, enqueue 0.085083 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15033 ms - Host latency: 0.192133 ms (end to end 0.265656 ms, enqueue 0.0846985 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.1495 ms - Host latency: 0.190955 ms (end to end 0.264056 ms, enqueue 0.0830078 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149353 ms - Host latency: 0.191138 ms (end to end 0.265131 ms, enqueue 0.0765747 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.190741 ms - Host latency: 0.237805 ms (end to end 0.269513 ms, enqueue 0.188684 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15296 ms - Host latency: 0.195007 ms (end to end 0.255872 ms, enqueue 0.0818848 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149683 ms - Host latency: 0.192047 ms (end to end 0.265082 ms, enqueue 0.0729065 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149835 ms - Host latency: 0.191681 ms (end to end 0.266241 ms, enqueue 0.0726196 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14986 ms - Host latency: 0.192285 ms (end to end 0.267932 ms, enqueue 0.0722351 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148969 ms - Host latency: 0.190759 ms (end to end 0.267017 ms, enqueue 0.0725281 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149335 ms - Host latency: 0.191992 ms (end to end 0.271741 ms, enqueue 0.10014 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149622 ms - Host latency: 0.191486 ms (end to end 0.274695 ms, enqueue 0.0953308 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149951 ms - Host latency: 0.191919 ms (end to end 0.274066 ms, enqueue 0.0963623 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149115 ms - Host latency: 0.191144 ms (end to end 0.271143 ms, enqueue 0.0965942 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150092 ms - Host latency: 0.191968 ms (end to end 0.273944 ms, enqueue 0.0984558 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149286 ms - Host latency: 0.191138 ms (end to end 0.270605 ms, enqueue 0.111108 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149115 ms - Host latency: 0.190808 ms (end to end 0.260376 ms, enqueue 0.111682 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14895 ms - Host latency: 0.190509 ms (end to end 0.259454 ms, enqueue 0.110919 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151459 ms - Host latency: 0.198975 ms (end to end 0.235034 ms, enqueue 0.15564 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.147021 ms - Host latency: 0.200293 ms (end to end 0.211633 ms, enqueue 0.161823 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.147034 ms - Host latency: 0.198425 ms (end to end 0.20885 ms, enqueue 0.161487 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.157709 ms - Host latency: 0.201385 ms (end to end 0.210944 ms, enqueue 0.183014 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15199 ms - Host latency: 0.193036 ms (end to end 0.201886 ms, enqueue 0.177045 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14726 ms - Host latency: 0.188202 ms (end to end 0.2008 ms, enqueue 0.17135 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150049 ms - Host latency: 0.190698 ms (end to end 0.198492 ms, enqueue 0.174994 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.147662 ms - Host latency: 0.188715 ms (end to end 0.200287 ms, enqueue 0.17226 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149542 ms - Host latency: 0.190991 ms (end to end 0.224121 ms, enqueue 0.120538 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148761 ms - Host latency: 0.190637 ms (end to end 0.278003 ms, enqueue 0.120148 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148645 ms - Host latency: 0.190778 ms (end to end 0.280835 ms, enqueue 0.120459 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149023 ms - Host latency: 0.190961 ms (end to end 0.281134 ms, enqueue 0.120404 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148602 ms - Host latency: 0.190387 ms (end to end 0.282239 ms, enqueue 0.120514 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148499 ms - Host latency: 0.190045 ms (end to end 0.280103 ms, enqueue 0.121765 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.190839 ms (end to end 0.276721 ms, enqueue 0.109814 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149567 ms - Host latency: 0.190552 ms (end to end 0.265723 ms, enqueue 0.086676 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149701 ms - Host latency: 0.191309 ms (end to end 0.263397 ms, enqueue 0.0862366 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149664 ms - Host latency: 0.190881 ms (end to end 0.264502 ms, enqueue 0.0861206 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15022 ms - Host latency: 0.191888 ms (end to end 0.266809 ms, enqueue 0.0878235 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149951 ms - Host latency: 0.192023 ms (end to end 0.264325 ms, enqueue 0.086969 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149878 ms - Host latency: 0.191711 ms (end to end 0.264728 ms, enqueue 0.0868042 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150043 ms - Host latency: 0.192377 ms (end to end 0.267224 ms, enqueue 0.0774597 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149518 ms - Host latency: 0.191766 ms (end to end 0.267011 ms, enqueue 0.0736694 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150085 ms - Host latency: 0.19248 ms (end to end 0.2677 ms, enqueue 0.0737671 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14975 ms - Host latency: 0.191998 ms (end to end 0.267944 ms, enqueue 0.0735779 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14989 ms - Host latency: 0.191595 ms (end to end 0.264795 ms, enqueue 0.0738159 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149609 ms - Host latency: 0.191174 ms (end to end 0.266309 ms, enqueue 0.0745422 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149847 ms - Host latency: 0.191846 ms (end to end 0.266193 ms, enqueue 0.073645 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149359 ms - Host latency: 0.190851 ms (end to end 0.266443 ms, enqueue 0.0721252 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150189 ms - Host latency: 0.192596 ms (end to end 0.255151 ms, enqueue 0.0937134 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149646 ms - Host latency: 0.191156 ms (end to end 0.273505 ms, enqueue 0.0954224 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149371 ms - Host latency: 0.191431 ms (end to end 0.271808 ms, enqueue 0.0959167 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149835 ms - Host latency: 0.191766 ms (end to end 0.274194 ms, enqueue 0.095697 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149719 ms - Host latency: 0.191833 ms (end to end 0.274072 ms, enqueue 0.0955933 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.190979 ms (end to end 0.274817 ms, enqueue 0.0959412 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148999 ms - Host latency: 0.190485 ms (end to end 0.276202 ms, enqueue 0.1026 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148346 ms - Host latency: 0.189825 ms (end to end 0.275726 ms, enqueue 0.103613 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149695 ms - Host latency: 0.200464 ms (end to end 0.231122 ms, enqueue 0.151233 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150165 ms - Host latency: 0.201721 ms (end to end 0.219397 ms, enqueue 0.155762 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150879 ms - Host latency: 0.20238 ms (end to end 0.218475 ms, enqueue 0.154828 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151233 ms - Host latency: 0.199701 ms (end to end 0.215118 ms, enqueue 0.160278 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152362 ms - Host latency: 0.196417 ms (end to end 0.206586 ms, enqueue 0.16897 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154321 ms - Host latency: 0.198688 ms (end to end 0.207776 ms, enqueue 0.169757 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154114 ms - Host latency: 0.198737 ms (end to end 0.208881 ms, enqueue 0.1716 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155359 ms - Host latency: 0.198749 ms (end to end 0.206165 ms, enqueue 0.170056 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15611 ms - Host latency: 0.202307 ms (end to end 0.212695 ms, enqueue 0.168353 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149792 ms - Host latency: 0.191217 ms (end to end 0.228143 ms, enqueue 0.126038 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149042 ms - Host latency: 0.190503 ms (end to end 0.252368 ms, enqueue 0.125769 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149139 ms - Host latency: 0.191699 ms (end to end 0.275653 ms, enqueue 0.119806 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149109 ms - Host latency: 0.191589 ms (end to end 0.280011 ms, enqueue 0.118256 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148273 ms - Host latency: 0.190088 ms (end to end 0.239087 ms, enqueue 0.15199 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.147375 ms - Host latency: 0.1883 ms (end to end 0.198279 ms, enqueue 0.172205 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.1703 ms - Host latency: 0.214673 ms (end to end 0.223395 ms, enqueue 0.198712 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.168475 ms - Host latency: 0.212598 ms (end to end 0.220581 ms, enqueue 0.196442 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.169537 ms - Host latency: 0.213824 ms (end to end 0.222034 ms, enqueue 0.19754 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.169727 ms - Host latency: 0.213983 ms (end to end 0.221918 ms, enqueue 0.197406 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.157312 ms - Host latency: 0.199847 ms (end to end 0.209375 ms, enqueue 0.145337 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153528 ms - Host latency: 0.195654 ms (end to end 0.204492 ms, enqueue 0.133197 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15246 ms - Host latency: 0.194061 ms (end to end 0.205768 ms, enqueue 0.133374 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153278 ms - Host latency: 0.195343 ms (end to end 0.207214 ms, enqueue 0.133093 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153925 ms - Host latency: 0.195691 ms (end to end 0.205249 ms, enqueue 0.133649 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152887 ms - Host latency: 0.194916 ms (end to end 0.207117 ms, enqueue 0.132855 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150903 ms - Host latency: 0.193011 ms (end to end 0.249225 ms, enqueue 0.102917 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152905 ms - Host latency: 0.199622 ms (end to end 0.222614 ms, enqueue 0.163855 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152905 ms - Host latency: 0.195264 ms (end to end 0.203021 ms, enqueue 0.168011 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153345 ms - Host latency: 0.199005 ms (end to end 0.207935 ms, enqueue 0.168896 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152533 ms - Host latency: 0.200751 ms (end to end 0.211157 ms, enqueue 0.167603 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153522 ms - Host latency: 0.199518 ms (end to end 0.209808 ms, enqueue 0.163782 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154718 ms - Host latency: 0.20116 ms (end to end 0.214545 ms, enqueue 0.14823 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154657 ms - Host latency: 0.20152 ms (end to end 0.214935 ms, enqueue 0.148523 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155219 ms - Host latency: 0.200861 ms (end to end 0.214661 ms, enqueue 0.147455 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155194 ms - Host latency: 0.201379 ms (end to end 0.215491 ms, enqueue 0.148938 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155286 ms - Host latency: 0.200232 ms (end to end 0.214819 ms, enqueue 0.14798 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151337 ms - Host latency: 0.193854 ms (end to end 0.231708 ms, enqueue 0.126099 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149274 ms - Host latency: 0.190887 ms (end to end 0.278424 ms, enqueue 0.109302 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149054 ms - Host latency: 0.19129 ms (end to end 0.277924 ms, enqueue 0.108258 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14881 ms - Host latency: 0.190356 ms (end to end 0.274652 ms, enqueue 0.0997742 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.161121 ms - Host latency: 0.204681 ms (end to end 0.280646 ms, enqueue 0.0932068 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.190338 ms - Host latency: 0.239307 ms (end to end 0.24986 ms, enqueue 0.219159 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.182477 ms - Host latency: 0.227271 ms (end to end 0.237512 ms, enqueue 0.211792 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.184991 ms - Host latency: 0.229883 ms (end to end 0.240729 ms, enqueue 0.214545 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.183569 ms - Host latency: 0.228656 ms (end to end 0.239813 ms, enqueue 0.213489 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.182477 ms - Host latency: 0.228595 ms (end to end 0.240143 ms, enqueue 0.210968 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156622 ms - Host latency: 0.199707 ms (end to end 0.211127 ms, enqueue 0.139575 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156042 ms - Host latency: 0.197949 ms (end to end 0.209131 ms, enqueue 0.139642 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155737 ms - Host latency: 0.198059 ms (end to end 0.212225 ms, enqueue 0.14035 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15144 ms - Host latency: 0.202161 ms (end to end 0.215222 ms, enqueue 0.15224 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153009 ms - Host latency: 0.203284 ms (end to end 0.21825 ms, enqueue 0.152411 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151636 ms - Host latency: 0.19765 ms (end to end 0.217023 ms, enqueue 0.139642 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149445 ms - Host latency: 0.191382 ms (end to end 0.275458 ms, enqueue 0.108081 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149347 ms - Host latency: 0.190942 ms (end to end 0.27276 ms, enqueue 0.0971985 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149835 ms - Host latency: 0.191608 ms (end to end 0.266718 ms, enqueue 0.0721802 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149591 ms - Host latency: 0.191315 ms (end to end 0.267828 ms, enqueue 0.0721314 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149854 ms - Host latency: 0.191632 ms (end to end 0.266943 ms, enqueue 0.0727844 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150012 ms - Host latency: 0.191541 ms (end to end 0.265491 ms, enqueue 0.0724243 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148535 ms - Host latency: 0.190137 ms (end to end 0.264362 ms, enqueue 0.072699 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150128 ms - Host latency: 0.191559 ms (end to end 0.265784 ms, enqueue 0.0721375 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149683 ms - Host latency: 0.191528 ms (end to end 0.267749 ms, enqueue 0.0722229 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14964 ms - Host latency: 0.191479 ms (end to end 0.268048 ms, enqueue 0.0730225 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149579 ms - Host latency: 0.191241 ms (end to end 0.269098 ms, enqueue 0.0721069 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149176 ms - Host latency: 0.191095 ms (end to end 0.267224 ms, enqueue 0.0721924 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149561 ms - Host latency: 0.191022 ms (end to end 0.268304 ms, enqueue 0.0737854 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149225 ms - Host latency: 0.190979 ms (end to end 0.268066 ms, enqueue 0.0735962 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149536 ms - Host latency: 0.1914 ms (end to end 0.268097 ms, enqueue 0.0737488 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149652 ms - Host latency: 0.19137 ms (end to end 0.268353 ms, enqueue 0.0735657 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14967 ms - Host latency: 0.191406 ms (end to end 0.2685 ms, enqueue 0.0739075 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149451 ms - Host latency: 0.191272 ms (end to end 0.267371 ms, enqueue 0.0738892 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148877 ms - Host latency: 0.190051 ms (end to end 0.268329 ms, enqueue 0.0736084 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149524 ms - Host latency: 0.191058 ms (end to end 0.267291 ms, enqueue 0.074115 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149463 ms - Host latency: 0.191125 ms (end to end 0.269629 ms, enqueue 0.0735168 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149561 ms - Host latency: 0.191699 ms (end to end 0.267755 ms, enqueue 0.0731995 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149341 ms - Host latency: 0.191022 ms (end to end 0.268988 ms, enqueue 0.0740234 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14928 ms - Host latency: 0.190973 ms (end to end 0.269818 ms, enqueue 0.0736328 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149451 ms - Host latency: 0.190973 ms (end to end 0.268683 ms, enqueue 0.0741211 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149042 ms - Host latency: 0.190472 ms (end to end 0.269153 ms, enqueue 0.0740478 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149347 ms - Host latency: 0.191138 ms (end to end 0.268933 ms, enqueue 0.073584 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14942 ms - Host latency: 0.191229 ms (end to end 0.268805 ms, enqueue 0.0740723 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149152 ms - Host latency: 0.190698 ms (end to end 0.269952 ms, enqueue 0.0740417 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149286 ms - Host latency: 0.190765 ms (end to end 0.270044 ms, enqueue 0.0733154 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149176 ms - Host latency: 0.191315 ms (end to end 0.268396 ms, enqueue 0.073529 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149182 ms - Host latency: 0.190924 ms (end to end 0.26972 ms, enqueue 0.0736816 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14895 ms - Host latency: 0.19057 ms (end to end 0.269513 ms, enqueue 0.0735596 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149664 ms - Host latency: 0.191724 ms (end to end 0.265558 ms, enqueue 0.0742188 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149609 ms - Host latency: 0.191577 ms (end to end 0.266797 ms, enqueue 0.0738403 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149829 ms - Host latency: 0.192114 ms (end to end 0.264972 ms, enqueue 0.0738403 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149756 ms - Host latency: 0.192285 ms (end to end 0.265979 ms, enqueue 0.0738464 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14942 ms - Host latency: 0.191168 ms (end to end 0.266119 ms, enqueue 0.0750793 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149469 ms - Host latency: 0.191235 ms (end to end 0.267975 ms, enqueue 0.077002 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149097 ms - Host latency: 0.190698 ms (end to end 0.272449 ms, enqueue 0.0735413 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149353 ms - Host latency: 0.19187 ms (end to end 0.274414 ms, enqueue 0.0734436 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148743 ms - Host latency: 0.190479 ms (end to end 0.272455 ms, enqueue 0.0749268 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149457 ms - Host latency: 0.19151 ms (end to end 0.273059 ms, enqueue 0.0733215 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148816 ms - Host latency: 0.190533 ms (end to end 0.27132 ms, enqueue 0.0736755 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148822 ms - Host latency: 0.190747 ms (end to end 0.2729 ms, enqueue 0.073529 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148877 ms - Host latency: 0.190833 ms (end to end 0.27243 ms, enqueue 0.0731934 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149152 ms - Host latency: 0.191132 ms (end to end 0.273065 ms, enqueue 0.0757202 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148785 ms - Host latency: 0.190332 ms (end to end 0.273175 ms, enqueue 0.0752319 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14834 ms - Host latency: 0.189691 ms (end to end 0.272571 ms, enqueue 0.0752319 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148846 ms - Host latency: 0.190704 ms (end to end 0.274066 ms, enqueue 0.0757751 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148468 ms - Host latency: 0.189984 ms (end to end 0.27373 ms, enqueue 0.0756531 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148865 ms - Host latency: 0.190692 ms (end to end 0.27406 ms, enqueue 0.0749573 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148285 ms - Host latency: 0.189752 ms (end to end 0.273157 ms, enqueue 0.0752014 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148865 ms - Host latency: 0.191003 ms (end to end 0.275427 ms, enqueue 0.0750244 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148352 ms - Host latency: 0.189636 ms (end to end 0.274731 ms, enqueue 0.0758545 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148303 ms - Host latency: 0.189526 ms (end to end 0.27384 ms, enqueue 0.0760864 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14856 ms - Host latency: 0.190405 ms (end to end 0.27395 ms, enqueue 0.0749146 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149353 ms - Host latency: 0.191174 ms (end to end 0.267822 ms, enqueue 0.0759033 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14884 ms - Host latency: 0.190283 ms (end to end 0.26499 ms, enqueue 0.0759521 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149585 ms - Host latency: 0.192029 ms (end to end 0.265161 ms, enqueue 0.0761963 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150122 ms - Host latency: 0.192175 ms (end to end 0.267383 ms, enqueue 0.0752563 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149048 ms - Host latency: 0.190649 ms (end to end 0.266003 ms, enqueue 0.0755859 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149414 ms - Host latency: 0.191174 ms (end to end 0.266956 ms, enqueue 0.0760498 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149707 ms - Host latency: 0.192261 ms (end to end 0.266907 ms, enqueue 0.0758667 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150037 ms - Host latency: 0.19209 ms (end to end 0.267151 ms, enqueue 0.0754639 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148938 ms - Host latency: 0.190967 ms (end to end 0.265698 ms, enqueue 0.0762939 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149524 ms - Host latency: 0.191077 ms (end to end 0.267529 ms, enqueue 0.0753662 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149304 ms - Host latency: 0.190808 ms (end to end 0.270679 ms, enqueue 0.0740234 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149329 ms - Host latency: 0.190845 ms (end to end 0.270801 ms, enqueue 0.0732544 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149023 ms - Host latency: 0.190527 ms (end to end 0.271094 ms, enqueue 0.073877 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.184998 ms - Host latency: 0.231616 ms (end to end 0.263306 ms, enqueue 0.181921 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.187781 ms - Host latency: 0.233594 ms (end to end 0.244714 ms, enqueue 0.217981 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.188098 ms - Host latency: 0.23363 ms (end to end 0.244421 ms, enqueue 0.217737 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.189807 ms - Host latency: 0.235327 ms (end to end 0.245874 ms, enqueue 0.21925 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.196631 ms - Host latency: 0.242749 ms (end to end 0.252808 ms, enqueue 0.224976 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.178101 ms - Host latency: 0.223853 ms (end to end 0.233862 ms, enqueue 0.198486 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156152 ms - Host latency: 0.199365 ms (end to end 0.210303 ms, enqueue 0.141443 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156592 ms - Host latency: 0.199268 ms (end to end 0.20957 ms, enqueue 0.139844 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155823 ms - Host latency: 0.198938 ms (end to end 0.211536 ms, enqueue 0.139673 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149414 ms - Host latency: 0.191113 ms (end to end 0.243433 ms, enqueue 0.118713 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149109 ms - Host latency: 0.191357 ms (end to end 0.276672 ms, enqueue 0.11228 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.159985 ms - Host latency: 0.202991 ms (end to end 0.266455 ms, enqueue 0.149756 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.170508 ms - Host latency: 0.215283 ms (end to end 0.224487 ms, enqueue 0.199573 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.169885 ms - Host latency: 0.216003 ms (end to end 0.2245 ms, enqueue 0.198657 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.170947 ms - Host latency: 0.215344 ms (end to end 0.223462 ms, enqueue 0.199341 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.169543 ms - Host latency: 0.214148 ms (end to end 0.223169 ms, enqueue 0.198376 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.158521 ms - Host latency: 0.20293 ms (end to end 0.213135 ms, enqueue 0.15636 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154834 ms - Host latency: 0.197229 ms (end to end 0.206128 ms, enqueue 0.134375 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154358 ms - Host latency: 0.196265 ms (end to end 0.20575 ms, enqueue 0.13396 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154919 ms - Host latency: 0.19718 ms (end to end 0.208154 ms, enqueue 0.134521 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154187 ms - Host latency: 0.195984 ms (end to end 0.20564 ms, enqueue 0.13418 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15509 ms - Host latency: 0.197156 ms (end to end 0.207068 ms, enqueue 0.134619 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153174 ms - Host latency: 0.194934 ms (end to end 0.223157 ms, enqueue 0.117737 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14856 ms - Host latency: 0.1896 ms (end to end 0.269006 ms, enqueue 0.0944946 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149072 ms - Host latency: 0.190869 ms (end to end 0.271387 ms, enqueue 0.095459 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149097 ms - Host latency: 0.190759 ms (end to end 0.270081 ms, enqueue 0.0947754 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149109 ms - Host latency: 0.19082 ms (end to end 0.268042 ms, enqueue 0.0947754 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14917 ms - Host latency: 0.191101 ms (end to end 0.271375 ms, enqueue 0.0949341 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149634 ms - Host latency: 0.191895 ms (end to end 0.271301 ms, enqueue 0.0947876 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.169617 ms - Host latency: 0.213696 ms (end to end 0.275928 ms, enqueue 0.137183 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.191785 ms - Host latency: 0.237598 ms (end to end 0.249329 ms, enqueue 0.221997 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15863 ms - Host latency: 0.202026 ms (end to end 0.259351 ms, enqueue 0.106812 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149561 ms - Host latency: 0.191443 ms (end to end 0.269348 ms, enqueue 0.0755493 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149573 ms - Host latency: 0.191431 ms (end to end 0.270764 ms, enqueue 0.0761841 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149353 ms - Host latency: 0.191321 ms (end to end 0.268799 ms, enqueue 0.0753296 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149866 ms - Host latency: 0.191687 ms (end to end 0.267603 ms, enqueue 0.0748291 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149316 ms - Host latency: 0.191272 ms (end to end 0.26925 ms, enqueue 0.0751465 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14939 ms - Host latency: 0.190979 ms (end to end 0.269373 ms, enqueue 0.075 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149512 ms - Host latency: 0.191602 ms (end to end 0.269153 ms, enqueue 0.0754761 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149463 ms - Host latency: 0.190735 ms (end to end 0.266492 ms, enqueue 0.0744385 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148816 ms - Host latency: 0.190588 ms (end to end 0.26886 ms, enqueue 0.0748779 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150085 ms - Host latency: 0.192859 ms (end to end 0.270276 ms, enqueue 0.0754639 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148755 ms - Host latency: 0.19032 ms (end to end 0.270752 ms, enqueue 0.0754639 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149353 ms - Host latency: 0.191345 ms (end to end 0.27002 ms, enqueue 0.0757446 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.18042 ms - Host latency: 0.225806 ms (end to end 0.264319 ms, enqueue 0.167883 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.186121 ms - Host latency: 0.231482 ms (end to end 0.242383 ms, enqueue 0.216394 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.185706 ms - Host latency: 0.23125 ms (end to end 0.24115 ms, enqueue 0.21488 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.186902 ms - Host latency: 0.232251 ms (end to end 0.242847 ms, enqueue 0.216724 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.188416 ms - Host latency: 0.233887 ms (end to end 0.244751 ms, enqueue 0.218152 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.187292 ms - Host latency: 0.232788 ms (end to end 0.243555 ms, enqueue 0.217017 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.166394 ms - Host latency: 0.213367 ms (end to end 0.226184 ms, enqueue 0.17478 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.157129 ms - Host latency: 0.199805 ms (end to end 0.209875 ms, enqueue 0.140723 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154224 ms - Host latency: 0.199573 ms (end to end 0.213013 ms, enqueue 0.147522 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155664 ms - Host latency: 0.198596 ms (end to end 0.211475 ms, enqueue 0.140186 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155469 ms - Host latency: 0.198315 ms (end to end 0.210022 ms, enqueue 0.139966 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.191565 ms - Host latency: 0.238245 ms (end to end 0.25022 ms, enqueue 0.21062 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.179712 ms - Host latency: 0.224268 ms (end to end 0.239905 ms, enqueue 0.184448 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149438 ms - Host latency: 0.191174 ms (end to end 0.264502 ms, enqueue 0.0755615 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150317 ms - Host latency: 0.191821 ms (end to end 0.262463 ms, enqueue 0.0751099 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150085 ms - Host latency: 0.192065 ms (end to end 0.256274 ms, enqueue 0.0746094 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150378 ms - Host latency: 0.191931 ms (end to end 0.263477 ms, enqueue 0.0753296 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150488 ms - Host latency: 0.192322 ms (end to end 0.263953 ms, enqueue 0.0793945 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149817 ms - Host latency: 0.191992 ms (end to end 0.267041 ms, enqueue 0.0878296 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150049 ms - Host latency: 0.191919 ms (end to end 0.265918 ms, enqueue 0.0876831 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149609 ms - Host latency: 0.191028 ms (end to end 0.267908 ms, enqueue 0.0879639 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149805 ms - Host latency: 0.191443 ms (end to end 0.263074 ms, enqueue 0.0871704 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150171 ms - Host latency: 0.19165 ms (end to end 0.26394 ms, enqueue 0.0875 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149731 ms - Host latency: 0.191284 ms (end to end 0.266101 ms, enqueue 0.0901245 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150012 ms - Host latency: 0.192163 ms (end to end 0.270227 ms, enqueue 0.0871704 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149597 ms - Host latency: 0.190723 ms (end to end 0.264832 ms, enqueue 0.0820801 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149426 ms - Host latency: 0.190979 ms (end to end 0.264038 ms, enqueue 0.0810181 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15 ms - Host latency: 0.19209 ms (end to end 0.265039 ms, enqueue 0.0806885 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149548 ms - Host latency: 0.19093 ms (end to end 0.264734 ms, enqueue 0.0822144 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150134 ms - Host latency: 0.191931 ms (end to end 0.264246 ms, enqueue 0.0808472 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149438 ms - Host latency: 0.191443 ms (end to end 0.264978 ms, enqueue 0.0809082 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149121 ms - Host latency: 0.190283 ms (end to end 0.267346 ms, enqueue 0.0788086 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149316 ms - Host latency: 0.191016 ms (end to end 0.267725 ms, enqueue 0.0776978 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148877 ms - Host latency: 0.19043 ms (end to end 0.266504 ms, enqueue 0.0786133 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149561 ms - Host latency: 0.191284 ms (end to end 0.267529 ms, enqueue 0.077063 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149207 ms - Host latency: 0.190845 ms (end to end 0.26759 ms, enqueue 0.0781128 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149011 ms - Host latency: 0.190161 ms (end to end 0.267578 ms, enqueue 0.0781616 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148938 ms - Host latency: 0.190308 ms (end to end 0.267102 ms, enqueue 0.0781738 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148816 ms - Host latency: 0.190674 ms (end to end 0.266809 ms, enqueue 0.0776855 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149048 ms - Host latency: 0.190637 ms (end to end 0.267773 ms, enqueue 0.077771 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149512 ms - Host latency: 0.191626 ms (end to end 0.266699 ms, enqueue 0.0777466 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149255 ms - Host latency: 0.191199 ms (end to end 0.267566 ms, enqueue 0.0782349 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149792 ms - Host latency: 0.192004 ms (end to end 0.268994 ms, enqueue 0.0776367 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14939 ms - Host latency: 0.191565 ms (end to end 0.266919 ms, enqueue 0.077417 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149817 ms - Host latency: 0.191724 ms (end to end 0.267725 ms, enqueue 0.0748901 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149255 ms - Host latency: 0.191064 ms (end to end 0.268152 ms, enqueue 0.0719482 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149097 ms - Host latency: 0.190552 ms (end to end 0.26803 ms, enqueue 0.0721436 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149561 ms - Host latency: 0.191589 ms (end to end 0.267493 ms, enqueue 0.077417 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150146 ms - Host latency: 0.192456 ms (end to end 0.26886 ms, enqueue 0.0776855 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149829 ms - Host latency: 0.191943 ms (end to end 0.268262 ms, enqueue 0.0777832 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14967 ms - Host latency: 0.192175 ms (end to end 0.267847 ms, enqueue 0.0771851 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149634 ms - Host latency: 0.191663 ms (end to end 0.268127 ms, enqueue 0.0778687 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.190747 ms (end to end 0.269189 ms, enqueue 0.0783813 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148901 ms - Host latency: 0.190515 ms (end to end 0.266846 ms, enqueue 0.0773926 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149365 ms - Host latency: 0.190747 ms (end to end 0.268713 ms, enqueue 0.0776245 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150134 ms - Host latency: 0.192627 ms (end to end 0.268921 ms, enqueue 0.0779785 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149365 ms - Host latency: 0.191248 ms (end to end 0.267712 ms, enqueue 0.0778564 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.171167 ms - Host latency: 0.215869 ms (end to end 0.267932 ms, enqueue 0.140808 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.185046 ms - Host latency: 0.230151 ms (end to end 0.240649 ms, enqueue 0.214661 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.187439 ms - Host latency: 0.232495 ms (end to end 0.241931 ms, enqueue 0.215613 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.185193 ms - Host latency: 0.230151 ms (end to end 0.240759 ms, enqueue 0.214819 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.163391 ms - Host latency: 0.21012 ms (end to end 0.220886 ms, enqueue 0.18418 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.147021 ms - Host latency: 0.191382 ms (end to end 0.201575 ms, enqueue 0.164026 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.147009 ms - Host latency: 0.195105 ms (end to end 0.205811 ms, enqueue 0.163062 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.147217 ms - Host latency: 0.192236 ms (end to end 0.201697 ms, enqueue 0.162988 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.146765 ms - Host latency: 0.192944 ms (end to end 0.203003 ms, enqueue 0.163 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.147534 ms - Host latency: 0.194861 ms (end to end 0.206189 ms, enqueue 0.160889 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149426 ms - Host latency: 0.19093 ms (end to end 0.250952 ms, enqueue 0.116406 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14917 ms - Host latency: 0.191077 ms (end to end 0.279431 ms, enqueue 0.115784 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149036 ms - Host latency: 0.191064 ms (end to end 0.278015 ms, enqueue 0.116895 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149365 ms - Host latency: 0.191223 ms (end to end 0.276111 ms, enqueue 0.114795 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149744 ms - Host latency: 0.191895 ms (end to end 0.280688 ms, enqueue 0.116394 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149402 ms - Host latency: 0.192444 ms (end to end 0.280286 ms, enqueue 0.115918 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149341 ms - Host latency: 0.19093 ms (end to end 0.274939 ms, enqueue 0.103308 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150464 ms - Host latency: 0.192249 ms (end to end 0.265625 ms, enqueue 0.0834961 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149963 ms - Host latency: 0.191699 ms (end to end 0.263818 ms, enqueue 0.0838257 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149792 ms - Host latency: 0.191504 ms (end to end 0.264624 ms, enqueue 0.0841309 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149731 ms - Host latency: 0.191492 ms (end to end 0.268103 ms, enqueue 0.0992432 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149878 ms - Host latency: 0.192175 ms (end to end 0.27179 ms, enqueue 0.0928101 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149915 ms - Host latency: 0.192639 ms (end to end 0.274011 ms, enqueue 0.0933594 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149512 ms - Host latency: 0.191284 ms (end to end 0.269885 ms, enqueue 0.0817017 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149951 ms - Host latency: 0.191736 ms (end to end 0.267773 ms, enqueue 0.0781738 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149719 ms - Host latency: 0.191528 ms (end to end 0.268445 ms, enqueue 0.0777344 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14873 ms - Host latency: 0.190002 ms (end to end 0.265222 ms, enqueue 0.0784058 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149268 ms - Host latency: 0.190918 ms (end to end 0.26593 ms, enqueue 0.0786865 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149329 ms - Host latency: 0.190698 ms (end to end 0.266479 ms, enqueue 0.0784424 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149548 ms - Host latency: 0.191016 ms (end to end 0.266687 ms, enqueue 0.0767822 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.158191 ms - Host latency: 0.201099 ms (end to end 0.266956 ms, enqueue 0.104651 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.181934 ms - Host latency: 0.226758 ms (end to end 0.237207 ms, enqueue 0.210974 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.179541 ms - Host latency: 0.224634 ms (end to end 0.235999 ms, enqueue 0.210083 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.179541 ms - Host latency: 0.224402 ms (end to end 0.235486 ms, enqueue 0.209094 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154944 ms - Host latency: 0.196655 ms (end to end 0.204736 ms, enqueue 0.177979 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148767 ms - Host latency: 0.189709 ms (end to end 0.19657 ms, enqueue 0.170715 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.147034 ms - Host latency: 0.187683 ms (end to end 0.198328 ms, enqueue 0.169995 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149231 ms - Host latency: 0.191504 ms (end to end 0.200806 ms, enqueue 0.172815 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149329 ms - Host latency: 0.190344 ms (end to end 0.199219 ms, enqueue 0.172351 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150342 ms - Host latency: 0.191846 ms (end to end 0.215247 ms, enqueue 0.131519 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14928 ms - Host latency: 0.190991 ms (end to end 0.256274 ms, enqueue 0.121484 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149634 ms - Host latency: 0.191626 ms (end to end 0.276648 ms, enqueue 0.121338 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148535 ms - Host latency: 0.190027 ms (end to end 0.282336 ms, enqueue 0.121826 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148743 ms - Host latency: 0.190417 ms (end to end 0.284741 ms, enqueue 0.121838 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148425 ms - Host latency: 0.189722 ms (end to end 0.281262 ms, enqueue 0.121375 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14873 ms - Host latency: 0.190576 ms (end to end 0.279907 ms, enqueue 0.11239 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149829 ms - Host latency: 0.191174 ms (end to end 0.267786 ms, enqueue 0.0877686 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149963 ms - Host latency: 0.191516 ms (end to end 0.266492 ms, enqueue 0.0872559 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149841 ms - Host latency: 0.191736 ms (end to end 0.265979 ms, enqueue 0.0877686 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150024 ms - Host latency: 0.191687 ms (end to end 0.266162 ms, enqueue 0.0877808 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149658 ms - Host latency: 0.190881 ms (end to end 0.263257 ms, enqueue 0.0882813 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150452 ms - Host latency: 0.192126 ms (end to end 0.262622 ms, enqueue 0.0869995 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149426 ms - Host latency: 0.19126 ms (end to end 0.26687 ms, enqueue 0.0833252 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149292 ms - Host latency: 0.19054 ms (end to end 0.262402 ms, enqueue 0.076416 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149683 ms - Host latency: 0.191064 ms (end to end 0.265369 ms, enqueue 0.0747314 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149695 ms - Host latency: 0.191235 ms (end to end 0.264795 ms, enqueue 0.0746704 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149548 ms - Host latency: 0.191064 ms (end to end 0.264661 ms, enqueue 0.0752197 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149683 ms - Host latency: 0.191541 ms (end to end 0.265173 ms, enqueue 0.0756348 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149744 ms - Host latency: 0.191797 ms (end to end 0.262952 ms, enqueue 0.0750977 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14989 ms - Host latency: 0.192322 ms (end to end 0.266467 ms, enqueue 0.0754272 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149329 ms - Host latency: 0.191321 ms (end to end 0.268127 ms, enqueue 0.0751709 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149731 ms - Host latency: 0.191699 ms (end to end 0.268005 ms, enqueue 0.0748779 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149341 ms - Host latency: 0.191418 ms (end to end 0.267456 ms, enqueue 0.0760376 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149988 ms - Host latency: 0.192419 ms (end to end 0.26698 ms, enqueue 0.0757324 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150012 ms - Host latency: 0.191602 ms (end to end 0.263135 ms, enqueue 0.0749756 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149487 ms - Host latency: 0.190845 ms (end to end 0.265161 ms, enqueue 0.0748535 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150281 ms - Host latency: 0.192395 ms (end to end 0.264673 ms, enqueue 0.0752808 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149609 ms - Host latency: 0.191138 ms (end to end 0.265527 ms, enqueue 0.0749878 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149988 ms - Host latency: 0.191565 ms (end to end 0.265686 ms, enqueue 0.0755127 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149487 ms - Host latency: 0.190906 ms (end to end 0.264417 ms, enqueue 0.0751831 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149707 ms - Host latency: 0.191357 ms (end to end 0.265063 ms, enqueue 0.0755615 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14978 ms - Host latency: 0.191626 ms (end to end 0.265149 ms, enqueue 0.0754761 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149487 ms - Host latency: 0.191077 ms (end to end 0.267236 ms, enqueue 0.0750244 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149133 ms - Host latency: 0.190955 ms (end to end 0.267822 ms, enqueue 0.075415 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149536 ms - Host latency: 0.191589 ms (end to end 0.270813 ms, enqueue 0.0759399 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149426 ms - Host latency: 0.191663 ms (end to end 0.268604 ms, enqueue 0.0756226 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149451 ms - Host latency: 0.191125 ms (end to end 0.26864 ms, enqueue 0.0754761 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149438 ms - Host latency: 0.191028 ms (end to end 0.272473 ms, enqueue 0.0755737 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148779 ms - Host latency: 0.190027 ms (end to end 0.272266 ms, enqueue 0.0748657 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148853 ms - Host latency: 0.189978 ms (end to end 0.272327 ms, enqueue 0.0753174 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148792 ms - Host latency: 0.19032 ms (end to end 0.271594 ms, enqueue 0.0749634 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149133 ms - Host latency: 0.190771 ms (end to end 0.272583 ms, enqueue 0.0748535 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148975 ms - Host latency: 0.190356 ms (end to end 0.272314 ms, enqueue 0.0751221 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148962 ms - Host latency: 0.190076 ms (end to end 0.272559 ms, enqueue 0.0750366 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149341 ms - Host latency: 0.190942 ms (end to end 0.271045 ms, enqueue 0.0761108 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148938 ms - Host latency: 0.190125 ms (end to end 0.273084 ms, enqueue 0.0747314 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149109 ms - Host latency: 0.190735 ms (end to end 0.271606 ms, enqueue 0.075354 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149402 ms - Host latency: 0.190869 ms (end to end 0.271912 ms, enqueue 0.0750488 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149207 ms - Host latency: 0.191003 ms (end to end 0.27085 ms, enqueue 0.0751343 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.190833 ms (end to end 0.271301 ms, enqueue 0.0755005 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149109 ms - Host latency: 0.190698 ms (end to end 0.271692 ms, enqueue 0.0761353 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148706 ms - Host latency: 0.190271 ms (end to end 0.271313 ms, enqueue 0.0749756 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149304 ms - Host latency: 0.191174 ms (end to end 0.270581 ms, enqueue 0.0749268 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148718 ms - Host latency: 0.190198 ms (end to end 0.260474 ms, enqueue 0.0765991 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149463 ms - Host latency: 0.190979 ms (end to end 0.272424 ms, enqueue 0.075 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149756 ms - Host latency: 0.191541 ms (end to end 0.270129 ms, enqueue 0.0756836 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149121 ms - Host latency: 0.190955 ms (end to end 0.270142 ms, enqueue 0.0755005 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148999 ms - Host latency: 0.190796 ms (end to end 0.271484 ms, enqueue 0.0756836 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149609 ms - Host latency: 0.191553 ms (end to end 0.271167 ms, enqueue 0.0763061 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149939 ms - Host latency: 0.191687 ms (end to end 0.268506 ms, enqueue 0.0757202 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149536 ms - Host latency: 0.191687 ms (end to end 0.269177 ms, enqueue 0.0775146 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149402 ms - Host latency: 0.191528 ms (end to end 0.269592 ms, enqueue 0.0781982 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149243 ms - Host latency: 0.191321 ms (end to end 0.271436 ms, enqueue 0.0769165 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149622 ms - Host latency: 0.191272 ms (end to end 0.271973 ms, enqueue 0.0922119 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148767 ms - Host latency: 0.190393 ms (end to end 0.274402 ms, enqueue 0.0962769 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148779 ms - Host latency: 0.190088 ms (end to end 0.268481 ms, enqueue 0.0733154 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149402 ms - Host latency: 0.191003 ms (end to end 0.269934 ms, enqueue 0.0733276 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149121 ms - Host latency: 0.190649 ms (end to end 0.269592 ms, enqueue 0.0723022 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151404 ms - Host latency: 0.194678 ms (end to end 0.240637 ms, enqueue 0.108423 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150891 ms - Host latency: 0.192151 ms (end to end 0.202368 ms, enqueue 0.134534 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152222 ms - Host latency: 0.193652 ms (end to end 0.203186 ms, enqueue 0.136316 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15105 ms - Host latency: 0.196082 ms (end to end 0.208191 ms, enqueue 0.141541 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150378 ms - Host latency: 0.203784 ms (end to end 0.214844 ms, enqueue 0.162256 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15033 ms - Host latency: 0.204761 ms (end to end 0.21554 ms, enqueue 0.163623 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153333 ms - Host latency: 0.205835 ms (end to end 0.214941 ms, enqueue 0.165405 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150732 ms - Host latency: 0.203186 ms (end to end 0.214465 ms, enqueue 0.164563 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151355 ms - Host latency: 0.204248 ms (end to end 0.214343 ms, enqueue 0.165222 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152686 ms - Host latency: 0.196033 ms (end to end 0.241089 ms, enqueue 0.126184 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14939 ms - Host latency: 0.192212 ms (end to end 0.278369 ms, enqueue 0.112952 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149109 ms - Host latency: 0.191443 ms (end to end 0.281226 ms, enqueue 0.11488 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149756 ms - Host latency: 0.192419 ms (end to end 0.277771 ms, enqueue 0.11405 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148877 ms - Host latency: 0.19137 ms (end to end 0.279639 ms, enqueue 0.114966 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149231 ms - Host latency: 0.191272 ms (end to end 0.276794 ms, enqueue 0.114575 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149609 ms - Host latency: 0.192896 ms (end to end 0.278406 ms, enqueue 0.114209 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149329 ms - Host latency: 0.191467 ms (end to end 0.273254 ms, enqueue 0.0933716 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148621 ms - Host latency: 0.189771 ms (end to end 0.271143 ms, enqueue 0.0903687 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148914 ms - Host latency: 0.190076 ms (end to end 0.271082 ms, enqueue 0.089856 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149048 ms - Host latency: 0.190649 ms (end to end 0.27157 ms, enqueue 0.0899536 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148669 ms - Host latency: 0.190295 ms (end to end 0.270825 ms, enqueue 0.0892334 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148633 ms - Host latency: 0.189722 ms (end to end 0.271094 ms, enqueue 0.09021 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148474 ms - Host latency: 0.189685 ms (end to end 0.270361 ms, enqueue 0.0895508 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149011 ms - Host latency: 0.190869 ms (end to end 0.271765 ms, enqueue 0.090979 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148828 ms - Host latency: 0.19043 ms (end to end 0.270996 ms, enqueue 0.0924927 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148718 ms - Host latency: 0.190149 ms (end to end 0.270691 ms, enqueue 0.0894897 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149084 ms - Host latency: 0.190234 ms (end to end 0.27146 ms, enqueue 0.0894409 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148657 ms - Host latency: 0.189941 ms (end to end 0.271643 ms, enqueue 0.0900147 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.190381 ms (end to end 0.270947 ms, enqueue 0.0890015 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14873 ms - Host latency: 0.190295 ms (end to end 0.270654 ms, enqueue 0.09021 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148804 ms - Host latency: 0.190271 ms (end to end 0.27019 ms, enqueue 0.088855 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148975 ms - Host latency: 0.190186 ms (end to end 0.271179 ms, enqueue 0.0891602 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148877 ms - Host latency: 0.190222 ms (end to end 0.270715 ms, enqueue 0.0906494 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148779 ms - Host latency: 0.190039 ms (end to end 0.271021 ms, enqueue 0.0894775 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149097 ms - Host latency: 0.190479 ms (end to end 0.270251 ms, enqueue 0.0884399 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149109 ms - Host latency: 0.190955 ms (end to end 0.263098 ms, enqueue 0.111206 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151172 ms - Host latency: 0.19314 ms (end to end 0.223584 ms, enqueue 0.133936 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154211 ms - Host latency: 0.196484 ms (end to end 0.207251 ms, enqueue 0.136084 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153369 ms - Host latency: 0.195276 ms (end to end 0.206946 ms, enqueue 0.133081 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154919 ms - Host latency: 0.196887 ms (end to end 0.206433 ms, enqueue 0.133875 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153711 ms - Host latency: 0.195276 ms (end to end 0.206555 ms, enqueue 0.13446 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15481 ms - Host latency: 0.196667 ms (end to end 0.206421 ms, enqueue 0.133679 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15116 ms - Host latency: 0.192896 ms (end to end 0.247583 ms, enqueue 0.102356 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149072 ms - Host latency: 0.190613 ms (end to end 0.268677 ms, enqueue 0.0938477 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148999 ms - Host latency: 0.190527 ms (end to end 0.271777 ms, enqueue 0.0937622 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149036 ms - Host latency: 0.190686 ms (end to end 0.271375 ms, enqueue 0.0952881 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14906 ms - Host latency: 0.190271 ms (end to end 0.270178 ms, enqueue 0.093811 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149109 ms - Host latency: 0.190698 ms (end to end 0.268787 ms, enqueue 0.0935181 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14895 ms - Host latency: 0.190125 ms (end to end 0.271375 ms, enqueue 0.0941772 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150159 ms - Host latency: 0.192651 ms (end to end 0.268213 ms, enqueue 0.0767944 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149438 ms - Host latency: 0.191064 ms (end to end 0.270093 ms, enqueue 0.0778931 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149634 ms - Host latency: 0.19198 ms (end to end 0.269812 ms, enqueue 0.077002 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149512 ms - Host latency: 0.19115 ms (end to end 0.270007 ms, enqueue 0.0778198 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149585 ms - Host latency: 0.19187 ms (end to end 0.267761 ms, enqueue 0.0773315 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149976 ms - Host latency: 0.192419 ms (end to end 0.269605 ms, enqueue 0.0770264 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150037 ms - Host latency: 0.191785 ms (end to end 0.270886 ms, enqueue 0.0766113 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149707 ms - Host latency: 0.191699 ms (end to end 0.268237 ms, enqueue 0.072998 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149133 ms - Host latency: 0.190662 ms (end to end 0.267761 ms, enqueue 0.072583 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149365 ms - Host latency: 0.191272 ms (end to end 0.271655 ms, enqueue 0.0731567 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148193 ms - Host latency: 0.190149 ms (end to end 0.278394 ms, enqueue 0.071936 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.147937 ms - Host latency: 0.189795 ms (end to end 0.27843 ms, enqueue 0.0723145 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14856 ms - Host latency: 0.190698 ms (end to end 0.27865 ms, enqueue 0.0724365 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148718 ms - Host latency: 0.190149 ms (end to end 0.280493 ms, enqueue 0.0724976 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148096 ms - Host latency: 0.189685 ms (end to end 0.278333 ms, enqueue 0.0732178 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148413 ms - Host latency: 0.190149 ms (end to end 0.278857 ms, enqueue 0.0738525 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148584 ms - Host latency: 0.190088 ms (end to end 0.279321 ms, enqueue 0.074231 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.147888 ms - Host latency: 0.188953 ms (end to end 0.279004 ms, enqueue 0.0739502 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.147876 ms - Host latency: 0.188965 ms (end to end 0.278357 ms, enqueue 0.0743408 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.147839 ms - Host latency: 0.189404 ms (end to end 0.278857 ms, enqueue 0.0739502 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148108 ms - Host latency: 0.189514 ms (end to end 0.276489 ms, enqueue 0.0755493 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148059 ms - Host latency: 0.189331 ms (end to end 0.277539 ms, enqueue 0.0750732 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.162427 ms - Host latency: 0.206152 ms (end to end 0.288977 ms, enqueue 0.0983887 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.186536 ms - Host latency: 0.232397 ms (end to end 0.24397 ms, enqueue 0.216919 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.18905 ms - Host latency: 0.234253 ms (end to end 0.245789 ms, enqueue 0.219458 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.167163 ms - Host latency: 0.211938 ms (end to end 0.223242 ms, enqueue 0.172791 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155945 ms - Host latency: 0.199585 ms (end to end 0.212683 ms, enqueue 0.142004 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155249 ms - Host latency: 0.198767 ms (end to end 0.211987 ms, enqueue 0.142224 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156116 ms - Host latency: 0.200391 ms (end to end 0.212805 ms, enqueue 0.143225 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156323 ms - Host latency: 0.199768 ms (end to end 0.211719 ms, enqueue 0.141199 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156738 ms - Host latency: 0.201709 ms (end to end 0.213379 ms, enqueue 0.143591 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149915 ms - Host latency: 0.192175 ms (end to end 0.254004 ms, enqueue 0.109131 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149036 ms - Host latency: 0.19093 ms (end to end 0.27373 ms, enqueue 0.102698 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.176221 ms - Host latency: 0.221667 ms (end to end 0.273804 ms, enqueue 0.167883 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.193713 ms - Host latency: 0.239209 ms (end to end 0.249963 ms, enqueue 0.223193 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.186243 ms - Host latency: 0.232446 ms (end to end 0.243469 ms, enqueue 0.216272 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.186047 ms - Host latency: 0.231567 ms (end to end 0.242212 ms, enqueue 0.215173 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.184839 ms - Host latency: 0.230286 ms (end to end 0.240759 ms, enqueue 0.214209 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.186951 ms - Host latency: 0.23219 ms (end to end 0.243042 ms, enqueue 0.21604 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.182446 ms - Host latency: 0.227209 ms (end to end 0.238062 ms, enqueue 0.206421 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155994 ms - Host latency: 0.199609 ms (end to end 0.210913 ms, enqueue 0.141296 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.158154 ms - Host latency: 0.201599 ms (end to end 0.212646 ms, enqueue 0.150586 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149097 ms - Host latency: 0.203723 ms (end to end 0.216138 ms, enqueue 0.15448 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151318 ms - Host latency: 0.203674 ms (end to end 0.216638 ms, enqueue 0.157886 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149463 ms - Host latency: 0.191174 ms (end to end 0.246326 ms, enqueue 0.116321 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14895 ms - Host latency: 0.190833 ms (end to end 0.283081 ms, enqueue 0.116663 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151892 ms - Host latency: 0.195789 ms (end to end 0.249084 ms, enqueue 0.135071 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154932 ms - Host latency: 0.201062 ms (end to end 0.214856 ms, enqueue 0.154956 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152026 ms - Host latency: 0.201758 ms (end to end 0.217334 ms, enqueue 0.150012 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15343 ms - Host latency: 0.201184 ms (end to end 0.216174 ms, enqueue 0.148621 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154004 ms - Host latency: 0.201257 ms (end to end 0.215796 ms, enqueue 0.147961 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150183 ms - Host latency: 0.194617 ms (end to end 0.244031 ms, enqueue 0.115454 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149451 ms - Host latency: 0.190771 ms (end to end 0.268713 ms, enqueue 0.100488 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149133 ms - Host latency: 0.190601 ms (end to end 0.273193 ms, enqueue 0.10199 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149341 ms - Host latency: 0.191284 ms (end to end 0.276196 ms, enqueue 0.100269 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149353 ms - Host latency: 0.191223 ms (end to end 0.275793 ms, enqueue 0.100244 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.191626 ms (end to end 0.22334 ms, enqueue 0.123926 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149438 ms - Host latency: 0.190649 ms (end to end 0.215271 ms, enqueue 0.12345 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148767 ms - Host latency: 0.190491 ms (end to end 0.268091 ms, enqueue 0.090918 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150305 ms - Host latency: 0.192297 ms (end to end 0.26842 ms, enqueue 0.0900757 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150305 ms - Host latency: 0.192407 ms (end to end 0.269763 ms, enqueue 0.0895508 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150134 ms - Host latency: 0.192017 ms (end to end 0.269116 ms, enqueue 0.0898193 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150439 ms - Host latency: 0.192517 ms (end to end 0.271021 ms, enqueue 0.089917 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149658 ms - Host latency: 0.191553 ms (end to end 0.266284 ms, enqueue 0.0897583 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.206921 ms - Host latency: 0.254944 ms (end to end 0.274365 ms, enqueue 0.226929 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.20061 ms - Host latency: 0.247607 ms (end to end 0.258154 ms, enqueue 0.228308 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.187512 ms - Host latency: 0.233276 ms (end to end 0.244299 ms, enqueue 0.21781 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.191077 ms (end to end 0.256775 ms, enqueue 0.0771851 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149463 ms - Host latency: 0.191101 ms (end to end 0.268921 ms, enqueue 0.072583 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149707 ms - Host latency: 0.191882 ms (end to end 0.269885 ms, enqueue 0.0809204 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14967 ms - Host latency: 0.19126 ms (end to end 0.267676 ms, enqueue 0.0922485 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149512 ms - Host latency: 0.190955 ms (end to end 0.270642 ms, enqueue 0.0925415 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150098 ms - Host latency: 0.191504 ms (end to end 0.262195 ms, enqueue 0.0933716 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150317 ms - Host latency: 0.19248 ms (end to end 0.274719 ms, enqueue 0.0928955 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149536 ms - Host latency: 0.191016 ms (end to end 0.271509 ms, enqueue 0.0927246 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.176392 ms - Host latency: 0.222009 ms (end to end 0.271765 ms, enqueue 0.163879 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.186072 ms - Host latency: 0.231555 ms (end to end 0.243323 ms, enqueue 0.216711 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.185059 ms - Host latency: 0.230627 ms (end to end 0.240845 ms, enqueue 0.214282 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.185034 ms - Host latency: 0.230493 ms (end to end 0.239893 ms, enqueue 0.213684 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.174036 ms - Host latency: 0.220337 ms (end to end 0.232776 ms, enqueue 0.192737 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155005 ms - Host latency: 0.202588 ms (end to end 0.218018 ms, enqueue 0.149268 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155969 ms - Host latency: 0.202393 ms (end to end 0.217432 ms, enqueue 0.148486 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153625 ms - Host latency: 0.202795 ms (end to end 0.21803 ms, enqueue 0.150793 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153857 ms - Host latency: 0.203906 ms (end to end 0.217981 ms, enqueue 0.149792 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151794 ms - Host latency: 0.1953 ms (end to end 0.242273 ms, enqueue 0.117505 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149585 ms - Host latency: 0.191492 ms (end to end 0.274976 ms, enqueue 0.109265 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148572 ms - Host latency: 0.190259 ms (end to end 0.28092 ms, enqueue 0.117761 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148682 ms - Host latency: 0.190771 ms (end to end 0.274878 ms, enqueue 0.11709 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.1495 ms - Host latency: 0.191675 ms (end to end 0.278357 ms, enqueue 0.117285 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149097 ms - Host latency: 0.19137 ms (end to end 0.281201 ms, enqueue 0.118079 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148792 ms - Host latency: 0.190576 ms (end to end 0.278027 ms, enqueue 0.117468 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14873 ms - Host latency: 0.190356 ms (end to end 0.271387 ms, enqueue 0.116797 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149707 ms - Host latency: 0.191638 ms (end to end 0.269946 ms, enqueue 0.0925049 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149902 ms - Host latency: 0.191406 ms (end to end 0.266541 ms, enqueue 0.0883423 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151538 ms - Host latency: 0.19469 ms (end to end 0.268848 ms, enqueue 0.10177 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154883 ms - Host latency: 0.202881 ms (end to end 0.219275 ms, enqueue 0.150793 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151587 ms - Host latency: 0.199988 ms (end to end 0.214856 ms, enqueue 0.154565 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151648 ms - Host latency: 0.200159 ms (end to end 0.214282 ms, enqueue 0.154602 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.167908 ms - Host latency: 0.212366 ms (end to end 0.221106 ms, enqueue 0.195825 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.160645 ms - Host latency: 0.204773 ms (end to end 0.210657 ms, enqueue 0.187231 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.166614 ms - Host latency: 0.211023 ms (end to end 0.218396 ms, enqueue 0.194446 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15863 ms - Host latency: 0.203271 ms (end to end 0.21012 ms, enqueue 0.186023 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154822 ms - Host latency: 0.198474 ms (end to end 0.210571 ms, enqueue 0.1495 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148755 ms - Host latency: 0.190186 ms (end to end 0.210767 ms, enqueue 0.124109 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148511 ms - Host latency: 0.189539 ms (end to end 0.212231 ms, enqueue 0.124561 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150244 ms - Host latency: 0.191565 ms (end to end 0.211194 ms, enqueue 0.12804 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150378 ms - Host latency: 0.191931 ms (end to end 0.205371 ms, enqueue 0.126318 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148816 ms - Host latency: 0.190588 ms (end to end 0.212988 ms, enqueue 0.124561 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15033 ms - Host latency: 0.191675 ms (end to end 0.217517 ms, enqueue 0.11958 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148315 ms - Host latency: 0.189221 ms (end to end 0.271826 ms, enqueue 0.0925171 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149304 ms - Host latency: 0.190918 ms (end to end 0.270776 ms, enqueue 0.0915771 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149609 ms - Host latency: 0.191187 ms (end to end 0.27196 ms, enqueue 0.0938232 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149146 ms - Host latency: 0.191113 ms (end to end 0.266846 ms, enqueue 0.090625 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149414 ms - Host latency: 0.190894 ms (end to end 0.258923 ms, enqueue 0.102332 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148987 ms - Host latency: 0.190698 ms (end to end 0.269641 ms, enqueue 0.0936279 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150476 ms - Host latency: 0.193237 ms (end to end 0.27041 ms, enqueue 0.0966553 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149084 ms - Host latency: 0.191345 ms (end to end 0.276636 ms, enqueue 0.100513 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149622 ms - Host latency: 0.191699 ms (end to end 0.276599 ms, enqueue 0.100232 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148352 ms - Host latency: 0.189917 ms (end to end 0.275891 ms, enqueue 0.0993164 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148572 ms - Host latency: 0.190027 ms (end to end 0.273962 ms, enqueue 0.0988525 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148792 ms - Host latency: 0.190955 ms (end to end 0.27782 ms, enqueue 0.101794 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14928 ms - Host latency: 0.191113 ms (end to end 0.274658 ms, enqueue 0.0983887 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148657 ms - Host latency: 0.190259 ms (end to end 0.273511 ms, enqueue 0.0886108 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14906 ms - Host latency: 0.192542 ms (end to end 0.274255 ms, enqueue 0.0853394 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.191504 ms (end to end 0.274268 ms, enqueue 0.086731 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148804 ms - Host latency: 0.191174 ms (end to end 0.274146 ms, enqueue 0.0822876 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149292 ms - Host latency: 0.191211 ms (end to end 0.272205 ms, enqueue 0.0898926 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14873 ms - Host latency: 0.190625 ms (end to end 0.273962 ms, enqueue 0.0783447 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148364 ms - Host latency: 0.190051 ms (end to end 0.273975 ms, enqueue 0.0788086 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148572 ms - Host latency: 0.190247 ms (end to end 0.274634 ms, enqueue 0.0790283 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.191028 ms (end to end 0.270984 ms, enqueue 0.0787231 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150073 ms - Host latency: 0.192712 ms (end to end 0.272913 ms, enqueue 0.079895 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149414 ms - Host latency: 0.191113 ms (end to end 0.271899 ms, enqueue 0.0787842 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149487 ms - Host latency: 0.191772 ms (end to end 0.272192 ms, enqueue 0.078186 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149512 ms - Host latency: 0.191406 ms (end to end 0.27196 ms, enqueue 0.0779663 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14884 ms - Host latency: 0.190442 ms (end to end 0.27312 ms, enqueue 0.0781372 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149121 ms - Host latency: 0.19104 ms (end to end 0.272803 ms, enqueue 0.079126 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149255 ms - Host latency: 0.191345 ms (end to end 0.272693 ms, enqueue 0.0790527 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149231 ms - Host latency: 0.191199 ms (end to end 0.27373 ms, enqueue 0.0783447 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154932 ms - Host latency: 0.198547 ms (end to end 0.247412 ms, enqueue 0.11532 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.1505 ms - Host latency: 0.191797 ms (end to end 0.2026 ms, enqueue 0.127209 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151062 ms - Host latency: 0.193079 ms (end to end 0.204504 ms, enqueue 0.133032 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.147327 ms - Host latency: 0.188086 ms (end to end 0.199268 ms, enqueue 0.172253 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148645 ms - Host latency: 0.189941 ms (end to end 0.197498 ms, enqueue 0.174097 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.147729 ms - Host latency: 0.188953 ms (end to end 0.200098 ms, enqueue 0.173853 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148914 ms - Host latency: 0.190393 ms (end to end 0.199231 ms, enqueue 0.175781 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148022 ms - Host latency: 0.188989 ms (end to end 0.198816 ms, enqueue 0.17262 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149805 ms - Host latency: 0.192896 ms (end to end 0.204944 ms, enqueue 0.139026 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150293 ms - Host latency: 0.192371 ms (end to end 0.266528 ms, enqueue 0.0800781 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149268 ms - Host latency: 0.191028 ms (end to end 0.266638 ms, enqueue 0.0790161 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149341 ms - Host latency: 0.190942 ms (end to end 0.267749 ms, enqueue 0.079541 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149316 ms - Host latency: 0.190674 ms (end to end 0.26665 ms, enqueue 0.0783325 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149365 ms - Host latency: 0.190735 ms (end to end 0.267847 ms, enqueue 0.0784424 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149475 ms - Host latency: 0.191223 ms (end to end 0.267297 ms, enqueue 0.0793213 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148669 ms - Host latency: 0.190308 ms (end to end 0.27168 ms, enqueue 0.0824585 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149255 ms - Host latency: 0.191309 ms (end to end 0.273084 ms, enqueue 0.0833496 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148425 ms - Host latency: 0.190002 ms (end to end 0.272534 ms, enqueue 0.0829224 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148328 ms - Host latency: 0.189661 ms (end to end 0.272754 ms, enqueue 0.0833618 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149487 ms - Host latency: 0.191187 ms (end to end 0.273169 ms, enqueue 0.0844238 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148962 ms - Host latency: 0.190454 ms (end to end 0.271094 ms, enqueue 0.0831543 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149512 ms - Host latency: 0.191138 ms (end to end 0.272388 ms, enqueue 0.0821289 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149463 ms - Host latency: 0.191614 ms (end to end 0.272876 ms, enqueue 0.0779907 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149182 ms - Host latency: 0.190918 ms (end to end 0.272925 ms, enqueue 0.0780762 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149536 ms - Host latency: 0.191589 ms (end to end 0.260669 ms, enqueue 0.0797729 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148132 ms - Host latency: 0.189172 ms (end to end 0.23407 ms, enqueue 0.0793701 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149512 ms - Host latency: 0.1922 ms (end to end 0.228198 ms, enqueue 0.0987061 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149255 ms - Host latency: 0.191077 ms (end to end 0.274915 ms, enqueue 0.112476 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149109 ms - Host latency: 0.190991 ms (end to end 0.275439 ms, enqueue 0.11189 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14939 ms - Host latency: 0.190942 ms (end to end 0.274011 ms, enqueue 0.115552 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148853 ms - Host latency: 0.191284 ms (end to end 0.278748 ms, enqueue 0.113391 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149438 ms - Host latency: 0.191394 ms (end to end 0.273914 ms, enqueue 0.0953247 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149231 ms - Host latency: 0.191333 ms (end to end 0.269189 ms, enqueue 0.0901489 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148889 ms - Host latency: 0.189856 ms (end to end 0.27124 ms, enqueue 0.0897339 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149072 ms - Host latency: 0.191064 ms (end to end 0.269666 ms, enqueue 0.0903809 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149011 ms - Host latency: 0.190381 ms (end to end 0.269019 ms, enqueue 0.0895996 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149097 ms - Host latency: 0.190308 ms (end to end 0.269421 ms, enqueue 0.0897827 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14895 ms - Host latency: 0.189954 ms (end to end 0.269385 ms, enqueue 0.0899536 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14917 ms - Host latency: 0.190405 ms (end to end 0.270203 ms, enqueue 0.0896606 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148853 ms - Host latency: 0.190393 ms (end to end 0.269116 ms, enqueue 0.094519 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.177344 ms - Host latency: 0.223108 ms (end to end 0.254407 ms, enqueue 0.182178 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.187305 ms - Host latency: 0.232739 ms (end to end 0.24353 ms, enqueue 0.217029 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.180396 ms - Host latency: 0.226111 ms (end to end 0.235657 ms, enqueue 0.210388 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.170667 ms - Host latency: 0.214795 ms (end to end 0.223071 ms, enqueue 0.198743 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.17124 ms - Host latency: 0.215588 ms (end to end 0.223657 ms, enqueue 0.19928 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.169812 ms - Host latency: 0.214026 ms (end to end 0.222253 ms, enqueue 0.197852 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.168555 ms - Host latency: 0.214832 ms (end to end 0.223059 ms, enqueue 0.195105 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154138 ms - Host latency: 0.195911 ms (end to end 0.20415 ms, enqueue 0.133691 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151404 ms - Host latency: 0.194263 ms (end to end 0.208264 ms, enqueue 0.130859 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148926 ms - Host latency: 0.191187 ms (end to end 0.268188 ms, enqueue 0.115894 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149316 ms - Host latency: 0.191748 ms (end to end 0.283533 ms, enqueue 0.117041 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150122 ms - Host latency: 0.193066 ms (end to end 0.283838 ms, enqueue 0.116125 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15022 ms - Host latency: 0.193018 ms (end to end 0.285901 ms, enqueue 0.117407 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149243 ms - Host latency: 0.191907 ms (end to end 0.285901 ms, enqueue 0.118347 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149207 ms - Host latency: 0.191614 ms (end to end 0.283704 ms, enqueue 0.116418 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149084 ms - Host latency: 0.19104 ms (end to end 0.281396 ms, enqueue 0.115845 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149304 ms - Host latency: 0.191113 ms (end to end 0.254395 ms, enqueue 0.132593 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148694 ms - Host latency: 0.190344 ms (end to end 0.270813 ms, enqueue 0.11604 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148413 ms - Host latency: 0.190332 ms (end to end 0.28114 ms, enqueue 0.115796 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149426 ms - Host latency: 0.192493 ms (end to end 0.285071 ms, enqueue 0.116138 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148767 ms - Host latency: 0.190588 ms (end to end 0.276904 ms, enqueue 0.0932739 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14895 ms - Host latency: 0.190503 ms (end to end 0.272778 ms, enqueue 0.0839722 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148779 ms - Host latency: 0.189954 ms (end to end 0.273791 ms, enqueue 0.0839722 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148938 ms - Host latency: 0.190491 ms (end to end 0.273389 ms, enqueue 0.0835937 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.175098 ms - Host latency: 0.220422 ms (end to end 0.269568 ms, enqueue 0.158594 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.174316 ms - Host latency: 0.222253 ms (end to end 0.232886 ms, enqueue 0.197327 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.147974 ms - Host latency: 0.199561 ms (end to end 0.211157 ms, enqueue 0.156458 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148315 ms - Host latency: 0.20249 ms (end to end 0.214624 ms, enqueue 0.154297 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148132 ms - Host latency: 0.200391 ms (end to end 0.212463 ms, enqueue 0.155298 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14845 ms - Host latency: 0.202588 ms (end to end 0.214685 ms, enqueue 0.154932 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148669 ms - Host latency: 0.202124 ms (end to end 0.215039 ms, enqueue 0.155188 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150256 ms - Host latency: 0.193994 ms (end to end 0.242798 ms, enqueue 0.121265 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149023 ms - Host latency: 0.191516 ms (end to end 0.273865 ms, enqueue 0.110596 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149231 ms - Host latency: 0.190955 ms (end to end 0.277734 ms, enqueue 0.109021 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149805 ms - Host latency: 0.192444 ms (end to end 0.273999 ms, enqueue 0.10813 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149243 ms - Host latency: 0.191064 ms (end to end 0.275488 ms, enqueue 0.109326 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149548 ms - Host latency: 0.191077 ms (end to end 0.273743 ms, enqueue 0.1078 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149634 ms - Host latency: 0.191724 ms (end to end 0.275439 ms, enqueue 0.108704 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150208 ms - Host latency: 0.191821 ms (end to end 0.270203 ms, enqueue 0.0932739 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149475 ms - Host latency: 0.19104 ms (end to end 0.264685 ms, enqueue 0.0825806 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149414 ms - Host latency: 0.191113 ms (end to end 0.265295 ms, enqueue 0.0824829 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149597 ms - Host latency: 0.190967 ms (end to end 0.26532 ms, enqueue 0.0827271 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149231 ms - Host latency: 0.190686 ms (end to end 0.26366 ms, enqueue 0.0828491 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149805 ms - Host latency: 0.192212 ms (end to end 0.267078 ms, enqueue 0.0824829 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149805 ms - Host latency: 0.192102 ms (end to end 0.265723 ms, enqueue 0.0825562 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149524 ms - Host latency: 0.191846 ms (end to end 0.268591 ms, enqueue 0.0731445 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150146 ms - Host latency: 0.192346 ms (end to end 0.270837 ms, enqueue 0.0727783 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14939 ms - Host latency: 0.191113 ms (end to end 0.267407 ms, enqueue 0.0727783 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149182 ms - Host latency: 0.190686 ms (end to end 0.268506 ms, enqueue 0.0727783 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14928 ms - Host latency: 0.190552 ms (end to end 0.268921 ms, enqueue 0.0723389 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.190723 ms (end to end 0.268762 ms, enqueue 0.072937 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.167187 ms - Host latency: 0.211646 ms (end to end 0.249194 ms, enqueue 0.164307 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.171338 ms - Host latency: 0.215906 ms (end to end 0.224817 ms, enqueue 0.199902 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.168445 ms - Host latency: 0.213293 ms (end to end 0.221838 ms, enqueue 0.196826 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.169556 ms - Host latency: 0.214319 ms (end to end 0.2224 ms, enqueue 0.197595 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.165442 ms - Host latency: 0.211011 ms (end to end 0.21991 ms, enqueue 0.188013 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155627 ms - Host latency: 0.1979 ms (end to end 0.210291 ms, enqueue 0.140588 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156152 ms - Host latency: 0.198279 ms (end to end 0.210535 ms, enqueue 0.139221 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155981 ms - Host latency: 0.199023 ms (end to end 0.210156 ms, enqueue 0.139929 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155615 ms - Host latency: 0.198303 ms (end to end 0.209778 ms, enqueue 0.139417 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155664 ms - Host latency: 0.19884 ms (end to end 0.209509 ms, enqueue 0.139673 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154175 ms - Host latency: 0.196765 ms (end to end 0.214343 ms, enqueue 0.130054 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149048 ms - Host latency: 0.190649 ms (end to end 0.273254 ms, enqueue 0.100403 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149316 ms - Host latency: 0.191211 ms (end to end 0.270435 ms, enqueue 0.100244 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.191199 ms (end to end 0.267114 ms, enqueue 0.100293 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148938 ms - Host latency: 0.190405 ms (end to end 0.268799 ms, enqueue 0.100317 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148999 ms - Host latency: 0.190332 ms (end to end 0.271582 ms, enqueue 0.100793 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148584 ms - Host latency: 0.189746 ms (end to end 0.271289 ms, enqueue 0.100281 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15 ms - Host latency: 0.19126 ms (end to end 0.271069 ms, enqueue 0.0897949 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149512 ms - Host latency: 0.190955 ms (end to end 0.263647 ms, enqueue 0.0817139 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150525 ms - Host latency: 0.191772 ms (end to end 0.265112 ms, enqueue 0.0813599 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149744 ms - Host latency: 0.190918 ms (end to end 0.263379 ms, enqueue 0.0821777 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149731 ms - Host latency: 0.190991 ms (end to end 0.262036 ms, enqueue 0.0817505 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149841 ms - Host latency: 0.190857 ms (end to end 0.263379 ms, enqueue 0.0810669 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150378 ms - Host latency: 0.191858 ms (end to end 0.266467 ms, enqueue 0.0814941 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149316 ms - Host latency: 0.191248 ms (end to end 0.265295 ms, enqueue 0.0737183 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149292 ms - Host latency: 0.191211 ms (end to end 0.265857 ms, enqueue 0.0734375 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149634 ms - Host latency: 0.190979 ms (end to end 0.266467 ms, enqueue 0.0735229 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149414 ms - Host latency: 0.19104 ms (end to end 0.265906 ms, enqueue 0.0736206 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149695 ms - Host latency: 0.19165 ms (end to end 0.266064 ms, enqueue 0.0740356 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149329 ms - Host latency: 0.191479 ms (end to end 0.267249 ms, enqueue 0.0735352 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149414 ms - Host latency: 0.190771 ms (end to end 0.267017 ms, enqueue 0.072998 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148706 ms - Host latency: 0.190198 ms (end to end 0.268774 ms, enqueue 0.0728027 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149341 ms - Host latency: 0.191089 ms (end to end 0.268567 ms, enqueue 0.0724609 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149268 ms - Host latency: 0.191248 ms (end to end 0.267212 ms, enqueue 0.072229 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14928 ms - Host latency: 0.190808 ms (end to end 0.268323 ms, enqueue 0.07229 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149622 ms - Host latency: 0.19137 ms (end to end 0.268103 ms, enqueue 0.0719482 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14906 ms - Host latency: 0.190295 ms (end to end 0.26792 ms, enqueue 0.0725342 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14989 ms - Host latency: 0.192078 ms (end to end 0.264722 ms, enqueue 0.0735229 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149536 ms - Host latency: 0.19176 ms (end to end 0.264062 ms, enqueue 0.0741333 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150073 ms - Host latency: 0.192407 ms (end to end 0.265784 ms, enqueue 0.0737793 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149634 ms - Host latency: 0.19165 ms (end to end 0.264978 ms, enqueue 0.0737305 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149866 ms - Host latency: 0.191565 ms (end to end 0.266016 ms, enqueue 0.0736694 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150085 ms - Host latency: 0.191956 ms (end to end 0.265515 ms, enqueue 0.0739014 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149658 ms - Host latency: 0.191858 ms (end to end 0.267236 ms, enqueue 0.0739258 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149414 ms - Host latency: 0.190845 ms (end to end 0.270044 ms, enqueue 0.0745483 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148914 ms - Host latency: 0.19021 ms (end to end 0.270947 ms, enqueue 0.0737061 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148987 ms - Host latency: 0.190173 ms (end to end 0.271814 ms, enqueue 0.0733643 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149133 ms - Host latency: 0.190491 ms (end to end 0.271411 ms, enqueue 0.0737671 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149084 ms - Host latency: 0.190515 ms (end to end 0.271631 ms, enqueue 0.0739014 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149036 ms - Host latency: 0.190283 ms (end to end 0.271326 ms, enqueue 0.074353 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148669 ms - Host latency: 0.190039 ms (end to end 0.270862 ms, enqueue 0.0740723 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149243 ms - Host latency: 0.190735 ms (end to end 0.27146 ms, enqueue 0.0736694 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149207 ms - Host latency: 0.19093 ms (end to end 0.270837 ms, enqueue 0.0740112 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149316 ms - Host latency: 0.190894 ms (end to end 0.271741 ms, enqueue 0.0741821 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149365 ms - Host latency: 0.191077 ms (end to end 0.271399 ms, enqueue 0.0739136 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148718 ms - Host latency: 0.190149 ms (end to end 0.271143 ms, enqueue 0.074707 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149109 ms - Host latency: 0.190491 ms (end to end 0.272278 ms, enqueue 0.0749146 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148608 ms - Host latency: 0.189954 ms (end to end 0.269995 ms, enqueue 0.0740967 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.190552 ms (end to end 0.27085 ms, enqueue 0.073938 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148779 ms - Host latency: 0.190137 ms (end to end 0.270898 ms, enqueue 0.0743164 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14906 ms - Host latency: 0.190454 ms (end to end 0.271594 ms, enqueue 0.0752808 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149231 ms - Host latency: 0.190515 ms (end to end 0.272156 ms, enqueue 0.0740112 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148804 ms - Host latency: 0.190125 ms (end to end 0.270959 ms, enqueue 0.0737061 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.190698 ms (end to end 0.27074 ms, enqueue 0.0741821 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.190393 ms (end to end 0.270935 ms, enqueue 0.0737549 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149109 ms - Host latency: 0.190601 ms (end to end 0.271594 ms, enqueue 0.0744019 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149146 ms - Host latency: 0.190967 ms (end to end 0.270557 ms, enqueue 0.0738647 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149255 ms - Host latency: 0.190723 ms (end to end 0.270825 ms, enqueue 0.0740356 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149341 ms - Host latency: 0.19115 ms (end to end 0.269214 ms, enqueue 0.0738525 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148975 ms - Host latency: 0.190637 ms (end to end 0.270874 ms, enqueue 0.0745117 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148853 ms - Host latency: 0.190198 ms (end to end 0.270728 ms, enqueue 0.0735718 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148962 ms - Host latency: 0.190613 ms (end to end 0.270496 ms, enqueue 0.0741333 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149121 ms - Host latency: 0.190845 ms (end to end 0.270349 ms, enqueue 0.0738525 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149097 ms - Host latency: 0.190466 ms (end to end 0.270764 ms, enqueue 0.0734375 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149133 ms - Host latency: 0.190417 ms (end to end 0.270947 ms, enqueue 0.0739258 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148804 ms - Host latency: 0.190454 ms (end to end 0.271033 ms, enqueue 0.074231 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149365 ms - Host latency: 0.191296 ms (end to end 0.26969 ms, enqueue 0.0744141 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149158 ms - Host latency: 0.190747 ms (end to end 0.27041 ms, enqueue 0.073999 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149146 ms - Host latency: 0.190833 ms (end to end 0.270422 ms, enqueue 0.073999 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148364 ms - Host latency: 0.190063 ms (end to end 0.271533 ms, enqueue 0.0742065 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149133 ms - Host latency: 0.190771 ms (end to end 0.27323 ms, enqueue 0.0738281 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149207 ms - Host latency: 0.191028 ms (end to end 0.274292 ms, enqueue 0.0739624 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148792 ms - Host latency: 0.190381 ms (end to end 0.273413 ms, enqueue 0.0736084 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148889 ms - Host latency: 0.190747 ms (end to end 0.274316 ms, enqueue 0.0735596 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148535 ms - Host latency: 0.189978 ms (end to end 0.272668 ms, enqueue 0.0732056 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148596 ms - Host latency: 0.190369 ms (end to end 0.273682 ms, enqueue 0.0734863 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148596 ms - Host latency: 0.190771 ms (end to end 0.273938 ms, enqueue 0.0736206 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14906 ms - Host latency: 0.190894 ms (end to end 0.274023 ms, enqueue 0.0738525 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148889 ms - Host latency: 0.190979 ms (end to end 0.273694 ms, enqueue 0.0735352 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.172412 ms - Host latency: 0.217847 ms (end to end 0.282092 ms, enqueue 0.129956 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.178149 ms - Host latency: 0.223413 ms (end to end 0.232373 ms, enqueue 0.206531 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.187231 ms - Host latency: 0.232593 ms (end to end 0.244629 ms, enqueue 0.217883 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.184998 ms - Host latency: 0.230029 ms (end to end 0.241235 ms, enqueue 0.215161 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.183411 ms - Host latency: 0.229138 ms (end to end 0.239685 ms, enqueue 0.213147 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.161694 ms - Host latency: 0.205835 ms (end to end 0.218323 ms, enqueue 0.156067 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155066 ms - Host latency: 0.199963 ms (end to end 0.212048 ms, enqueue 0.140991 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154443 ms - Host latency: 0.197009 ms (end to end 0.207861 ms, enqueue 0.142114 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150024 ms - Host latency: 0.191357 ms (end to end 0.203101 ms, enqueue 0.127466 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150049 ms - Host latency: 0.190918 ms (end to end 0.201709 ms, enqueue 0.127637 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150623 ms - Host latency: 0.191895 ms (end to end 0.203186 ms, enqueue 0.128357 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154053 ms - Host latency: 0.19751 ms (end to end 0.207532 ms, enqueue 0.140076 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156116 ms - Host latency: 0.199878 ms (end to end 0.212097 ms, enqueue 0.140808 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15603 ms - Host latency: 0.199023 ms (end to end 0.211023 ms, enqueue 0.140454 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15658 ms - Host latency: 0.19917 ms (end to end 0.210364 ms, enqueue 0.139954 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156458 ms - Host latency: 0.199084 ms (end to end 0.212061 ms, enqueue 0.141016 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156873 ms - Host latency: 0.199658 ms (end to end 0.20979 ms, enqueue 0.140063 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153467 ms - Host latency: 0.196167 ms (end to end 0.231702 ms, enqueue 0.119189 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15 ms - Host latency: 0.192505 ms (end to end 0.273096 ms, enqueue 0.100098 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149023 ms - Host latency: 0.191211 ms (end to end 0.272192 ms, enqueue 0.0987549 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149072 ms - Host latency: 0.191138 ms (end to end 0.27146 ms, enqueue 0.0987061 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.191333 ms (end to end 0.272729 ms, enqueue 0.0981445 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148706 ms - Host latency: 0.190747 ms (end to end 0.271631 ms, enqueue 0.0987061 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149854 ms - Host latency: 0.191992 ms (end to end 0.273853 ms, enqueue 0.0966064 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.192407 ms - Host latency: 0.238892 ms (end to end 0.264307 ms, enqueue 0.19834 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.183472 ms - Host latency: 0.228882 ms (end to end 0.240796 ms, enqueue 0.214111 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.186377 ms - Host latency: 0.231641 ms (end to end 0.242896 ms, enqueue 0.21626 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.184326 ms - Host latency: 0.230518 ms (end to end 0.240332 ms, enqueue 0.212793 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.147119 ms - Host latency: 0.192188 ms (end to end 0.202686 ms, enqueue 0.163965 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148071 ms - Host latency: 0.191553 ms (end to end 0.202539 ms, enqueue 0.166626 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.146973 ms - Host latency: 0.19231 ms (end to end 0.203052 ms, enqueue 0.163818 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148096 ms - Host latency: 0.194019 ms (end to end 0.204443 ms, enqueue 0.162476 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149854 ms - Host latency: 0.191968 ms (end to end 0.255884 ms, enqueue 0.0802002 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150024 ms - Host latency: 0.19165 ms (end to end 0.264087 ms, enqueue 0.0764893 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149536 ms - Host latency: 0.190991 ms (end to end 0.261792 ms, enqueue 0.0730713 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15061 ms - Host latency: 0.192676 ms (end to end 0.264111 ms, enqueue 0.0745605 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149707 ms - Host latency: 0.191382 ms (end to end 0.261719 ms, enqueue 0.0716309 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149609 ms - Host latency: 0.191211 ms (end to end 0.254956 ms, enqueue 0.0725342 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149146 ms - Host latency: 0.190161 ms (end to end 0.254565 ms, enqueue 0.0719482 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148975 ms - Host latency: 0.190259 ms (end to end 0.249243 ms, enqueue 0.0720459 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150439 ms - Host latency: 0.192456 ms (end to end 0.265381 ms, enqueue 0.0721924 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150049 ms - Host latency: 0.192041 ms (end to end 0.264722 ms, enqueue 0.0719238 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14978 ms - Host latency: 0.191675 ms (end to end 0.261694 ms, enqueue 0.0720703 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15022 ms - Host latency: 0.192188 ms (end to end 0.263281 ms, enqueue 0.0718018 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150098 ms - Host latency: 0.192334 ms (end to end 0.264746 ms, enqueue 0.0729004 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150293 ms - Host latency: 0.192261 ms (end to end 0.26333 ms, enqueue 0.0724854 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150049 ms - Host latency: 0.192041 ms (end to end 0.265698 ms, enqueue 0.0739502 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150098 ms - Host latency: 0.192188 ms (end to end 0.268677 ms, enqueue 0.0745117 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149316 ms - Host latency: 0.191235 ms (end to end 0.267529 ms, enqueue 0.0738037 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14978 ms - Host latency: 0.19187 ms (end to end 0.266699 ms, enqueue 0.073291 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149634 ms - Host latency: 0.191553 ms (end to end 0.236475 ms, enqueue 0.108716 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149731 ms - Host latency: 0.191382 ms (end to end 0.218164 ms, enqueue 0.129077 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149854 ms - Host latency: 0.191455 ms (end to end 0.221533 ms, enqueue 0.128687 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149023 ms - Host latency: 0.190869 ms (end to end 0.252222 ms, enqueue 0.100391 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.19104 ms (end to end 0.270898 ms, enqueue 0.092041 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149121 ms - Host latency: 0.19082 ms (end to end 0.272363 ms, enqueue 0.0922852 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149097 ms - Host latency: 0.191113 ms (end to end 0.272583 ms, enqueue 0.0925049 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148828 ms - Host latency: 0.190405 ms (end to end 0.27168 ms, enqueue 0.0920166 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149023 ms - Host latency: 0.190552 ms (end to end 0.271094 ms, enqueue 0.0927979 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149609 ms - Host latency: 0.191602 ms (end to end 0.272656 ms, enqueue 0.0925049 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.190771 ms (end to end 0.270898 ms, enqueue 0.089209 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149072 ms - Host latency: 0.190234 ms (end to end 0.271582 ms, enqueue 0.0892578 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.190723 ms (end to end 0.271704 ms, enqueue 0.089624 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149048 ms - Host latency: 0.190649 ms (end to end 0.27229 ms, enqueue 0.0878906 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148975 ms - Host latency: 0.190918 ms (end to end 0.272241 ms, enqueue 0.0724854 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149048 ms - Host latency: 0.190601 ms (end to end 0.273218 ms, enqueue 0.0725586 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149634 ms - Host latency: 0.191577 ms (end to end 0.27417 ms, enqueue 0.0727051 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148901 ms - Host latency: 0.190308 ms (end to end 0.27063 ms, enqueue 0.07229 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148999 ms - Host latency: 0.190259 ms (end to end 0.269849 ms, enqueue 0.072876 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149658 ms - Host latency: 0.191895 ms (end to end 0.270166 ms, enqueue 0.0724121 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.190625 ms (end to end 0.270557 ms, enqueue 0.0723389 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148877 ms - Host latency: 0.18999 ms (end to end 0.269849 ms, enqueue 0.0726563 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14895 ms - Host latency: 0.190454 ms (end to end 0.270532 ms, enqueue 0.0725586 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149268 ms - Host latency: 0.190625 ms (end to end 0.27168 ms, enqueue 0.074585 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148975 ms - Host latency: 0.190552 ms (end to end 0.271973 ms, enqueue 0.0739258 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149023 ms - Host latency: 0.190308 ms (end to end 0.271387 ms, enqueue 0.073877 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148901 ms - Host latency: 0.190308 ms (end to end 0.271729 ms, enqueue 0.0745361 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14895 ms - Host latency: 0.190161 ms (end to end 0.27168 ms, enqueue 0.074292 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148926 ms - Host latency: 0.190503 ms (end to end 0.271704 ms, enqueue 0.0736572 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149268 ms - Host latency: 0.190674 ms (end to end 0.270288 ms, enqueue 0.0741211 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149023 ms - Host latency: 0.190454 ms (end to end 0.271338 ms, enqueue 0.0740723 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14917 ms - Host latency: 0.190723 ms (end to end 0.270337 ms, enqueue 0.073877 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14917 ms - Host latency: 0.190747 ms (end to end 0.27002 ms, enqueue 0.0751953 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14895 ms - Host latency: 0.190674 ms (end to end 0.271167 ms, enqueue 0.0741699 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148975 ms - Host latency: 0.190503 ms (end to end 0.266187 ms, enqueue 0.0794189 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148901 ms - Host latency: 0.190845 ms (end to end 0.272583 ms, enqueue 0.0822754 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149048 ms - Host latency: 0.190381 ms (end to end 0.272339 ms, enqueue 0.0831299 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148926 ms - Host latency: 0.191382 ms (end to end 0.275391 ms, enqueue 0.0910889 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148828 ms - Host latency: 0.190869 ms (end to end 0.27478 ms, enqueue 0.104419 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148462 ms - Host latency: 0.190698 ms (end to end 0.277783 ms, enqueue 0.104224 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148975 ms - Host latency: 0.19104 ms (end to end 0.275146 ms, enqueue 0.104541 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149292 ms - Host latency: 0.191455 ms (end to end 0.276416 ms, enqueue 0.103857 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148999 ms - Host latency: 0.191016 ms (end to end 0.276416 ms, enqueue 0.104443 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149048 ms - Host latency: 0.190381 ms (end to end 0.274512 ms, enqueue 0.0941895 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148926 ms - Host latency: 0.190015 ms (end to end 0.270117 ms, enqueue 0.0888916 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149121 ms - Host latency: 0.190454 ms (end to end 0.27085 ms, enqueue 0.0893311 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148804 ms - Host latency: 0.190356 ms (end to end 0.271167 ms, enqueue 0.0883789 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149023 ms - Host latency: 0.190552 ms (end to end 0.270361 ms, enqueue 0.0889893 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149121 ms - Host latency: 0.190454 ms (end to end 0.270117 ms, enqueue 0.0894775 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148926 ms - Host latency: 0.190259 ms (end to end 0.270459 ms, enqueue 0.0888184 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.190869 ms (end to end 0.26936 ms, enqueue 0.0792969 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149756 ms - Host latency: 0.191821 ms (end to end 0.269482 ms, enqueue 0.0759277 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149829 ms - Host latency: 0.192261 ms (end to end 0.270801 ms, enqueue 0.0761475 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150049 ms - Host latency: 0.192163 ms (end to end 0.269409 ms, enqueue 0.0762695 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149414 ms - Host latency: 0.190894 ms (end to end 0.271313 ms, enqueue 0.0751221 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149268 ms - Host latency: 0.19082 ms (end to end 0.270874 ms, enqueue 0.0836426 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149512 ms - Host latency: 0.191211 ms (end to end 0.268994 ms, enqueue 0.0822998 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149463 ms - Host latency: 0.19126 ms (end to end 0.270288 ms, enqueue 0.0781494 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149292 ms - Host latency: 0.191455 ms (end to end 0.266187 ms, enqueue 0.078125 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149731 ms - Host latency: 0.191675 ms (end to end 0.268286 ms, enqueue 0.0782471 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149463 ms - Host latency: 0.19104 ms (end to end 0.266797 ms, enqueue 0.0779541 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149341 ms - Host latency: 0.191187 ms (end to end 0.268945 ms, enqueue 0.0790039 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149561 ms - Host latency: 0.191357 ms (end to end 0.266992 ms, enqueue 0.0779785 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156714 ms - Host latency: 0.199341 ms (end to end 0.272583 ms, enqueue 0.0975586 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.171973 ms - Host latency: 0.216895 ms (end to end 0.225708 ms, enqueue 0.200464 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.171362 ms - Host latency: 0.215942 ms (end to end 0.224536 ms, enqueue 0.199341 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.170532 ms - Host latency: 0.214819 ms (end to end 0.223486 ms, enqueue 0.19873 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.166504 ms - Host latency: 0.212524 ms (end to end 0.22334 ms, enqueue 0.187061 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155762 ms - Host latency: 0.20249 ms (end to end 0.217749 ms, enqueue 0.14856 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155518 ms - Host latency: 0.202197 ms (end to end 0.218335 ms, enqueue 0.148462 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156055 ms - Host latency: 0.202417 ms (end to end 0.217798 ms, enqueue 0.148022 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154004 ms - Host latency: 0.202954 ms (end to end 0.217236 ms, enqueue 0.148755 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155005 ms - Host latency: 0.200684 ms (end to end 0.217236 ms, enqueue 0.147949 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151318 ms - Host latency: 0.195239 ms (end to end 0.230737 ms, enqueue 0.124609 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148877 ms - Host latency: 0.191016 ms (end to end 0.268408 ms, enqueue 0.100464 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149512 ms - Host latency: 0.191113 ms (end to end 0.269141 ms, enqueue 0.0997314 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149097 ms - Host latency: 0.190576 ms (end to end 0.270581 ms, enqueue 0.0992187 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14939 ms - Host latency: 0.191089 ms (end to end 0.271313 ms, enqueue 0.099585 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149658 ms - Host latency: 0.191968 ms (end to end 0.271094 ms, enqueue 0.099585 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149805 ms - Host latency: 0.193433 ms (end to end 0.252759 ms, enqueue 0.113062 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151978 ms - Host latency: 0.193945 ms (end to end 0.222803 ms, enqueue 0.134644 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153223 ms - Host latency: 0.195728 ms (end to end 0.205591 ms, enqueue 0.134985 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15271 ms - Host latency: 0.194751 ms (end to end 0.2052 ms, enqueue 0.133862 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153516 ms - Host latency: 0.195337 ms (end to end 0.205908 ms, enqueue 0.133911 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154395 ms - Host latency: 0.19668 ms (end to end 0.206201 ms, enqueue 0.134595 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155322 ms - Host latency: 0.197241 ms (end to end 0.205347 ms, enqueue 0.134961 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151392 ms - Host latency: 0.193384 ms (end to end 0.211499 ms, enqueue 0.124902 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149487 ms - Host latency: 0.191504 ms (end to end 0.26814 ms, enqueue 0.116821 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148999 ms - Host latency: 0.191284 ms (end to end 0.280664 ms, enqueue 0.116479 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.191431 ms (end to end 0.279712 ms, enqueue 0.117065 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148682 ms - Host latency: 0.18999 ms (end to end 0.27981 ms, enqueue 0.116309 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.191797 ms (end to end 0.27666 ms, enqueue 0.115649 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149048 ms - Host latency: 0.191016 ms (end to end 0.278784 ms, enqueue 0.115796 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149463 ms - Host latency: 0.191553 ms (end to end 0.273706 ms, enqueue 0.102051 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149902 ms - Host latency: 0.191577 ms (end to end 0.271924 ms, enqueue 0.0951416 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14939 ms - Host latency: 0.191479 ms (end to end 0.269238 ms, enqueue 0.0939453 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149023 ms - Host latency: 0.190698 ms (end to end 0.268311 ms, enqueue 0.0935303 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149634 ms - Host latency: 0.191968 ms (end to end 0.270435 ms, enqueue 0.0938721 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149438 ms - Host latency: 0.191626 ms (end to end 0.273267 ms, enqueue 0.0937256 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149878 ms - Host latency: 0.19187 ms (end to end 0.271069 ms, enqueue 0.0936035 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149854 ms - Host latency: 0.190942 ms (end to end 0.263477 ms, enqueue 0.0813232 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150537 ms - Host latency: 0.192261 ms (end to end 0.263306 ms, enqueue 0.0786621 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150317 ms - Host latency: 0.192163 ms (end to end 0.26272 ms, enqueue 0.0793701 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150269 ms - Host latency: 0.191797 ms (end to end 0.265381 ms, enqueue 0.0782471 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149854 ms - Host latency: 0.191553 ms (end to end 0.266528 ms, enqueue 0.0790039 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.147949 ms - Host latency: 0.201831 ms (end to end 0.22334 ms, enqueue 0.151001 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.174512 ms - Host latency: 0.222705 ms (end to end 0.233423 ms, enqueue 0.198413 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.182495 ms - Host latency: 0.227759 ms (end to end 0.238623 ms, enqueue 0.212842 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.185937 ms - Host latency: 0.231934 ms (end to end 0.242407 ms, enqueue 0.215723 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.183789 ms - Host latency: 0.229199 ms (end to end 0.238794 ms, enqueue 0.21272 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.163501 ms - Host latency: 0.206055 ms (end to end 0.217358 ms, enqueue 0.156519 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15625 ms - Host latency: 0.199023 ms (end to end 0.210034 ms, enqueue 0.13938 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151904 ms - Host latency: 0.195874 ms (end to end 0.231055 ms, enqueue 0.12063 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149121 ms - Host latency: 0.190991 ms (end to end 0.274463 ms, enqueue 0.0983643 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148877 ms - Host latency: 0.190942 ms (end to end 0.27373 ms, enqueue 0.097998 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148804 ms - Host latency: 0.190308 ms (end to end 0.273413 ms, enqueue 0.0986816 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.190991 ms (end to end 0.277026 ms, enqueue 0.105273 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148999 ms - Host latency: 0.19104 ms (end to end 0.279614 ms, enqueue 0.112329 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149121 ms - Host latency: 0.191479 ms (end to end 0.277222 ms, enqueue 0.111621 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149121 ms - Host latency: 0.190796 ms (end to end 0.278125 ms, enqueue 0.112109 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.191064 ms (end to end 0.279614 ms, enqueue 0.111816 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149707 ms - Host latency: 0.191943 ms (end to end 0.280811 ms, enqueue 0.111548 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148853 ms - Host latency: 0.19104 ms (end to end 0.276172 ms, enqueue 0.11189 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149097 ms - Host latency: 0.190503 ms (end to end 0.273657 ms, enqueue 0.0929687 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148926 ms - Host latency: 0.190088 ms (end to end 0.269336 ms, enqueue 0.0887939 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148828 ms - Host latency: 0.190234 ms (end to end 0.259741 ms, enqueue 0.0892578 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149023 ms - Host latency: 0.19043 ms (end to end 0.270166 ms, enqueue 0.0892578 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148486 ms - Host latency: 0.189966 ms (end to end 0.268237 ms, enqueue 0.0885742 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14917 ms - Host latency: 0.190771 ms (end to end 0.269653 ms, enqueue 0.0895264 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148682 ms - Host latency: 0.190137 ms (end to end 0.269727 ms, enqueue 0.0891846 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.190771 ms (end to end 0.268652 ms, enqueue 0.0744629 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.191187 ms (end to end 0.270532 ms, enqueue 0.074292 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148877 ms - Host latency: 0.190381 ms (end to end 0.27207 ms, enqueue 0.0741455 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148657 ms - Host latency: 0.190063 ms (end to end 0.268945 ms, enqueue 0.0744629 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154687 ms - Host latency: 0.197607 ms (end to end 0.264233 ms, enqueue 0.0987793 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148047 ms - Host latency: 0.190869 ms (end to end 0.200586 ms, enqueue 0.166504 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.172949 ms - Host latency: 0.217993 ms (end to end 0.227295 ms, enqueue 0.199219 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.172559 ms - Host latency: 0.217432 ms (end to end 0.22749 ms, enqueue 0.201733 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.17666 ms - Host latency: 0.222339 ms (end to end 0.232202 ms, enqueue 0.205151 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.174243 ms - Host latency: 0.219531 ms (end to end 0.229175 ms, enqueue 0.203027 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.157251 ms - Host latency: 0.199707 ms (end to end 0.211035 ms, enqueue 0.143213 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15498 ms - Host latency: 0.196338 ms (end to end 0.20813 ms, enqueue 0.134253 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155127 ms - Host latency: 0.197412 ms (end to end 0.207617 ms, enqueue 0.134302 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154126 ms - Host latency: 0.195947 ms (end to end 0.20625 ms, enqueue 0.134253 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152954 ms - Host latency: 0.194189 ms (end to end 0.204443 ms, enqueue 0.134131 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153857 ms - Host latency: 0.19563 ms (end to end 0.207324 ms, enqueue 0.134497 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152124 ms - Host latency: 0.193896 ms (end to end 0.225391 ms, enqueue 0.116162 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149829 ms - Host latency: 0.191528 ms (end to end 0.27583 ms, enqueue 0.0956055 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.191162 ms (end to end 0.274097 ms, enqueue 0.0968994 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149487 ms - Host latency: 0.191309 ms (end to end 0.27373 ms, enqueue 0.0958252 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149268 ms - Host latency: 0.191162 ms (end to end 0.274512 ms, enqueue 0.0953613 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149609 ms - Host latency: 0.191602 ms (end to end 0.274194 ms, enqueue 0.0963867 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149463 ms - Host latency: 0.191113 ms (end to end 0.274585 ms, enqueue 0.0962402 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149707 ms - Host latency: 0.191943 ms (end to end 0.269092 ms, enqueue 0.0789795 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149072 ms - Host latency: 0.191113 ms (end to end 0.270337 ms, enqueue 0.0781738 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148901 ms - Host latency: 0.190747 ms (end to end 0.268945 ms, enqueue 0.0772949 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153369 ms - Host latency: 0.194946 ms (end to end 0.26438 ms, enqueue 0.0946289 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14939 ms - Host latency: 0.191724 ms (end to end 0.271606 ms, enqueue 0.0772461 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149561 ms - Host latency: 0.19165 ms (end to end 0.270728 ms, enqueue 0.0779541 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149463 ms - Host latency: 0.191382 ms (end to end 0.272095 ms, enqueue 0.0765381 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149072 ms - Host latency: 0.190723 ms (end to end 0.270825 ms, enqueue 0.0725586 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149634 ms - Host latency: 0.191479 ms (end to end 0.27207 ms, enqueue 0.0730957 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148706 ms - Host latency: 0.190186 ms (end to end 0.269434 ms, enqueue 0.0720703 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149316 ms - Host latency: 0.190967 ms (end to end 0.270239 ms, enqueue 0.0723389 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148755 ms - Host latency: 0.190454 ms (end to end 0.269702 ms, enqueue 0.0731201 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149146 ms - Host latency: 0.191113 ms (end to end 0.273999 ms, enqueue 0.0720459 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149072 ms - Host latency: 0.190771 ms (end to end 0.273389 ms, enqueue 0.0726563 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149365 ms - Host latency: 0.191113 ms (end to end 0.273608 ms, enqueue 0.0789795 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148975 ms - Host latency: 0.190576 ms (end to end 0.27395 ms, enqueue 0.0776855 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148877 ms - Host latency: 0.190796 ms (end to end 0.272266 ms, enqueue 0.0776611 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149463 ms - Host latency: 0.191602 ms (end to end 0.245898 ms, enqueue 0.104614 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149268 ms - Host latency: 0.191504 ms (end to end 0.264233 ms, enqueue 0.130103 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.18916 ms - Host latency: 0.235303 ms (end to end 0.245923 ms, enqueue 0.218335 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.190283 ms - Host latency: 0.236182 ms (end to end 0.246118 ms, enqueue 0.218872 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.184717 ms - Host latency: 0.230225 ms (end to end 0.241504 ms, enqueue 0.214893 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.185449 ms - Host latency: 0.230737 ms (end to end 0.241235 ms, enqueue 0.215063 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.180322 ms - Host latency: 0.225562 ms (end to end 0.237158 ms, enqueue 0.200488 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.157056 ms - Host latency: 0.200488 ms (end to end 0.212866 ms, enqueue 0.142944 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156079 ms - Host latency: 0.199927 ms (end to end 0.21145 ms, enqueue 0.141675 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15603 ms - Host latency: 0.199756 ms (end to end 0.212085 ms, enqueue 0.14187 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156348 ms - Host latency: 0.199487 ms (end to end 0.212305 ms, enqueue 0.14043 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156299 ms - Host latency: 0.199683 ms (end to end 0.210742 ms, enqueue 0.140796 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15271 ms - Host latency: 0.196191 ms (end to end 0.230762 ms, enqueue 0.122021 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150073 ms - Host latency: 0.192334 ms (end to end 0.275977 ms, enqueue 0.103394 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148193 ms - Host latency: 0.18999 ms (end to end 0.274365 ms, enqueue 0.102881 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148706 ms - Host latency: 0.190381 ms (end to end 0.27688 ms, enqueue 0.103564 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149072 ms - Host latency: 0.190991 ms (end to end 0.27666 ms, enqueue 0.102979 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.19126 ms (end to end 0.276025 ms, enqueue 0.102612 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148608 ms - Host latency: 0.190552 ms (end to end 0.277051 ms, enqueue 0.102124 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149414 ms - Host latency: 0.191138 ms (end to end 0.271484 ms, enqueue 0.0914795 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14895 ms - Host latency: 0.19043 ms (end to end 0.269385 ms, enqueue 0.0820801 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150684 ms - Host latency: 0.192554 ms (end to end 0.27085 ms, enqueue 0.0935303 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.175049 ms - Host latency: 0.220483 ms (end to end 0.229321 ms, enqueue 0.203638 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.173169 ms - Host latency: 0.21814 ms (end to end 0.226831 ms, enqueue 0.20166 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.171362 ms - Host latency: 0.216382 ms (end to end 0.224683 ms, enqueue 0.199341 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.17251 ms - Host latency: 0.217456 ms (end to end 0.226904 ms, enqueue 0.201099 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.171216 ms - Host latency: 0.217065 ms (end to end 0.226514 ms, enqueue 0.199756 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.171826 ms - Host latency: 0.216528 ms (end to end 0.225903 ms, enqueue 0.200757 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.16062 ms - Host latency: 0.204785 ms (end to end 0.214771 ms, enqueue 0.161157 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154492 ms - Host latency: 0.196851 ms (end to end 0.207251 ms, enqueue 0.134326 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155225 ms - Host latency: 0.19707 ms (end to end 0.20647 ms, enqueue 0.134497 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153809 ms - Host latency: 0.196069 ms (end to end 0.208398 ms, enqueue 0.135937 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154468 ms - Host latency: 0.196313 ms (end to end 0.206909 ms, enqueue 0.135034 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155273 ms - Host latency: 0.197241 ms (end to end 0.207764 ms, enqueue 0.134619 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153027 ms - Host latency: 0.195679 ms (end to end 0.209766 ms, enqueue 0.126953 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149243 ms - Host latency: 0.19104 ms (end to end 0.270703 ms, enqueue 0.0954834 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149072 ms - Host latency: 0.191235 ms (end to end 0.269092 ms, enqueue 0.0968994 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149365 ms - Host latency: 0.191333 ms (end to end 0.272656 ms, enqueue 0.0967529 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149292 ms - Host latency: 0.191187 ms (end to end 0.265356 ms, enqueue 0.0983398 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149976 ms - Host latency: 0.191821 ms (end to end 0.265918 ms, enqueue 0.0754883 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150342 ms - Host latency: 0.192114 ms (end to end 0.2625 ms, enqueue 0.0741211 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150195 ms - Host latency: 0.19231 ms (end to end 0.263208 ms, enqueue 0.0804443 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150098 ms - Host latency: 0.19248 ms (end to end 0.265308 ms, enqueue 0.0733398 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150171 ms - Host latency: 0.191943 ms (end to end 0.265845 ms, enqueue 0.075 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149829 ms - Host latency: 0.191016 ms (end to end 0.262378 ms, enqueue 0.0733398 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149731 ms - Host latency: 0.191919 ms (end to end 0.264648 ms, enqueue 0.0729004 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150049 ms - Host latency: 0.191968 ms (end to end 0.265161 ms, enqueue 0.0724609 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149365 ms - Host latency: 0.191284 ms (end to end 0.265723 ms, enqueue 0.072583 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148999 ms - Host latency: 0.190454 ms (end to end 0.266968 ms, enqueue 0.0727295 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149585 ms - Host latency: 0.191089 ms (end to end 0.265332 ms, enqueue 0.0733154 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149512 ms - Host latency: 0.191284 ms (end to end 0.267773 ms, enqueue 0.071875 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14939 ms - Host latency: 0.191406 ms (end to end 0.266992 ms, enqueue 0.072583 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149658 ms - Host latency: 0.191528 ms (end to end 0.268115 ms, enqueue 0.0724609 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.190601 ms (end to end 0.2677 ms, enqueue 0.0727295 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149316 ms - Host latency: 0.191162 ms (end to end 0.268677 ms, enqueue 0.0738037 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14939 ms - Host latency: 0.190991 ms (end to end 0.268506 ms, enqueue 0.0739746 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149414 ms - Host latency: 0.191455 ms (end to end 0.268018 ms, enqueue 0.0740967 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14978 ms - Host latency: 0.191431 ms (end to end 0.266553 ms, enqueue 0.0743897 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149414 ms - Host latency: 0.191357 ms (end to end 0.268384 ms, enqueue 0.0741943 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149561 ms - Host latency: 0.191431 ms (end to end 0.267749 ms, enqueue 0.0742432 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149146 ms - Host latency: 0.190601 ms (end to end 0.267603 ms, enqueue 0.0738281 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149609 ms - Host latency: 0.191797 ms (end to end 0.26958 ms, enqueue 0.0739258 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149414 ms - Host latency: 0.191138 ms (end to end 0.269067 ms, enqueue 0.0738037 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.191113 ms (end to end 0.264502 ms, enqueue 0.0876709 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148657 ms - Host latency: 0.19021 ms (end to end 0.273193 ms, enqueue 0.0924561 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151636 ms - Host latency: 0.194189 ms (end to end 0.221191 ms, enqueue 0.164136 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.147632 ms - Host latency: 0.188452 ms (end to end 0.197925 ms, enqueue 0.174292 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.188232 ms - Host latency: 0.233643 ms (end to end 0.24436 ms, enqueue 0.217749 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.185156 ms - Host latency: 0.230688 ms (end to end 0.241724 ms, enqueue 0.215356 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.185596 ms - Host latency: 0.231104 ms (end to end 0.242212 ms, enqueue 0.215991 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.177393 ms - Host latency: 0.223755 ms (end to end 0.235986 ms, enqueue 0.203931 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154419 ms - Host latency: 0.198608 ms (end to end 0.21123 ms, enqueue 0.142676 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155542 ms - Host latency: 0.199512 ms (end to end 0.21123 ms, enqueue 0.142847 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155713 ms - Host latency: 0.199512 ms (end to end 0.210254 ms, enqueue 0.140137 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156836 ms - Host latency: 0.199146 ms (end to end 0.211401 ms, enqueue 0.141211 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156348 ms - Host latency: 0.198828 ms (end to end 0.209546 ms, enqueue 0.140137 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154956 ms - Host latency: 0.197339 ms (end to end 0.210913 ms, enqueue 0.13208 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149634 ms - Host latency: 0.191382 ms (end to end 0.27356 ms, enqueue 0.0984131 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149463 ms - Host latency: 0.191699 ms (end to end 0.273975 ms, enqueue 0.0977051 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149463 ms - Host latency: 0.191357 ms (end to end 0.274414 ms, enqueue 0.0983398 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149609 ms - Host latency: 0.191943 ms (end to end 0.2729 ms, enqueue 0.098291 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149414 ms - Host latency: 0.191064 ms (end to end 0.27583 ms, enqueue 0.0976318 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14895 ms - Host latency: 0.190454 ms (end to end 0.272729 ms, enqueue 0.0977783 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149878 ms - Host latency: 0.191675 ms (end to end 0.270093 ms, enqueue 0.0914795 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149609 ms - Host latency: 0.191064 ms (end to end 0.263525 ms, enqueue 0.0815186 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15061 ms - Host latency: 0.192896 ms (end to end 0.266089 ms, enqueue 0.0819824 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149951 ms - Host latency: 0.191895 ms (end to end 0.264062 ms, enqueue 0.080127 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148706 ms - Host latency: 0.190112 ms (end to end 0.263477 ms, enqueue 0.0830322 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149658 ms - Host latency: 0.191406 ms (end to end 0.263745 ms, enqueue 0.0760254 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150171 ms - Host latency: 0.191821 ms (end to end 0.263208 ms, enqueue 0.0762695 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150049 ms - Host latency: 0.192285 ms (end to end 0.26499 ms, enqueue 0.0904785 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149048 ms - Host latency: 0.191138 ms (end to end 0.271436 ms, enqueue 0.0964111 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149585 ms - Host latency: 0.191528 ms (end to end 0.272729 ms, enqueue 0.0973389 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149756 ms - Host latency: 0.191357 ms (end to end 0.271509 ms, enqueue 0.0959473 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150146 ms - Host latency: 0.192383 ms (end to end 0.272021 ms, enqueue 0.0956543 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149316 ms - Host latency: 0.191284 ms (end to end 0.27168 ms, enqueue 0.0961182 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148828 ms - Host latency: 0.190869 ms (end to end 0.273706 ms, enqueue 0.0952637 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149487 ms - Host latency: 0.191382 ms (end to end 0.2729 ms, enqueue 0.0849854 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150366 ms - Host latency: 0.192334 ms (end to end 0.271216 ms, enqueue 0.0859863 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149268 ms - Host latency: 0.191235 ms (end to end 0.269605 ms, enqueue 0.0847168 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149634 ms - Host latency: 0.191602 ms (end to end 0.269775 ms, enqueue 0.0855957 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149121 ms - Host latency: 0.190771 ms (end to end 0.268262 ms, enqueue 0.0855957 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149341 ms - Host latency: 0.191211 ms (end to end 0.270044 ms, enqueue 0.0846436 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151392 ms - Host latency: 0.195557 ms (end to end 0.235449 ms, enqueue 0.120532 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149487 ms - Host latency: 0.19165 ms (end to end 0.278589 ms, enqueue 0.109155 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149878 ms - Host latency: 0.191553 ms (end to end 0.272534 ms, enqueue 0.111548 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.190894 ms (end to end 0.275415 ms, enqueue 0.10835 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149634 ms - Host latency: 0.191431 ms (end to end 0.27561 ms, enqueue 0.109082 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.172852 ms - Host latency: 0.21897 ms (end to end 0.267603 ms, enqueue 0.183423 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.184668 ms - Host latency: 0.230078 ms (end to end 0.24165 ms, enqueue 0.215137 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.186426 ms - Host latency: 0.23291 ms (end to end 0.243359 ms, enqueue 0.216992 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.185522 ms - Host latency: 0.230786 ms (end to end 0.241382 ms, enqueue 0.215234 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.188379 ms - Host latency: 0.233838 ms (end to end 0.243408 ms, enqueue 0.21665 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.170972 ms - Host latency: 0.217065 ms (end to end 0.230615 ms, enqueue 0.185034 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153564 ms - Host latency: 0.199683 ms (end to end 0.215015 ms, enqueue 0.148755 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152734 ms - Host latency: 0.201001 ms (end to end 0.215894 ms, enqueue 0.148413 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154126 ms - Host latency: 0.201489 ms (end to end 0.216162 ms, enqueue 0.149341 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153931 ms - Host latency: 0.203149 ms (end to end 0.216699 ms, enqueue 0.14917 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154395 ms - Host latency: 0.200049 ms (end to end 0.215625 ms, enqueue 0.148096 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149414 ms - Host latency: 0.191479 ms (end to end 0.259937 ms, enqueue 0.104419 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149414 ms - Host latency: 0.191138 ms (end to end 0.275024 ms, enqueue 0.104419 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.191064 ms (end to end 0.274927 ms, enqueue 0.104687 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149341 ms - Host latency: 0.191138 ms (end to end 0.270605 ms, enqueue 0.105151 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.190674 ms (end to end 0.272974 ms, enqueue 0.105029 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149414 ms - Host latency: 0.190918 ms (end to end 0.267871 ms, enqueue 0.104956 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149072 ms - Host latency: 0.190942 ms (end to end 0.275049 ms, enqueue 0.100464 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149292 ms - Host latency: 0.190991 ms (end to end 0.270459 ms, enqueue 0.081958 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149146 ms - Host latency: 0.190747 ms (end to end 0.269873 ms, enqueue 0.0822266 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149023 ms - Host latency: 0.190796 ms (end to end 0.270459 ms, enqueue 0.0814209 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148877 ms - Host latency: 0.190308 ms (end to end 0.269214 ms, enqueue 0.0824707 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148975 ms - Host latency: 0.190332 ms (end to end 0.270532 ms, enqueue 0.0817871 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14873 ms - Host latency: 0.190649 ms (end to end 0.269971 ms, enqueue 0.0815674 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.190527 ms (end to end 0.270947 ms, enqueue 0.0782959 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.19043 ms (end to end 0.272266 ms, enqueue 0.0739746 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148975 ms - Host latency: 0.190771 ms (end to end 0.271021 ms, enqueue 0.0746826 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149365 ms - Host latency: 0.19104 ms (end to end 0.272778 ms, enqueue 0.0749268 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149341 ms - Host latency: 0.190894 ms (end to end 0.269897 ms, enqueue 0.0740967 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149414 ms - Host latency: 0.19165 ms (end to end 0.269678 ms, enqueue 0.0747803 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149927 ms - Host latency: 0.192212 ms (end to end 0.271802 ms, enqueue 0.0762207 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14917 ms - Host latency: 0.190674 ms (end to end 0.270142 ms, enqueue 0.072583 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14895 ms - Host latency: 0.190234 ms (end to end 0.27002 ms, enqueue 0.0757568 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14917 ms - Host latency: 0.190796 ms (end to end 0.271167 ms, enqueue 0.0724121 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149316 ms - Host latency: 0.191357 ms (end to end 0.269678 ms, enqueue 0.0731201 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.156714 ms - Host latency: 0.199805 ms (end to end 0.265991 ms, enqueue 0.113525 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.169873 ms - Host latency: 0.214209 ms (end to end 0.222803 ms, enqueue 0.19873 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.173096 ms - Host latency: 0.217578 ms (end to end 0.225537 ms, enqueue 0.201074 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.170654 ms - Host latency: 0.214917 ms (end to end 0.223389 ms, enqueue 0.198193 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.169702 ms - Host latency: 0.213989 ms (end to end 0.222656 ms, enqueue 0.198022 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.171533 ms - Host latency: 0.215918 ms (end to end 0.225439 ms, enqueue 0.199951 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154614 ms - Host latency: 0.198047 ms (end to end 0.207813 ms, enqueue 0.142896 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153711 ms - Host latency: 0.195508 ms (end to end 0.206494 ms, enqueue 0.134375 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153638 ms - Host latency: 0.195312 ms (end to end 0.204736 ms, enqueue 0.13396 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154736 ms - Host latency: 0.196948 ms (end to end 0.206543 ms, enqueue 0.134106 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153613 ms - Host latency: 0.195557 ms (end to end 0.205811 ms, enqueue 0.134155 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154492 ms - Host latency: 0.196313 ms (end to end 0.206494 ms, enqueue 0.134106 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153662 ms - Host latency: 0.196069 ms (end to end 0.221606 ms, enqueue 0.120435 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149121 ms - Host latency: 0.190552 ms (end to end 0.274048 ms, enqueue 0.0947021 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14939 ms - Host latency: 0.191284 ms (end to end 0.27334 ms, enqueue 0.0941895 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148975 ms - Host latency: 0.190674 ms (end to end 0.270361 ms, enqueue 0.0942627 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149243 ms - Host latency: 0.19104 ms (end to end 0.273145 ms, enqueue 0.0947266 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149438 ms - Host latency: 0.191235 ms (end to end 0.268042 ms, enqueue 0.0936768 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149097 ms - Host latency: 0.19043 ms (end to end 0.270996 ms, enqueue 0.0941895 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150073 ms - Host latency: 0.192065 ms (end to end 0.274048 ms, enqueue 0.0906738 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148975 ms - Host latency: 0.190796 ms (end to end 0.27041 ms, enqueue 0.0783447 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148804 ms - Host latency: 0.19021 ms (end to end 0.272314 ms, enqueue 0.0776855 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150024 ms - Host latency: 0.197363 ms (end to end 0.247046 ms, enqueue 0.119702 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154053 ms - Host latency: 0.200708 ms (end to end 0.217017 ms, enqueue 0.14856 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155078 ms - Host latency: 0.201904 ms (end to end 0.217456 ms, enqueue 0.148267 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152271 ms - Host latency: 0.197021 ms (end to end 0.229126 ms, enqueue 0.129688 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148877 ms - Host latency: 0.190332 ms (end to end 0.277905 ms, enqueue 0.108179 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14917 ms - Host latency: 0.191479 ms (end to end 0.276416 ms, enqueue 0.107471 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149072 ms - Host latency: 0.19104 ms (end to end 0.278076 ms, enqueue 0.108447 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149414 ms - Host latency: 0.19104 ms (end to end 0.278076 ms, enqueue 0.107568 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149097 ms - Host latency: 0.190747 ms (end to end 0.277832 ms, enqueue 0.107227 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149316 ms - Host latency: 0.191748 ms (end to end 0.276929 ms, enqueue 0.107129 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148975 ms - Host latency: 0.190356 ms (end to end 0.275635 ms, enqueue 0.0950439 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148804 ms - Host latency: 0.190356 ms (end to end 0.27124 ms, enqueue 0.0891846 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149292 ms - Host latency: 0.190967 ms (end to end 0.271289 ms, enqueue 0.0888672 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149365 ms - Host latency: 0.191016 ms (end to end 0.271289 ms, enqueue 0.0888916 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148779 ms - Host latency: 0.190161 ms (end to end 0.271387 ms, enqueue 0.0899658 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148633 ms - Host latency: 0.189624 ms (end to end 0.270654 ms, enqueue 0.0889648 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149561 ms - Host latency: 0.19126 ms (end to end 0.271973 ms, enqueue 0.0899414 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149438 ms - Host latency: 0.191064 ms (end to end 0.271973 ms, enqueue 0.0893799 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149512 ms - Host latency: 0.190894 ms (end to end 0.271753 ms, enqueue 0.0894043 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148657 ms - Host latency: 0.189868 ms (end to end 0.270947 ms, enqueue 0.0897949 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149243 ms - Host latency: 0.190625 ms (end to end 0.271509 ms, enqueue 0.0893066 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149072 ms - Host latency: 0.190332 ms (end to end 0.270459 ms, enqueue 0.0888916 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148877 ms - Host latency: 0.190039 ms (end to end 0.270557 ms, enqueue 0.0895752 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148755 ms - Host latency: 0.190015 ms (end to end 0.270972 ms, enqueue 0.0892334 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14873 ms - Host latency: 0.190186 ms (end to end 0.270532 ms, enqueue 0.0894775 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148901 ms - Host latency: 0.18999 ms (end to end 0.2698 ms, enqueue 0.0890137 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148779 ms - Host latency: 0.190137 ms (end to end 0.270898 ms, enqueue 0.0888184 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148779 ms - Host latency: 0.191602 ms (end to end 0.270361 ms, enqueue 0.0819824 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148901 ms - Host latency: 0.190723 ms (end to end 0.272681 ms, enqueue 0.0729004 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14895 ms - Host latency: 0.190747 ms (end to end 0.272729 ms, enqueue 0.0731445 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148926 ms - Host latency: 0.190649 ms (end to end 0.271216 ms, enqueue 0.0725586 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148926 ms - Host latency: 0.19043 ms (end to end 0.27207 ms, enqueue 0.0730225 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149365 ms - Host latency: 0.191187 ms (end to end 0.270166 ms, enqueue 0.0728271 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14895 ms - Host latency: 0.190405 ms (end to end 0.270679 ms, enqueue 0.0726807 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149536 ms - Host latency: 0.19104 ms (end to end 0.269727 ms, enqueue 0.0729492 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.175122 ms - Host latency: 0.219897 ms (end to end 0.271606 ms, enqueue 0.138525 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.18623 ms - Host latency: 0.231348 ms (end to end 0.242065 ms, enqueue 0.21626 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.183057 ms - Host latency: 0.228125 ms (end to end 0.239453 ms, enqueue 0.213843 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.184448 ms - Host latency: 0.229346 ms (end to end 0.240039 ms, enqueue 0.214526 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.18457 ms - Host latency: 0.229785 ms (end to end 0.240283 ms, enqueue 0.214526 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.173682 ms - Host latency: 0.218408 ms (end to end 0.230981 ms, enqueue 0.191138 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154199 ms - Host latency: 0.200317 ms (end to end 0.215747 ms, enqueue 0.147656 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15481 ms - Host latency: 0.201245 ms (end to end 0.215967 ms, enqueue 0.146582 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155347 ms - Host latency: 0.201514 ms (end to end 0.216626 ms, enqueue 0.146997 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.155078 ms - Host latency: 0.201782 ms (end to end 0.215918 ms, enqueue 0.147192 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154907 ms - Host latency: 0.200928 ms (end to end 0.216895 ms, enqueue 0.147339 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149756 ms - Host latency: 0.192896 ms (end to end 0.253564 ms, enqueue 0.109644 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148682 ms - Host latency: 0.190308 ms (end to end 0.275342 ms, enqueue 0.104565 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149634 ms - Host latency: 0.191699 ms (end to end 0.277979 ms, enqueue 0.104541 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.183154 ms - Host latency: 0.228516 ms (end to end 0.262378 ms, enqueue 0.201416 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.191016 ms - Host latency: 0.236914 ms (end to end 0.24502 ms, enqueue 0.217065 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.171094 ms - Host latency: 0.21582 ms (end to end 0.223828 ms, enqueue 0.198901 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.168506 ms - Host latency: 0.213428 ms (end to end 0.222461 ms, enqueue 0.196802 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.169458 ms - Host latency: 0.213965 ms (end to end 0.221655 ms, enqueue 0.197266 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.168091 ms - Host latency: 0.212305 ms (end to end 0.220532 ms, enqueue 0.196436 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.161084 ms - Host latency: 0.205688 ms (end to end 0.213843 ms, enqueue 0.162988 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153809 ms - Host latency: 0.196851 ms (end to end 0.207397 ms, enqueue 0.140674 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153076 ms - Host latency: 0.19519 ms (end to end 0.205981 ms, enqueue 0.132935 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152515 ms - Host latency: 0.194165 ms (end to end 0.205591 ms, enqueue 0.133594 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151489 ms - Host latency: 0.193042 ms (end to end 0.202417 ms, enqueue 0.132617 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152686 ms - Host latency: 0.194678 ms (end to end 0.205591 ms, enqueue 0.133838 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151099 ms - Host latency: 0.192871 ms (end to end 0.229004 ms, enqueue 0.114453 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148853 ms - Host latency: 0.190845 ms (end to end 0.271167 ms, enqueue 0.0955078 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149927 ms - Host latency: 0.192065 ms (end to end 0.262085 ms, enqueue 0.0977783 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148975 ms - Host latency: 0.190405 ms (end to end 0.274243 ms, enqueue 0.0952637 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149487 ms - Host latency: 0.191553 ms (end to end 0.274268 ms, enqueue 0.0965088 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149097 ms - Host latency: 0.190674 ms (end to end 0.268188 ms, enqueue 0.0965332 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14939 ms - Host latency: 0.191187 ms (end to end 0.273511 ms, enqueue 0.0959961 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149023 ms - Host latency: 0.190796 ms (end to end 0.270605 ms, enqueue 0.0904297 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149292 ms - Host latency: 0.191528 ms (end to end 0.269702 ms, enqueue 0.0846924 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14939 ms - Host latency: 0.191479 ms (end to end 0.267969 ms, enqueue 0.0848145 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149023 ms - Host latency: 0.190234 ms (end to end 0.269653 ms, enqueue 0.086084 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.19104 ms (end to end 0.26748 ms, enqueue 0.0849609 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.165869 ms - Host latency: 0.209985 ms (end to end 0.275122 ms, enqueue 0.120996 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.193262 ms - Host latency: 0.238916 ms (end to end 0.250122 ms, enqueue 0.222314 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.188916 ms - Host latency: 0.234668 ms (end to end 0.24563 ms, enqueue 0.219141 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.186572 ms - Host latency: 0.233276 ms (end to end 0.244702 ms, enqueue 0.216235 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.207764 ms - Host latency: 0.255957 ms (end to end 0.264502 ms, enqueue 0.23252 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.158228 ms - Host latency: 0.209277 ms (end to end 0.221021 ms, enqueue 0.171118 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148926 ms - Host latency: 0.203345 ms (end to end 0.21521 ms, enqueue 0.155273 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148145 ms - Host latency: 0.201392 ms (end to end 0.212183 ms, enqueue 0.156641 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.203882 ms (end to end 0.215234 ms, enqueue 0.155127 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149121 ms - Host latency: 0.205054 ms (end to end 0.215356 ms, enqueue 0.155835 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149438 ms - Host latency: 0.196265 ms (end to end 0.227344 ms, enqueue 0.129883 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14895 ms - Host latency: 0.191113 ms (end to end 0.276929 ms, enqueue 0.110889 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149146 ms - Host latency: 0.191211 ms (end to end 0.277466 ms, enqueue 0.110352 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14917 ms - Host latency: 0.191089 ms (end to end 0.277441 ms, enqueue 0.109155 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14917 ms - Host latency: 0.191064 ms (end to end 0.277002 ms, enqueue 0.110059 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14917 ms - Host latency: 0.190894 ms (end to end 0.275708 ms, enqueue 0.109302 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148804 ms - Host latency: 0.19082 ms (end to end 0.275513 ms, enqueue 0.109253 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14939 ms - Host latency: 0.19126 ms (end to end 0.27395 ms, enqueue 0.090332 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149634 ms - Host latency: 0.191772 ms (end to end 0.270361 ms, enqueue 0.0833984 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149536 ms - Host latency: 0.191406 ms (end to end 0.269165 ms, enqueue 0.084668 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.199414 ms - Host latency: 0.247021 ms (end to end 0.259277 ms, enqueue 0.229395 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.184888 ms - Host latency: 0.230103 ms (end to end 0.241089 ms, enqueue 0.214624 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.170679 ms - Host latency: 0.21499 ms (end to end 0.225049 ms, enqueue 0.199561 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.170581 ms - Host latency: 0.215332 ms (end to end 0.223828 ms, enqueue 0.198706 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.174731 ms - Host latency: 0.219751 ms (end to end 0.229102 ms, enqueue 0.202734 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.170361 ms - Host latency: 0.215039 ms (end to end 0.224048 ms, enqueue 0.19856 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.17085 ms - Host latency: 0.215601 ms (end to end 0.226587 ms, enqueue 0.162085 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15166 ms - Host latency: 0.193213 ms (end to end 0.205176 ms, enqueue 0.132837 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153491 ms - Host latency: 0.195654 ms (end to end 0.20647 ms, enqueue 0.135059 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154736 ms - Host latency: 0.197119 ms (end to end 0.206299 ms, enqueue 0.134009 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154443 ms - Host latency: 0.195898 ms (end to end 0.206079 ms, enqueue 0.133716 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153662 ms - Host latency: 0.195459 ms (end to end 0.206738 ms, enqueue 0.134497 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152856 ms - Host latency: 0.194531 ms (end to end 0.209106 ms, enqueue 0.135254 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150439 ms - Host latency: 0.192749 ms (end to end 0.255835 ms, enqueue 0.0978272 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150488 ms - Host latency: 0.193359 ms (end to end 0.272314 ms, enqueue 0.0942383 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149487 ms - Host latency: 0.191675 ms (end to end 0.270044 ms, enqueue 0.0944336 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149561 ms - Host latency: 0.191333 ms (end to end 0.272266 ms, enqueue 0.0952637 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149756 ms - Host latency: 0.191577 ms (end to end 0.270264 ms, enqueue 0.0945557 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15022 ms - Host latency: 0.192065 ms (end to end 0.275366 ms, enqueue 0.094043 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149707 ms - Host latency: 0.192041 ms (end to end 0.270093 ms, enqueue 0.0887695 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14939 ms - Host latency: 0.191602 ms (end to end 0.265308 ms, enqueue 0.0760254 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149731 ms - Host latency: 0.193213 ms (end to end 0.259912 ms, enqueue 0.0910889 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149414 ms - Host latency: 0.19104 ms (end to end 0.231323 ms, enqueue 0.121045 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149072 ms - Host latency: 0.190796 ms (end to end 0.277051 ms, enqueue 0.121313 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14917 ms - Host latency: 0.191309 ms (end to end 0.270386 ms, enqueue 0.124658 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148779 ms - Host latency: 0.190503 ms (end to end 0.279199 ms, enqueue 0.120166 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149365 ms - Host latency: 0.191187 ms (end to end 0.272241 ms, enqueue 0.125073 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148999 ms - Host latency: 0.190503 ms (end to end 0.248193 ms, enqueue 0.127368 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150146 ms - Host latency: 0.191577 ms (end to end 0.237842 ms, enqueue 0.126978 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150098 ms - Host latency: 0.191333 ms (end to end 0.229517 ms, enqueue 0.127295 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149268 ms - Host latency: 0.190698 ms (end to end 0.219434 ms, enqueue 0.12666 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149023 ms - Host latency: 0.190186 ms (end to end 0.205688 ms, enqueue 0.126294 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150098 ms - Host latency: 0.191528 ms (end to end 0.204639 ms, enqueue 0.126758 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148413 ms - Host latency: 0.189966 ms (end to end 0.255371 ms, enqueue 0.0963623 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149097 ms - Host latency: 0.191309 ms (end to end 0.26897 ms, enqueue 0.092334 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149731 ms - Host latency: 0.191821 ms (end to end 0.269824 ms, enqueue 0.0924561 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149048 ms - Host latency: 0.190649 ms (end to end 0.268921 ms, enqueue 0.0927734 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150098 ms - Host latency: 0.195605 ms (end to end 0.256714 ms, enqueue 0.123975 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153857 ms - Host latency: 0.203442 ms (end to end 0.217749 ms, enqueue 0.153027 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.163354 ms - Host latency: 0.206177 ms (end to end 0.21582 ms, enqueue 0.184497 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.161426 ms - Host latency: 0.202148 ms (end to end 0.212183 ms, enqueue 0.188794 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.164062 ms - Host latency: 0.205591 ms (end to end 0.214307 ms, enqueue 0.191211 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.160742 ms - Host latency: 0.201953 ms (end to end 0.212451 ms, enqueue 0.189307 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.159009 ms - Host latency: 0.201392 ms (end to end 0.212988 ms, enqueue 0.170825 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152881 ms - Host latency: 0.194946 ms (end to end 0.202612 ms, enqueue 0.135156 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153491 ms - Host latency: 0.195215 ms (end to end 0.205249 ms, enqueue 0.136377 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152417 ms - Host latency: 0.194092 ms (end to end 0.205518 ms, enqueue 0.134082 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.152637 ms - Host latency: 0.19436 ms (end to end 0.203247 ms, enqueue 0.134399 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.153149 ms - Host latency: 0.194971 ms (end to end 0.206592 ms, enqueue 0.135107 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.151978 ms - Host latency: 0.193945 ms (end to end 0.206323 ms, enqueue 0.127441 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148486 ms - Host latency: 0.190088 ms (end to end 0.273022 ms, enqueue 0.0950195 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149268 ms - Host latency: 0.191113 ms (end to end 0.268164 ms, enqueue 0.0940186 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.190796 ms (end to end 0.269727 ms, enqueue 0.0929443 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148804 ms - Host latency: 0.190552 ms (end to end 0.269653 ms, enqueue 0.0939941 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.191504 ms (end to end 0.270361 ms, enqueue 0.0929443 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149146 ms - Host latency: 0.190845 ms (end to end 0.270483 ms, enqueue 0.0938965 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148877 ms - Host latency: 0.190576 ms (end to end 0.271191 ms, enqueue 0.0932129 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149048 ms - Host latency: 0.190527 ms (end to end 0.273804 ms, enqueue 0.0818848 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148584 ms - Host latency: 0.190454 ms (end to end 0.274854 ms, enqueue 0.0780273 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148877 ms - Host latency: 0.190674 ms (end to end 0.274731 ms, enqueue 0.0780029 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148364 ms - Host latency: 0.189722 ms (end to end 0.274658 ms, enqueue 0.0785156 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14856 ms - Host latency: 0.190601 ms (end to end 0.275537 ms, enqueue 0.0796143 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148804 ms - Host latency: 0.190332 ms (end to end 0.275073 ms, enqueue 0.0782227 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14873 ms - Host latency: 0.19021 ms (end to end 0.275195 ms, enqueue 0.0793457 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148267 ms - Host latency: 0.189893 ms (end to end 0.273999 ms, enqueue 0.0780762 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148389 ms - Host latency: 0.189697 ms (end to end 0.275171 ms, enqueue 0.0778076 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14873 ms - Host latency: 0.190503 ms (end to end 0.274634 ms, enqueue 0.0782471 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148584 ms - Host latency: 0.190137 ms (end to end 0.274438 ms, enqueue 0.0781738 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148315 ms - Host latency: 0.189819 ms (end to end 0.274536 ms, enqueue 0.0781006 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148364 ms - Host latency: 0.189795 ms (end to end 0.275415 ms, enqueue 0.0784912 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148291 ms - Host latency: 0.189868 ms (end to end 0.274683 ms, enqueue 0.0779297 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148413 ms - Host latency: 0.190088 ms (end to end 0.274902 ms, enqueue 0.0779053 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148633 ms - Host latency: 0.190161 ms (end to end 0.276099 ms, enqueue 0.0776367 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14834 ms - Host latency: 0.190186 ms (end to end 0.275122 ms, enqueue 0.078125 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148413 ms - Host latency: 0.190308 ms (end to end 0.275293 ms, enqueue 0.0788574 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148193 ms - Host latency: 0.189307 ms (end to end 0.274292 ms, enqueue 0.0774414 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148364 ms - Host latency: 0.190088 ms (end to end 0.275269 ms, enqueue 0.0781494 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148511 ms - Host latency: 0.190283 ms (end to end 0.274243 ms, enqueue 0.0782471 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148462 ms - Host latency: 0.190015 ms (end to end 0.275122 ms, enqueue 0.0779541 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148486 ms - Host latency: 0.190234 ms (end to end 0.275049 ms, enqueue 0.0778564 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148022 ms - Host latency: 0.189185 ms (end to end 0.276001 ms, enqueue 0.077832 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148096 ms - Host latency: 0.189746 ms (end to end 0.274927 ms, enqueue 0.0774414 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148535 ms - Host latency: 0.189868 ms (end to end 0.275757 ms, enqueue 0.0787109 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148267 ms - Host latency: 0.189673 ms (end to end 0.275024 ms, enqueue 0.0783936 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148584 ms - Host latency: 0.190137 ms (end to end 0.276074 ms, enqueue 0.0780762 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148193 ms - Host latency: 0.189551 ms (end to end 0.275415 ms, enqueue 0.0784424 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148633 ms - Host latency: 0.190356 ms (end to end 0.274756 ms, enqueue 0.0791748 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148413 ms - Host latency: 0.189844 ms (end to end 0.275586 ms, enqueue 0.0794678 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148486 ms - Host latency: 0.190088 ms (end to end 0.275806 ms, enqueue 0.0786133 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148364 ms - Host latency: 0.189844 ms (end to end 0.275854 ms, enqueue 0.0781494 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148364 ms - Host latency: 0.189575 ms (end to end 0.274902 ms, enqueue 0.0780029 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148438 ms - Host latency: 0.18999 ms (end to end 0.274463 ms, enqueue 0.0786377 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148218 ms - Host latency: 0.189307 ms (end to end 0.275732 ms, enqueue 0.0780273 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148535 ms - Host latency: 0.190283 ms (end to end 0.273462 ms, enqueue 0.078833 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149243 ms - Host latency: 0.19104 ms (end to end 0.274927 ms, enqueue 0.0784912 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148706 ms - Host latency: 0.190186 ms (end to end 0.274097 ms, enqueue 0.078833 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148511 ms - Host latency: 0.190283 ms (end to end 0.273975 ms, enqueue 0.078125 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148413 ms - Host latency: 0.190015 ms (end to end 0.274634 ms, enqueue 0.0779541 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.182251 ms - Host latency: 0.227515 ms (end to end 0.278394 ms, enqueue 0.162817 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.192773 ms - Host latency: 0.238672 ms (end to end 0.248853 ms, enqueue 0.221631 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.193091 ms - Host latency: 0.239307 ms (end to end 0.24895 ms, enqueue 0.220654 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.172754 ms - Host latency: 0.218433 ms (end to end 0.22915 ms, enqueue 0.196289 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14834 ms - Host latency: 0.192896 ms (end to end 0.20293 ms, enqueue 0.166895 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148218 ms - Host latency: 0.192822 ms (end to end 0.202466 ms, enqueue 0.166333 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148584 ms - Host latency: 0.193091 ms (end to end 0.202856 ms, enqueue 0.167896 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148071 ms - Host latency: 0.193237 ms (end to end 0.20376 ms, enqueue 0.168433 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148267 ms - Host latency: 0.194849 ms (end to end 0.216626 ms, enqueue 0.14104 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148779 ms - Host latency: 0.190698 ms (end to end 0.269238 ms, enqueue 0.120435 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149365 ms - Host latency: 0.191626 ms (end to end 0.271338 ms, enqueue 0.118848 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148486 ms - Host latency: 0.190186 ms (end to end 0.275391 ms, enqueue 0.116602 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149268 ms - Host latency: 0.191821 ms (end to end 0.279321 ms, enqueue 0.119116 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14873 ms - Host latency: 0.190552 ms (end to end 0.280005 ms, enqueue 0.118579 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148682 ms - Host latency: 0.190527 ms (end to end 0.274902 ms, enqueue 0.118115 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150366 ms - Host latency: 0.19231 ms (end to end 0.273389 ms, enqueue 0.101367 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150195 ms - Host latency: 0.192188 ms (end to end 0.269019 ms, enqueue 0.0864746 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.150122 ms - Host latency: 0.192065 ms (end to end 0.265771 ms, enqueue 0.0871826 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.15022 ms - Host latency: 0.191943 ms (end to end 0.265845 ms, enqueue 0.088501 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149683 ms - Host latency: 0.19104 ms (end to end 0.264966 ms, enqueue 0.0874023 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149292 ms - Host latency: 0.190991 ms (end to end 0.271289 ms, enqueue 0.0898926 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148999 ms - Host latency: 0.190649 ms (end to end 0.268896 ms, enqueue 0.0850586 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149951 ms - Host latency: 0.192944 ms (end to end 0.274512 ms, enqueue 0.0912842 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.172461 ms - Host latency: 0.21748 ms (end to end 0.226172 ms, enqueue 0.200708 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.17478 ms - Host latency: 0.220166 ms (end to end 0.228931 ms, enqueue 0.203687 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.169165 ms - Host latency: 0.213672 ms (end to end 0.222241 ms, enqueue 0.197681 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.154712 ms - Host latency: 0.20083 ms (end to end 0.210913 ms, enqueue 0.176343 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.147095 ms - Host latency: 0.193164 ms (end to end 0.203369 ms, enqueue 0.16333 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.146924 ms - Host latency: 0.191992 ms (end to end 0.201392 ms, enqueue 0.164233 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.146924 ms - Host latency: 0.190894 ms (end to end 0.20127 ms, enqueue 0.163672 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.146997 ms - Host latency: 0.192065 ms (end to end 0.201538 ms, enqueue 0.163745 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148853 ms - Host latency: 0.190161 ms (end to end 0.211108 ms, enqueue 0.139014 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149561 ms - Host latency: 0.192212 ms (end to end 0.27998 ms, enqueue 0.116992 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14939 ms - Host latency: 0.192383 ms (end to end 0.280933 ms, enqueue 0.119092 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.191553 ms (end to end 0.281372 ms, enqueue 0.116772 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149121 ms - Host latency: 0.191309 ms (end to end 0.280737 ms, enqueue 0.117188 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14939 ms - Host latency: 0.19165 ms (end to end 0.277734 ms, enqueue 0.117212 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148267 ms - Host latency: 0.189966 ms (end to end 0.282129 ms, enqueue 0.118481 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149048 ms - Host latency: 0.190845 ms (end to end 0.269238 ms, enqueue 0.0878174 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149512 ms - Host latency: 0.191284 ms (end to end 0.270776 ms, enqueue 0.0891113 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149438 ms - Host latency: 0.191479 ms (end to end 0.269238 ms, enqueue 0.088501 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14917 ms - Host latency: 0.19082 ms (end to end 0.26814 ms, enqueue 0.0878906 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149316 ms - Host latency: 0.190771 ms (end to end 0.268726 ms, enqueue 0.0887695 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149268 ms - Host latency: 0.19082 ms (end to end 0.269238 ms, enqueue 0.0884033 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14856 ms - Host latency: 0.189771 ms (end to end 0.270386 ms, enqueue 0.0854004 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14873 ms - Host latency: 0.190234 ms (end to end 0.272485 ms, enqueue 0.0756104 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148267 ms - Host latency: 0.18938 ms (end to end 0.272363 ms, enqueue 0.075415 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148901 ms - Host latency: 0.19043 ms (end to end 0.271509 ms, enqueue 0.076123 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149072 ms - Host latency: 0.190967 ms (end to end 0.272925 ms, enqueue 0.0756348 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148535 ms - Host latency: 0.190234 ms (end to end 0.274902 ms, enqueue 0.0751953 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148633 ms - Host latency: 0.190234 ms (end to end 0.274902 ms, enqueue 0.0752197 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149414 ms - Host latency: 0.190894 ms (end to end 0.270386 ms, enqueue 0.0746338 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14917 ms - Host latency: 0.190454 ms (end to end 0.27019 ms, enqueue 0.0734619 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149097 ms - Host latency: 0.190527 ms (end to end 0.268091 ms, enqueue 0.0740967 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148828 ms - Host latency: 0.190527 ms (end to end 0.270117 ms, enqueue 0.0730713 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149268 ms - Host latency: 0.191016 ms (end to end 0.270825 ms, enqueue 0.0725342 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148999 ms - Host latency: 0.190479 ms (end to end 0.270361 ms, enqueue 0.0731445 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149268 ms - Host latency: 0.19104 ms (end to end 0.270654 ms, enqueue 0.0730957 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148779 ms - Host latency: 0.190259 ms (end to end 0.271313 ms, enqueue 0.0731934 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14939 ms - Host latency: 0.191235 ms (end to end 0.270728 ms, enqueue 0.0733154 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149585 ms - Host latency: 0.191235 ms (end to end 0.271313 ms, enqueue 0.0743164 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14895 ms - Host latency: 0.190869 ms (end to end 0.260547 ms, enqueue 0.0841064 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148853 ms - Host latency: 0.190381 ms (end to end 0.271875 ms, enqueue 0.0899658 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149048 ms - Host latency: 0.190747 ms (end to end 0.272314 ms, enqueue 0.0892822 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148901 ms - Host latency: 0.190674 ms (end to end 0.271924 ms, enqueue 0.0905029 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148706 ms - Host latency: 0.189673 ms (end to end 0.270386 ms, enqueue 0.0892822 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149097 ms - Host latency: 0.190234 ms (end to end 0.271606 ms, enqueue 0.0897949 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148608 ms - Host latency: 0.189795 ms (end to end 0.270386 ms, enqueue 0.0897461 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148657 ms - Host latency: 0.190088 ms (end to end 0.271826 ms, enqueue 0.0900391 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.190649 ms (end to end 0.272046 ms, enqueue 0.0904785 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148926 ms - Host latency: 0.190039 ms (end to end 0.271777 ms, enqueue 0.0900391 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149048 ms - Host latency: 0.190259 ms (end to end 0.271729 ms, enqueue 0.0904053 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149146 ms - Host latency: 0.190796 ms (end to end 0.271094 ms, enqueue 0.0902588 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149292 ms - Host latency: 0.190942 ms (end to end 0.272095 ms, enqueue 0.0899902 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148901 ms - Host latency: 0.190039 ms (end to end 0.27146 ms, enqueue 0.0906006 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14895 ms - Host latency: 0.190381 ms (end to end 0.261768 ms, enqueue 0.0902588 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148828 ms - Host latency: 0.190308 ms (end to end 0.272168 ms, enqueue 0.0900879 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149121 ms - Host latency: 0.190625 ms (end to end 0.271338 ms, enqueue 0.0898682 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148755 ms - Host latency: 0.190039 ms (end to end 0.271118 ms, enqueue 0.0895996 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148853 ms - Host latency: 0.190308 ms (end to end 0.271167 ms, enqueue 0.0902344 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.19104 ms (end to end 0.271387 ms, enqueue 0.0894775 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148682 ms - Host latency: 0.190283 ms (end to end 0.271265 ms, enqueue 0.0894775 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148804 ms - Host latency: 0.190381 ms (end to end 0.270972 ms, enqueue 0.0894287 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148853 ms - Host latency: 0.190405 ms (end to end 0.272168 ms, enqueue 0.0904053 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148633 ms - Host latency: 0.189648 ms (end to end 0.268335 ms, enqueue 0.0890869 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149268 ms - Host latency: 0.19082 ms (end to end 0.274634 ms, enqueue 0.0815674 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148657 ms - Host latency: 0.190381 ms (end to end 0.27334 ms, enqueue 0.0728027 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148975 ms - Host latency: 0.190479 ms (end to end 0.272974 ms, enqueue 0.0734375 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148877 ms - Host latency: 0.190601 ms (end to end 0.270996 ms, enqueue 0.0730469 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.190576 ms (end to end 0.272949 ms, enqueue 0.0727783 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148633 ms - Host latency: 0.190063 ms (end to end 0.269995 ms, enqueue 0.072876 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149023 ms - Host latency: 0.190479 ms (end to end 0.268408 ms, enqueue 0.0757324 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149194 ms - Host latency: 0.190942 ms (end to end 0.270825 ms, enqueue 0.0810791 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149243 ms - Host latency: 0.190845 ms (end to end 0.270728 ms, enqueue 0.0816895 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149341 ms - Host latency: 0.19104 ms (end to end 0.270703 ms, enqueue 0.0808594 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148633 ms - Host latency: 0.189868 ms (end to end 0.270215 ms, enqueue 0.0811279 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149072 ms - Host latency: 0.19043 ms (end to end 0.271948 ms, enqueue 0.080835 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148975 ms - Host latency: 0.190454 ms (end to end 0.270996 ms, enqueue 0.0804443 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149341 ms - Host latency: 0.191162 ms (end to end 0.270801 ms, enqueue 0.0782715 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14895 ms - Host latency: 0.190942 ms (end to end 0.27168 ms, enqueue 0.0781494 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149731 ms - Host latency: 0.191846 ms (end to end 0.271948 ms, enqueue 0.078125 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149268 ms - Host latency: 0.191089 ms (end to end 0.271948 ms, enqueue 0.0786133 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.191504 ms (end to end 0.271045 ms, enqueue 0.0777344 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148901 ms - Host latency: 0.190747 ms (end to end 0.269141 ms, enqueue 0.0773682 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149316 ms - Host latency: 0.191333 ms (end to end 0.27168 ms, enqueue 0.0783203 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148926 ms - Host latency: 0.190332 ms (end to end 0.272119 ms, enqueue 0.0745605 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148682 ms - Host latency: 0.190015 ms (end to end 0.271948 ms, enqueue 0.0757812 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149072 ms - Host latency: 0.190674 ms (end to end 0.271704 ms, enqueue 0.0739258 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148755 ms - Host latency: 0.190186 ms (end to end 0.272192 ms, enqueue 0.0748535 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148828 ms - Host latency: 0.19021 ms (end to end 0.271582 ms, enqueue 0.0747314 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148828 ms - Host latency: 0.190356 ms (end to end 0.270166 ms, enqueue 0.074585 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149146 ms - Host latency: 0.190796 ms (end to end 0.271582 ms, enqueue 0.0757812 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14917 ms - Host latency: 0.191309 ms (end to end 0.272974 ms, enqueue 0.0724609 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14895 ms - Host latency: 0.190576 ms (end to end 0.27146 ms, enqueue 0.0734375 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149072 ms - Host latency: 0.190552 ms (end to end 0.272925 ms, enqueue 0.0723145 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149121 ms - Host latency: 0.190674 ms (end to end 0.271118 ms, enqueue 0.073291 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149731 ms - Host latency: 0.19209 ms (end to end 0.272559 ms, enqueue 0.0729004 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149292 ms - Host latency: 0.190747 ms (end to end 0.273022 ms, enqueue 0.0727295 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148975 ms - Host latency: 0.190649 ms (end to end 0.270483 ms, enqueue 0.072583 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149146 ms - Host latency: 0.190503 ms (end to end 0.272632 ms, enqueue 0.0730469 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149023 ms - Host latency: 0.190649 ms (end to end 0.269751 ms, enqueue 0.0722412 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149341 ms - Host latency: 0.190894 ms (end to end 0.271436 ms, enqueue 0.0724365 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148828 ms - Host latency: 0.190625 ms (end to end 0.271436 ms, enqueue 0.0727539 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149316 ms - Host latency: 0.190967 ms (end to end 0.271729 ms, enqueue 0.0721924 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148926 ms - Host latency: 0.190479 ms (end to end 0.271094 ms, enqueue 0.0734375 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148486 ms - Host latency: 0.189819 ms (end to end 0.270996 ms, enqueue 0.0743164 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148999 ms - Host latency: 0.190308 ms (end to end 0.272559 ms, enqueue 0.0743652 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148975 ms - Host latency: 0.190527 ms (end to end 0.271655 ms, enqueue 0.0747803 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149219 ms - Host latency: 0.190625 ms (end to end 0.272217 ms, enqueue 0.0742432 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148755 ms - Host latency: 0.189893 ms (end to end 0.270532 ms, enqueue 0.0743408 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149023 ms - Host latency: 0.190381 ms (end to end 0.265137 ms, enqueue 0.0934814 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.14895 ms - Host latency: 0.190503 ms (end to end 0.271973 ms, enqueue 0.0895752 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148267 ms - Host latency: 0.189551 ms (end to end 0.26377 ms, enqueue 0.0920654 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148901 ms - Host latency: 0.190137 ms (end to end 0.267114 ms, enqueue 0.0906494 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148584 ms - Host latency: 0.190259 ms (end to end 0.271216 ms, enqueue 0.0905029 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148901 ms - Host latency: 0.19082 ms (end to end 0.275952 ms, enqueue 0.0894775 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.149072 ms - Host latency: 0.190991 ms (end to end 0.27627 ms, enqueue 0.0900147 ms)
[12/29/2021-03:40:37] [I] Average on 10 runs - GPU latency: 0.148315 ms - Host latency: 0.190137 ms (end to end 0.27373 ms, enqueue 0.0894531 ms)
[12/29/2021-03:40:37] [I] 
[12/29/2021-03:40:37] [I] === Performance summary ===
[12/29/2021-03:40:37] [I] Throughput: 6022.82 qps
[12/29/2021-03:40:37] [I] Latency: min = 0.186035 ms, max = 0.417908 ms, mean = 0.195768 ms, median = 0.191406 ms, percentile(99%) = 0.24707 ms
[12/29/2021-03:40:37] [I] End-to-End Host Latency: min = 0.19165 ms, max = 0.436401 ms, mean = 0.25681 ms, median = 0.267822 ms, percentile(99%) = 0.291016 ms
[12/29/2021-03:40:37] [I] Enqueue Time: min = 0.0700684 ms, max = 0.383667 ms, mean = 0.107998 ms, median = 0.0893555 ms, percentile(99%) = 0.22644 ms
[12/29/2021-03:40:37] [I] H2D Latency: min = 0.0360107 ms, max = 0.0658264 ms, mean = 0.0376347 ms, median = 0.0375977 ms, percentile(99%) = 0.0397949 ms
[12/29/2021-03:40:37] [I] GPU Compute Time: min = 0.146118 ms, max = 0.358582 ms, mean = 0.15315 ms, median = 0.149475 ms, percentile(99%) = 0.199554 ms
[12/29/2021-03:40:37] [I] D2H Latency: min = 0.00268555 ms, max = 0.0484619 ms, mean = 0.00498258 ms, median = 0.00415039 ms, percentile(99%) = 0.0166626 ms
[12/29/2021-03:40:37] [I] Total Host Walltime: 3.00025 s
[12/29/2021-03:40:37] [I] Total GPU Compute Time: 2.76742 s
[12/29/2021-03:40:37] [I] Explanations of the performance metrics are printed in the verbose logs.
[12/29/2021-03:40:37] [V] 
[12/29/2021-03:40:37] [V] === Explanations of the performance metrics ===
[12/29/2021-03:40:37] [V] Total Host Walltime: the host walltime from when the first query (after warmups) is enqueued to when the last query is completed.
[12/29/2021-03:40:37] [V] GPU Compute Time: the GPU latency to execute the kernels for a query.
[12/29/2021-03:40:37] [V] Total GPU Compute Time: the summation of the GPU Compute Time of all the queries. If this is significantly shorter than Total Host Walltime, the GPU may be under-utilized because of host-side overheads or data transfers.
[12/29/2021-03:40:37] [V] Throughput: the observed throughput computed by dividing the number of queries by the Total Host Walltime. If this is significantly lower than the reciprocal of GPU Compute Time, the GPU may be under-utilized because of host-side overheads or data transfers.
[12/29/2021-03:40:37] [V] Enqueue Time: the host latency to enqueue a query. If this is longer than GPU Compute Time, the GPU may be under-utilized.
[12/29/2021-03:40:37] [V] H2D Latency: the latency for host-to-device data transfers for input tensors of a single query.
[12/29/2021-03:40:37] [V] D2H Latency: the latency for device-to-host data transfers for output tensors of a single query.
[12/29/2021-03:40:37] [V] Latency: the summation of H2D Latency, GPU Compute Time, and D2H Latency. This is the latency to infer a single query.
[12/29/2021-03:40:37] [V] End-to-End Host Latency: the duration from when the H2D of a query is called to when the D2H of the same query is completed, which includes the latency to wait for the completion of the previous query. This is the latency of a query if multiple queries are enqueued consecutively.
[12/29/2021-03:40:37] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8001] # trtexec --onnx=default_model.onnx --saveEngine=tmp.trt --verbose --int8
[12/29/2021-03:40:37] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 2053, GPU 4008 (MiB)
