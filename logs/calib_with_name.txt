&&&& RUNNING TensorRT.trtexec [TensorRT v8001] # trtexec --onnx=default_model.onnx --saveEngine=tmp.trt --verbose --calib=model.calib --int8
[12/29/2021-03:46:41] [I] === Model Options ===
[12/29/2021-03:46:41] [I] Format: ONNX
[12/29/2021-03:46:41] [I] Model: default_model.onnx
[12/29/2021-03:46:41] [I] Output:
[12/29/2021-03:46:41] [I] === Build Options ===
[12/29/2021-03:46:41] [I] Max batch: explicit
[12/29/2021-03:46:41] [I] Workspace: 16 MiB
[12/29/2021-03:46:41] [I] minTiming: 1
[12/29/2021-03:46:41] [I] avgTiming: 8
[12/29/2021-03:46:41] [I] Precision: FP32+INT8
[12/29/2021-03:46:41] [I] Calibration: model.calib
[12/29/2021-03:46:41] [I] Refit: Disabled
[12/29/2021-03:46:41] [I] Sparsity: Disabled
[12/29/2021-03:46:41] [I] Safe mode: Disabled
[12/29/2021-03:46:41] [I] Restricted mode: Disabled
[12/29/2021-03:46:41] [I] Save engine: tmp.trt
[12/29/2021-03:46:41] [I] Load engine: 
[12/29/2021-03:46:41] [I] NVTX verbosity: 0
[12/29/2021-03:46:41] [I] Tactic sources: Using default tactic sources
[12/29/2021-03:46:41] [I] timingCacheMode: local
[12/29/2021-03:46:41] [I] timingCacheFile: 
[12/29/2021-03:46:41] [I] Input(s)s format: fp32:CHW
[12/29/2021-03:46:41] [I] Output(s)s format: fp32:CHW
[12/29/2021-03:46:41] [I] Input build shapes: model
[12/29/2021-03:46:41] [I] Input calibration shapes: model
[12/29/2021-03:46:41] [I] === System Options ===
[12/29/2021-03:46:41] [I] Device: 0
[12/29/2021-03:46:41] [I] DLACore: 
[12/29/2021-03:46:41] [I] Plugins:
[12/29/2021-03:46:41] [I] === Inference Options ===
[12/29/2021-03:46:41] [I] Batch: Explicit
[12/29/2021-03:46:41] [I] Input inference shapes: model
[12/29/2021-03:46:41] [I] Iterations: 10
[12/29/2021-03:46:41] [I] Duration: 3s (+ 200ms warm up)
[12/29/2021-03:46:41] [I] Sleep time: 0ms
[12/29/2021-03:46:41] [I] Streams: 1
[12/29/2021-03:46:41] [I] ExposeDMA: Disabled
[12/29/2021-03:46:41] [I] Data transfers: Enabled
[12/29/2021-03:46:41] [I] Spin-wait: Disabled
[12/29/2021-03:46:41] [I] Multithreading: Disabled
[12/29/2021-03:46:41] [I] CUDA Graph: Disabled
[12/29/2021-03:46:41] [I] Separate profiling: Disabled
[12/29/2021-03:46:41] [I] Time Deserialize: Disabled
[12/29/2021-03:46:41] [I] Time Refit: Disabled
[12/29/2021-03:46:41] [I] Skip inference: Disabled
[12/29/2021-03:46:41] [I] Inputs:
[12/29/2021-03:46:41] [I] === Reporting Options ===
[12/29/2021-03:46:41] [I] Verbose: Enabled
[12/29/2021-03:46:41] [I] Averages: 10 inferences
[12/29/2021-03:46:41] [I] Percentile: 99
[12/29/2021-03:46:41] [I] Dump refittable layers:Disabled
[12/29/2021-03:46:41] [I] Dump output: Disabled
[12/29/2021-03:46:41] [I] Profile: Disabled
[12/29/2021-03:46:41] [I] Export timing to JSON file: 
[12/29/2021-03:46:41] [I] Export output to JSON file: 
[12/29/2021-03:46:41] [I] Export profile to JSON file: 
[12/29/2021-03:46:41] [I] 
[12/29/2021-03:46:41] [I] === Device Information ===
[12/29/2021-03:46:41] [I] Selected Device: NVIDIA GeForce RTX 3090
[12/29/2021-03:46:41] [I] Compute Capability: 8.6
[12/29/2021-03:46:41] [I] SMs: 82
[12/29/2021-03:46:41] [I] Compute Clock Rate: 1.695 GHz
[12/29/2021-03:46:41] [I] Device Global Memory: 24260 MiB
[12/29/2021-03:46:41] [I] Shared Memory per SM: 100 KiB
[12/29/2021-03:46:41] [I] Memory Bus Width: 384 bits (ECC disabled)
[12/29/2021-03:46:41] [I] Memory Clock Rate: 9.751 GHz
[12/29/2021-03:46:41] [I] 
[12/29/2021-03:46:41] [I] TensorRT version: 8001
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::Region_TRT version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::Clip_TRT version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::ScatterND version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::CropAndResize version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::Proposal version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::Split version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1
[12/29/2021-03:46:41] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1
[12/29/2021-03:46:42] [I] [TRT] [MemUsageChange] Init CUDA: CPU +534, GPU +0, now: CPU 541, GPU 3269 (MiB)
[12/29/2021-03:46:42] [I] Start parsing network model
[12/29/2021-03:46:42] [I] [TRT] ----------------------------------------------------------------
[12/29/2021-03:46:42] [I] [TRT] Input filename:   default_model.onnx
[12/29/2021-03:46:42] [I] [TRT] ONNX IR version:  0.0.6
[12/29/2021-03:46:42] [I] [TRT] Opset version:    9
[12/29/2021-03:46:42] [I] [TRT] Producer name:    pytorch
[12/29/2021-03:46:42] [I] [TRT] Producer version: 1.8
[12/29/2021-03:46:42] [I] [TRT] Domain:           
[12/29/2021-03:46:42] [I] [TRT] Model version:    0
[12/29/2021-03:46:42] [I] [TRT] Doc string:       
[12/29/2021-03:46:42] [I] [TRT] ----------------------------------------------------------------
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::Clip_TRT version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::ScatterND version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::Proposal version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::Split version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1
[12/29/2021-03:46:42] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1
[12/29/2021-03:46:42] [V] [TRT] Adding network input: actual_input_1 with dtype: float32, dimensions: (32, 3, 32, 32)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: actual_input_1 for ONNX tensor: actual_input_1
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: fc.module.weight
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: fc.module.bias
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 271
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 272
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 274
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 275
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 277
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 278
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 280
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 281
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 283
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 284
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 286
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 287
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 289
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 290
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 292
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 293
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 295
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 296
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 298
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 299
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 301
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 302
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 304
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 305
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 307
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 308
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 310
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 311
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 313
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 314
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 316
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 317
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 319
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 320
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 322
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 323
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 325
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 326
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 328
[12/29/2021-03:46:42] [V] [TRT] Importing initializer: 329
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Conv_2 [Conv]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: actual_input_1
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 271
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 272
[12/29/2021-03:46:42] [V] [TRT] Conv_2 [Conv] inputs: [actual_input_1 -> (32, 3, 32, 32)[FLOAT]], [271 -> (64, 3, 7, 7)[FLOAT]], [272 -> (64)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Convolution input dimensions: (32, 3, 32, 32)
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Conv_2 for ONNX node: Conv_2
[12/29/2021-03:46:42] [V] [TRT] Using kernel: (7, 7), strides: (2, 2), prepadding: (3, 3), postpadding: (3, 3), dilations: (1, 1), numOutputs: 64
[12/29/2021-03:46:42] [V] [TRT] Convolution output dimensions: (32, 64, 16, 16)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 270 for ONNX tensor: 270
[12/29/2021-03:46:42] [V] [TRT] Conv_2 [Conv] outputs: [270 -> (32, 64, 16, 16)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Relu_5 [Relu]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 270
[12/29/2021-03:46:42] [V] [TRT] Relu_5 [Relu] inputs: [270 -> (32, 64, 16, 16)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Relu_5 for ONNX node: Relu_5
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 129 for ONNX tensor: 129
[12/29/2021-03:46:42] [V] [TRT] Relu_5 [Relu] outputs: [129 -> (32, 64, 16, 16)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: MaxPool_8 [MaxPool]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 129
[12/29/2021-03:46:42] [V] [TRT] MaxPool_8 [MaxPool] inputs: [129 -> (32, 64, 16, 16)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: MaxPool_8 for ONNX node: MaxPool_8
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 132 for ONNX tensor: 132
[12/29/2021-03:46:42] [V] [TRT] MaxPool_8 [MaxPool] outputs: [132 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Conv_11 [Conv]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 132
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 274
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 275
[12/29/2021-03:46:42] [V] [TRT] Conv_11 [Conv] inputs: [132 -> (32, 64, 8, 8)[FLOAT]], [274 -> (64, 64, 3, 3)[FLOAT]], [275 -> (64)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Convolution input dimensions: (32, 64, 8, 8)
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Conv_11 for ONNX node: Conv_11
[12/29/2021-03:46:42] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[12/29/2021-03:46:42] [V] [TRT] Convolution output dimensions: (32, 64, 8, 8)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 273 for ONNX tensor: 273
[12/29/2021-03:46:42] [V] [TRT] Conv_11 [Conv] outputs: [273 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Relu_14 [Relu]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 273
[12/29/2021-03:46:42] [V] [TRT] Relu_14 [Relu] inputs: [273 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Relu_14 for ONNX node: Relu_14
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 139 for ONNX tensor: 139
[12/29/2021-03:46:42] [V] [TRT] Relu_14 [Relu] outputs: [139 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Conv_17 [Conv]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 139
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 277
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 278
[12/29/2021-03:46:42] [V] [TRT] Conv_17 [Conv] inputs: [139 -> (32, 64, 8, 8)[FLOAT]], [277 -> (64, 64, 3, 3)[FLOAT]], [278 -> (64)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Convolution input dimensions: (32, 64, 8, 8)
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Conv_17 for ONNX node: Conv_17
[12/29/2021-03:46:42] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[12/29/2021-03:46:42] [V] [TRT] Convolution output dimensions: (32, 64, 8, 8)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 276 for ONNX tensor: 276
[12/29/2021-03:46:42] [V] [TRT] Conv_17 [Conv] outputs: [276 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Add_18 [Add]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 276
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 132
[12/29/2021-03:46:42] [V] [TRT] Add_18 [Add] inputs: [276 -> (32, 64, 8, 8)[FLOAT]], [132 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Add_18 for ONNX node: Add_18
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 144 for ONNX tensor: 144
[12/29/2021-03:46:42] [V] [TRT] Add_18 [Add] outputs: [144 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Relu_21 [Relu]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 144
[12/29/2021-03:46:42] [V] [TRT] Relu_21 [Relu] inputs: [144 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Relu_21 for ONNX node: Relu_21
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 147 for ONNX tensor: 147
[12/29/2021-03:46:42] [V] [TRT] Relu_21 [Relu] outputs: [147 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Conv_24 [Conv]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 147
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 280
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 281
[12/29/2021-03:46:42] [V] [TRT] Conv_24 [Conv] inputs: [147 -> (32, 64, 8, 8)[FLOAT]], [280 -> (64, 64, 3, 3)[FLOAT]], [281 -> (64)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Convolution input dimensions: (32, 64, 8, 8)
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Conv_24 for ONNX node: Conv_24
[12/29/2021-03:46:42] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[12/29/2021-03:46:42] [V] [TRT] Convolution output dimensions: (32, 64, 8, 8)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 279 for ONNX tensor: 279
[12/29/2021-03:46:42] [V] [TRT] Conv_24 [Conv] outputs: [279 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Relu_27 [Relu]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 279
[12/29/2021-03:46:42] [V] [TRT] Relu_27 [Relu] inputs: [279 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Relu_27 for ONNX node: Relu_27
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 154 for ONNX tensor: 154
[12/29/2021-03:46:42] [V] [TRT] Relu_27 [Relu] outputs: [154 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Conv_30 [Conv]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 154
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 283
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 284
[12/29/2021-03:46:42] [V] [TRT] Conv_30 [Conv] inputs: [154 -> (32, 64, 8, 8)[FLOAT]], [283 -> (64, 64, 3, 3)[FLOAT]], [284 -> (64)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Convolution input dimensions: (32, 64, 8, 8)
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Conv_30 for ONNX node: Conv_30
[12/29/2021-03:46:42] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[12/29/2021-03:46:42] [V] [TRT] Convolution output dimensions: (32, 64, 8, 8)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 282 for ONNX tensor: 282
[12/29/2021-03:46:42] [V] [TRT] Conv_30 [Conv] outputs: [282 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Add_31 [Add]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 282
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 147
[12/29/2021-03:46:42] [V] [TRT] Add_31 [Add] inputs: [282 -> (32, 64, 8, 8)[FLOAT]], [147 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Add_31 for ONNX node: Add_31
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 159 for ONNX tensor: 159
[12/29/2021-03:46:42] [V] [TRT] Add_31 [Add] outputs: [159 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Relu_34 [Relu]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 159
[12/29/2021-03:46:42] [V] [TRT] Relu_34 [Relu] inputs: [159 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Relu_34 for ONNX node: Relu_34
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 162 for ONNX tensor: 162
[12/29/2021-03:46:42] [V] [TRT] Relu_34 [Relu] outputs: [162 -> (32, 64, 8, 8)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Conv_37 [Conv]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 162
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 286
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 287
[12/29/2021-03:46:42] [V] [TRT] Conv_37 [Conv] inputs: [162 -> (32, 64, 8, 8)[FLOAT]], [286 -> (128, 64, 3, 3)[FLOAT]], [287 -> (128)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Convolution input dimensions: (32, 64, 8, 8)
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Conv_37 for ONNX node: Conv_37
[12/29/2021-03:46:42] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[12/29/2021-03:46:42] [V] [TRT] Convolution output dimensions: (32, 128, 4, 4)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 285 for ONNX tensor: 285
[12/29/2021-03:46:42] [V] [TRT] Conv_37 [Conv] outputs: [285 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Relu_40 [Relu]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 285
[12/29/2021-03:46:42] [V] [TRT] Relu_40 [Relu] inputs: [285 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Relu_40 for ONNX node: Relu_40
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 169 for ONNX tensor: 169
[12/29/2021-03:46:42] [V] [TRT] Relu_40 [Relu] outputs: [169 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Conv_43 [Conv]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 169
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 289
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 290
[12/29/2021-03:46:42] [V] [TRT] Conv_43 [Conv] inputs: [169 -> (32, 128, 4, 4)[FLOAT]], [289 -> (128, 128, 3, 3)[FLOAT]], [290 -> (128)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Convolution input dimensions: (32, 128, 4, 4)
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Conv_43 for ONNX node: Conv_43
[12/29/2021-03:46:42] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[12/29/2021-03:46:42] [V] [TRT] Convolution output dimensions: (32, 128, 4, 4)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 288 for ONNX tensor: 288
[12/29/2021-03:46:42] [V] [TRT] Conv_43 [Conv] outputs: [288 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Conv_46 [Conv]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 162
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 292
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 293
[12/29/2021-03:46:42] [V] [TRT] Conv_46 [Conv] inputs: [162 -> (32, 64, 8, 8)[FLOAT]], [292 -> (128, 64, 1, 1)[FLOAT]], [293 -> (128)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Convolution input dimensions: (32, 64, 8, 8)
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Conv_46 for ONNX node: Conv_46
[12/29/2021-03:46:42] [V] [TRT] Using kernel: (1, 1), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[12/29/2021-03:46:42] [V] [TRT] Convolution output dimensions: (32, 128, 4, 4)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 291 for ONNX tensor: 291
[12/29/2021-03:46:42] [V] [TRT] Conv_46 [Conv] outputs: [291 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Add_47 [Add]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 288
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 291
[12/29/2021-03:46:42] [V] [TRT] Add_47 [Add] inputs: [288 -> (32, 128, 4, 4)[FLOAT]], [291 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Add_47 for ONNX node: Add_47
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 178 for ONNX tensor: 178
[12/29/2021-03:46:42] [V] [TRT] Add_47 [Add] outputs: [178 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Relu_50 [Relu]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 178
[12/29/2021-03:46:42] [V] [TRT] Relu_50 [Relu] inputs: [178 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Relu_50 for ONNX node: Relu_50
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 181 for ONNX tensor: 181
[12/29/2021-03:46:42] [V] [TRT] Relu_50 [Relu] outputs: [181 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Conv_53 [Conv]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 181
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 295
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 296
[12/29/2021-03:46:42] [V] [TRT] Conv_53 [Conv] inputs: [181 -> (32, 128, 4, 4)[FLOAT]], [295 -> (128, 128, 3, 3)[FLOAT]], [296 -> (128)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Convolution input dimensions: (32, 128, 4, 4)
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Conv_53 for ONNX node: Conv_53
[12/29/2021-03:46:42] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[12/29/2021-03:46:42] [V] [TRT] Convolution output dimensions: (32, 128, 4, 4)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 294 for ONNX tensor: 294
[12/29/2021-03:46:42] [V] [TRT] Conv_53 [Conv] outputs: [294 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Relu_56 [Relu]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 294
[12/29/2021-03:46:42] [V] [TRT] Relu_56 [Relu] inputs: [294 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Relu_56 for ONNX node: Relu_56
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 188 for ONNX tensor: 188
[12/29/2021-03:46:42] [V] [TRT] Relu_56 [Relu] outputs: [188 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Conv_59 [Conv]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 188
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 298
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 299
[12/29/2021-03:46:42] [V] [TRT] Conv_59 [Conv] inputs: [188 -> (32, 128, 4, 4)[FLOAT]], [298 -> (128, 128, 3, 3)[FLOAT]], [299 -> (128)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Convolution input dimensions: (32, 128, 4, 4)
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Conv_59 for ONNX node: Conv_59
[12/29/2021-03:46:42] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[12/29/2021-03:46:42] [V] [TRT] Convolution output dimensions: (32, 128, 4, 4)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 297 for ONNX tensor: 297
[12/29/2021-03:46:42] [V] [TRT] Conv_59 [Conv] outputs: [297 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Add_60 [Add]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 297
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 181
[12/29/2021-03:46:42] [V] [TRT] Add_60 [Add] inputs: [297 -> (32, 128, 4, 4)[FLOAT]], [181 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Add_60 for ONNX node: Add_60
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 193 for ONNX tensor: 193
[12/29/2021-03:46:42] [V] [TRT] Add_60 [Add] outputs: [193 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Relu_63 [Relu]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 193
[12/29/2021-03:46:42] [V] [TRT] Relu_63 [Relu] inputs: [193 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Relu_63 for ONNX node: Relu_63
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 196 for ONNX tensor: 196
[12/29/2021-03:46:42] [V] [TRT] Relu_63 [Relu] outputs: [196 -> (32, 128, 4, 4)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Conv_66 [Conv]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 196
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 301
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 302
[12/29/2021-03:46:42] [V] [TRT] Conv_66 [Conv] inputs: [196 -> (32, 128, 4, 4)[FLOAT]], [301 -> (256, 128, 3, 3)[FLOAT]], [302 -> (256)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Convolution input dimensions: (32, 128, 4, 4)
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Conv_66 for ONNX node: Conv_66
[12/29/2021-03:46:42] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[12/29/2021-03:46:42] [V] [TRT] Convolution output dimensions: (32, 256, 2, 2)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 300 for ONNX tensor: 300
[12/29/2021-03:46:42] [V] [TRT] Conv_66 [Conv] outputs: [300 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Relu_69 [Relu]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 300
[12/29/2021-03:46:42] [V] [TRT] Relu_69 [Relu] inputs: [300 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Relu_69 for ONNX node: Relu_69
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 203 for ONNX tensor: 203
[12/29/2021-03:46:42] [V] [TRT] Relu_69 [Relu] outputs: [203 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Conv_72 [Conv]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 203
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 304
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 305
[12/29/2021-03:46:42] [V] [TRT] Conv_72 [Conv] inputs: [203 -> (32, 256, 2, 2)[FLOAT]], [304 -> (256, 256, 3, 3)[FLOAT]], [305 -> (256)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Convolution input dimensions: (32, 256, 2, 2)
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Conv_72 for ONNX node: Conv_72
[12/29/2021-03:46:42] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[12/29/2021-03:46:42] [V] [TRT] Convolution output dimensions: (32, 256, 2, 2)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 303 for ONNX tensor: 303
[12/29/2021-03:46:42] [V] [TRT] Conv_72 [Conv] outputs: [303 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Conv_75 [Conv]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 196
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 307
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 308
[12/29/2021-03:46:42] [V] [TRT] Conv_75 [Conv] inputs: [196 -> (32, 128, 4, 4)[FLOAT]], [307 -> (256, 128, 1, 1)[FLOAT]], [308 -> (256)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Convolution input dimensions: (32, 128, 4, 4)
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Conv_75 for ONNX node: Conv_75
[12/29/2021-03:46:42] [V] [TRT] Using kernel: (1, 1), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[12/29/2021-03:46:42] [V] [TRT] Convolution output dimensions: (32, 256, 2, 2)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 306 for ONNX tensor: 306
[12/29/2021-03:46:42] [V] [TRT] Conv_75 [Conv] outputs: [306 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Add_76 [Add]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 303
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 306
[12/29/2021-03:46:42] [V] [TRT] Add_76 [Add] inputs: [303 -> (32, 256, 2, 2)[FLOAT]], [306 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Add_76 for ONNX node: Add_76
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 212 for ONNX tensor: 212
[12/29/2021-03:46:42] [V] [TRT] Add_76 [Add] outputs: [212 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Relu_79 [Relu]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 212
[12/29/2021-03:46:42] [V] [TRT] Relu_79 [Relu] inputs: [212 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Relu_79 for ONNX node: Relu_79
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 215 for ONNX tensor: 215
[12/29/2021-03:46:42] [V] [TRT] Relu_79 [Relu] outputs: [215 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Conv_82 [Conv]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 215
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 310
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 311
[12/29/2021-03:46:42] [V] [TRT] Conv_82 [Conv] inputs: [215 -> (32, 256, 2, 2)[FLOAT]], [310 -> (256, 256, 3, 3)[FLOAT]], [311 -> (256)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Convolution input dimensions: (32, 256, 2, 2)
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Conv_82 for ONNX node: Conv_82
[12/29/2021-03:46:42] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[12/29/2021-03:46:42] [V] [TRT] Convolution output dimensions: (32, 256, 2, 2)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 309 for ONNX tensor: 309
[12/29/2021-03:46:42] [V] [TRT] Conv_82 [Conv] outputs: [309 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Relu_85 [Relu]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 309
[12/29/2021-03:46:42] [V] [TRT] Relu_85 [Relu] inputs: [309 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Relu_85 for ONNX node: Relu_85
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 222 for ONNX tensor: 222
[12/29/2021-03:46:42] [V] [TRT] Relu_85 [Relu] outputs: [222 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Conv_88 [Conv]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 222
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 313
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 314
[12/29/2021-03:46:42] [V] [TRT] Conv_88 [Conv] inputs: [222 -> (32, 256, 2, 2)[FLOAT]], [313 -> (256, 256, 3, 3)[FLOAT]], [314 -> (256)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Convolution input dimensions: (32, 256, 2, 2)
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Conv_88 for ONNX node: Conv_88
[12/29/2021-03:46:42] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[12/29/2021-03:46:42] [V] [TRT] Convolution output dimensions: (32, 256, 2, 2)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 312 for ONNX tensor: 312
[12/29/2021-03:46:42] [V] [TRT] Conv_88 [Conv] outputs: [312 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Add_89 [Add]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 312
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 215
[12/29/2021-03:46:42] [V] [TRT] Add_89 [Add] inputs: [312 -> (32, 256, 2, 2)[FLOAT]], [215 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Add_89 for ONNX node: Add_89
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 227 for ONNX tensor: 227
[12/29/2021-03:46:42] [V] [TRT] Add_89 [Add] outputs: [227 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Relu_92 [Relu]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 227
[12/29/2021-03:46:42] [V] [TRT] Relu_92 [Relu] inputs: [227 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Relu_92 for ONNX node: Relu_92
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 230 for ONNX tensor: 230
[12/29/2021-03:46:42] [V] [TRT] Relu_92 [Relu] outputs: [230 -> (32, 256, 2, 2)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Conv_95 [Conv]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 230
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 316
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 317
[12/29/2021-03:46:42] [V] [TRT] Conv_95 [Conv] inputs: [230 -> (32, 256, 2, 2)[FLOAT]], [316 -> (512, 256, 3, 3)[FLOAT]], [317 -> (512)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Convolution input dimensions: (32, 256, 2, 2)
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Conv_95 for ONNX node: Conv_95
[12/29/2021-03:46:42] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 512
[12/29/2021-03:46:42] [V] [TRT] Convolution output dimensions: (32, 512, 1, 1)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 315 for ONNX tensor: 315
[12/29/2021-03:46:42] [V] [TRT] Conv_95 [Conv] outputs: [315 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Relu_98 [Relu]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 315
[12/29/2021-03:46:42] [V] [TRT] Relu_98 [Relu] inputs: [315 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Relu_98 for ONNX node: Relu_98
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 237 for ONNX tensor: 237
[12/29/2021-03:46:42] [V] [TRT] Relu_98 [Relu] outputs: [237 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Conv_101 [Conv]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 237
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 319
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 320
[12/29/2021-03:46:42] [V] [TRT] Conv_101 [Conv] inputs: [237 -> (32, 512, 1, 1)[FLOAT]], [319 -> (512, 512, 3, 3)[FLOAT]], [320 -> (512)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Convolution input dimensions: (32, 512, 1, 1)
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Conv_101 for ONNX node: Conv_101
[12/29/2021-03:46:42] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 512
[12/29/2021-03:46:42] [V] [TRT] Convolution output dimensions: (32, 512, 1, 1)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 318 for ONNX tensor: 318
[12/29/2021-03:46:42] [V] [TRT] Conv_101 [Conv] outputs: [318 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Conv_104 [Conv]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 230
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 322
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 323
[12/29/2021-03:46:42] [V] [TRT] Conv_104 [Conv] inputs: [230 -> (32, 256, 2, 2)[FLOAT]], [322 -> (512, 256, 1, 1)[FLOAT]], [323 -> (512)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Convolution input dimensions: (32, 256, 2, 2)
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Conv_104 for ONNX node: Conv_104
[12/29/2021-03:46:42] [V] [TRT] Using kernel: (1, 1), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[12/29/2021-03:46:42] [V] [TRT] Convolution output dimensions: (32, 512, 1, 1)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 321 for ONNX tensor: 321
[12/29/2021-03:46:42] [V] [TRT] Conv_104 [Conv] outputs: [321 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Add_105 [Add]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 318
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 321
[12/29/2021-03:46:42] [V] [TRT] Add_105 [Add] inputs: [318 -> (32, 512, 1, 1)[FLOAT]], [321 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Add_105 for ONNX node: Add_105
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 246 for ONNX tensor: 246
[12/29/2021-03:46:42] [V] [TRT] Add_105 [Add] outputs: [246 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Relu_108 [Relu]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 246
[12/29/2021-03:46:42] [V] [TRT] Relu_108 [Relu] inputs: [246 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Relu_108 for ONNX node: Relu_108
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 249 for ONNX tensor: 249
[12/29/2021-03:46:42] [V] [TRT] Relu_108 [Relu] outputs: [249 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Conv_111 [Conv]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 249
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 325
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 326
[12/29/2021-03:46:42] [V] [TRT] Conv_111 [Conv] inputs: [249 -> (32, 512, 1, 1)[FLOAT]], [325 -> (512, 512, 3, 3)[FLOAT]], [326 -> (512)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Convolution input dimensions: (32, 512, 1, 1)
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Conv_111 for ONNX node: Conv_111
[12/29/2021-03:46:42] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 512
[12/29/2021-03:46:42] [V] [TRT] Convolution output dimensions: (32, 512, 1, 1)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 324 for ONNX tensor: 324
[12/29/2021-03:46:42] [V] [TRT] Conv_111 [Conv] outputs: [324 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Relu_114 [Relu]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 324
[12/29/2021-03:46:42] [V] [TRT] Relu_114 [Relu] inputs: [324 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Relu_114 for ONNX node: Relu_114
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 256 for ONNX tensor: 256
[12/29/2021-03:46:42] [V] [TRT] Relu_114 [Relu] outputs: [256 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Conv_117 [Conv]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 256
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 328
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 329
[12/29/2021-03:46:42] [V] [TRT] Conv_117 [Conv] inputs: [256 -> (32, 512, 1, 1)[FLOAT]], [328 -> (512, 512, 3, 3)[FLOAT]], [329 -> (512)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Convolution input dimensions: (32, 512, 1, 1)
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Conv_117 for ONNX node: Conv_117
[12/29/2021-03:46:42] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 512
[12/29/2021-03:46:42] [V] [TRT] Convolution output dimensions: (32, 512, 1, 1)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 327 for ONNX tensor: 327
[12/29/2021-03:46:42] [V] [TRT] Conv_117 [Conv] outputs: [327 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Add_118 [Add]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 327
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 249
[12/29/2021-03:46:42] [V] [TRT] Add_118 [Add] inputs: [327 -> (32, 512, 1, 1)[FLOAT]], [249 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Add_118 for ONNX node: Add_118
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 261 for ONNX tensor: 261
[12/29/2021-03:46:42] [V] [TRT] Add_118 [Add] outputs: [261 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Relu_121 [Relu]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 261
[12/29/2021-03:46:42] [V] [TRT] Relu_121 [Relu] inputs: [261 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Relu_121 for ONNX node: Relu_121
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 264 for ONNX tensor: 264
[12/29/2021-03:46:42] [V] [TRT] Relu_121 [Relu] outputs: [264 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: GlobalAveragePool_122 [GlobalAveragePool]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 264
[12/29/2021-03:46:42] [V] [TRT] GlobalAveragePool_122 [GlobalAveragePool] inputs: [264 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: GlobalAveragePool_122 for ONNX node: GlobalAveragePool_122
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 265 for ONNX tensor: 265
[12/29/2021-03:46:42] [V] [TRT] GlobalAveragePool_122 [GlobalAveragePool] outputs: [265 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Flatten_123 [Flatten]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 265
[12/29/2021-03:46:42] [V] [TRT] Flatten_123 [Flatten] inputs: [265 -> (32, 512, 1, 1)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Flatten_123 for ONNX node: Flatten_123
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: 266 for ONNX tensor: 266
[12/29/2021-03:46:42] [V] [TRT] Flatten_123 [Flatten] outputs: [266 -> (32, 512)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Parsing node: Gemm_126 [Gemm]
[12/29/2021-03:46:42] [V] [TRT] Searching for input: 266
[12/29/2021-03:46:42] [V] [TRT] Searching for input: fc.module.weight
[12/29/2021-03:46:42] [V] [TRT] Searching for input: fc.module.bias
[12/29/2021-03:46:42] [V] [TRT] Gemm_126 [Gemm] inputs: [266 -> (32, 512)[FLOAT]], [fc.module.weight -> (10, 512)[FLOAT]], [fc.module.bias -> (10)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] GEMM: using FC layer instead of MM because all criteria were met.
[12/29/2021-03:46:42] [V] [TRT] Original shape: (32, 512), unsqueezing to: (32, 512, 1, 1)
[12/29/2021-03:46:42] [V] [TRT] Registering layer: Gemm_126 for ONNX node: Gemm_126
[12/29/2021-03:46:42] [V] [TRT] Original shape: (32, 10, 1, 1), squeezing to: (32, 10)
[12/29/2021-03:46:42] [V] [TRT] Registering tensor: output1_0 for ONNX tensor: output1
[12/29/2021-03:46:42] [V] [TRT] Gemm_126 [Gemm] outputs: [output1 -> (32, 10)[FLOAT]], 
[12/29/2021-03:46:42] [V] [TRT] Marking output1_0 as output: output1
[12/29/2021-03:46:42] [I] Finish parsing network model
[12/29/2021-03:46:42] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 582, GPU 3269 (MiB)
[12/29/2021-03:46:42] [I] FP32 and INT8 precisions have been specified - more performance might be enabled by additionally specifying --fp16 or --best
[12/29/2021-03:46:42] [I] [TRT] [MemUsageSnapshot] Builder begin: CPU 582 MiB, GPU 3269 MiB
[12/29/2021-03:46:42] [V] [TRT] Original: 51 layers
[12/29/2021-03:46:42] [V] [TRT] After dead-layer removal: 51 layers
[12/29/2021-03:46:42] [V] [TRT] Convert layer type of Gemm_126 from FULLY_CONNECTED to CONVOLUTION
[12/29/2021-03:46:42] [V] [TRT] Removing shuffle_between_(Unnamed Layer* 48) [Shuffle]_output_and_Gemm_126
[12/29/2021-03:46:42] [V] [TRT] After scale fusion: 51 layers
[12/29/2021-03:46:42] [V] [TRT] Swap the layer type of Relu_5 from ACTIVATION to POINTWISE
[12/29/2021-03:46:42] [V] [TRT] Swap the layer type of Relu_14 from ACTIVATION to POINTWISE
[12/29/2021-03:46:42] [V] [TRT] Swap the layer type of Relu_21 from ACTIVATION to POINTWISE
[12/29/2021-03:46:42] [V] [TRT] Swap the layer type of Relu_27 from ACTIVATION to POINTWISE
[12/29/2021-03:46:42] [V] [TRT] Swap the layer type of Relu_34 from ACTIVATION to POINTWISE
[12/29/2021-03:46:42] [V] [TRT] Swap the layer type of Relu_40 from ACTIVATION to POINTWISE
[12/29/2021-03:46:42] [V] [TRT] Swap the layer type of Relu_50 from ACTIVATION to POINTWISE
[12/29/2021-03:46:42] [V] [TRT] Swap the layer type of Relu_56 from ACTIVATION to POINTWISE
[12/29/2021-03:46:42] [V] [TRT] Swap the layer type of Relu_63 from ACTIVATION to POINTWISE
[12/29/2021-03:46:42] [V] [TRT] Swap the layer type of Relu_69 from ACTIVATION to POINTWISE
[12/29/2021-03:46:42] [V] [TRT] Swap the layer type of Relu_79 from ACTIVATION to POINTWISE
[12/29/2021-03:46:42] [V] [TRT] Swap the layer type of Relu_85 from ACTIVATION to POINTWISE
[12/29/2021-03:46:42] [V] [TRT] Swap the layer type of Relu_92 from ACTIVATION to POINTWISE
[12/29/2021-03:46:42] [V] [TRT] Swap the layer type of Relu_98 from ACTIVATION to POINTWISE
[12/29/2021-03:46:42] [V] [TRT] Swap the layer type of Relu_108 from ACTIVATION to POINTWISE
[12/29/2021-03:46:42] [V] [TRT] Swap the layer type of Relu_114 from ACTIVATION to POINTWISE
[12/29/2021-03:46:42] [V] [TRT] Swap the layer type of Relu_121 from ACTIVATION to POINTWISE
[12/29/2021-03:46:42] [V] [TRT] After vertical fusions: 51 layers
[12/29/2021-03:46:42] [V] [TRT] After final dead-layer removal: 51 layers
[12/29/2021-03:46:42] [V] [TRT] After concat removal: 51 layers
[12/29/2021-03:46:42] [V] [TRT] After tensor merging: 51 layers
[12/29/2021-03:46:42] [I] [TRT] Reading Calibration Cache for calibrator: EntropyCalibration2
[12/29/2021-03:46:42] [I] [TRT] Generated calibration scales using calibration cache. Make sure that calibration cache has latest scales.
[12/29/2021-03:46:42] [I] [TRT] To regenerate calibration cache, please delete the existing one. TensorRT will generate a new calibration cache.
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: actual_input_1 scale and zero-point Quantization(scale: {0.0203247,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 270 scale and zero-point Quantization(scale: {0.0761741,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 129 scale and zero-point Quantization(scale: {0.0297118,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 132 scale and zero-point Quantization(scale: {0.0225558,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 273 scale and zero-point Quantization(scale: {0.0523693,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 139 scale and zero-point Quantization(scale: {0.0209975,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 276 scale and zero-point Quantization(scale: {0.0370378,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 147 scale and zero-point Quantization(scale: {0.0256307,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 279 scale and zero-point Quantization(scale: {0.0829737,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 154 scale and zero-point Quantization(scale: {0.0315438,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 282 scale and zero-point Quantization(scale: {0.0415631,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 162 scale and zero-point Quantization(scale: {0.0339319,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 285 scale and zero-point Quantization(scale: {0.0664687,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 169 scale and zero-point Quantization(scale: {0.0277645,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 288 scale and zero-point Quantization(scale: {0.0462997,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 291 scale and zero-point Quantization(scale: {0.0460983,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 181 scale and zero-point Quantization(scale: {0.0296639,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 294 scale and zero-point Quantization(scale: {0.0453227,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 188 scale and zero-point Quantization(scale: {0.0232894,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 297 scale and zero-point Quantization(scale: {0.0299404,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 196 scale and zero-point Quantization(scale: {0.0280925,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 300 scale and zero-point Quantization(scale: {0.0301538,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 203 scale and zero-point Quantization(scale: {0.0142102,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 303 scale and zero-point Quantization(scale: {0.0270986,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 306 scale and zero-point Quantization(scale: {0.0111315,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 215 scale and zero-point Quantization(scale: {0.0161066,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 309 scale and zero-point Quantization(scale: {0.0264487,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 222 scale and zero-point Quantization(scale: {0.0172282,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 312 scale and zero-point Quantization(scale: {0.0193074,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 230 scale and zero-point Quantization(scale: {0.0195712,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 315 scale and zero-point Quantization(scale: {0.0349623,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 237 scale and zero-point Quantization(scale: {0.0256173,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 318 scale and zero-point Quantization(scale: {0.0344227,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 321 scale and zero-point Quantization(scale: {0.0323227,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 249 scale and zero-point Quantization(scale: {0.0315835,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 324 scale and zero-point Quantization(scale: {0.0246684,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 256 scale and zero-point Quantization(scale: {0.0138321,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 327 scale and zero-point Quantization(scale: {0.104862,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 264 scale and zero-point Quantization(scale: {0.0211667,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: 266 scale and zero-point Quantization(scale: {0.0593414,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: (Unnamed Layer* 48) [Shuffle]_output scale and zero-point Quantization(scale: {0.0593414,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: (Unnamed Layer* 49) [Fully Connected]_output scale and zero-point Quantization(scale: {0.0593414,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] INT8 Inference Tensor scales and zero-points: output1 scale and zero-point Quantization(scale: {0.0723407,}, zero-point: {})
[12/29/2021-03:46:42] [V] [TRT] Configuring builder for Int8 Mode completed in 0.00697021 seconds.
[12/29/2021-03:46:42] [12/29/2021-03:46:42] [12/29/2021-03:46:42] [12/29/2021-03:46:42] [12/29/2021-03:46:42] [12/29/2021-03:46:42] [12/29/2021-03:46:42] [12/29/2021-03:46:42] [12/29/2021-03:46:42] [12/29/2021-03:46:42] [V] [TRT] Applying generic optimizations to the graph for inference.
[12/29/2021-03:46:42] [V] [TRT] Original: 51 layers
[12/29/2021-03:46:42] [V] [TRT] After dead-layer removal: 51 layers
[12/29/2021-03:46:42] [V] [TRT] ShuffleShuffleFusion: Fusing Flatten_123 with (Unnamed Layer* 48) [Shuffle]
[12/29/2021-03:46:42] [V] [TRT] Removing Flatten_123 + (Unnamed Layer* 48) [Shuffle]
[12/29/2021-03:46:42] [V] [TRT] After Myelin optimization: 49 layers
[12/29/2021-03:46:42] [V] [TRT] Convert layer type of Gemm_126 from FULLY_CONNECTED to CONVOLUTION
[12/29/2021-03:46:42] [V] [TRT] Removing shuffle_between_265_and_Gemm_126
[12/29/2021-03:46:42] [V] [TRT] After scale fusion: 49 layers
[12/29/2021-03:46:42] [V] [TRT] ConvReluFusion: Fusing Conv_2 with Relu_5
[12/29/2021-03:46:42] [V] [TRT] ConvActPoolFusion: Fusing Conv_2 + Relu_5 with MaxPool_8
[12/29/2021-03:46:42] [V] [TRT] ConvReluFusion: Fusing Conv_11 with Relu_14
[12/29/2021-03:46:42] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_17 with Add_18
[12/29/2021-03:46:42] [V] [TRT] ConvReluFusion: Fusing Conv_17 + Add_18 with Relu_21
[12/29/2021-03:46:42] [V] [TRT] ConvReluFusion: Fusing Conv_24 with Relu_27
[12/29/2021-03:46:42] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_30 with Add_31
[12/29/2021-03:46:42] [V] [TRT] ConvReluFusion: Fusing Conv_30 + Add_31 with Relu_34
[12/29/2021-03:46:42] [V] [TRT] ConvReluFusion: Fusing Conv_37 with Relu_40
[12/29/2021-03:46:42] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_43 with Add_47
[12/29/2021-03:46:42] [V] [TRT] ConvReluFusion: Fusing Conv_43 + Add_47 with Relu_50
[12/29/2021-03:46:42] [V] [TRT] ConvReluFusion: Fusing Conv_53 with Relu_56
[12/29/2021-03:46:42] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_59 with Add_60
[12/29/2021-03:46:42] [V] [TRT] ConvReluFusion: Fusing Conv_59 + Add_60 with Relu_63
[12/29/2021-03:46:42] [V] [TRT] ConvReluFusion: Fusing Conv_66 with Relu_69
[12/29/2021-03:46:42] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_72 with Add_76
[12/29/2021-03:46:42] [V] [TRT] ConvReluFusion: Fusing Conv_72 + Add_76 with Relu_79
[12/29/2021-03:46:42] [V] [TRT] ConvReluFusion: Fusing Conv_82 with Relu_85
[12/29/2021-03:46:42] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_88 with Add_89
[12/29/2021-03:46:42] [V] [TRT] ConvReluFusion: Fusing Conv_88 + Add_89 with Relu_92
[12/29/2021-03:46:42] [V] [TRT] ConvReluFusion: Fusing Conv_95 with Relu_98
[12/29/2021-03:46:42] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_101 with Add_105
[12/29/2021-03:46:42] [V] [TRT] ConvReluFusion: Fusing Conv_101 + Add_105 with Relu_108
[12/29/2021-03:46:42] [V] [TRT] ConvReluFusion: Fusing Conv_111 with Relu_114
[12/29/2021-03:46:42] [V] [TRT] ConvEltwiseSumFusion: Fusing Conv_117 with Add_118
[12/29/2021-03:46:42] [V] [TRT] ConvReluFusion: Fusing Conv_117 + Add_118 with Relu_121
[12/29/2021-03:46:42] [V] [TRT] Swap the layer type of GlobalAveragePool_122 from REDUCE to POOLING
[12/29/2021-03:46:42] [V] [TRT] After vertical fusions: 23 layers
[12/29/2021-03:46:42] [V] [TRT] After dupe layer removal: 23 layers
[12/29/2021-03:46:42] [V] [TRT] After final dead-layer removal: 23 layers
[12/29/2021-03:46:42] [V] [TRT] After tensor merging: 23 layers
[12/29/2021-03:46:42] [V] [TRT] After concat removal: 23 layers
[12/29/2021-03:46:42] [V] [TRT] Graph construction and optimization completed in 0.0396201 seconds.
[12/29/2021-03:46:42] [V] [TRT] Using cublasLt a tactic source
[12/29/2021-03:46:42] [12/29/2021-03:46:42] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +635, GPU +266, now: CPU 1217, GPU 3535 (MiB)
[12/29/2021-03:46:42] [V] [TRT] Using cuDNN as a tactic source
[12/29/2021-03:46:43] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +369, GPU +260, now: CPU 1586, GPU 3795 (MiB)
[12/29/2021-03:46:43] [12/29/2021-03:46:43] [12/29/2021-03:46:43] [V] [TRT] Constructing optimization profile number 0 [1/1].
[12/29/2021-03:46:43] [V] [TRT] Rejecting some int8 implementation of layer GlobalAveragePool_122 due to missing int8 scales for tensor 265 at output index 0
[12/29/2021-03:46:43] [V] [TRT] Rejecting some int8 implementation of layer Gemm_126 due to missing int8 scales for tensor 265 at input index 0
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Float(3072,1024,32,1) -> Int8(3072,1024,32,1) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.039832
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.005504
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.005504
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning format combination: Int8(3072,1024,32,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Conv_2 + Relu_5 + MaxPool_8 (ConvActPool)
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1000 Time: 0.014876
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1100 Time: 0.014732
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1110 Time: 0.015796
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1111 Time: 0.014676
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1112 Time: 0.017992
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1120 Time: 0.01602
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1121 Time: 0.01486
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1122 Time: 0.01818
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1130 Time: 0.015792
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1131 Time: 0.014596
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1132 Time: 0.018
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1140 Time: 0.01602
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1141 Time: 0.014728
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1142 Time: 0.0182
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 1131 Time: 0.014596
[12/29/2021-03:46:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: ConvActPool Tactic: 1131
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.007724
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.00608
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.00608
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.007564
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.006112
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.006112
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.00864
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.00654
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.00654
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.007864
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.00966
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.007864
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.007052
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.004724
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1 Time: 0.00522
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.004724
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.008308
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.005972
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.005972
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.008336
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.006088
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.006088
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.007064
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.004744
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.004744
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.007188
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.00744
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.007188
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.008524
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.005992
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.005992
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.007132
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.005676
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.005676
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.00744
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.00628
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.00628
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.007456
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.008164
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.007456
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.008528
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.006072
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.006072
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.007144
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.005676
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.005676
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.008416
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.00632
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.00632
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.008404
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.008012
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.008012
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.008572
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.006116
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.006116
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.008192
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.005772
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.005772
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.007128
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.005964
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.005964
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.007728
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.006436
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.006436
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.00776
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.0081
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 1002 Time: 0.00776
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.007776
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.005128
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.005128
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.00788
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.006132
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.006132
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.008728
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.006536
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.006536
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.007116
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.0052
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.0052
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.00772
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.006184
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.006184
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.0076
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.006156
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.006156
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.008632
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.006512
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.006512
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1002 Time: 0.006996
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 0 Time: 0.004736
[12/29/2021-03:46:43] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:43] [V] [TRT] Tactic: 1 Time: 0.005272
[12/29/2021-03:46:43] [V] [TRT] Fastest Tactic: 0 Time: 0.004736
[12/29/2021-03:46:43] [V] [TRT] *************** Autotuning format combination: Float(4096,64,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CudaDepthwiseConvolution)
[12/29/2021-03:46:43] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:43] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (FusedConvActConvolution)
[12/29/2021-03:46:43] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:44] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CudnnConvolution)
[12/29/2021-03:46:44] [V] [TRT] Tactic: 0 Time: 0.035632
[12/29/2021-03:46:44] [V] [TRT] Tactic: 1 Time: 0.052124
[12/29/2021-03:46:44] [V] [TRT] Tactic: 2 Time: 0.067792
[12/29/2021-03:46:44] [V] [TRT] Tactic: 4 Time: 0.047576
[12/29/2021-03:46:44] [V] [TRT] Tactic: 5 skipped. Scratch requested: 35651584, available: 16777216
[12/29/2021-03:46:44] [V] [TRT] Tactic: 6 Time: 0.027348
[12/29/2021-03:46:44] [V] [TRT] Tactic: 56 Time: 0.035832
[12/29/2021-03:46:44] [V] [TRT] Tactic: 57 Time: 0.032872
[12/29/2021-03:46:44] [V] [TRT] Tactic: 58 Time: 0.067804
[12/29/2021-03:46:44] [V] [TRT] Tactic: 60 Time: 0.047796
[12/29/2021-03:46:44] [V] [TRT] Tactic: 61 skipped. Scratch requested: 35651584, available: 16777216
[12/29/2021-03:46:44] [V] [TRT] Tactic: 62 Time: 0.027368
[12/29/2021-03:46:44] [V] [TRT] Tactic: 112 Time: 0.035988
[12/29/2021-03:46:44] [V] [TRT] Tactic: 113 Time: 0.091552
[12/29/2021-03:46:44] [V] [TRT] Tactic: 114 Time: 0.06788
[12/29/2021-03:46:44] [V] [TRT] Tactic: 116 Time: 0.047576
[12/29/2021-03:46:44] [V] [TRT] Tactic: 117 skipped. Scratch requested: 35651584, available: 16777216
[12/29/2021-03:46:44] [V] [TRT] Tactic: 118 Time: 0.027348
[12/29/2021-03:46:44] [I] [TRT] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.
[12/29/2021-03:46:44] [V] [TRT] Fastest Tactic: 118 Time: 0.027348
[12/29/2021-03:46:44] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CaskConvolution)
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:46:44] [V] [TRT] Tactic: 4549827808004681195 Time: 0.062884
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:46:44] [V] [TRT] Tactic: 5779835512569528575 Time: 0.079968
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[12/29/2021-03:46:44] [V] [TRT] Tactic: 6053873026024413720 Time: 0.089268
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[12/29/2021-03:46:44] [V] [TRT] Tactic: 6767548733843469815 Time: 0.068568
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:46:44] [V] [TRT] Tactic: -6313876406580483184 Time: 0.075428
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:46:44] [V] [TRT] Tactic: -1123676555321336786 Time: 0.087588
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:46:44] [V] [TRT] Tactic: -701551393537224327 Time: 0.076932
[12/29/2021-03:46:44] [V] [TRT] Fastest Tactic: 4549827808004681195 Time: 0.062884
[12/29/2021-03:46:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 118
[12/29/2021-03:46:44] [V] [TRT] *************** Autotuning format combination: Float(4096,1,512,64) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:44] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CudnnConvolution)
[12/29/2021-03:46:44] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:44] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CaskConvolution)
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:46:44] [V] [TRT] Tactic: 2860655430572478466 Time: 0.0489
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:46:44] [V] [TRT] Tactic: 4474630279712975759 Time: 0.03038
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:46:44] [V] [TRT] Tactic: 4479823862704990365 Time: 0.029736
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:46:44] [V] [TRT] Tactic: 4696204239951173149 Time: 0.049764
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:46:44] [V] [TRT] Tactic: 5778138195697110003 Time: 0.078912
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:46:44] [V] [TRT] Tactic: 7155825427510256858 Time: 0.079376
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:46:44] [V] [TRT] Tactic: 8918020581761223752 Time: 0.077604
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:46:44] [V] [TRT] Tactic: -4756382386362004279 Time: 0.04896
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:46:44] [V] [TRT] Tactic: -3855385237722507464 Time: 0.08044
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:46:44] [V] [TRT] Tactic: -2809379259463049391 Time: 0.07914
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:46:44] [V] [TRT] Tactic: -504296718212024303 Time: 0.076652
[12/29/2021-03:46:44] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.029736
[12/29/2021-03:46:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:46:44] [V] [TRT] *************** Autotuning format combination: Float(1024,1:4,128,16) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:44] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CudnnConvolution)
[12/29/2021-03:46:44] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:44] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CaskConvolution)
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:46:44] [V] [TRT] Tactic: 2860655430572478466 Time: 0.04896
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:46:44] [V] [TRT] Tactic: 4474630279712975759 Time: 0.03036
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:46:44] [V] [TRT] Tactic: 4479823862704990365 Time: 0.029652
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:46:44] [V] [TRT] Tactic: 4696204239951173149 Time: 0.049784
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:46:44] [V] [TRT] Tactic: 5778138195697110003 Time: 0.078924
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:46:44] [V] [TRT] Tactic: 7155825427510256858 Time: 0.0793
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:46:44] [V] [TRT] Tactic: 7342025736444949634 Time: 0.054392
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:46:44] [V] [TRT] Tactic: 8918020581761223752 Time: 0.07778
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:46:44] [V] [TRT] Tactic: -7377458734869418330 Time: 0.05376
[12/29/2021-03:46:44] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:46:45] [V] [TRT] Tactic: -5457304872213719461 Time: 0.054492
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:46:45] [V] [TRT] Tactic: -4756382386362004279 Time: 0.048812
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:46:45] [V] [TRT] Tactic: -3855385237722507464 Time: 0.080288
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:46:45] [V] [TRT] Tactic: -2809379259463049391 Time: 0.078956
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:46:45] [V] [TRT] Tactic: -504296718212024303 Time: 0.076584
[12/29/2021-03:46:45] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.029652
[12/29/2021-03:46:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:46:45] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:45] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CudaDepthwiseConvolution)
[12/29/2021-03:46:45] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:45] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CaskConvolution)
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 1332468635798226953
[12/29/2021-03:46:45] [V] [TRT] Tactic: 1332468635798226953 Time: 0.034992
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:46:45] [V] [TRT] Tactic: 1508480131241957639 Time: 0.033164
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 1947019689364377201
[12/29/2021-03:46:45] [V] [TRT] Tactic: 1947019689364377201 Time: 0.025096
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:46:45] [V] [TRT] Tactic: 3239257003214966313 Time: 0.03478
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:46:45] [V] [TRT] Tactic: 5592640619112287921 Time: 0.022268
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:46:45] [V] [TRT] Tactic: 7621465827583909090 Time: 0.02324
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:46:45] [V] [TRT] Tactic: -5576936487443445631 Time: 0.026952
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:46:45] [V] [TRT] Tactic: -2297737319934264721 Time: 0.030608
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:46:45] [V] [TRT] Tactic: -1425085658556684465 Time: 0.028872
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:46:45] [V] [TRT] Tactic: -108011214168778087 Time: 0.0257
[12/29/2021-03:46:45] [V] [TRT] Fastest Tactic: 5592640619112287921 Time: 0.022268
[12/29/2021-03:46:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5592640619112287921
[12/29/2021-03:46:45] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:45] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CudaDepthwiseConvolution)
[12/29/2021-03:46:45] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:45] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (FusedConvActConvolution)
[12/29/2021-03:46:45] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:45] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CaskConvolution)
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:46:45] [V] [TRT] Tactic: 175853789719975416 Time: 0.028476
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:46:45] [V] [TRT] Tactic: 2171150287007712632 Time: 0.026688
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:46:45] [V] [TRT] Tactic: 2234457234705232274 Time: 0.020864
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:46:45] [V] [TRT] Tactic: 5834048089706882838 Time: 0.024608
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:46:45] [V] [TRT] Tactic: -8626990807754934295 Time: 0.023812
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:46:45] [V] [TRT] Tactic: -7303593854972602201 Time: 0.0202
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:46:45] [V] [TRT] Tactic: -6585664687867083638 Time: 0.031992
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: -3730012925709297561
[12/29/2021-03:46:45] [V] [TRT] Tactic: -3730012925709297561 Time: 0.02286
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: -2277259417488004546
[12/29/2021-03:46:45] [V] [TRT] Tactic: -2277259417488004546 Time: 0.032252
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:46:45] [V] [TRT] Tactic: -683636008127039856 Time: 0.030368
[12/29/2021-03:46:45] [V] [TRT] Fastest Tactic: -7303593854972602201 Time: 0.0202
[12/29/2021-03:46:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7303593854972602201
[12/29/2021-03:46:45] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:45] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CaskConvolution)
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 984309058095623735
[12/29/2021-03:46:45] [V] [TRT] Tactic: 984309058095623735 Time: 0.022648
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:46:45] [V] [TRT] Tactic: 1100922622480907544 Time: 0.02352
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 3238312825609165543
[12/29/2021-03:46:45] [V] [TRT] Tactic: 3238312825609165543 Time: 0.032132
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:46:45] [V] [TRT] Tactic: 3606311198834416176 Time: 0.02444
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:46:45] [V] [TRT] Tactic: 4325765560739862899 Time: 0.03036
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:46:45] [V] [TRT] Tactic: -4255737803793506479 Time: 0.031756
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:46:45] [V] [TRT] Tactic: -3958182351168863467 Time: 0.020016
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:46:45] [V] [TRT] Tactic: -3111968753064955248 Time: 0.026456
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:46:45] [V] [TRT] Tactic: -1492575840277333548 Time: 0.02834
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:46:45] [V] [TRT] Tactic: -868495160148524802 Time: 0.02074
[12/29/2021-03:46:45] [V] [TRT] Fastest Tactic: -3958182351168863467 Time: 0.020016
[12/29/2021-03:46:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3958182351168863467
[12/29/2021-03:46:45] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:45] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CaskConvolution)
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:46:45] [V] [TRT] Tactic: 1011019097971850911 Time: 0.0149
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:46:45] [V] [TRT] Tactic: 1071114551801767124 Time: 0.009632
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:46:45] [V] [TRT] Tactic: 2623576043214044314 Time: 0.008932
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:46:45] [V] [TRT] Tactic: 3281631721811475881 Time: 0.008824
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:46:45] [V] [TRT] Tactic: 4551754795416974366 Time: 0.008612
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:46:45] [V] [TRT] Tactic: 4925112190271421402 Time: 0.009136
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:46:45] [V] [TRT] Tactic: 5012796702462679112 Time: 0.020356
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:46:45] [V] [TRT] Tactic: 5041593333398049019 Time: 0.008548
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:46:45] [V] [TRT] Tactic: 5166018662410176512 Time: 0.020776
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:46:45] [V] [TRT] Tactic: 6191867932654611882 Time: 0.0127
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:46:45] [V] [TRT] Tactic: 6556170942941957134 Time: 0.015104
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:46:45] [V] [TRT] Tactic: 6852868042694587230 Time: 0.008924
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:46:45] [V] [TRT] Tactic: 8399092794516815300 Time: 0.019324
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:46:45] [V] [TRT] Tactic: -9132922677633967263 Time: 0.010044
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:46:45] [V] [TRT] Tactic: -7988637803896331454 Time: 0.014228
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: -7865001268126363229
[12/29/2021-03:46:45] [V] [TRT] Tactic: -7865001268126363229 Time: 0.017008
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:46:45] [V] [TRT] Tactic: -7606074703023778034 Time: 0.014548
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:46:45] [V] [TRT] Tactic: -7413564913826321357 Time: 0.015276
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:46:45] [V] [TRT] Tactic: -7282232519526877434 Time: 0.01992
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:46:45] [V] [TRT] Tactic: -5942379529065248478 Time: 0.010392
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:46:45] [V] [TRT] Tactic: -5603587790314027122 Time: 0.016268
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:46:45] [V] [TRT] Tactic: -5334776871777565833 Time: 0.021348
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:46:45] [V] [TRT] Tactic: -5157868397078537095 Time: 0.013308
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:46:45] [V] [TRT] Tactic: -5100834417027499764 Time: 0.008076
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:46:45] [V] [TRT] Tactic: -3365360067423513506 Time: 0.008444
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2194148180068068313
[12/29/2021-03:46:45] [V] [TRT] Tactic: -2194148180068068313 Time: 0.020432
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:46:45] [V] [TRT] Tactic: -1782593837177056527 Time: 0.010752
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:46:45] [V] [TRT] Tactic: -1610768292520086910 Time: 0.0153
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:46:45] [V] [TRT] Tactic: -1573035963956198975 Time: 0.018824
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -1558762241666006941
[12/29/2021-03:46:45] [V] [TRT] Tactic: -1558762241666006941 Time: 0.015532
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -1365353082499976145
[12/29/2021-03:46:45] [V] [TRT] Tactic: -1365353082499976145 Time: 0.016732
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:46:45] [V] [TRT] Tactic: -621838502160440068 Time: 0.016448
[12/29/2021-03:46:45] [V] [TRT] Fastest Tactic: -5100834417027499764 Time: 0.008076
[12/29/2021-03:46:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -5100834417027499764
[12/29/2021-03:46:45] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:45] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CudaGroupConvolution)
[12/29/2021-03:46:45] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:45] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CudaDepthwiseConvolution)
[12/29/2021-03:46:45] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:45] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (FusedConvActConvolution)
[12/29/2021-03:46:45] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:45] [V] [TRT] --------------- Timing Runner: Conv_11 + Relu_14 (CaskConvolution)
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 177040020707947851
[12/29/2021-03:46:45] [V] [TRT] Tactic: 177040020707947851 Time: 0.008332
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 1550399266192842845
[12/29/2021-03:46:45] [V] [TRT] Tactic: 1550399266192842845 Time: 0.008592
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 1572887561103143487
[12/29/2021-03:46:45] [V] [TRT] Tactic: 1572887561103143487 Time: 0.00966
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:46:45] [V] [TRT] Tactic: 2325023763229477890 Time: 0.01298
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 2985940154541537814
[12/29/2021-03:46:45] [V] [TRT] Tactic: 2985940154541537814 Time: 0.015164
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:46:45] [V] [TRT] Tactic: 3284282970967328046 Time: 0.00806
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:46:45] [V] [TRT] Tactic: 3401614690060226673 Time: 0.007876
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3512426920013359699
[12/29/2021-03:46:45] [V] [TRT] Tactic: 3512426920013359699 Time: 0.007972
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 3899284354987683408
[12/29/2021-03:46:45] [V] [TRT] Tactic: 3899284354987683408 Time: 0.020872
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:46:45] [V] [TRT] Tactic: 4042202769383439184 Time: 0.009708
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: 4182625619810185112
[12/29/2021-03:46:45] [V] [TRT] Tactic: 4182625619810185112 Time: 0.016916
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 4259547356717612415
[12/29/2021-03:46:45] [V] [TRT] Tactic: 4259547356717612415 Time: 0.01016
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: 4717285412741024953
[12/29/2021-03:46:45] [V] [TRT] Tactic: 4717285412741024953 Time: 0.015244
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:46:45] [V] [TRT] Tactic: 4734519122557206480 Time: 0.018952
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 5121596860264626879
[12/29/2021-03:46:45] [V] [TRT] Tactic: 5121596860264626879 Time: 0.019108
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:46:45] [V] [TRT] Tactic: 5136656982162849059 Time: 0.007988
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 5158259316594207439
[12/29/2021-03:46:45] [V] [TRT] Tactic: 5158259316594207439 Time: 0.00972
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 5966973378912044513
[12/29/2021-03:46:45] [V] [TRT] Tactic: 5966973378912044513 Time: 0.012592
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:46:45] [V] [TRT] Tactic: 6004789655466615912 Time: 0.009684
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:46:45] [V] [TRT] Tactic: 6146901278630392829 Time: 0.018528
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 6434020722187266170
[12/29/2021-03:46:45] [V] [TRT] Tactic: 6434020722187266170 Time: 0.019228
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:46:45] [V] [TRT] Tactic: 6781129591847482048 Time: 0.009856
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7191893591576074000
[12/29/2021-03:46:45] [V] [TRT] Tactic: 7191893591576074000 Time: 0.008292
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7438984192263206338
[12/29/2021-03:46:45] [V] [TRT] Tactic: 7438984192263206338 Time: 0.009156
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 7504901284678552178
[12/29/2021-03:46:45] [V] [TRT] Tactic: 7504901284678552178 Time: 0.0126
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:46:45] [V] [TRT] Tactic: 8096257414008860171 Time: 0.009428
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 9143438935315839085
[12/29/2021-03:46:45] [V] [TRT] Tactic: 9143438935315839085 Time: 0.007872
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:46:45] [V] [TRT] Tactic: -9165697322068360861 Time: 0.01934
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -9118785798277698619
[12/29/2021-03:46:45] [V] [TRT] Tactic: -9118785798277698619 Time: 0.014528
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:46:45] [V] [TRT] Tactic: -8263994888336646547 Time: 0.012492
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:46:45] [V] [TRT] Tactic: -8205948405243401049 Time: 0.008416
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -7992068592656168418
[12/29/2021-03:46:45] [V] [TRT] Tactic: -7992068592656168418 Time: 0.009248
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: -7842775553137511386
[12/29/2021-03:46:45] [V] [TRT] Tactic: -7842775553137511386 Time: 0.01296
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:46:45] [V] [TRT] Tactic: -7683887278997527517 Time: 0.00846
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -6400348606759295499
[12/29/2021-03:46:45] [V] [TRT] Tactic: -6400348606759295499 Time: 0.014264
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -5980889159865208399
[12/29/2021-03:46:45] [V] [TRT] Tactic: -5980889159865208399 Time: 0.020552
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5766140806760372989
[12/29/2021-03:46:45] [V] [TRT] Tactic: -5766140806760372989 Time: 0.01604
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5709079507616090666
[12/29/2021-03:46:45] [V] [TRT] Tactic: -5709079507616090666 Time: 0.012276
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5698636014239116282
[12/29/2021-03:46:45] [V] [TRT] Tactic: -5698636014239116282 Time: 0.018568
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:46:45] [V] [TRT] Tactic: -4933563390723451692 Time: 0.008064
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -4516822589357530549
[12/29/2021-03:46:45] [V] [TRT] Tactic: -4516822589357530549 Time: 0.016148
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -3413217501222406256
[12/29/2021-03:46:45] [V] [TRT] Tactic: -3413217501222406256 Time: 0.018768
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:46:45] [V] [TRT] Tactic: -3238475748440751107 Time: 0.009212
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:46:45] [V] [TRT] Tactic: -3182884991006484042 Time: 0.01278
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:46:45] [V] [TRT] Tactic: -3173468756112541306 Time: 0.008408
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2917455979290586480
[12/29/2021-03:46:45] [V] [TRT] Tactic: -2917455979290586480 Time: 0.020888
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -2571022005763160364
[12/29/2021-03:46:45] [V] [TRT] Tactic: -2571022005763160364 Time: 0.015584
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -2083778562631872334
[12/29/2021-03:46:45] [V] [TRT] Tactic: -2083778562631872334 Time: 0.009712
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:46:45] [V] [TRT] Tactic: -1546787387293556842 Time: 0.012328
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:46:45] [V] [TRT] Tactic: -1498626619443284096 Time: 0.010324
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:46:45] [V] [TRT] Tactic: -1283580231568512025 Time: 0.008392
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: -1173968681844185579
[12/29/2021-03:46:45] [V] [TRT] Tactic: -1173968681844185579 Time: 0.0084
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:46:45] [V] [TRT] Tactic: -762222380308749469 Time: 0.008436
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -556794153877490941
[12/29/2021-03:46:45] [V] [TRT] Tactic: -556794153877490941 Time: 0.008292
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:46:45] [V] [TRT] Tactic: -516725800067794372 Time: 0.018604
[12/29/2021-03:46:45] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -428104331444385564
[12/29/2021-03:46:46] [V] [TRT] Tactic: -428104331444385564 Time: 0.016496
[12/29/2021-03:46:46] [V] [TRT] Fastest Tactic: 9143438935315839085 Time: 0.007872
[12/29/2021-03:46:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 9143438935315839085
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:46] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:46] [V] [TRT] Tactic: 1002 Time: 0.008288
[12/29/2021-03:46:46] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:46] [V] [TRT] Tactic: 0 Time: 0.00926
[12/29/2021-03:46:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.008288
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:46] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:46] [V] [TRT] Tactic: 1002 Time: 0.008132
[12/29/2021-03:46:46] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:46] [V] [TRT] Tactic: 0 Time: 0.009608
[12/29/2021-03:46:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.008132
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:46] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:46] [V] [TRT] Tactic: 1002 Time: 0.007264
[12/29/2021-03:46:46] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:46] [V] [TRT] Tactic: 0 Time: 0.009808
[12/29/2021-03:46:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.007264
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:46] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:46] [V] [TRT] Tactic: 1002 Time: 0.008376
[12/29/2021-03:46:46] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:46] [V] [TRT] Tactic: 0 Time: 0.009624
[12/29/2021-03:46:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.008376
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:46] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:46] [V] [TRT] Tactic: 1002 Time: 0.008004
[12/29/2021-03:46:46] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:46] [V] [TRT] Tactic: 0 Time: 0.009556
[12/29/2021-03:46:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.008004
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning format combination: Float(4096,64,8,1), Float(4096,64,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CudaDepthwiseConvolution)
[12/29/2021-03:46:46] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (FusedConvActConvolution)
[12/29/2021-03:46:46] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CudnnConvolution)
[12/29/2021-03:46:46] [V] [TRT] Tactic: 0 Time: 0.0389
[12/29/2021-03:46:46] [V] [TRT] Tactic: 1 Time: 0.07458
[12/29/2021-03:46:46] [V] [TRT] Tactic: 2 Time: 0.07802
[12/29/2021-03:46:46] [V] [TRT] Tactic: 4 Time: 0.051344
[12/29/2021-03:46:46] [V] [TRT] Tactic: 5 skipped. Scratch requested: 35651584, available: 16777216
[12/29/2021-03:46:46] [V] [TRT] Tactic: 6 Time: 0.030092
[12/29/2021-03:46:46] [V] [TRT] Tactic: 56 Time: 0.038748
[12/29/2021-03:46:46] [V] [TRT] Tactic: 57 Time: 0.071332
[12/29/2021-03:46:46] [V] [TRT] Tactic: 58 Time: 0.077964
[12/29/2021-03:46:46] [V] [TRT] Tactic: 60 Time: 0.050908
[12/29/2021-03:46:46] [V] [TRT] Tactic: 61 skipped. Scratch requested: 35651584, available: 16777216
[12/29/2021-03:46:46] [V] [TRT] Tactic: 62 Time: 0.030012
[12/29/2021-03:46:46] [V] [TRT] Tactic: 112 Time: 0.038796
[12/29/2021-03:46:46] [V] [TRT] Tactic: 113 Time: 0.104328
[12/29/2021-03:46:46] [V] [TRT] Tactic: 114 Time: 0.077944
[12/29/2021-03:46:46] [V] [TRT] Tactic: 116 Time: 0.05098
[12/29/2021-03:46:46] [V] [TRT] Tactic: 117 skipped. Scratch requested: 35651584, available: 16777216
[12/29/2021-03:46:46] [V] [TRT] Tactic: 118 Time: 0.030212
[12/29/2021-03:46:46] [V] [TRT] Fastest Tactic: 62 Time: 0.030012
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CaskConvolution)
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:46:46] [V] [TRT] Tactic: 4549827808004681195 Time: 0.064068
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:46:46] [V] [TRT] Tactic: 5779835512569528575 Time: 0.080992
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[12/29/2021-03:46:46] [V] [TRT] Tactic: 6053873026024413720 Time: 0.090468
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[12/29/2021-03:46:46] [V] [TRT] Tactic: 6767548733843469815 Time: 0.06982
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:46:46] [V] [TRT] Tactic: -6313876406580483184 Time: 0.076452
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:46:46] [V] [TRT] Tactic: -1123676555321336786 Time: 0.088828
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:46:46] [V] [TRT] Tactic: -701551393537224327 Time: 0.077788
[12/29/2021-03:46:46] [V] [TRT] Fastest Tactic: 4549827808004681195 Time: 0.064068
[12/29/2021-03:46:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 62
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning format combination: Float(4096,1,512,64), Float(4096,1,512,64) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CudnnConvolution)
[12/29/2021-03:46:46] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CaskConvolution)
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:46:46] [V] [TRT] Tactic: 2860655430572478466 Time: 0.049968
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:46:46] [V] [TRT] Tactic: 4474630279712975759 Time: 0.03136
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:46:46] [V] [TRT] Tactic: 4479823862704990365 Time: 0.03076
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:46:46] [V] [TRT] Tactic: 4696204239951173149 Time: 0.050864
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:46:46] [V] [TRT] Tactic: 5778138195697110003 Time: 0.079596
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:46:46] [V] [TRT] Tactic: 7155825427510256858 Time: 0.079892
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:46:46] [V] [TRT] Tactic: 8918020581761223752 Time: 0.078424
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:46:46] [V] [TRT] Tactic: -4756382386362004279 Time: 0.05004
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:46:46] [V] [TRT] Tactic: -3855385237722507464 Time: 0.0811
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:46:46] [V] [TRT] Tactic: -2809379259463049391 Time: 0.0799
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:46:46] [V] [TRT] Tactic: -504296718212024303 Time: 0.077368
[12/29/2021-03:46:46] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.03076
[12/29/2021-03:46:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning format combination: Float(1024,1:4,128,16), Float(1024,1:4,128,16) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CudnnConvolution)
[12/29/2021-03:46:46] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CaskConvolution)
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:46:46] [V] [TRT] Tactic: 2860655430572478466 Time: 0.050116
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:46:46] [V] [TRT] Tactic: 4474630279712975759 Time: 0.031384
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:46:46] [V] [TRT] Tactic: 4479823862704990365 Time: 0.030768
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:46:46] [V] [TRT] Tactic: 4696204239951173149 Time: 0.050716
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:46:46] [V] [TRT] Tactic: 5778138195697110003 Time: 0.07952
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:46:46] [V] [TRT] Tactic: 7155825427510256858 Time: 0.079788
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:46:46] [V] [TRT] Tactic: 7342025736444949634 Time: 0.055796
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:46:46] [V] [TRT] Tactic: 8918020581761223752 Time: 0.078292
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:46:46] [V] [TRT] Tactic: -7377458734869418330 Time: 0.055016
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:46:46] [V] [TRT] Tactic: -5457304872213719461 Time: 0.055672
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:46:46] [V] [TRT] Tactic: -4756382386362004279 Time: 0.0499
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:46:46] [V] [TRT] Tactic: -3855385237722507464 Time: 0.080872
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:46:46] [V] [TRT] Tactic: -2809379259463049391 Time: 0.07952
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:46:46] [V] [TRT] Tactic: -504296718212024303 Time: 0.07724
[12/29/2021-03:46:46] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.030768
[12/29/2021-03:46:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1), Float(4096,64,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CudaDepthwiseConvolution)
[12/29/2021-03:46:46] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CaskConvolution)
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 1332468635798226953
[12/29/2021-03:46:46] [V] [TRT] Tactic: 1332468635798226953 Time: 0.035928
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:46:46] [V] [TRT] Tactic: 1508480131241957639 Time: 0.034184
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 1947019689364377201
[12/29/2021-03:46:46] [V] [TRT] Tactic: 1947019689364377201 Time: 0.026152
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:46:46] [V] [TRT] Tactic: 3239257003214966313 Time: 0.035748
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:46:46] [V] [TRT] Tactic: 5592640619112287921 Time: 0.023352
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:46:46] [V] [TRT] Tactic: 7621465827583909090 Time: 0.024288
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:46:46] [V] [TRT] Tactic: -5576936487443445631 Time: 0.02802
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:46:46] [V] [TRT] Tactic: -2297737319934264721 Time: 0.031672
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:46:46] [V] [TRT] Tactic: -1425085658556684465 Time: 0.029988
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:46:46] [V] [TRT] Tactic: -108011214168778087 Time: 0.026892
[12/29/2021-03:46:46] [V] [TRT] Fastest Tactic: 5592640619112287921 Time: 0.023352
[12/29/2021-03:46:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5592640619112287921
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1), Int8(1024,64:4,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CudaDepthwiseConvolution)
[12/29/2021-03:46:46] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (FusedConvActConvolution)
[12/29/2021-03:46:46] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CaskConvolution)
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:46:46] [V] [TRT] Tactic: 175853789719975416 Time: 0.029968
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:46:46] [V] [TRT] Tactic: 2171150287007712632 Time: 0.028348
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:46:46] [V] [TRT] Tactic: 2234457234705232274 Time: 0.022516
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:46:46] [V] [TRT] Tactic: 5834048089706882838 Time: 0.026068
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:46:46] [V] [TRT] Tactic: -8626990807754934295 Time: 0.025236
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:46:46] [V] [TRT] Tactic: -7303593854972602201 Time: 0.02174
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:46:46] [V] [TRT] Tactic: -6585664687867083638 Time: 0.033632
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: -3730012925709297561
[12/29/2021-03:46:46] [V] [TRT] Tactic: -3730012925709297561 Time: 0.024208
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: -2277259417488004546
[12/29/2021-03:46:46] [V] [TRT] Tactic: -2277259417488004546 Time: 0.033896
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:46:46] [V] [TRT] Tactic: -683636008127039856 Time: 0.032
[12/29/2021-03:46:46] [V] [TRT] Fastest Tactic: -7303593854972602201 Time: 0.02174
[12/29/2021-03:46:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7303593854972602201
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1), Int8(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CaskConvolution)
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 984309058095623735
[12/29/2021-03:46:46] [V] [TRT] Tactic: 984309058095623735 Time: 0.024188
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:46:46] [V] [TRT] Tactic: 1100922622480907544 Time: 0.025296
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 3238312825609165543
[12/29/2021-03:46:46] [V] [TRT] Tactic: 3238312825609165543 Time: 0.033824
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:46:46] [V] [TRT] Tactic: 3606311198834416176 Time: 0.026272
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:46:46] [V] [TRT] Tactic: 4325765560739862899 Time: 0.031948
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:46:46] [V] [TRT] Tactic: -4255737803793506479 Time: 0.033516
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:46:46] [V] [TRT] Tactic: -3958182351168863467 Time: 0.0218
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:46:46] [V] [TRT] Tactic: -3111968753064955248 Time: 0.028136
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:46:46] [V] [TRT] Tactic: -1492575840277333548 Time: 0.029924
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:46:46] [V] [TRT] Tactic: -868495160148524802 Time: 0.02258
[12/29/2021-03:46:46] [V] [TRT] Fastest Tactic: -3958182351168863467 Time: 0.0218
[12/29/2021-03:46:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3958182351168863467
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1), Float(128,64:32,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CaskConvolution)
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:46:46] [V] [TRT] Tactic: 1011019097971850911 Time: 0.01586
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:46:46] [V] [TRT] Tactic: 1071114551801767124 Time: 0.010316
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:46:46] [V] [TRT] Tactic: 2623576043214044314 Time: 0.009088
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:46:46] [V] [TRT] Tactic: 3281631721811475881 Time: 0.009036
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:46:46] [V] [TRT] Tactic: 4551754795416974366 Time: 0.009256
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:46:46] [V] [TRT] Tactic: 4925112190271421402 Time: 0.0088
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:46:46] [V] [TRT] Tactic: 5012796702462679112 Time: 0.0219
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:46:46] [V] [TRT] Tactic: 5041593333398049019 Time: 0.008592
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:46:46] [V] [TRT] Tactic: 5166018662410176512 Time: 0.021532
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:46:46] [V] [TRT] Tactic: 6191867932654611882 Time: 0.014108
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:46:46] [V] [TRT] Tactic: 6556170942941957134 Time: 0.015952
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:46:46] [V] [TRT] Tactic: 6852868042694587230 Time: 0.009384
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:46:46] [V] [TRT] Tactic: 8399092794516815300 Time: 0.020876
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:46:46] [V] [TRT] Tactic: -9132922677633967263 Time: 0.01076
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:46:46] [V] [TRT] Tactic: -7988637803896331454 Time: 0.01512
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: -7865001268126363229
[12/29/2021-03:46:46] [V] [TRT] Tactic: -7865001268126363229 Time: 0.018504
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:46:46] [V] [TRT] Tactic: -7606074703023778034 Time: 0.016048
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:46:46] [V] [TRT] Tactic: -7413564913826321357 Time: 0.01606
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:46:46] [V] [TRT] Tactic: -7282232519526877434 Time: 0.021388
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:46:46] [V] [TRT] Tactic: -5942379529065248478 Time: 0.0111
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:46:46] [V] [TRT] Tactic: -5603587790314027122 Time: 0.017712
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:46:46] [V] [TRT] Tactic: -5334776871777565833 Time: 0.022048
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:46:46] [V] [TRT] Tactic: -5157868397078537095 Time: 0.014416
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:46:46] [V] [TRT] Tactic: -5100834417027499764 Time: 0.008532
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:46:46] [V] [TRT] Tactic: -3365360067423513506 Time: 0.008436
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2194148180068068313
[12/29/2021-03:46:46] [V] [TRT] Tactic: -2194148180068068313 Time: 0.021804
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:46:46] [V] [TRT] Tactic: -1782593837177056527 Time: 0.01146
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:46:46] [V] [TRT] Tactic: -1610768292520086910 Time: 0.016728
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:46:46] [V] [TRT] Tactic: -1573035963956198975 Time: 0.020332
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -1558762241666006941
[12/29/2021-03:46:46] [V] [TRT] Tactic: -1558762241666006941 Time: 0.01646
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -1365353082499976145
[12/29/2021-03:46:46] [V] [TRT] Tactic: -1365353082499976145 Time: 0.018048
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:46:46] [V] [TRT] Tactic: -621838502160440068 Time: 0.017916
[12/29/2021-03:46:46] [V] [TRT] Fastest Tactic: -3365360067423513506 Time: 0.008436
[12/29/2021-03:46:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3365360067423513506
[12/29/2021-03:46:46] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1), Int8(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CudaGroupConvolution)
[12/29/2021-03:46:46] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CudaDepthwiseConvolution)
[12/29/2021-03:46:46] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (FusedConvActConvolution)
[12/29/2021-03:46:46] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:46] [V] [TRT] --------------- Timing Runner: Conv_17 + Add_18 + Relu_21 (CaskConvolution)
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:46:46] [V] [TRT] Tactic: 2325023763229477890 Time: 0.013856
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 2985940154541537814
[12/29/2021-03:46:46] [V] [TRT] Tactic: 2985940154541537814 Time: 0.01616
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:46:46] [V] [TRT] Tactic: 3401614690060226673 Time: 0.00848
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 3899284354987683408
[12/29/2021-03:46:46] [V] [TRT] Tactic: 3899284354987683408 Time: 0.022708
[12/29/2021-03:46:46] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:46:47] [V] [TRT] Tactic: 4042202769383439184 Time: 0.010172
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: 4182625619810185112
[12/29/2021-03:46:47] [V] [TRT] Tactic: 4182625619810185112 Time: 0.018044
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: 4717285412741024953
[12/29/2021-03:46:47] [V] [TRT] Tactic: 4717285412741024953 Time: 0.016272
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:46:47] [V] [TRT] Tactic: 4734519122557206480 Time: 0.019696
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:46:47] [V] [TRT] Tactic: 5136656982162849059 Time: 0.008268
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:46:47] [V] [TRT] Tactic: 6004789655466615912 Time: 0.010492
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:46:47] [V] [TRT] Tactic: 6146901278630392829 Time: 0.019304
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:46:47] [V] [TRT] Tactic: 6781129591847482048 Time: 0.01058
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:46:47] [V] [TRT] Tactic: 8096257414008860171 Time: 0.010184
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:46:47] [V] [TRT] Tactic: -9165697322068360861 Time: 0.020212
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -9118785798277698619
[12/29/2021-03:46:47] [V] [TRT] Tactic: -9118785798277698619 Time: 0.01548
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:46:47] [V] [TRT] Tactic: -8263994888336646547 Time: 0.013292
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:46:47] [V] [TRT] Tactic: -8205948405243401049 Time: 0.009
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:46:47] [V] [TRT] Tactic: -7683887278997527517 Time: 0.008728
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -6400348606759295499
[12/29/2021-03:46:47] [V] [TRT] Tactic: -6400348606759295499 Time: 0.01538
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -5980889159865208399
[12/29/2021-03:46:47] [V] [TRT] Tactic: -5980889159865208399 Time: 0.02238
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5766140806760372989
[12/29/2021-03:46:47] [V] [TRT] Tactic: -5766140806760372989 Time: 0.017196
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:46:47] [V] [TRT] Tactic: -4933563390723451692 Time: 0.008772
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -4516822589357530549
[12/29/2021-03:46:47] [V] [TRT] Tactic: -4516822589357530549 Time: 0.017264
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:46:47] [V] [TRT] Tactic: -3238475748440751107 Time: 0.009972
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:46:47] [V] [TRT] Tactic: -3182884991006484042 Time: 0.013668
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:46:47] [V] [TRT] Tactic: -3173468756112541306 Time: 0.0085
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2917455979290586480
[12/29/2021-03:46:47] [V] [TRT] Tactic: -2917455979290586480 Time: 0.022756
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -2571022005763160364
[12/29/2021-03:46:47] [V] [TRT] Tactic: -2571022005763160364 Time: 0.01666
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:46:47] [V] [TRT] Tactic: -1546787387293556842 Time: 0.013036
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:46:47] [V] [TRT] Tactic: -1498626619443284096 Time: 0.011168
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:46:47] [V] [TRT] Tactic: -1283580231568512025 Time: 0.008752
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:46:47] [V] [TRT] Tactic: -762222380308749469 Time: 0.00882
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:46:47] [V] [TRT] Tactic: -516725800067794372 Time: 0.019576
[12/29/2021-03:46:47] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -428104331444385564
[12/29/2021-03:46:47] [V] [TRT] Tactic: -428104331444385564 Time: 0.017604
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 5136656982162849059 Time: 0.008268
[12/29/2021-03:46:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5136656982162849059
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.008232
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.00602
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 0 Time: 0.00602
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.00826
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.006148
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 0 Time: 0.006148
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.008328
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.00918
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.008328
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.007056
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.004708
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 0 Time: 0.004708
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.00706
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.007364
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.00706
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.008576
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.005976
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 0 Time: 0.005976
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.007136
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.005696
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 0 Time: 0.005696
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.008232
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.00966
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.008232
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.007368
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.006256
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 0 Time: 0.006256
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.007496
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.008036
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.007496
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.008464
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.006004
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 0 Time: 0.006004
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.007104
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.005704
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 0 Time: 0.005704
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.007108
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.00972
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.007108
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.0085
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.006304
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 0 Time: 0.006304
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.008472
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.008108
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 0 Time: 0.008108
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.008536
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.006092
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 0 Time: 0.006092
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.008356
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.00576
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 0 Time: 0.00576
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.007224
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.006004
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 0 Time: 0.006004
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.007768
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.006424
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 0 Time: 0.006424
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.007812
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.008156
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.007812
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.00782
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.005028
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 0 Time: 0.005028
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.007884
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.006228
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 0 Time: 0.006228
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.008704
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.006468
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 0 Time: 0.006468
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.00816
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.009616
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.00816
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1002 Time: 0.007156
[12/29/2021-03:46:47] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.005296
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 0 Time: 0.005296
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning format combination: Float(4096,64,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning format combination: Float(4096,1,512,64) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning format combination: Float(1024,1:4,128,16) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning format combination: Float(4096,64,8,1), Float(4096,64,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning format combination: Float(4096,1,512,64), Float(4096,1,512,64) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning format combination: Float(1024,1:4,128,16), Float(1024,1:4,128,16) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1), Float(4096,64,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1), Int8(1024,64:4,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1), Int8(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1), Float(128,64:32,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1), Int8(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning format combination: Float(4096,64,8,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CudaDepthwiseConvolution)
[12/29/2021-03:46:47] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (FusedConvActConvolution)
[12/29/2021-03:46:47] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CudnnConvolution)
[12/29/2021-03:46:47] [V] [TRT] Tactic: 0 Time: 0.033568
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1 Time: 0.048532
[12/29/2021-03:46:47] [V] [TRT] Tactic: 2 Time: 0.06658
[12/29/2021-03:46:47] [V] [TRT] Tactic: 5 skipped. Scratch requested: 62390272, available: 16777216
[12/29/2021-03:46:47] [V] [TRT] Tactic: 56 Time: 0.033696
[12/29/2021-03:46:47] [V] [TRT] Tactic: 57 Time: 0.061736
[12/29/2021-03:46:47] [V] [TRT] Tactic: 58 Time: 0.066564
[12/29/2021-03:46:47] [V] [TRT] Tactic: 61 skipped. Scratch requested: 62390272, available: 16777216
[12/29/2021-03:46:47] [V] [TRT] Tactic: 112 Time: 0.033652
[12/29/2021-03:46:47] [V] [TRT] Tactic: 113 Time: 0.129568
[12/29/2021-03:46:47] [V] [TRT] Tactic: 114 Time: 0.066616
[12/29/2021-03:46:47] [V] [TRT] Tactic: 117 skipped. Scratch requested: 62390272, available: 16777216
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 0 Time: 0.033568
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CaskConvolution)
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:46:47] [V] [TRT] Tactic: 4549827808004681195 Time: 0.062888
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:46:47] [V] [TRT] Tactic: 5779835512569528575 Time: 0.080248
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[12/29/2021-03:46:47] [V] [TRT] Tactic: 6053873026024413720 Time: 0.08434
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[12/29/2021-03:46:47] [V] [TRT] Tactic: 6767548733843469815 Time: 0.065712
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:46:47] [V] [TRT] Tactic: -6313876406580483184 Time: 0.078204
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:46:47] [V] [TRT] Tactic: -1123676555321336786 Time: 0.083328
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:46:47] [V] [TRT] Tactic: -701551393537224327 Time: 0.071692
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 4549827808004681195 Time: 0.062888
[12/29/2021-03:46:47] [V] [TRT] Setting workspace to 62390272enables more tactics for profiling
[12/29/2021-03:46:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 0
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning format combination: Float(4096,1,512,64) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CudnnConvolution)
[12/29/2021-03:46:47] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CaskConvolution)
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:46:47] [V] [TRT] Tactic: 2860655430572478466 Time: 0.048768
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:46:47] [V] [TRT] Tactic: 4474630279712975759 Time: 0.030056
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:46:47] [V] [TRT] Tactic: 4479823862704990365 Time: 0.029444
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:46:47] [V] [TRT] Tactic: 4696204239951173149 Time: 0.049936
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:46:47] [V] [TRT] Tactic: 5778138195697110003 Time: 0.082556
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:46:47] [V] [TRT] Tactic: 7155825427510256858 Time: 0.078528
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:46:47] [V] [TRT] Tactic: 8918020581761223752 Time: 0.076832
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:46:47] [V] [TRT] Tactic: -4756382386362004279 Time: 0.048964
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:46:47] [V] [TRT] Tactic: -3855385237722507464 Time: 0.082788
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:46:47] [V] [TRT] Tactic: -2809379259463049391 Time: 0.08128
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:46:47] [V] [TRT] Tactic: -504296718212024303 Time: 0.07642
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.029444
[12/29/2021-03:46:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning format combination: Float(1024,1:4,128,16) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CudnnConvolution)
[12/29/2021-03:46:47] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CaskConvolution)
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:46:47] [V] [TRT] Tactic: 2860655430572478466 Time: 0.048868
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:46:47] [V] [TRT] Tactic: 4474630279712975759 Time: 0.029996
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:46:47] [V] [TRT] Tactic: 4479823862704990365 Time: 0.02944
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:46:47] [V] [TRT] Tactic: 4696204239951173149 Time: 0.04986
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:46:47] [V] [TRT] Tactic: 5778138195697110003 Time: 0.082348
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:46:47] [V] [TRT] Tactic: 7155825427510256858 Time: 0.07852
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:46:47] [V] [TRT] Tactic: 7342025736444949634 Time: 0.054416
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:46:47] [V] [TRT] Tactic: 8918020581761223752 Time: 0.07686
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:46:47] [V] [TRT] Tactic: -7377458734869418330 Time: 0.053932
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:46:47] [V] [TRT] Tactic: -5457304872213719461 Time: 0.054628
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:46:47] [V] [TRT] Tactic: -4756382386362004279 Time: 0.048932
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:46:47] [V] [TRT] Tactic: -3855385237722507464 Time: 0.082744
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:46:47] [V] [TRT] Tactic: -2809379259463049391 Time: 0.081232
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:46:47] [V] [TRT] Tactic: -504296718212024303 Time: 0.076448
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.02944
[12/29/2021-03:46:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CudaDepthwiseConvolution)
[12/29/2021-03:46:47] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CaskConvolution)
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 1332468635798226953
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1332468635798226953 Time: 0.034144
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1508480131241957639 Time: 0.033092
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 1947019689364377201
[12/29/2021-03:46:47] [V] [TRT] Tactic: 1947019689364377201 Time: 0.024108
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:46:47] [V] [TRT] Tactic: 3239257003214966313 Time: 0.033792
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:46:47] [V] [TRT] Tactic: 5592640619112287921 Time: 0.022096
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:46:47] [V] [TRT] Tactic: 7621465827583909090 Time: 0.023236
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:46:47] [V] [TRT] Tactic: -5576936487443445631 Time: 0.025488
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:46:47] [V] [TRT] Tactic: -2297737319934264721 Time: 0.029436
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:46:47] [V] [TRT] Tactic: -1425085658556684465 Time: 0.026324
[12/29/2021-03:46:47] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:46:47] [V] [TRT] Tactic: -108011214168778087 Time: 0.026308
[12/29/2021-03:46:47] [V] [TRT] Fastest Tactic: 5592640619112287921 Time: 0.022096
[12/29/2021-03:46:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5592640619112287921
[12/29/2021-03:46:47] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:47] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CudaDepthwiseConvolution)
[12/29/2021-03:46:47] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:48] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (FusedConvActConvolution)
[12/29/2021-03:46:48] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:48] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CaskConvolution)
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:46:48] [V] [TRT] Tactic: 175853789719975416 Time: 0.027276
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:46:48] [V] [TRT] Tactic: 2171150287007712632 Time: 0.024336
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:46:48] [V] [TRT] Tactic: 2234457234705232274 Time: 0.020732
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:46:48] [V] [TRT] Tactic: 5834048089706882838 Time: 0.023372
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:46:48] [V] [TRT] Tactic: -8626990807754934295 Time: 0.024356
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:46:48] [V] [TRT] Tactic: -7303593854972602201 Time: 0.019988
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:46:48] [V] [TRT] Tactic: -6585664687867083638 Time: 0.03106
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: -3730012925709297561
[12/29/2021-03:46:48] [V] [TRT] Tactic: -3730012925709297561 Time: 0.02188
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: -2277259417488004546
[12/29/2021-03:46:48] [V] [TRT] Tactic: -2277259417488004546 Time: 0.03156
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:46:48] [V] [TRT] Tactic: -683636008127039856 Time: 0.030364
[12/29/2021-03:46:48] [V] [TRT] Fastest Tactic: -7303593854972602201 Time: 0.019988
[12/29/2021-03:46:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7303593854972602201
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:48] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CaskConvolution)
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 984309058095623735
[12/29/2021-03:46:48] [V] [TRT] Tactic: 984309058095623735 Time: 0.021752
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:46:48] [V] [TRT] Tactic: 1100922622480907544 Time: 0.02416
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 3238312825609165543
[12/29/2021-03:46:48] [V] [TRT] Tactic: 3238312825609165543 Time: 0.031552
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:46:48] [V] [TRT] Tactic: 3606311198834416176 Time: 0.023068
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:46:48] [V] [TRT] Tactic: 4325765560739862899 Time: 0.0303
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:46:48] [V] [TRT] Tactic: -4255737803793506479 Time: 0.031024
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:46:48] [V] [TRT] Tactic: -3958182351168863467 Time: 0.019888
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:46:48] [V] [TRT] Tactic: -3111968753064955248 Time: 0.024196
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:46:48] [V] [TRT] Tactic: -1492575840277333548 Time: 0.027288
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:46:48] [V] [TRT] Tactic: -868495160148524802 Time: 0.020556
[12/29/2021-03:46:48] [V] [TRT] Fastest Tactic: -3958182351168863467 Time: 0.019888
[12/29/2021-03:46:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3958182351168863467
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:48] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CaskConvolution)
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:46:48] [V] [TRT] Tactic: 1011019097971850911 Time: 0.015096
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:46:48] [V] [TRT] Tactic: 1071114551801767124 Time: 0.010356
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:46:48] [V] [TRT] Tactic: 2623576043214044314 Time: 0.007904
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:46:48] [V] [TRT] Tactic: 3281631721811475881 Time: 0.008452
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:46:48] [V] [TRT] Tactic: 4551754795416974366 Time: 0.00834
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:46:48] [V] [TRT] Tactic: 4925112190271421402 Time: 0.00782
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:46:48] [V] [TRT] Tactic: 5012796702462679112 Time: 0.022284
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:46:48] [V] [TRT] Tactic: 5041593333398049019 Time: 0.007452
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:46:48] [V] [TRT] Tactic: 5166018662410176512 Time: 0.023976
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:46:48] [V] [TRT] Tactic: 6191867932654611882 Time: 0.014476
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:46:48] [V] [TRT] Tactic: 6556170942941957134 Time: 0.015296
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:46:48] [V] [TRT] Tactic: 6852868042694587230 Time: 0.00876
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:46:48] [V] [TRT] Tactic: 8399092794516815300 Time: 0.021108
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:46:48] [V] [TRT] Tactic: -9132922677633967263 Time: 0.010792
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:46:48] [V] [TRT] Tactic: -7988637803896331454 Time: 0.0145
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: -7865001268126363229
[12/29/2021-03:46:48] [V] [TRT] Tactic: -7865001268126363229 Time: 0.017104
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:46:48] [V] [TRT] Tactic: -7606074703023778034 Time: 0.014712
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:46:48] [V] [TRT] Tactic: -7413564913826321357 Time: 0.015444
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:46:48] [V] [TRT] Tactic: -7282232519526877434 Time: 0.02196
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:46:48] [V] [TRT] Tactic: -5942379529065248478 Time: 0.010508
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:46:48] [V] [TRT] Tactic: -5603587790314027122 Time: 0.016016
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:46:48] [V] [TRT] Tactic: -5334776871777565833 Time: 0.024576
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:46:48] [V] [TRT] Tactic: -5157868397078537095 Time: 0.014908
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:46:48] [V] [TRT] Tactic: -5100834417027499764 Time: 0.007704
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:46:48] [V] [TRT] Tactic: -3365360067423513506 Time: 0.007212
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2194148180068068313
[12/29/2021-03:46:48] [V] [TRT] Tactic: -2194148180068068313 Time: 0.022236
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:46:48] [V] [TRT] Tactic: -1782593837177056527 Time: 0.01084
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:46:48] [V] [TRT] Tactic: -1610768292520086910 Time: 0.015524
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:46:48] [V] [TRT] Tactic: -1573035963956198975 Time: 0.020764
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -1558762241666006941
[12/29/2021-03:46:48] [V] [TRT] Tactic: -1558762241666006941 Time: 0.016108
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -1365353082499976145
[12/29/2021-03:46:48] [V] [TRT] Tactic: -1365353082499976145 Time: 0.016572
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:46:48] [V] [TRT] Tactic: -621838502160440068 Time: 0.016852
[12/29/2021-03:46:48] [V] [TRT] Fastest Tactic: -3365360067423513506 Time: 0.007212
[12/29/2021-03:46:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3365360067423513506
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:48] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CudaGroupConvolution)
[12/29/2021-03:46:48] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:48] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CudaDepthwiseConvolution)
[12/29/2021-03:46:48] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:48] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (FusedConvActConvolution)
[12/29/2021-03:46:48] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:48] [V] [TRT] --------------- Timing Runner: Conv_37 + Relu_40 (CaskConvolution)
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 177040020707947851
[12/29/2021-03:46:48] [V] [TRT] Tactic: 177040020707947851 Time: 0.008064
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 1550399266192842845
[12/29/2021-03:46:48] [V] [TRT] Tactic: 1550399266192842845 Time: 0.00764
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 1572887561103143487
[12/29/2021-03:46:48] [V] [TRT] Tactic: 1572887561103143487 Time: 0.009748
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:46:48] [V] [TRT] Tactic: 2325023763229477890 Time: 0.013012
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 2985940154541537814
[12/29/2021-03:46:48] [V] [TRT] Tactic: 2985940154541537814 Time: 0.014864
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:46:48] [V] [TRT] Tactic: 3284282970967328046 Time: 0.007036
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:46:48] [V] [TRT] Tactic: 3401614690060226673 Time: 0.00768
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3512426920013359699
[12/29/2021-03:46:48] [V] [TRT] Tactic: 3512426920013359699 Time: 0.007908
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 3899284354987683408
[12/29/2021-03:46:48] [V] [TRT] Tactic: 3899284354987683408 Time: 0.02094
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:46:48] [V] [TRT] Tactic: 4042202769383439184 Time: 0.009612
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: 4182625619810185112
[12/29/2021-03:46:48] [V] [TRT] Tactic: 4182625619810185112 Time: 0.01674
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 4259547356717612415
[12/29/2021-03:46:48] [V] [TRT] Tactic: 4259547356717612415 Time: 0.010336
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: 4717285412741024953
[12/29/2021-03:46:48] [V] [TRT] Tactic: 4717285412741024953 Time: 0.015312
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:46:48] [V] [TRT] Tactic: 4734519122557206480 Time: 0.019036
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 5121596860264626879
[12/29/2021-03:46:48] [V] [TRT] Tactic: 5121596860264626879 Time: 0.01916
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:46:48] [V] [TRT] Tactic: 5136656982162849059 Time: 0.007236
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 5158259316594207439
[12/29/2021-03:46:48] [V] [TRT] Tactic: 5158259316594207439 Time: 0.009676
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 5966973378912044513
[12/29/2021-03:46:48] [V] [TRT] Tactic: 5966973378912044513 Time: 0.012796
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:46:48] [V] [TRT] Tactic: 6004789655466615912 Time: 0.009852
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:46:48] [V] [TRT] Tactic: 6146901278630392829 Time: 0.018568
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 6434020722187266170
[12/29/2021-03:46:48] [V] [TRT] Tactic: 6434020722187266170 Time: 0.0195
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:46:48] [V] [TRT] Tactic: 6781129591847482048 Time: 0.009844
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7191893591576074000
[12/29/2021-03:46:48] [V] [TRT] Tactic: 7191893591576074000 Time: 0.007344
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7438984192263206338
[12/29/2021-03:46:48] [V] [TRT] Tactic: 7438984192263206338 Time: 0.009276
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 7504901284678552178
[12/29/2021-03:46:48] [V] [TRT] Tactic: 7504901284678552178 Time: 0.01274
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:46:48] [V] [TRT] Tactic: 8096257414008860171 Time: 0.0094
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 9143438935315839085
[12/29/2021-03:46:48] [V] [TRT] Tactic: 9143438935315839085 Time: 0.00778
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:46:48] [V] [TRT] Tactic: -9165697322068360861 Time: 0.019444
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -9118785798277698619
[12/29/2021-03:46:48] [V] [TRT] Tactic: -9118785798277698619 Time: 0.014512
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:46:48] [V] [TRT] Tactic: -8263994888336646547 Time: 0.012596
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:46:48] [V] [TRT] Tactic: -8205948405243401049 Time: 0.007728
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -7992068592656168418
[12/29/2021-03:46:48] [V] [TRT] Tactic: -7992068592656168418 Time: 0.009416
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: -7842775553137511386
[12/29/2021-03:46:48] [V] [TRT] Tactic: -7842775553137511386 Time: 0.013072
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:46:48] [V] [TRT] Tactic: -7683887278997527517 Time: 0.008476
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -6400348606759295499
[12/29/2021-03:46:48] [V] [TRT] Tactic: -6400348606759295499 Time: 0.014308
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -5980889159865208399
[12/29/2021-03:46:48] [V] [TRT] Tactic: -5980889159865208399 Time: 0.020696
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5766140806760372989
[12/29/2021-03:46:48] [V] [TRT] Tactic: -5766140806760372989 Time: 0.015652
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5709079507616090666
[12/29/2021-03:46:48] [V] [TRT] Tactic: -5709079507616090666 Time: 0.012392
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5698636014239116282
[12/29/2021-03:46:48] [V] [TRT] Tactic: -5698636014239116282 Time: 0.018572
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:46:48] [V] [TRT] Tactic: -4933563390723451692 Time: 0.008108
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -4516822589357530549
[12/29/2021-03:46:48] [V] [TRT] Tactic: -4516822589357530549 Time: 0.01648
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -3413217501222406256
[12/29/2021-03:46:48] [V] [TRT] Tactic: -3413217501222406256 Time: 0.018972
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:46:48] [V] [TRT] Tactic: -3238475748440751107 Time: 0.009156
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:46:48] [V] [TRT] Tactic: -3182884991006484042 Time: 0.012708
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:46:48] [V] [TRT] Tactic: -3173468756112541306 Time: 0.007424
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2917455979290586480
[12/29/2021-03:46:48] [V] [TRT] Tactic: -2917455979290586480 Time: 0.020872
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -2571022005763160364
[12/29/2021-03:46:48] [V] [TRT] Tactic: -2571022005763160364 Time: 0.015828
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -2083778562631872334
[12/29/2021-03:46:48] [V] [TRT] Tactic: -2083778562631872334 Time: 0.009864
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:46:48] [V] [TRT] Tactic: -1546787387293556842 Time: 0.01238
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:46:48] [V] [TRT] Tactic: -1498626619443284096 Time: 0.010312
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:46:48] [V] [TRT] Tactic: -1283580231568512025 Time: 0.007656
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: -1173968681844185579
[12/29/2021-03:46:48] [V] [TRT] Tactic: -1173968681844185579 Time: 0.007536
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:46:48] [V] [TRT] Tactic: -762222380308749469 Time: 0.00824
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -556794153877490941
[12/29/2021-03:46:48] [V] [TRT] Tactic: -556794153877490941 Time: 0.008336
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:46:48] [V] [TRT] Tactic: -516725800067794372 Time: 0.01892
[12/29/2021-03:46:48] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -428104331444385564
[12/29/2021-03:46:48] [V] [TRT] Tactic: -428104331444385564 Time: 0.016292
[12/29/2021-03:46:48] [V] [TRT] Fastest Tactic: 3284282970967328046 Time: 0.007036
[12/29/2021-03:46:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3284282970967328046
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Float(4096,64,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Float(4096,1,512,64) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Float(1024,1:4,128,16) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Float(128,64:32,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Int8(1024,64:4,8,1) -> Int8(128,64:32,8,1) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,64,8,1) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(4096,1,512,64) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Float(1024,1:4,128,16) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning Reformat:Int8(128,64:32,8,1) -> Int8(1024,64:4,8,1) ***************
[12/29/2021-03:46:48] [V] [TRT] *************** Autotuning format combination: Float(4096,64,8,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:48] [V] [TRT] --------------- Timing Runner: Conv_46 (CudaDepthwiseConvolution)
[12/29/2021-03:46:48] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:48] [V] [TRT] --------------- Timing Runner: Conv_46 (FusedConvActConvolution)
[12/29/2021-03:46:48] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:48] [V] [TRT] --------------- Timing Runner: Conv_46 (CudnnConvolution)
[12/29/2021-03:46:48] [V] [TRT] Tactic: 0 Time: 0.011276
[12/29/2021-03:46:48] [V] [TRT] Tactic: 1 Time: 0.011224
[12/29/2021-03:46:48] [V] [TRT] Tactic: 2 Time: 0.032204
[12/29/2021-03:46:48] [V] [TRT] Tactic: 56 Time: 0.011344
[12/29/2021-03:46:48] [V] [TRT] Tactic: 57 Time: 0.011248
[12/29/2021-03:46:48] [V] [TRT] Tactic: 58 Time: 0.032316
[12/29/2021-03:46:48] [V] [TRT] Tactic: 112 Time: 0.011424
[12/29/2021-03:46:48] [V] [TRT] Tactic: 113 Time: 0.011192
[12/29/2021-03:46:48] [V] [TRT] Tactic: 114 Time: 0.032328
[12/29/2021-03:46:48] [V] [TRT] Fastest Tactic: 113 Time: 0.011192
[12/29/2021-03:46:48] [V] [TRT] --------------- Timing Runner: Conv_46 (CaskConvolution)
[12/29/2021-03:46:48] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:46:48] [V] [TRT] Tactic: 4549827808004681195 Time: 0.01534
[12/29/2021-03:46:48] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:46:49] [V] [TRT] Tactic: 5779835512569528575 Time: 0.018272
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 9151672657204310840
[12/29/2021-03:46:49] [V] [TRT] Tactic: 9151672657204310840 Time: 0.02874
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: -7491730084094677098
[12/29/2021-03:46:49] [V] [TRT] Tactic: -7491730084094677098 Time: 0.016596
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:46:49] [V] [TRT] Tactic: -6313876406580483184 Time: 0.017028
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: -6273689210331812572
[12/29/2021-03:46:49] [V] [TRT] Tactic: -6273689210331812572 Time: 0.018108
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: -4337126844824617177
[12/29/2021-03:46:49] [V] [TRT] Tactic: -4337126844824617177 Time: 0.014888
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:46:49] [V] [TRT] Tactic: -1123676555321336786 Time: 0.018396
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:46:49] [V] [TRT] Tactic: -701551393537224327 Time: 0.015628
[12/29/2021-03:46:49] [V] [TRT] Fastest Tactic: -4337126844824617177 Time: 0.014888
[12/29/2021-03:46:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 113
[12/29/2021-03:46:49] [V] [TRT] *************** Autotuning format combination: Float(4096,1,512,64) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:49] [V] [TRT] --------------- Timing Runner: Conv_46 (CudnnConvolution)
[12/29/2021-03:46:49] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:49] [V] [TRT] --------------- Timing Runner: Conv_46 (CaskConvolution)
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 1663866669559596164
[12/29/2021-03:46:49] [V] [TRT] Tactic: 1663866669559596164 Time: 0.016924
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:46:49] [V] [TRT] Tactic: 2860655430572478466 Time: 0.013072
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:46:49] [V] [TRT] Tactic: 4474630279712975759 Time: 0.010908
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:46:49] [V] [TRT] Tactic: 4479823862704990365 Time: 0.010824
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:46:49] [V] [TRT] Tactic: 4696204239951173149 Time: 0.012872
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:46:49] [V] [TRT] Tactic: 5778138195697110003 Time: 0.016956
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:46:49] [V] [TRT] Tactic: 8918020581761223752 Time: 0.016252
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -5905193483742532701
[12/29/2021-03:46:49] [V] [TRT] Tactic: -5905193483742532701 Time: 0.0124
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -4035591156787122265
[12/29/2021-03:46:49] [V] [TRT] Tactic: -4035591156787122265 Time: 0.010744
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:46:49] [V] [TRT] Tactic: -2809379259463049391 Time: 0.016932
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -1985235291706575900
[12/29/2021-03:46:49] [V] [TRT] Tactic: -1985235291706575900 Time: 0.016332
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:46:49] [V] [TRT] Tactic: -504296718212024303 Time: 0.016312
[12/29/2021-03:46:49] [V] [TRT] Fastest Tactic: -4035591156787122265 Time: 0.010744
[12/29/2021-03:46:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4035591156787122265
[12/29/2021-03:46:49] [V] [TRT] *************** Autotuning format combination: Float(1024,1:4,128,16) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:49] [V] [TRT] --------------- Timing Runner: Conv_46 (CudnnConvolution)
[12/29/2021-03:46:49] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:49] [V] [TRT] --------------- Timing Runner: Conv_46 (CaskConvolution)
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 1373022415249282411
[12/29/2021-03:46:49] [V] [TRT] Tactic: 1373022415249282411 Time: 0.013124
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 1663866669559596164
[12/29/2021-03:46:49] [V] [TRT] Tactic: 1663866669559596164 Time: 0.01682
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:46:49] [V] [TRT] Tactic: 2860655430572478466 Time: 0.012964
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:46:49] [V] [TRT] Tactic: 4474630279712975759 Time: 0.010916
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:46:49] [V] [TRT] Tactic: 4479823862704990365 Time: 0.010756
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:46:49] [V] [TRT] Tactic: 4696204239951173149 Time: 0.01288
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:46:49] [V] [TRT] Tactic: 5778138195697110003 Time: 0.01704
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:46:49] [V] [TRT] Tactic: 7342025736444949634 Time: 0.013264
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:46:49] [V] [TRT] Tactic: 8918020581761223752 Time: 0.016284
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -5905193483742532701
[12/29/2021-03:46:49] [V] [TRT] Tactic: -5905193483742532701 Time: 0.01242
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:46:49] [V] [TRT] Tactic: -5457304872213719461 Time: 0.013708
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -4035591156787122265
[12/29/2021-03:46:49] [V] [TRT] Tactic: -4035591156787122265 Time: 0.010628
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:46:49] [V] [TRT] Tactic: -2809379259463049391 Time: 0.017028
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -1985235291706575900
[12/29/2021-03:46:49] [V] [TRT] Tactic: -1985235291706575900 Time: 0.01628
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:46:49] [V] [TRT] Tactic: -504296718212024303 Time: 0.016316
[12/29/2021-03:46:49] [V] [TRT] Fastest Tactic: -4035591156787122265 Time: 0.010628
[12/29/2021-03:46:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4035591156787122265
[12/29/2021-03:46:49] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:49] [V] [TRT] --------------- Timing Runner: Conv_46 (CudaDepthwiseConvolution)
[12/29/2021-03:46:49] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:49] [V] [TRT] --------------- Timing Runner: Conv_46 (CaskConvolution)
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:46:49] [V] [TRT] Tactic: 1508480131241957639 Time: 0.013176
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 2141154648944475104
[12/29/2021-03:46:49] [V] [TRT] Tactic: 2141154648944475104 Time: 0.0131
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:46:49] [V] [TRT] Tactic: 3239257003214966313 Time: 0.013264
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:46:49] [V] [TRT] Tactic: 5592640619112287921 Time: 0.01088
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:46:49] [V] [TRT] Tactic: 7621465827583909090 Time: 0.011404
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: -6580271968881459581
[12/29/2021-03:46:49] [V] [TRT] Tactic: -6580271968881459581 Time: 0.011156
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:46:49] [V] [TRT] Tactic: -5576936487443445631 Time: 0.011528
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: -4443833619060044580
[12/29/2021-03:46:49] [V] [TRT] Tactic: -4443833619060044580 Time: 0.01094
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:46:49] [V] [TRT] Tactic: -2297737319934264721 Time: 0.011404
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:46:49] [V] [TRT] Tactic: -1425085658556684465 Time: 0.011104
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:46:49] [V] [TRT] Tactic: -108011214168778087 Time: 0.011104
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: -42427192380281294
[12/29/2021-03:46:49] [V] [TRT] Tactic: -42427192380281294 Time: 0.011248
[12/29/2021-03:46:49] [V] [TRT] Fastest Tactic: 5592640619112287921 Time: 0.01088
[12/29/2021-03:46:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5592640619112287921
[12/29/2021-03:46:49] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:49] [V] [TRT] --------------- Timing Runner: Conv_46 (CudaDepthwiseConvolution)
[12/29/2021-03:46:49] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:49] [V] [TRT] --------------- Timing Runner: Conv_46 (FusedConvActConvolution)
[12/29/2021-03:46:49] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:49] [V] [TRT] --------------- Timing Runner: Conv_46 (CaskConvolution)
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:46:49] [V] [TRT] Tactic: 175853789719975416 Time: 0.009276
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:46:49] [V] [TRT] Tactic: 2171150287007712632 Time: 0.009104
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:46:49] [V] [TRT] Tactic: 2234457234705232274 Time: 0.008856
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:46:49] [V] [TRT] Tactic: 5834048089706882838 Time: 0.009012
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 6299962968199310600
[12/29/2021-03:46:49] [V] [TRT] Tactic: 6299962968199310600 Time: 0.010372
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 6341572697076960911
[12/29/2021-03:46:49] [V] [TRT] Tactic: 6341572697076960911 Time: 0.008884
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:46:49] [V] [TRT] Tactic: -8626990807754934295 Time: 0.009084
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: -8498217049614706532
[12/29/2021-03:46:49] [V] [TRT] Tactic: -8498217049614706532 Time: 0.008724
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:46:49] [V] [TRT] Tactic: -7303593854972602201 Time: 0.008808
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:46:49] [V] [TRT] Tactic: -6585664687867083638 Time: 0.010612
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: -3326139578711341011
[12/29/2021-03:46:49] [V] [TRT] Tactic: -3326139578711341011 Time: 0.008976
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:46:49] [V] [TRT] Tactic: -683636008127039856 Time: 0.010508
[12/29/2021-03:46:49] [V] [TRT] Fastest Tactic: -8498217049614706532 Time: 0.008724
[12/29/2021-03:46:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -8498217049614706532
[12/29/2021-03:46:49] [V] [TRT] *************** Autotuning format combination: Int8(1024,64:4,8,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:49] [V] [TRT] --------------- Timing Runner: Conv_46 (CaskConvolution)
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:46:49] [V] [TRT] Tactic: 1100922622480907544 Time: 0.008972
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_c32_nn_v1 Tactic: 2855900226702061782
[12/29/2021-03:46:49] [V] [TRT] Tactic: 2855900226702061782 Time: 0.010448
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:46:49] [V] [TRT] Tactic: 3606311198834416176 Time: 0.00888
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:46:49] [V] [TRT] Tactic: 4325765560739862899 Time: 0.010456
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 8803458114157674373
[12/29/2021-03:46:49] [V] [TRT] Tactic: 8803458114157674373 Time: 0.008636
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: -6934773036503365000
[12/29/2021-03:46:49] [V] [TRT] Tactic: -6934773036503365000 Time: 0.00886
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: -4431642509665791294
[12/29/2021-03:46:49] [V] [TRT] Tactic: -4431642509665791294 Time: 0.00862
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:46:49] [V] [TRT] Tactic: -4255737803793506479 Time: 0.010456
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:46:49] [V] [TRT] Tactic: -3958182351168863467 Time: 0.008512
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:46:49] [V] [TRT] Tactic: -3111968753064955248 Time: 0.00892
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:46:49] [V] [TRT] Tactic: -1492575840277333548 Time: 0.009156
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:46:49] [V] [TRT] Tactic: -868495160148524802 Time: 0.008808
[12/29/2021-03:46:49] [V] [TRT] Fastest Tactic: -3958182351168863467 Time: 0.008512
[12/29/2021-03:46:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3958182351168863467
[12/29/2021-03:46:49] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:49] [V] [TRT] --------------- Timing Runner: Conv_46 (CaskConvolution)
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:46:49] [V] [TRT] Tactic: 2623576043214044314 Time: 0.006256
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 2818014835119698671
[12/29/2021-03:46:49] [V] [TRT] Tactic: 2818014835119698671 Time: 0.007712
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 3721599319722771137
[12/29/2021-03:46:49] [V] [TRT] Tactic: 3721599319722771137 Time: 0.006024
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_interior_nt_v1 Tactic: 4178917718361232468
[12/29/2021-03:46:49] [V] [TRT] Tactic: 4178917718361232468 Time: 0.008896
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:46:49] [V] [TRT] Tactic: 4551754795416974366 Time: 0.006312
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:46:49] [V] [TRT] Tactic: 4925112190271421402 Time: 0.006044
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:46:49] [V] [TRT] Tactic: 5012796702462679112 Time: 0.011664
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:46:49] [V] [TRT] Tactic: 6556170942941957134 Time: 0.008908
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 6618077155362058131
[12/29/2021-03:46:49] [V] [TRT] Tactic: 6618077155362058131 Time: 0.005808
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:46:49] [V] [TRT] Tactic: 6852868042694587230 Time: 0.006656
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 6969462133921577484
[12/29/2021-03:46:49] [V] [TRT] Tactic: 6969462133921577484 Time: 0.01076
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:46:49] [V] [TRT] Tactic: 8399092794516815300 Time: 0.010792
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:46:49] [V] [TRT] Tactic: -9132922677633967263 Time: 0.007592
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -8912999970161746151
[12/29/2021-03:46:49] [V] [TRT] Tactic: -8912999970161746151 Time: 0.00758
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -8893439100868426414
[12/29/2021-03:46:49] [V] [TRT] Tactic: -8893439100868426414 Time: 0.01012
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:46:49] [V] [TRT] Tactic: -7988637803896331454 Time: 0.008812
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_interior_nt_v1 Tactic: -7904635102498369361
[12/29/2021-03:46:49] [V] [TRT] Tactic: -7904635102498369361 Time: 0.011276
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:46:49] [V] [TRT] Tactic: -7606074703023778034 Time: 0.008776
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:46:49] [V] [TRT] Tactic: -7413564913826321357 Time: 0.010108
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:46:49] [V] [TRT] Tactic: -7282232519526877434 Time: 0.011516
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -6406011580107094428
[12/29/2021-03:46:49] [V] [TRT] Tactic: -6406011580107094428 Time: 0.00654
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:46:49] [V] [TRT] Tactic: -5603587790314027122 Time: 0.008868
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_interior_nt_v1 Tactic: -5416590980288859834
[12/29/2021-03:46:49] [V] [TRT] Tactic: -5416590980288859834 Time: 0.0089
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:46:49] [V] [TRT] Tactic: -5334776871777565833 Time: 0.01426
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:46:49] [V] [TRT] Tactic: -5157868397078537095 Time: 0.009704
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -3665201838779845683
[12/29/2021-03:46:49] [V] [TRT] Tactic: -3665201838779845683 Time: 0.013936
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_interior_nt_v1 Tactic: -3644377136375731441
[12/29/2021-03:46:49] [V] [TRT] Tactic: -3644377136375731441 Time: 0.008912
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -3502495740607894730
[12/29/2021-03:46:49] [V] [TRT] Tactic: -3502495740607894730 Time: 0.005988
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -2342404147487779225
[12/29/2021-03:46:49] [V] [TRT] Tactic: -2342404147487779225 Time: 0.009644
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:46:49] [V] [TRT] Tactic: -1782593837177056527 Time: 0.008012
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:46:49] [V] [TRT] Tactic: -1610768292520086910 Time: 0.008884
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:46:49] [V] [TRT] Tactic: -621838502160440068 Time: 0.009056
[12/29/2021-03:46:49] [V] [TRT] Fastest Tactic: 6618077155362058131 Time: 0.005808
[12/29/2021-03:46:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6618077155362058131
[12/29/2021-03:46:49] [V] [TRT] *************** Autotuning format combination: Int8(128,64:32,8,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:49] [V] [TRT] --------------- Timing Runner: Conv_46 (CudaGroupConvolution)
[12/29/2021-03:46:49] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:49] [V] [TRT] --------------- Timing Runner: Conv_46 (CudaDepthwiseConvolution)
[12/29/2021-03:46:49] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:49] [V] [TRT] --------------- Timing Runner: Conv_46 (FusedConvActConvolution)
[12/29/2021-03:46:49] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:49] [V] [TRT] --------------- Timing Runner: Conv_46 (CaskConvolution)
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 177040020707947851
[12/29/2021-03:46:49] [V] [TRT] Tactic: 177040020707947851 Time: 0.006324
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_interior_nt_v1 Tactic: 434957160407688216
[12/29/2021-03:46:49] [V] [TRT] Tactic: 434957160407688216 Time: 0.01028
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 805889586762897346
[12/29/2021-03:46:49] [V] [TRT] Tactic: 805889586762897346 Time: 0.009192
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 1550399266192842845
[12/29/2021-03:46:49] [V] [TRT] Tactic: 1550399266192842845 Time: 0.006112
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:46:49] [V] [TRT] Tactic: 2325023763229477890 Time: 0.007884
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_interior_nt_v1 Tactic: 2346437292116182513
[12/29/2021-03:46:49] [V] [TRT] Tactic: 2346437292116182513 Time: 0.008516
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_interior_nt_v1 Tactic: 2522133112320625287
[12/29/2021-03:46:49] [V] [TRT] Tactic: 2522133112320625287 Time: 0.008844
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 2985940154541537814
[12/29/2021-03:46:49] [V] [TRT] Tactic: 2985940154541537814 Time: 0.008592
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 3538565962642681625
[12/29/2021-03:46:49] [V] [TRT] Tactic: 3538565962642681625 Time: 0.00608
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 3899284354987683408
[12/29/2021-03:46:49] [V] [TRT] Tactic: 3899284354987683408 Time: 0.01056
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:46:49] [V] [TRT] Tactic: 4042202769383439184 Time: 0.006816
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 4259547356717612415
[12/29/2021-03:46:49] [V] [TRT] Tactic: 4259547356717612415 Time: 0.007168
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: 4717285412741024953
[12/29/2021-03:46:49] [V] [TRT] Tactic: 4717285412741024953 Time: 0.00884
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:46:49] [V] [TRT] Tactic: 4734519122557206480 Time: 0.009052
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 5121596860264626879
[12/29/2021-03:46:49] [V] [TRT] Tactic: 5121596860264626879 Time: 0.008964
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_interior_nt_v1 Tactic: 5126565865931538390
[12/29/2021-03:46:49] [V] [TRT] Tactic: 5126565865931538390 Time: 0.008844
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 5158259316594207439
[12/29/2021-03:46:49] [V] [TRT] Tactic: 5158259316594207439 Time: 0.006788
[12/29/2021-03:46:49] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 5375256703210220108
[12/29/2021-03:46:50] [V] [TRT] Tactic: 5375256703210220108 Time: 0.00662
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 6433368103202497147
[12/29/2021-03:46:50] [V] [TRT] Tactic: 6433368103202497147 Time: 0.00754
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 6434020722187266170
[12/29/2021-03:46:50] [V] [TRT] Tactic: 6434020722187266170 Time: 0.00938
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 6441948709525127755
[12/29/2021-03:46:50] [V] [TRT] Tactic: 6441948709525127755 Time: 0.005828
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 6457435868048963632
[12/29/2021-03:46:50] [V] [TRT] Tactic: 6457435868048963632 Time: 0.006572
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:46:50] [V] [TRT] Tactic: 6781129591847482048 Time: 0.006868
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 6925201228918187099
[12/29/2021-03:46:50] [V] [TRT] Tactic: 6925201228918187099 Time: 0.0075
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 7504901284678552178
[12/29/2021-03:46:50] [V] [TRT] Tactic: 7504901284678552178 Time: 0.00758
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 7731430299029542276
[12/29/2021-03:46:50] [V] [TRT] Tactic: 7731430299029542276 Time: 0.00754
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 7738495016763012180
[12/29/2021-03:46:50] [V] [TRT] Tactic: 7738495016763012180 Time: 0.009
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 8234775147403903473
[12/29/2021-03:46:50] [V] [TRT] Tactic: 8234775147403903473 Time: 0.009116
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:46:50] [V] [TRT] Tactic: -9165697322068360861 Time: 0.009456
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -9118785798277698619
[12/29/2021-03:46:50] [V] [TRT] Tactic: -9118785798277698619 Time: 0.008784
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -8556775352640313933
[12/29/2021-03:46:50] [V] [TRT] Tactic: -8556775352640313933 Time: 0.00758
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:46:50] [V] [TRT] Tactic: -8263994888336646547 Time: 0.007592
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:46:50] [V] [TRT] Tactic: -8205948405243401049 Time: 0.00608
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: -7842775553137511386
[12/29/2021-03:46:50] [V] [TRT] Tactic: -7842775553137511386 Time: 0.007708
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:46:50] [V] [TRT] Tactic: -7683887278997527517 Time: 0.006276
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -6527178416855951297
[12/29/2021-03:46:50] [V] [TRT] Tactic: -6527178416855951297 Time: 0.00594
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -6510232214299595844
[12/29/2021-03:46:50] [V] [TRT] Tactic: -6510232214299595844 Time: 0.005928
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -6400348606759295499
[12/29/2021-03:46:50] [V] [TRT] Tactic: -6400348606759295499 Time: 0.008492
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -5980889159865208399
[12/29/2021-03:46:50] [V] [TRT] Tactic: -5980889159865208399 Time: 0.010408
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5766140806760372989
[12/29/2021-03:46:50] [V] [TRT] Tactic: -5766140806760372989 Time: 0.00898
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -5170003087447722174
[12/29/2021-03:46:50] [V] [TRT] Tactic: -5170003087447722174 Time: 0.005812
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -4849712423393454704
[12/29/2021-03:46:50] [V] [TRT] Tactic: -4849712423393454704 Time: 0.006636
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -4516822589357530549
[12/29/2021-03:46:50] [V] [TRT] Tactic: -4516822589357530549 Time: 0.008976
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -3613322253849278738
[12/29/2021-03:46:50] [V] [TRT] Tactic: -3613322253849278738 Time: 0.005828
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -3577322188448771475
[12/29/2021-03:46:50] [V] [TRT] Tactic: -3577322188448771475 Time: 0.007036
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -2754311112012636251
[12/29/2021-03:46:50] [V] [TRT] Tactic: -2754311112012636251 Time: 0.00722
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: -2315453944962430928
[12/29/2021-03:46:50] [V] [TRT] Tactic: -2315453944962430928 Time: 0.008888
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -2083778562631872334
[12/29/2021-03:46:50] [V] [TRT] Tactic: -2083778562631872334 Time: 0.006832
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -1499578657823798783
[12/29/2021-03:46:50] [V] [TRT] Tactic: -1499578657823798783 Time: 0.006048
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:46:50] [V] [TRT] Tactic: -1498626619443284096 Time: 0.007168
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:46:50] [V] [TRT] Tactic: -1283580231568512025 Time: 0.006048
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: -1173968681844185579
[12/29/2021-03:46:50] [V] [TRT] Tactic: -1173968681844185579 Time: 0.00606
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:46:50] [V] [TRT] Tactic: -762222380308749469 Time: 0.006348
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -713022856474991236
[12/29/2021-03:46:50] [V] [TRT] Tactic: -713022856474991236 Time: 0.005888
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -556794153877490941
[12/29/2021-03:46:50] [V] [TRT] Tactic: -556794153877490941 Time: 0.006432
[12/29/2021-03:46:50] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -375949437730908730
[12/29/2021-03:46:50] [V] [TRT] Tactic: -375949437730908730 Time: 0.006724
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: -5170003087447722174 Time: 0.005812
[12/29/2021-03:46:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -5170003087447722174
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.008688
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.005556
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005556
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.008592
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.005696
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005696
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.007708
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.004568
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.004568
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.007604
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.005384
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005384
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.008748
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.005276
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005276
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.007
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.00532
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.00532
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.007888
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.005428
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005428
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.00776
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.005464
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005464
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.0088
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.005304
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005304
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.007048
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.00524
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.00524
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.008776
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.005408
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005408
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.008708
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.00536
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.00536
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.00872
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.005128
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005128
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.008928
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.005148
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005148
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.006948
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.00528
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.00528
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.007988
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.005332
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005332
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.007884
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.005412
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005412
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.007488
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.004628
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.004628
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.008692
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.005656
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005656
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.008792
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.005616
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005616
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.007276
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.004832
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.004832
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.007412
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.005536
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005536
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.00774
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.00564
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.00564
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.008812
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.005716
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005716
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.007084
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.004624
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1 Time: 0.004876
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.004624
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.008612
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.005424
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005424
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.009156
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.005532
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.005532
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.007
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.00546
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.00546
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.009052
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.00564
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.00564
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1002 Time: 0.008124
[12/29/2021-03:46:50] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.00558
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 0 Time: 0.00558
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning format combination: Float(2048,16,4,1), Float(2048,16,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CudaDepthwiseConvolution)
[12/29/2021-03:46:50] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (FusedConvActConvolution)
[12/29/2021-03:46:50] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CudnnConvolution)
[12/29/2021-03:46:50] [V] [TRT] Tactic: 0 Time: 0.058368
[12/29/2021-03:46:50] [V] [TRT] Tactic: 1 Time: 0.077632
[12/29/2021-03:46:50] [V] [TRT] Tactic: 2 Time: 0.08066
[12/29/2021-03:46:50] [V] [TRT] Tactic: 4 skipped. Scratch requested: 47775744, available: 16777216
[12/29/2021-03:46:50] [V] [TRT] Tactic: 5 skipped. Scratch requested: 106954752, available: 16777216
[12/29/2021-03:46:50] [V] [TRT] Tactic: 6 Time: 0.04004
[12/29/2021-03:46:50] [V] [TRT] Tactic: 56 Time: 0.05832
[12/29/2021-03:46:50] [V] [TRT] Tactic: 57 Time: 0.055392
[12/29/2021-03:46:50] [V] [TRT] Tactic: 58 Time: 0.08054
[12/29/2021-03:46:50] [V] [TRT] Tactic: 60 skipped. Scratch requested: 47775744, available: 16777216
[12/29/2021-03:46:50] [V] [TRT] Tactic: 61 skipped. Scratch requested: 106954752, available: 16777216
[12/29/2021-03:46:50] [V] [TRT] Tactic: 62 Time: 0.039908
[12/29/2021-03:46:50] [V] [TRT] Tactic: 112 Time: 0.058248
[12/29/2021-03:46:50] [V] [TRT] Tactic: 113 Time: 0.186032
[12/29/2021-03:46:50] [V] [TRT] Tactic: 114 Time: 0.080604
[12/29/2021-03:46:50] [V] [TRT] Tactic: 116 skipped. Scratch requested: 47775744, available: 16777216
[12/29/2021-03:46:50] [V] [TRT] Tactic: 117 skipped. Scratch requested: 106954752, available: 16777216
[12/29/2021-03:46:50] [V] [TRT] Tactic: 118 Time: 0.040024
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 62 Time: 0.039908
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CaskConvolution)
[12/29/2021-03:46:50] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:46:50] [V] [TRT] Tactic: 4549827808004681195 Time: 0.117428
[12/29/2021-03:46:50] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:46:50] [V] [TRT] Tactic: 5779835512569528575 Time: 0.150604
[12/29/2021-03:46:50] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[12/29/2021-03:46:50] [V] [TRT] Tactic: 6053873026024413720 Time: 0.183388
[12/29/2021-03:46:50] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[12/29/2021-03:46:50] [V] [TRT] Tactic: 6767548733843469815 Time: 0.138932
[12/29/2021-03:46:50] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:46:50] [V] [TRT] Tactic: -6313876406580483184 Time: 0.140384
[12/29/2021-03:46:50] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:46:50] [V] [TRT] Tactic: -1123676555321336786 Time: 0.178524
[12/29/2021-03:46:50] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:46:50] [V] [TRT] Tactic: -701551393537224327 Time: 0.161336
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 4549827808004681195 Time: 0.117428
[12/29/2021-03:46:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 62
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning format combination: Float(2048,1,512,128), Float(2048,1,512,128) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CudnnConvolution)
[12/29/2021-03:46:50] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CaskConvolution)
[12/29/2021-03:46:50] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:46:50] [V] [TRT] Tactic: 2860655430572478466 Time: 0.090156
[12/29/2021-03:46:50] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:46:50] [V] [TRT] Tactic: 4474630279712975759 Time: 0.053544
[12/29/2021-03:46:50] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:46:50] [V] [TRT] Tactic: 4479823862704990365 Time: 0.051216
[12/29/2021-03:46:50] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:46:50] [V] [TRT] Tactic: 4696204239951173149 Time: 0.095552
[12/29/2021-03:46:50] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:46:50] [V] [TRT] Tactic: 5778138195697110003 Time: 0.150952
[12/29/2021-03:46:50] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:46:50] [V] [TRT] Tactic: 7155825427510256858 Time: 0.154496
[12/29/2021-03:46:50] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:46:50] [V] [TRT] Tactic: 8918020581761223752 Time: 0.151264
[12/29/2021-03:46:50] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:46:50] [V] [TRT] Tactic: -4756382386362004279 Time: 0.094
[12/29/2021-03:46:50] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:46:50] [V] [TRT] Tactic: -3855385237722507464 Time: 0.155316
[12/29/2021-03:46:50] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:46:50] [V] [TRT] Tactic: -2809379259463049391 Time: 0.152876
[12/29/2021-03:46:50] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:46:50] [V] [TRT] Tactic: -504296718212024303 Time: 0.145192
[12/29/2021-03:46:50] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.051216
[12/29/2021-03:46:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:46:50] [V] [TRT] *************** Autotuning format combination: Float(512,1:4,128,32), Float(512,1:4,128,32) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CudnnConvolution)
[12/29/2021-03:46:50] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:50] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CaskConvolution)
[12/29/2021-03:46:50] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:46:51] [V] [TRT] Tactic: 2860655430572478466 Time: 0.090172
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:46:51] [V] [TRT] Tactic: 4474630279712975759 Time: 0.053596
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:46:51] [V] [TRT] Tactic: 4479823862704990365 Time: 0.051144
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:46:51] [V] [TRT] Tactic: 4696204239951173149 Time: 0.095484
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:46:51] [V] [TRT] Tactic: 5778138195697110003 Time: 0.15092
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:46:51] [V] [TRT] Tactic: 7155825427510256858 Time: 0.154652
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:46:51] [V] [TRT] Tactic: 7342025736444949634 Time: 0.102428
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:46:51] [V] [TRT] Tactic: 8918020581761223752 Time: 0.15122
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:46:51] [V] [TRT] Tactic: -7377458734869418330 Time: 0.100908
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:46:51] [V] [TRT] Tactic: -5457304872213719461 Time: 0.101952
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:46:51] [V] [TRT] Tactic: -4756382386362004279 Time: 0.093968
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:46:51] [V] [TRT] Tactic: -3855385237722507464 Time: 0.155292
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:46:51] [V] [TRT] Tactic: -2809379259463049391 Time: 0.152716
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:46:51] [V] [TRT] Tactic: -504296718212024303 Time: 0.14506
[12/29/2021-03:46:51] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.051144
[12/29/2021-03:46:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:46:51] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1), Float(2048,16,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:51] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CudaDepthwiseConvolution)
[12/29/2021-03:46:51] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:51] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CaskConvolution)
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 1332468635798226953
[12/29/2021-03:46:51] [V] [TRT] Tactic: 1332468635798226953 Time: 0.061828
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:46:51] [V] [TRT] Tactic: 1508480131241957639 Time: 0.05678
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 1947019689364377201
[12/29/2021-03:46:51] [V] [TRT] Tactic: 1947019689364377201 Time: 0.044484
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:46:51] [V] [TRT] Tactic: 3239257003214966313 Time: 0.061384
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:46:51] [V] [TRT] Tactic: 5592640619112287921 Time: 0.0359
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:46:51] [V] [TRT] Tactic: 7621465827583909090 Time: 0.037748
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:46:51] [V] [TRT] Tactic: -5576936487443445631 Time: 0.049008
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:46:51] [V] [TRT] Tactic: -2297737319934264721 Time: 0.0564
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:46:51] [V] [TRT] Tactic: -1425085658556684465 Time: 0.054712
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:46:51] [V] [TRT] Tactic: -108011214168778087 Time: 0.042864
[12/29/2021-03:46:51] [V] [TRT] Fastest Tactic: 5592640619112287921 Time: 0.0359
[12/29/2021-03:46:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5592640619112287921
[12/29/2021-03:46:51] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1), Int8(512,16:4,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:51] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CudaDepthwiseConvolution)
[12/29/2021-03:46:51] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:51] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (FusedConvActConvolution)
[12/29/2021-03:46:51] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:51] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CaskConvolution)
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:46:51] [V] [TRT] Tactic: 175853789719975416 Time: 0.05508
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:46:51] [V] [TRT] Tactic: 2171150287007712632 Time: 0.0531
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:46:51] [V] [TRT] Tactic: 2234457234705232274 Time: 0.03584
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:46:51] [V] [TRT] Tactic: 5834048089706882838 Time: 0.047172
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:46:51] [V] [TRT] Tactic: -8626990807754934295 Time: 0.041212
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:46:51] [V] [TRT] Tactic: -7303593854972602201 Time: 0.034348
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:46:51] [V] [TRT] Tactic: -6585664687867083638 Time: 0.059148
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: -3730012925709297561
[12/29/2021-03:46:51] [V] [TRT] Tactic: -3730012925709297561 Time: 0.042056
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: -2277259417488004546
[12/29/2021-03:46:51] [V] [TRT] Tactic: -2277259417488004546 Time: 0.059536
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:46:51] [V] [TRT] Tactic: -683636008127039856 Time: 0.054544
[12/29/2021-03:46:51] [V] [TRT] Fastest Tactic: -7303593854972602201 Time: 0.034348
[12/29/2021-03:46:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7303593854972602201
[12/29/2021-03:46:51] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1), Int8(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:51] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CaskConvolution)
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 984309058095623735
[12/29/2021-03:46:51] [V] [TRT] Tactic: 984309058095623735 Time: 0.042364
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:46:51] [V] [TRT] Tactic: 1100922622480907544 Time: 0.041136
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 3238312825609165543
[12/29/2021-03:46:51] [V] [TRT] Tactic: 3238312825609165543 Time: 0.05984
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:46:51] [V] [TRT] Tactic: 3606311198834416176 Time: 0.047208
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:46:51] [V] [TRT] Tactic: 4325765560739862899 Time: 0.05498
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:46:51] [V] [TRT] Tactic: -4255737803793506479 Time: 0.059728
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:46:51] [V] [TRT] Tactic: -3958182351168863467 Time: 0.034276
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:46:51] [V] [TRT] Tactic: -3111968753064955248 Time: 0.05312
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:46:51] [V] [TRT] Tactic: -1492575840277333548 Time: 0.055012
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:46:51] [V] [TRT] Tactic: -868495160148524802 Time: 0.036028
[12/29/2021-03:46:51] [V] [TRT] Fastest Tactic: -3958182351168863467 Time: 0.034276
[12/29/2021-03:46:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3958182351168863467
[12/29/2021-03:46:51] [V] [TRT] *************** Autotuning format combination: Int8(64,16:32,4,1), Float(64,16:32,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:51] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CaskConvolution)
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:46:51] [V] [TRT] Tactic: 1011019097971850911 Time: 0.021188
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:46:51] [V] [TRT] Tactic: 1071114551801767124 Time: 0.013572
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:46:51] [V] [TRT] Tactic: 2623576043214044314 Time: 0.009668
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:46:51] [V] [TRT] Tactic: 3281631721811475881 Time: 0.010964
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:46:51] [V] [TRT] Tactic: 4551754795416974366 Time: 0.01078
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:46:51] [V] [TRT] Tactic: 4925112190271421402 Time: 0.009252
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:46:51] [V] [TRT] Tactic: 5012796702462679112 Time: 0.03762
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:46:51] [V] [TRT] Tactic: 5041593333398049019 Time: 0.009184
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:46:51] [V] [TRT] Tactic: 5166018662410176512 Time: 0.035948
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:46:51] [V] [TRT] Tactic: 6191867932654611882 Time: 0.020388
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:46:51] [V] [TRT] Tactic: 6556170942941957134 Time: 0.024832
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:46:51] [V] [TRT] Tactic: 6852868042694587230 Time: 0.010948
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:46:51] [V] [TRT] Tactic: 8399092794516815300 Time: 0.03246
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:46:51] [V] [TRT] Tactic: -9132922677633967263 Time: 0.014052
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:46:51] [V] [TRT] Tactic: -7988637803896331454 Time: 0.022036
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: -7865001268126363229
[12/29/2021-03:46:51] [V] [TRT] Tactic: -7865001268126363229 Time: 0.03
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:46:51] [V] [TRT] Tactic: -7606074703023778034 Time: 0.02246
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:46:51] [V] [TRT] Tactic: -7413564913826321357 Time: 0.021396
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:46:51] [V] [TRT] Tactic: -7282232519526877434 Time: 0.03654
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:46:51] [V] [TRT] Tactic: -5942379529065248478 Time: 0.013772
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:46:51] [V] [TRT] Tactic: -5603587790314027122 Time: 0.028516
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:46:51] [V] [TRT] Tactic: -5334776871777565833 Time: 0.036284
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:46:51] [V] [TRT] Tactic: -5157868397078537095 Time: 0.020672
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:46:51] [V] [TRT] Tactic: -5100834417027499764 Time: 0.009924
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:46:51] [V] [TRT] Tactic: -3365360067423513506 Time: 0.008376
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2194148180068068313
[12/29/2021-03:46:51] [V] [TRT] Tactic: -2194148180068068313 Time: 0.037488
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:46:51] [V] [TRT] Tactic: -1782593837177056527 Time: 0.014076
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:46:51] [V] [TRT] Tactic: -1610768292520086910 Time: 0.023752
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:46:51] [V] [TRT] Tactic: -1573035963956198975 Time: 0.03198
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -1558762241666006941
[12/29/2021-03:46:51] [V] [TRT] Tactic: -1558762241666006941 Time: 0.026144
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -1365353082499976145
[12/29/2021-03:46:51] [V] [TRT] Tactic: -1365353082499976145 Time: 0.029284
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:46:51] [V] [TRT] Tactic: -621838502160440068 Time: 0.029224
[12/29/2021-03:46:51] [V] [TRT] Fastest Tactic: -3365360067423513506 Time: 0.008376
[12/29/2021-03:46:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3365360067423513506
[12/29/2021-03:46:51] [V] [TRT] *************** Autotuning format combination: Int8(64,16:32,4,1), Int8(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:51] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CudaGroupConvolution)
[12/29/2021-03:46:51] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:51] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CudaDepthwiseConvolution)
[12/29/2021-03:46:51] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:51] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (FusedConvActConvolution)
[12/29/2021-03:46:51] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:51] [V] [TRT] --------------- Timing Runner: Conv_43 + Add_47 + Relu_50 (CaskConvolution)
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:46:51] [V] [TRT] Tactic: 2325023763229477890 Time: 0.01938
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 2985940154541537814
[12/29/2021-03:46:51] [V] [TRT] Tactic: 2985940154541537814 Time: 0.024456
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:46:51] [V] [TRT] Tactic: 3401614690060226673 Time: 0.009628
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 3899284354987683408
[12/29/2021-03:46:51] [V] [TRT] Tactic: 3899284354987683408 Time: 0.034808
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:46:51] [V] [TRT] Tactic: 4042202769383439184 Time: 0.012908
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: 4182625619810185112
[12/29/2021-03:46:51] [V] [TRT] Tactic: 4182625619810185112 Time: 0.029704
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: 4717285412741024953
[12/29/2021-03:46:51] [V] [TRT] Tactic: 4717285412741024953 Time: 0.023324
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:46:51] [V] [TRT] Tactic: 4734519122557206480 Time: 0.031012
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:46:51] [V] [TRT] Tactic: 5136656982162849059 Time: 0.008256
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:46:51] [V] [TRT] Tactic: 6004789655466615912 Time: 0.0135
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:46:51] [V] [TRT] Tactic: 6146901278630392829 Time: 0.030408
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:46:51] [V] [TRT] Tactic: 6781129591847482048 Time: 0.01326
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:46:51] [V] [TRT] Tactic: 8096257414008860171 Time: 0.012988
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:46:51] [V] [TRT] Tactic: -9165697322068360861 Time: 0.031616
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -9118785798277698619
[12/29/2021-03:46:51] [V] [TRT] Tactic: -9118785798277698619 Time: 0.02202
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:46:51] [V] [TRT] Tactic: -8263994888336646547 Time: 0.01908
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:46:51] [V] [TRT] Tactic: -8205948405243401049 Time: 0.009088
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:46:51] [V] [TRT] Tactic: -7683887278997527517 Time: 0.01026
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -6400348606759295499
[12/29/2021-03:46:51] [V] [TRT] Tactic: -6400348606759295499 Time: 0.021848
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -5980889159865208399
[12/29/2021-03:46:51] [V] [TRT] Tactic: -5980889159865208399 Time: 0.033572
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5766140806760372989
[12/29/2021-03:46:51] [V] [TRT] Tactic: -5766140806760372989 Time: 0.028024
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:46:51] [V] [TRT] Tactic: -4933563390723451692 Time: 0.010492
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -4516822589357530549
[12/29/2021-03:46:51] [V] [TRT] Tactic: -4516822589357530549 Time: 0.02862
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:46:51] [V] [TRT] Tactic: -3238475748440751107 Time: 0.012532
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:46:51] [V] [TRT] Tactic: -3182884991006484042 Time: 0.019172
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:46:51] [V] [TRT] Tactic: -3173468756112541306 Time: 0.00878
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2917455979290586480
[12/29/2021-03:46:51] [V] [TRT] Tactic: -2917455979290586480 Time: 0.034468
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -2571022005763160364
[12/29/2021-03:46:51] [V] [TRT] Tactic: -2571022005763160364 Time: 0.025736
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:46:51] [V] [TRT] Tactic: -1546787387293556842 Time: 0.018852
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:46:51] [V] [TRT] Tactic: -1498626619443284096 Time: 0.014408
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:46:51] [V] [TRT] Tactic: -1283580231568512025 Time: 0.009004
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:46:51] [V] [TRT] Tactic: -762222380308749469 Time: 0.01052
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:46:51] [V] [TRT] Tactic: -516725800067794372 Time: 0.030884
[12/29/2021-03:46:51] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -428104331444385564
[12/29/2021-03:46:51] [V] [TRT] Tactic: -428104331444385564 Time: 0.028788
[12/29/2021-03:46:51] [V] [TRT] Fastest Tactic: 5136656982162849059 Time: 0.008256
[12/29/2021-03:46:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5136656982162849059
[12/29/2021-03:46:51] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:51] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:51] [V] [TRT] Tactic: 1002 Time: 0.008504
[12/29/2021-03:46:51] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:51] [V] [TRT] Tactic: 0 Time: 0.005552
[12/29/2021-03:46:51] [V] [TRT] Fastest Tactic: 0 Time: 0.005552
[12/29/2021-03:46:51] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:51] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:51] [V] [TRT] Tactic: 1002 Time: 0.00844
[12/29/2021-03:46:51] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:51] [V] [TRT] Tactic: 0 Time: 0.005544
[12/29/2021-03:46:51] [V] [TRT] Fastest Tactic: 0 Time: 0.005544
[12/29/2021-03:46:51] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:51] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:51] [V] [TRT] Tactic: 1002 Time: 0.008564
[12/29/2021-03:46:51] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:51] [V] [TRT] Tactic: 0 Time: 0.005376
[12/29/2021-03:46:51] [V] [TRT] Fastest Tactic: 0 Time: 0.005376
[12/29/2021-03:46:51] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:51] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:51] [V] [TRT] Tactic: 1002 Time: 0.00754
[12/29/2021-03:46:51] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:51] [V] [TRT] Tactic: 0 Time: 0.004556
[12/29/2021-03:46:51] [V] [TRT] Fastest Tactic: 0 Time: 0.004556
[12/29/2021-03:46:51] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:51] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:51] [V] [TRT] Tactic: 1002 Time: 0.007536
[12/29/2021-03:46:51] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:51] [V] [TRT] Tactic: 0 Time: 0.005372
[12/29/2021-03:46:51] [V] [TRT] Fastest Tactic: 0 Time: 0.005372
[12/29/2021-03:46:51] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:51] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.0087
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.005188
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.005188
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.007024
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.005288
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.005288
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.009
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.005452
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.005452
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.0077
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.005308
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.005308
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.007548
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.005308
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.005308
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.008716
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.005276
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.005276
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.006868
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.005184
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.005184
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.006944
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.005516
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.005516
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.00866
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.005384
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.005384
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.008616
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.00538
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.00538
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.008668
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.005264
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.005264
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.00886
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.00518
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.00518
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.007012
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.005328
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.005328
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.0081
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.00534
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.00534
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.007952
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.005416
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.005416
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.0075
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.004656
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.004656
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.008668
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.00562
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.00562
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.008852
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.00564
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.00564
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.00904
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.005592
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.005592
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.00722
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.004716
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.004716
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.007504
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.00546
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.00546
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.007688
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.0056
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.0056
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.00862
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.005576
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.005576
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.007976
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.0057
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.0057
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1002 Time: 0.006916
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.004464
[12/29/2021-03:46:52] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1 Time: 0.004752
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 0 Time: 0.004464
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning format combination: Float(2048,16,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CudaDepthwiseConvolution)
[12/29/2021-03:46:52] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (FusedConvActConvolution)
[12/29/2021-03:46:52] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CudnnConvolution)
[12/29/2021-03:46:52] [V] [TRT] Tactic: 0 Time: 0.055564
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1 Time: 0.044852
[12/29/2021-03:46:52] [V] [TRT] Tactic: 2 Time: 0.078028
[12/29/2021-03:46:52] [V] [TRT] Tactic: 4 skipped. Scratch requested: 47775744, available: 16777216
[12/29/2021-03:46:52] [V] [TRT] Tactic: 5 skipped. Scratch requested: 106954752, available: 16777216
[12/29/2021-03:46:52] [V] [TRT] Tactic: 6 Time: 0.037368
[12/29/2021-03:46:52] [V] [TRT] Tactic: 56 Time: 0.05562
[12/29/2021-03:46:52] [V] [TRT] Tactic: 57 Time: 0.044892
[12/29/2021-03:46:52] [V] [TRT] Tactic: 58 Time: 0.07802
[12/29/2021-03:46:52] [V] [TRT] Tactic: 60 skipped. Scratch requested: 47775744, available: 16777216
[12/29/2021-03:46:52] [V] [TRT] Tactic: 61 skipped. Scratch requested: 106954752, available: 16777216
[12/29/2021-03:46:52] [V] [TRT] Tactic: 62 Time: 0.037388
[12/29/2021-03:46:52] [V] [TRT] Tactic: 112 Time: 0.055696
[12/29/2021-03:46:52] [V] [TRT] Tactic: 113 Time: 0.289796
[12/29/2021-03:46:52] [V] [TRT] Tactic: 114 Time: 0.077916
[12/29/2021-03:46:52] [V] [TRT] Tactic: 116 skipped. Scratch requested: 47775744, available: 16777216
[12/29/2021-03:46:52] [V] [TRT] Tactic: 117 skipped. Scratch requested: 106954752, available: 16777216
[12/29/2021-03:46:52] [V] [TRT] Tactic: 118 Time: 0.037364
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 118 Time: 0.037364
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CaskConvolution)
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:46:52] [V] [TRT] Tactic: 4549827808004681195 Time: 0.116436
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:46:52] [V] [TRT] Tactic: 5779835512569528575 Time: 0.14946
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[12/29/2021-03:46:52] [V] [TRT] Tactic: 6053873026024413720 Time: 0.182108
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[12/29/2021-03:46:52] [V] [TRT] Tactic: 6767548733843469815 Time: 0.138196
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:46:52] [V] [TRT] Tactic: -6313876406580483184 Time: 0.13914
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:46:52] [V] [TRT] Tactic: -1123676555321336786 Time: 0.177192
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:46:52] [V] [TRT] Tactic: -701551393537224327 Time: 0.160332
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 4549827808004681195 Time: 0.116436
[12/29/2021-03:46:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 118
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning format combination: Float(2048,1,512,128) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CudnnConvolution)
[12/29/2021-03:46:52] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CaskConvolution)
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:46:52] [V] [TRT] Tactic: 2860655430572478466 Time: 0.089096
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:46:52] [V] [TRT] Tactic: 4474630279712975759 Time: 0.052644
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:46:52] [V] [TRT] Tactic: 4479823862704990365 Time: 0.050364
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:46:52] [V] [TRT] Tactic: 4696204239951173149 Time: 0.094652
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:46:52] [V] [TRT] Tactic: 5778138195697110003 Time: 0.150932
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:46:52] [V] [TRT] Tactic: 7155825427510256858 Time: 0.153744
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:46:52] [V] [TRT] Tactic: 8918020581761223752 Time: 0.150424
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:46:52] [V] [TRT] Tactic: -4756382386362004279 Time: 0.093132
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:46:52] [V] [TRT] Tactic: -3855385237722507464 Time: 0.15454
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:46:52] [V] [TRT] Tactic: -2809379259463049391 Time: 0.151884
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:46:52] [V] [TRT] Tactic: -504296718212024303 Time: 0.144236
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.050364
[12/29/2021-03:46:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning format combination: Float(512,1:4,128,32) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CudnnConvolution)
[12/29/2021-03:46:52] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CaskConvolution)
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:46:52] [V] [TRT] Tactic: 2860655430572478466 Time: 0.089024
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:46:52] [V] [TRT] Tactic: 4474630279712975759 Time: 0.05272
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:46:52] [V] [TRT] Tactic: 4479823862704990365 Time: 0.050224
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:46:52] [V] [TRT] Tactic: 4696204239951173149 Time: 0.094616
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:46:52] [V] [TRT] Tactic: 5778138195697110003 Time: 0.150944
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:46:52] [V] [TRT] Tactic: 7155825427510256858 Time: 0.153696
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:46:52] [V] [TRT] Tactic: 7342025736444949634 Time: 0.100784
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:46:52] [V] [TRT] Tactic: 8918020581761223752 Time: 0.150332
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:46:52] [V] [TRT] Tactic: -7377458734869418330 Time: 0.099544
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:46:52] [V] [TRT] Tactic: -5457304872213719461 Time: 0.100592
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:46:52] [V] [TRT] Tactic: -4756382386362004279 Time: 0.093128
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:46:52] [V] [TRT] Tactic: -3855385237722507464 Time: 0.154556
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:46:52] [V] [TRT] Tactic: -2809379259463049391 Time: 0.151816
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:46:52] [V] [TRT] Tactic: -504296718212024303 Time: 0.1442
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.050224
[12/29/2021-03:46:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CudaDepthwiseConvolution)
[12/29/2021-03:46:52] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CaskConvolution)
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 1332468635798226953
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1332468635798226953 Time: 0.060608
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1508480131241957639 Time: 0.055592
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 1947019689364377201
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1947019689364377201 Time: 0.043056
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:46:52] [V] [TRT] Tactic: 3239257003214966313 Time: 0.060056
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:46:52] [V] [TRT] Tactic: 5592640619112287921 Time: 0.034936
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:46:52] [V] [TRT] Tactic: 7621465827583909090 Time: 0.036504
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:46:52] [V] [TRT] Tactic: -5576936487443445631 Time: 0.04774
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:46:52] [V] [TRT] Tactic: -2297737319934264721 Time: 0.055344
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:46:52] [V] [TRT] Tactic: -1425085658556684465 Time: 0.053732
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:46:52] [V] [TRT] Tactic: -108011214168778087 Time: 0.04172
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: 5592640619112287921 Time: 0.034936
[12/29/2021-03:46:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5592640619112287921
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CudaDepthwiseConvolution)
[12/29/2021-03:46:52] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (FusedConvActConvolution)
[12/29/2021-03:46:52] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CaskConvolution)
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:46:52] [V] [TRT] Tactic: 175853789719975416 Time: 0.053516
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:46:52] [V] [TRT] Tactic: 2171150287007712632 Time: 0.051316
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:46:52] [V] [TRT] Tactic: 2234457234705232274 Time: 0.034288
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:46:52] [V] [TRT] Tactic: 5834048089706882838 Time: 0.04556
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:46:52] [V] [TRT] Tactic: -8626990807754934295 Time: 0.039588
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:46:52] [V] [TRT] Tactic: -7303593854972602201 Time: 0.032744
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:46:52] [V] [TRT] Tactic: -6585664687867083638 Time: 0.0578
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: -3730012925709297561
[12/29/2021-03:46:52] [V] [TRT] Tactic: -3730012925709297561 Time: 0.040484
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: -2277259417488004546
[12/29/2021-03:46:52] [V] [TRT] Tactic: -2277259417488004546 Time: 0.057988
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:46:52] [V] [TRT] Tactic: -683636008127039856 Time: 0.052988
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: -7303593854972602201 Time: 0.032744
[12/29/2021-03:46:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7303593854972602201
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CaskConvolution)
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 984309058095623735
[12/29/2021-03:46:52] [V] [TRT] Tactic: 984309058095623735 Time: 0.04052
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1100922622480907544 Time: 0.039368
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 3238312825609165543
[12/29/2021-03:46:52] [V] [TRT] Tactic: 3238312825609165543 Time: 0.057964
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:46:52] [V] [TRT] Tactic: 3606311198834416176 Time: 0.045472
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:46:52] [V] [TRT] Tactic: 4325765560739862899 Time: 0.052904
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:46:52] [V] [TRT] Tactic: -4255737803793506479 Time: 0.057644
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:46:52] [V] [TRT] Tactic: -3958182351168863467 Time: 0.032608
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:46:52] [V] [TRT] Tactic: -3111968753064955248 Time: 0.051188
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:46:52] [V] [TRT] Tactic: -1492575840277333548 Time: 0.053188
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:46:52] [V] [TRT] Tactic: -868495160148524802 Time: 0.03422
[12/29/2021-03:46:52] [V] [TRT] Fastest Tactic: -3958182351168863467 Time: 0.032608
[12/29/2021-03:46:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3958182351168863467
[12/29/2021-03:46:52] [V] [TRT] *************** Autotuning format combination: Int8(64,16:32,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:52] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CaskConvolution)
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1011019097971850911 Time: 0.020308
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:46:52] [V] [TRT] Tactic: 1071114551801767124 Time: 0.013052
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:46:52] [V] [TRT] Tactic: 2623576043214044314 Time: 0.00936
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:46:52] [V] [TRT] Tactic: 3281631721811475881 Time: 0.01054
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:46:52] [V] [TRT] Tactic: 4551754795416974366 Time: 0.010088
[12/29/2021-03:46:52] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:46:53] [V] [TRT] Tactic: 4925112190271421402 Time: 0.009124
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:46:53] [V] [TRT] Tactic: 5012796702462679112 Time: 0.03396
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:46:53] [V] [TRT] Tactic: 5041593333398049019 Time: 0.008692
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:46:53] [V] [TRT] Tactic: 5166018662410176512 Time: 0.034748
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:46:53] [V] [TRT] Tactic: 6191867932654611882 Time: 0.020148
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:46:53] [V] [TRT] Tactic: 6556170942941957134 Time: 0.023384
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:46:53] [V] [TRT] Tactic: 6852868042694587230 Time: 0.010456
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:46:53] [V] [TRT] Tactic: 8399092794516815300 Time: 0.032064
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:46:53] [V] [TRT] Tactic: -9132922677633967263 Time: 0.013484
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:46:53] [V] [TRT] Tactic: -7988637803896331454 Time: 0.020684
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: -7865001268126363229
[12/29/2021-03:46:53] [V] [TRT] Tactic: -7865001268126363229 Time: 0.028608
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:46:53] [V] [TRT] Tactic: -7606074703023778034 Time: 0.021072
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:46:53] [V] [TRT] Tactic: -7413564913826321357 Time: 0.020748
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:46:53] [V] [TRT] Tactic: -7282232519526877434 Time: 0.032904
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:46:53] [V] [TRT] Tactic: -5942379529065248478 Time: 0.013088
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:46:53] [V] [TRT] Tactic: -5603587790314027122 Time: 0.02712
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:46:53] [V] [TRT] Tactic: -5334776871777565833 Time: 0.035192
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:46:53] [V] [TRT] Tactic: -5157868397078537095 Time: 0.020396
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:46:53] [V] [TRT] Tactic: -5100834417027499764 Time: 0.009256
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:46:53] [V] [TRT] Tactic: -3365360067423513506 Time: 0.008304
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2194148180068068313
[12/29/2021-03:46:53] [V] [TRT] Tactic: -2194148180068068313 Time: 0.033668
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:46:53] [V] [TRT] Tactic: -1782593837177056527 Time: 0.01342
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:46:53] [V] [TRT] Tactic: -1610768292520086910 Time: 0.022452
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:46:53] [V] [TRT] Tactic: -1573035963956198975 Time: 0.031632
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -1558762241666006941
[12/29/2021-03:46:53] [V] [TRT] Tactic: -1558762241666006941 Time: 0.024684
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -1365353082499976145
[12/29/2021-03:46:53] [V] [TRT] Tactic: -1365353082499976145 Time: 0.027776
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:46:53] [V] [TRT] Tactic: -621838502160440068 Time: 0.028008
[12/29/2021-03:46:53] [V] [TRT] Fastest Tactic: -3365360067423513506 Time: 0.008304
[12/29/2021-03:46:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3365360067423513506
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning format combination: Int8(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CudaGroupConvolution)
[12/29/2021-03:46:53] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:53] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CudaDepthwiseConvolution)
[12/29/2021-03:46:53] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:53] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (FusedConvActConvolution)
[12/29/2021-03:46:53] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:53] [V] [TRT] --------------- Timing Runner: Conv_53 + Relu_56 (CaskConvolution)
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 177040020707947851
[12/29/2021-03:46:53] [V] [TRT] Tactic: 177040020707947851 Time: 0.009992
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 1550399266192842845
[12/29/2021-03:46:53] [V] [TRT] Tactic: 1550399266192842845 Time: 0.009148
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 1572887561103143487
[12/29/2021-03:46:53] [V] [TRT] Tactic: 1572887561103143487 Time: 0.012496
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:46:53] [V] [TRT] Tactic: 2325023763229477890 Time: 0.018356
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 2985940154541537814
[12/29/2021-03:46:53] [V] [TRT] Tactic: 2985940154541537814 Time: 0.023264
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:46:53] [V] [TRT] Tactic: 3284282970967328046 Time: 0.008192
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:46:53] [V] [TRT] Tactic: 3401614690060226673 Time: 0.009312
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3512426920013359699
[12/29/2021-03:46:53] [V] [TRT] Tactic: 3512426920013359699 Time: 0.010024
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 3899284354987683408
[12/29/2021-03:46:53] [V] [TRT] Tactic: 3899284354987683408 Time: 0.033176
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:46:53] [V] [TRT] Tactic: 4042202769383439184 Time: 0.012328
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: 4182625619810185112
[12/29/2021-03:46:53] [V] [TRT] Tactic: 4182625619810185112 Time: 0.028568
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 4259547356717612415
[12/29/2021-03:46:53] [V] [TRT] Tactic: 4259547356717612415 Time: 0.013136
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: 4717285412741024953
[12/29/2021-03:46:53] [V] [TRT] Tactic: 4717285412741024953 Time: 0.022304
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:46:53] [V] [TRT] Tactic: 4734519122557206480 Time: 0.029828
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 5121596860264626879
[12/29/2021-03:46:53] [V] [TRT] Tactic: 5121596860264626879 Time: 0.0299
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:46:53] [V] [TRT] Tactic: 5136656982162849059 Time: 0.0082
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 5158259316594207439
[12/29/2021-03:46:53] [V] [TRT] Tactic: 5158259316594207439 Time: 0.01234
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 5966973378912044513
[12/29/2021-03:46:53] [V] [TRT] Tactic: 5966973378912044513 Time: 0.01804
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:46:53] [V] [TRT] Tactic: 6004789655466615912 Time: 0.012572
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:46:53] [V] [TRT] Tactic: 6146901278630392829 Time: 0.029456
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 6434020722187266170
[12/29/2021-03:46:53] [V] [TRT] Tactic: 6434020722187266170 Time: 0.030152
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:46:53] [V] [TRT] Tactic: 6781129591847482048 Time: 0.012528
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7191893591576074000
[12/29/2021-03:46:53] [V] [TRT] Tactic: 7191893591576074000 Time: 0.008684
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7438984192263206338
[12/29/2021-03:46:53] [V] [TRT] Tactic: 7438984192263206338 Time: 0.011968
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 7504901284678552178
[12/29/2021-03:46:53] [V] [TRT] Tactic: 7504901284678552178 Time: 0.018
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:46:53] [V] [TRT] Tactic: 8096257414008860171 Time: 0.012192
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 9143438935315839085
[12/29/2021-03:46:53] [V] [TRT] Tactic: 9143438935315839085 Time: 0.0095
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:46:53] [V] [TRT] Tactic: -9165697322068360861 Time: 0.030184
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -9118785798277698619
[12/29/2021-03:46:53] [V] [TRT] Tactic: -9118785798277698619 Time: 0.020848
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:46:53] [V] [TRT] Tactic: -8263994888336646547 Time: 0.018032
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:46:53] [V] [TRT] Tactic: -8205948405243401049 Time: 0.008952
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -7992068592656168418
[12/29/2021-03:46:53] [V] [TRT] Tactic: -7992068592656168418 Time: 0.012192
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: -7842775553137511386
[12/29/2021-03:46:53] [V] [TRT] Tactic: -7842775553137511386 Time: 0.0183
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:46:53] [V] [TRT] Tactic: -7683887278997527517 Time: 0.009984
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -6400348606759295499
[12/29/2021-03:46:53] [V] [TRT] Tactic: -6400348606759295499 Time: 0.020564
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -5980889159865208399
[12/29/2021-03:46:53] [V] [TRT] Tactic: -5980889159865208399 Time: 0.032056
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5766140806760372989
[12/29/2021-03:46:53] [V] [TRT] Tactic: -5766140806760372989 Time: 0.027044
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5709079507616090666
[12/29/2021-03:46:53] [V] [TRT] Tactic: -5709079507616090666 Time: 0.017828
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5698636014239116282
[12/29/2021-03:46:53] [V] [TRT] Tactic: -5698636014239116282 Time: 0.02946
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:46:53] [V] [TRT] Tactic: -4933563390723451692 Time: 0.010148
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -4516822589357530549
[12/29/2021-03:46:53] [V] [TRT] Tactic: -4516822589357530549 Time: 0.027496
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -3413217501222406256
[12/29/2021-03:46:53] [V] [TRT] Tactic: -3413217501222406256 Time: 0.029832
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:46:53] [V] [TRT] Tactic: -3238475748440751107 Time: 0.01202
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:46:53] [V] [TRT] Tactic: -3182884991006484042 Time: 0.018168
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:46:53] [V] [TRT] Tactic: -3173468756112541306 Time: 0.008688
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2917455979290586480
[12/29/2021-03:46:53] [V] [TRT] Tactic: -2917455979290586480 Time: 0.0329
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -2571022005763160364
[12/29/2021-03:46:53] [V] [TRT] Tactic: -2571022005763160364 Time: 0.024712
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -2083778562631872334
[12/29/2021-03:46:53] [V] [TRT] Tactic: -2083778562631872334 Time: 0.01248
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:46:53] [V] [TRT] Tactic: -1546787387293556842 Time: 0.017756
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:46:53] [V] [TRT] Tactic: -1498626619443284096 Time: 0.013484
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:46:53] [V] [TRT] Tactic: -1283580231568512025 Time: 0.008952
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: -1173968681844185579
[12/29/2021-03:46:53] [V] [TRT] Tactic: -1173968681844185579 Time: 0.008692
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:46:53] [V] [TRT] Tactic: -762222380308749469 Time: 0.010096
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -556794153877490941
[12/29/2021-03:46:53] [V] [TRT] Tactic: -556794153877490941 Time: 0.009876
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:46:53] [V] [TRT] Tactic: -516725800067794372 Time: 0.029532
[12/29/2021-03:46:53] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -428104331444385564
[12/29/2021-03:46:53] [V] [TRT] Tactic: -428104331444385564 Time: 0.027576
[12/29/2021-03:46:53] [V] [TRT] Fastest Tactic: 3284282970967328046 Time: 0.008192
[12/29/2021-03:46:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3284282970967328046
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning format combination: Float(2048,16,4,1), Float(2048,16,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning format combination: Float(2048,1,512,128), Float(2048,1,512,128) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning format combination: Float(512,1:4,128,32), Float(512,1:4,128,32) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1), Float(2048,16,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1), Int8(512,16:4,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1), Int8(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning format combination: Int8(64,16:32,4,1), Float(64,16:32,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning format combination: Int8(64,16:32,4,1), Int8(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning format combination: Float(2048,16,4,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:53] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CudaDepthwiseConvolution)
[12/29/2021-03:46:53] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:53] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (FusedConvActConvolution)
[12/29/2021-03:46:53] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:53] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CudnnConvolution)
[12/29/2021-03:46:53] [V] [TRT] Tactic: 0 Time: 0.057716
[12/29/2021-03:46:53] [V] [TRT] Tactic: 1 Time: 0.046804
[12/29/2021-03:46:53] [V] [TRT] Tactic: 2 Time: 0.077264
[12/29/2021-03:46:53] [V] [TRT] Tactic: 5 skipped. Scratch requested: 196083712, available: 16777216
[12/29/2021-03:46:53] [V] [TRT] Tactic: 56 Time: 0.057784
[12/29/2021-03:46:53] [V] [TRT] Tactic: 57 Time: 0.046284
[12/29/2021-03:46:53] [V] [TRT] Tactic: 58 Time: 0.077284
[12/29/2021-03:46:53] [V] [TRT] Tactic: 61 skipped. Scratch requested: 196083712, available: 16777216
[12/29/2021-03:46:53] [V] [TRT] Tactic: 112 Time: 0.0579
[12/29/2021-03:46:53] [V] [TRT] Tactic: 113 Time: 0.329904
[12/29/2021-03:46:53] [V] [TRT] Tactic: 114 Time: 0.077488
[12/29/2021-03:46:53] [V] [TRT] Tactic: 117 skipped. Scratch requested: 196083712, available: 16777216
[12/29/2021-03:46:53] [V] [TRT] Fastest Tactic: 57 Time: 0.046284
[12/29/2021-03:46:53] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CaskConvolution)
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:46:53] [V] [TRT] Tactic: 4549827808004681195 Time: 0.116528
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:46:53] [V] [TRT] Tactic: 5779835512569528575 Time: 0.154172
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[12/29/2021-03:46:53] [V] [TRT] Tactic: 6053873026024413720 Time: 0.160932
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[12/29/2021-03:46:53] [V] [TRT] Tactic: 6767548733843469815 Time: 0.121928
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:46:53] [V] [TRT] Tactic: -6313876406580483184 Time: 0.147376
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:46:53] [V] [TRT] Tactic: -1123676555321336786 Time: 0.159232
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:46:53] [V] [TRT] Tactic: -701551393537224327 Time: 0.134836
[12/29/2021-03:46:53] [V] [TRT] Fastest Tactic: 4549827808004681195 Time: 0.116528
[12/29/2021-03:46:53] [V] [TRT] Setting workspace to 196083712enables more tactics for profiling
[12/29/2021-03:46:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 57
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning format combination: Float(2048,1,512,128) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:53] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CudnnConvolution)
[12/29/2021-03:46:53] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:53] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CaskConvolution)
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:46:53] [V] [TRT] Tactic: 2860655430572478466 Time: 0.089128
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:46:53] [V] [TRT] Tactic: 4474630279712975759 Time: 0.053732
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:46:53] [V] [TRT] Tactic: 4479823862704990365 Time: 0.05032
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:46:53] [V] [TRT] Tactic: 4696204239951173149 Time: 0.092352
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:46:53] [V] [TRT] Tactic: 5778138195697110003 Time: 0.15332
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:46:53] [V] [TRT] Tactic: 7155825427510256858 Time: 0.147532
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:46:53] [V] [TRT] Tactic: 8918020581761223752 Time: 0.144368
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:46:53] [V] [TRT] Tactic: -4756382386362004279 Time: 0.090184
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:46:53] [V] [TRT] Tactic: -3855385237722507464 Time: 0.160284
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:46:53] [V] [TRT] Tactic: -2809379259463049391 Time: 0.157292
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:46:53] [V] [TRT] Tactic: -504296718212024303 Time: 0.14394
[12/29/2021-03:46:53] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.05032
[12/29/2021-03:46:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:46:53] [V] [TRT] *************** Autotuning format combination: Float(512,1:4,128,32) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:53] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CudnnConvolution)
[12/29/2021-03:46:53] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:53] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CaskConvolution)
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:46:53] [V] [TRT] Tactic: 2860655430572478466 Time: 0.08906
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:46:53] [V] [TRT] Tactic: 4474630279712975759 Time: 0.053768
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:46:53] [V] [TRT] Tactic: 4479823862704990365 Time: 0.05026
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:46:53] [V] [TRT] Tactic: 4696204239951173149 Time: 0.092416
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:46:53] [V] [TRT] Tactic: 5778138195697110003 Time: 0.153564
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:46:53] [V] [TRT] Tactic: 7155825427510256858 Time: 0.147432
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:46:53] [V] [TRT] Tactic: 7342025736444949634 Time: 0.1007
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:46:53] [V] [TRT] Tactic: 8918020581761223752 Time: 0.144456
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:46:53] [V] [TRT] Tactic: -7377458734869418330 Time: 0.099512
[12/29/2021-03:46:53] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:46:54] [V] [TRT] Tactic: -5457304872213719461 Time: 0.1003
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:46:54] [V] [TRT] Tactic: -4756382386362004279 Time: 0.090024
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:46:54] [V] [TRT] Tactic: -3855385237722507464 Time: 0.16024
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:46:54] [V] [TRT] Tactic: -2809379259463049391 Time: 0.157236
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:46:54] [V] [TRT] Tactic: -504296718212024303 Time: 0.143876
[12/29/2021-03:46:54] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.05026
[12/29/2021-03:46:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:46:54] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:54] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CudaDepthwiseConvolution)
[12/29/2021-03:46:54] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:54] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CaskConvolution)
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 1332468635798226953
[12/29/2021-03:46:54] [V] [TRT] Tactic: 1332468635798226953 Time: 0.059548
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:46:54] [V] [TRT] Tactic: 1508480131241957639 Time: 0.05752
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 1947019689364377201
[12/29/2021-03:46:54] [V] [TRT] Tactic: 1947019689364377201 Time: 0.038104
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:46:54] [V] [TRT] Tactic: 3239257003214966313 Time: 0.058952
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:46:54] [V] [TRT] Tactic: 5592640619112287921 Time: 0.034924
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:46:54] [V] [TRT] Tactic: 7621465827583909090 Time: 0.036548
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:46:54] [V] [TRT] Tactic: -5576936487443445631 Time: 0.041276
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:46:54] [V] [TRT] Tactic: -2297737319934264721 Time: 0.04956
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:46:54] [V] [TRT] Tactic: -1425085658556684465 Time: 0.042944
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:46:54] [V] [TRT] Tactic: -108011214168778087 Time: 0.043748
[12/29/2021-03:46:54] [V] [TRT] Fastest Tactic: 5592640619112287921 Time: 0.034924
[12/29/2021-03:46:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5592640619112287921
[12/29/2021-03:46:54] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:54] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CudaDepthwiseConvolution)
[12/29/2021-03:46:54] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:54] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (FusedConvActConvolution)
[12/29/2021-03:46:54] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:54] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CaskConvolution)
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:46:54] [V] [TRT] Tactic: 175853789719975416 Time: 0.047384
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:46:54] [V] [TRT] Tactic: 2171150287007712632 Time: 0.040832
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:46:54] [V] [TRT] Tactic: 2234457234705232274 Time: 0.03438
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:46:54] [V] [TRT] Tactic: 5834048089706882838 Time: 0.03894
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:46:54] [V] [TRT] Tactic: -8626990807754934295 Time: 0.04178
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:46:54] [V] [TRT] Tactic: -7303593854972602201 Time: 0.03274
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:46:54] [V] [TRT] Tactic: -6585664687867083638 Time: 0.05468
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: -3730012925709297561
[12/29/2021-03:46:54] [V] [TRT] Tactic: -3730012925709297561 Time: 0.035832
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: -2277259417488004546
[12/29/2021-03:46:54] [V] [TRT] Tactic: -2277259417488004546 Time: 0.05518
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:46:54] [V] [TRT] Tactic: -683636008127039856 Time: 0.05332
[12/29/2021-03:46:54] [V] [TRT] Fastest Tactic: -7303593854972602201 Time: 0.03274
[12/29/2021-03:46:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7303593854972602201
[12/29/2021-03:46:54] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:54] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CaskConvolution)
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 984309058095623735
[12/29/2021-03:46:54] [V] [TRT] Tactic: 984309058095623735 Time: 0.035512
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:46:54] [V] [TRT] Tactic: 1100922622480907544 Time: 0.041524
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 3238312825609165543
[12/29/2021-03:46:54] [V] [TRT] Tactic: 3238312825609165543 Time: 0.054744
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:46:54] [V] [TRT] Tactic: 3606311198834416176 Time: 0.038872
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:46:54] [V] [TRT] Tactic: 4325765560739862899 Time: 0.052628
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:46:54] [V] [TRT] Tactic: -4255737803793506479 Time: 0.054204
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:46:54] [V] [TRT] Tactic: -3958182351168863467 Time: 0.03274
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:46:54] [V] [TRT] Tactic: -3111968753064955248 Time: 0.040684
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:46:54] [V] [TRT] Tactic: -1492575840277333548 Time: 0.04726
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:46:54] [V] [TRT] Tactic: -868495160148524802 Time: 0.034092
[12/29/2021-03:46:54] [V] [TRT] Fastest Tactic: -3958182351168863467 Time: 0.03274
[12/29/2021-03:46:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3958182351168863467
[12/29/2021-03:46:54] [V] [TRT] *************** Autotuning format combination: Int8(64,16:32,4,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:46:54] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CaskConvolution)
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:46:54] [V] [TRT] Tactic: 1011019097971850911 Time: 0.019248
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:46:54] [V] [TRT] Tactic: 1071114551801767124 Time: 0.012988
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:46:54] [V] [TRT] Tactic: 2623576043214044314 Time: 0.00944
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:46:54] [V] [TRT] Tactic: 3281631721811475881 Time: 0.01032
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:46:54] [V] [TRT] Tactic: 4551754795416974366 Time: 0.010064
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:46:54] [V] [TRT] Tactic: 4925112190271421402 Time: 0.008876
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:46:54] [V] [TRT] Tactic: 5012796702462679112 Time: 0.031988
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:46:54] [V] [TRT] Tactic: 5041593333398049019 Time: 0.008648
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:46:54] [V] [TRT] Tactic: 5166018662410176512 Time: 0.031856
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:46:54] [V] [TRT] Tactic: 6191867932654611882 Time: 0.019892
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:46:54] [V] [TRT] Tactic: 6556170942941957134 Time: 0.02188
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:46:54] [V] [TRT] Tactic: 6852868042694587230 Time: 0.010412
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:46:54] [V] [TRT] Tactic: 8399092794516815300 Time: 0.03504
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:46:54] [V] [TRT] Tactic: -9132922677633967263 Time: 0.0136
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:46:54] [V] [TRT] Tactic: -7988637803896331454 Time: 0.020588
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: -7865001268126363229
[12/29/2021-03:46:54] [V] [TRT] Tactic: -7865001268126363229 Time: 0.02376
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:46:54] [V] [TRT] Tactic: -7606074703023778034 Time: 0.020804
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:46:54] [V] [TRT] Tactic: -7413564913826321357 Time: 0.019424
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:46:54] [V] [TRT] Tactic: -7282232519526877434 Time: 0.031308
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:46:54] [V] [TRT] Tactic: -5942379529065248478 Time: 0.013088
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:46:54] [V] [TRT] Tactic: -5603587790314027122 Time: 0.022212
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:46:54] [V] [TRT] Tactic: -5334776871777565833 Time: 0.032512
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:46:54] [V] [TRT] Tactic: -5157868397078537095 Time: 0.020168
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:46:54] [V] [TRT] Tactic: -5100834417027499764 Time: 0.009424
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:46:54] [V] [TRT] Tactic: -3365360067423513506 Time: 0.008148
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2194148180068068313
[12/29/2021-03:46:54] [V] [TRT] Tactic: -2194148180068068313 Time: 0.031568
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:46:54] [V] [TRT] Tactic: -1782593837177056527 Time: 0.013352
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:46:54] [V] [TRT] Tactic: -1610768292520086910 Time: 0.02228
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:46:54] [V] [TRT] Tactic: -1573035963956198975 Time: 0.03458
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -1558762241666006941
[12/29/2021-03:46:54] [V] [TRT] Tactic: -1558762241666006941 Time: 0.023492
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -1365353082499976145
[12/29/2021-03:46:54] [V] [TRT] Tactic: -1365353082499976145 Time: 0.023272
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:46:54] [V] [TRT] Tactic: -621838502160440068 Time: 0.023116
[12/29/2021-03:46:54] [V] [TRT] Fastest Tactic: -3365360067423513506 Time: 0.008148
[12/29/2021-03:46:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3365360067423513506
[12/29/2021-03:46:54] [V] [TRT] *************** Autotuning format combination: Int8(64,16:32,4,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:54] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CudaGroupConvolution)
[12/29/2021-03:46:54] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:54] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CudaDepthwiseConvolution)
[12/29/2021-03:46:54] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:54] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (FusedConvActConvolution)
[12/29/2021-03:46:54] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:54] [V] [TRT] --------------- Timing Runner: Conv_66 + Relu_69 (CaskConvolution)
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 177040020707947851
[12/29/2021-03:46:54] [V] [TRT] Tactic: 177040020707947851 Time: 0.009908
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 1550399266192842845
[12/29/2021-03:46:54] [V] [TRT] Tactic: 1550399266192842845 Time: 0.009032
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 1572887561103143487
[12/29/2021-03:46:54] [V] [TRT] Tactic: 1572887561103143487 Time: 0.01294
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:46:54] [V] [TRT] Tactic: 2325023763229477890 Time: 0.018444
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 2985940154541537814
[12/29/2021-03:46:54] [V] [TRT] Tactic: 2985940154541537814 Time: 0.021868
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:46:54] [V] [TRT] Tactic: 3284282970967328046 Time: 0.008072
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:46:54] [V] [TRT] Tactic: 3401614690060226673 Time: 0.009384
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3512426920013359699
[12/29/2021-03:46:54] [V] [TRT] Tactic: 3512426920013359699 Time: 0.00988
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 3899284354987683408
[12/29/2021-03:46:54] [V] [TRT] Tactic: 3899284354987683408 Time: 0.032664
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:46:54] [V] [TRT] Tactic: 4042202769383439184 Time: 0.012248
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: 4182625619810185112
[12/29/2021-03:46:54] [V] [TRT] Tactic: 4182625619810185112 Time: 0.023852
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 4259547356717612415
[12/29/2021-03:46:54] [V] [TRT] Tactic: 4259547356717612415 Time: 0.013232
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: 4717285412741024953
[12/29/2021-03:46:54] [V] [TRT] Tactic: 4717285412741024953 Time: 0.022328
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:46:54] [V] [TRT] Tactic: 4734519122557206480 Time: 0.030012
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 5121596860264626879
[12/29/2021-03:46:54] [V] [TRT] Tactic: 5121596860264626879 Time: 0.029868
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:46:54] [V] [TRT] Tactic: 5136656982162849059 Time: 0.00804
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 5158259316594207439
[12/29/2021-03:46:54] [V] [TRT] Tactic: 5158259316594207439 Time: 0.012304
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 5966973378912044513
[12/29/2021-03:46:54] [V] [TRT] Tactic: 5966973378912044513 Time: 0.018104
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:46:54] [V] [TRT] Tactic: 6004789655466615912 Time: 0.01284
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:46:54] [V] [TRT] Tactic: 6146901278630392829 Time: 0.029536
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 6434020722187266170
[12/29/2021-03:46:54] [V] [TRT] Tactic: 6434020722187266170 Time: 0.030092
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:46:54] [V] [TRT] Tactic: 6781129591847482048 Time: 0.012516
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7191893591576074000
[12/29/2021-03:46:54] [V] [TRT] Tactic: 7191893591576074000 Time: 0.008704
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7438984192263206338
[12/29/2021-03:46:54] [V] [TRT] Tactic: 7438984192263206338 Time: 0.011916
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 7504901284678552178
[12/29/2021-03:46:54] [V] [TRT] Tactic: 7504901284678552178 Time: 0.017996
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:46:54] [V] [TRT] Tactic: 8096257414008860171 Time: 0.012096
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 9143438935315839085
[12/29/2021-03:46:54] [V] [TRT] Tactic: 9143438935315839085 Time: 0.009392
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:46:54] [V] [TRT] Tactic: -9165697322068360861 Time: 0.030236
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -9118785798277698619
[12/29/2021-03:46:54] [V] [TRT] Tactic: -9118785798277698619 Time: 0.020932
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:46:54] [V] [TRT] Tactic: -8263994888336646547 Time: 0.018108
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:46:54] [V] [TRT] Tactic: -8205948405243401049 Time: 0.009012
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -7992068592656168418
[12/29/2021-03:46:54] [V] [TRT] Tactic: -7992068592656168418 Time: 0.012212
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: -7842775553137511386
[12/29/2021-03:46:54] [V] [TRT] Tactic: -7842775553137511386 Time: 0.018556
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:46:54] [V] [TRT] Tactic: -7683887278997527517 Time: 0.010064
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -6400348606759295499
[12/29/2021-03:46:54] [V] [TRT] Tactic: -6400348606759295499 Time: 0.02074
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -5980889159865208399
[12/29/2021-03:46:54] [V] [TRT] Tactic: -5980889159865208399 Time: 0.03208
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5766140806760372989
[12/29/2021-03:46:54] [V] [TRT] Tactic: -5766140806760372989 Time: 0.022348
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5709079507616090666
[12/29/2021-03:46:54] [V] [TRT] Tactic: -5709079507616090666 Time: 0.017976
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5698636014239116282
[12/29/2021-03:46:54] [V] [TRT] Tactic: -5698636014239116282 Time: 0.029816
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:46:54] [V] [TRT] Tactic: -4933563390723451692 Time: 0.009948
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -4516822589357530549
[12/29/2021-03:46:54] [V] [TRT] Tactic: -4516822589357530549 Time: 0.02336
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -3413217501222406256
[12/29/2021-03:46:54] [V] [TRT] Tactic: -3413217501222406256 Time: 0.029736
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:46:54] [V] [TRT] Tactic: -3238475748440751107 Time: 0.011952
[12/29/2021-03:46:54] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:46:55] [V] [TRT] Tactic: -3182884991006484042 Time: 0.018108
[12/29/2021-03:46:55] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:46:55] [V] [TRT] Tactic: -3173468756112541306 Time: 0.008548
[12/29/2021-03:46:55] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2917455979290586480
[12/29/2021-03:46:55] [V] [TRT] Tactic: -2917455979290586480 Time: 0.03228
[12/29/2021-03:46:55] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -2571022005763160364
[12/29/2021-03:46:55] [V] [TRT] Tactic: -2571022005763160364 Time: 0.02336
[12/29/2021-03:46:55] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -2083778562631872334
[12/29/2021-03:46:55] [V] [TRT] Tactic: -2083778562631872334 Time: 0.012424
[12/29/2021-03:46:55] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:46:55] [V] [TRT] Tactic: -1546787387293556842 Time: 0.01772
[12/29/2021-03:46:55] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:46:55] [V] [TRT] Tactic: -1498626619443284096 Time: 0.013536
[12/29/2021-03:46:55] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:46:55] [V] [TRT] Tactic: -1283580231568512025 Time: 0.008792
[12/29/2021-03:46:55] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: -1173968681844185579
[12/29/2021-03:46:55] [V] [TRT] Tactic: -1173968681844185579 Time: 0.008556
[12/29/2021-03:46:55] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:46:55] [V] [TRT] Tactic: -762222380308749469 Time: 0.010012
[12/29/2021-03:46:55] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -556794153877490941
[12/29/2021-03:46:55] [V] [TRT] Tactic: -556794153877490941 Time: 0.0099
[12/29/2021-03:46:55] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:46:55] [V] [TRT] Tactic: -516725800067794372 Time: 0.0296
[12/29/2021-03:46:55] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -428104331444385564
[12/29/2021-03:46:55] [V] [TRT] Tactic: -428104331444385564 Time: 0.023304
[12/29/2021-03:46:55] [V] [TRT] Fastest Tactic: 5136656982162849059 Time: 0.00804
[12/29/2021-03:46:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5136656982162849059
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Float(2048,16,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Float(2048,1,512,128) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Float(512,1:4,128,32) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Float(64,16:32,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Int8(512,16:4,4,1) -> Int8(64,16:32,4,1) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,16,4,1) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(2048,1,512,128) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Float(512,1:4,128,32) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning Reformat:Int8(64,16:32,4,1) -> Int8(512,16:4,4,1) ***************
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning format combination: Float(2048,16,4,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:55] [V] [TRT] --------------- Timing Runner: Conv_75 (CudaDepthwiseConvolution)
[12/29/2021-03:46:55] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:55] [V] [TRT] --------------- Timing Runner: Conv_75 (FusedConvActConvolution)
[12/29/2021-03:46:55] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:55] [V] [TRT] --------------- Timing Runner: Conv_75 (CudnnConvolution)
[12/29/2021-03:46:55] [V] [TRT] Tactic: 0 Time: 0.01432
[12/29/2021-03:46:55] [V] [TRT] Tactic: 1 Time: 0.014344
[12/29/2021-03:46:55] [V] [TRT] Tactic: 2 Time: 0.051136
[12/29/2021-03:46:55] [V] [TRT] Tactic: 56 Time: 0.014336
[12/29/2021-03:46:55] [V] [TRT] Tactic: 57 Time: 0.01424
[12/29/2021-03:46:55] [V] [TRT] Tactic: 58 Time: 0.051028
[12/29/2021-03:46:55] [V] [TRT] Tactic: 112 Time: 0.014364
[12/29/2021-03:46:55] [V] [TRT] Tactic: 113 Time: 0.014268
[12/29/2021-03:46:55] [V] [TRT] Tactic: 114 Time: 0.051072
[12/29/2021-03:46:55] [V] [TRT] Fastest Tactic: 57 Time: 0.01424
[12/29/2021-03:46:55] [V] [TRT] --------------- Timing Runner: Conv_75 (CaskConvolution)
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:46:55] [V] [TRT] Tactic: 4549827808004681195 Time: 0.021864
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:46:55] [V] [TRT] Tactic: 5779835512569528575 Time: 0.03086
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 9151672657204310840
[12/29/2021-03:46:55] [V] [TRT] Tactic: 9151672657204310840 Time: 0.037296
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: -7491730084094677098
[12/29/2021-03:46:55] [V] [TRT] Tactic: -7491730084094677098 Time: 0.02544
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:46:55] [V] [TRT] Tactic: -6313876406580483184 Time: 0.026396
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: -6273689210331812572
[12/29/2021-03:46:55] [V] [TRT] Tactic: -6273689210331812572 Time: 0.030548
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: -4337126844824617177
[12/29/2021-03:46:55] [V] [TRT] Tactic: -4337126844824617177 Time: 0.02092
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:46:55] [V] [TRT] Tactic: -1123676555321336786 Time: 0.030712
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:46:55] [V] [TRT] Tactic: -701551393537224327 Time: 0.022148
[12/29/2021-03:46:55] [V] [TRT] Fastest Tactic: -4337126844824617177 Time: 0.02092
[12/29/2021-03:46:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 57
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning format combination: Float(2048,1,512,128) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:55] [V] [TRT] --------------- Timing Runner: Conv_75 (CudnnConvolution)
[12/29/2021-03:46:55] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:55] [V] [TRT] --------------- Timing Runner: Conv_75 (CaskConvolution)
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 1663866669559596164
[12/29/2021-03:46:55] [V] [TRT] Tactic: 1663866669559596164 Time: 0.02486
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:46:55] [V] [TRT] Tactic: 2860655430572478466 Time: 0.017308
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:46:55] [V] [TRT] Tactic: 4474630279712975759 Time: 0.013188
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:46:55] [V] [TRT] Tactic: 4479823862704990365 Time: 0.0132
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:46:55] [V] [TRT] Tactic: 4696204239951173149 Time: 0.01714
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:46:55] [V] [TRT] Tactic: 5778138195697110003 Time: 0.025084
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:46:55] [V] [TRT] Tactic: 8918020581761223752 Time: 0.02362
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -5905193483742532701
[12/29/2021-03:46:55] [V] [TRT] Tactic: -5905193483742532701 Time: 0.016228
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -4035591156787122265
[12/29/2021-03:46:55] [V] [TRT] Tactic: -4035591156787122265 Time: 0.012896
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:46:55] [V] [TRT] Tactic: -2809379259463049391 Time: 0.025008
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -1985235291706575900
[12/29/2021-03:46:55] [V] [TRT] Tactic: -1985235291706575900 Time: 0.023544
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:46:55] [V] [TRT] Tactic: -504296718212024303 Time: 0.02388
[12/29/2021-03:46:55] [V] [TRT] Fastest Tactic: -4035591156787122265 Time: 0.012896
[12/29/2021-03:46:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4035591156787122265
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning format combination: Float(512,1:4,128,32) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:55] [V] [TRT] --------------- Timing Runner: Conv_75 (CudnnConvolution)
[12/29/2021-03:46:55] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:55] [V] [TRT] --------------- Timing Runner: Conv_75 (CaskConvolution)
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 1373022415249282411
[12/29/2021-03:46:55] [V] [TRT] Tactic: 1373022415249282411 Time: 0.01814
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 1663866669559596164
[12/29/2021-03:46:55] [V] [TRT] Tactic: 1663866669559596164 Time: 0.024824
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:46:55] [V] [TRT] Tactic: 2860655430572478466 Time: 0.017384
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:46:55] [V] [TRT] Tactic: 4474630279712975759 Time: 0.013184
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:46:55] [V] [TRT] Tactic: 4479823862704990365 Time: 0.013148
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:46:55] [V] [TRT] Tactic: 4696204239951173149 Time: 0.017156
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:46:55] [V] [TRT] Tactic: 5778138195697110003 Time: 0.025132
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:46:55] [V] [TRT] Tactic: 7342025736444949634 Time: 0.018412
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:46:55] [V] [TRT] Tactic: 8918020581761223752 Time: 0.023504
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -5905193483742532701
[12/29/2021-03:46:55] [V] [TRT] Tactic: -5905193483742532701 Time: 0.016208
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:46:55] [V] [TRT] Tactic: -5457304872213719461 Time: 0.018728
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -4035591156787122265
[12/29/2021-03:46:55] [V] [TRT] Tactic: -4035591156787122265 Time: 0.012868
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:46:55] [V] [TRT] Tactic: -2809379259463049391 Time: 0.025212
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -1985235291706575900
[12/29/2021-03:46:55] [V] [TRT] Tactic: -1985235291706575900 Time: 0.023564
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:46:55] [V] [TRT] Tactic: -504296718212024303 Time: 0.02382
[12/29/2021-03:46:55] [V] [TRT] Fastest Tactic: -4035591156787122265 Time: 0.012868
[12/29/2021-03:46:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4035591156787122265
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:55] [V] [TRT] --------------- Timing Runner: Conv_75 (CudaDepthwiseConvolution)
[12/29/2021-03:46:55] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:55] [V] [TRT] --------------- Timing Runner: Conv_75 (CaskConvolution)
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:46:55] [V] [TRT] Tactic: 1508480131241957639 Time: 0.018132
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 2141154648944475104
[12/29/2021-03:46:55] [V] [TRT] Tactic: 2141154648944475104 Time: 0.018156
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:46:55] [V] [TRT] Tactic: 3239257003214966313 Time: 0.0182
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:46:55] [V] [TRT] Tactic: 5592640619112287921 Time: 0.012312
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:46:55] [V] [TRT] Tactic: 7621465827583909090 Time: 0.013032
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: -6580271968881459581
[12/29/2021-03:46:55] [V] [TRT] Tactic: -6580271968881459581 Time: 0.013412
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:46:55] [V] [TRT] Tactic: -5576936487443445631 Time: 0.013144
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: -4443833619060044580
[12/29/2021-03:46:55] [V] [TRT] Tactic: -4443833619060044580 Time: 0.012212
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:46:55] [V] [TRT] Tactic: -2297737319934264721 Time: 0.013892
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:46:55] [V] [TRT] Tactic: -1425085658556684465 Time: 0.012968
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:46:55] [V] [TRT] Tactic: -108011214168778087 Time: 0.013508
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: -42427192380281294
[12/29/2021-03:46:55] [V] [TRT] Tactic: -42427192380281294 Time: 0.012792
[12/29/2021-03:46:55] [V] [TRT] Fastest Tactic: -4443833619060044580 Time: 0.012212
[12/29/2021-03:46:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4443833619060044580
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:55] [V] [TRT] --------------- Timing Runner: Conv_75 (CudaDepthwiseConvolution)
[12/29/2021-03:46:55] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:55] [V] [TRT] --------------- Timing Runner: Conv_75 (FusedConvActConvolution)
[12/29/2021-03:46:55] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:55] [V] [TRT] --------------- Timing Runner: Conv_75 (CaskConvolution)
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:46:55] [V] [TRT] Tactic: 175853789719975416 Time: 0.011752
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:46:55] [V] [TRT] Tactic: 2171150287007712632 Time: 0.010916
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:46:55] [V] [TRT] Tactic: 2234457234705232274 Time: 0.010736
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:46:55] [V] [TRT] Tactic: 5834048089706882838 Time: 0.0109
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 6299962968199310600
[12/29/2021-03:46:55] [V] [TRT] Tactic: 6299962968199310600 Time: 0.013896
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 6341572697076960911
[12/29/2021-03:46:55] [V] [TRT] Tactic: 6341572697076960911 Time: 0.010432
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:46:55] [V] [TRT] Tactic: -8626990807754934295 Time: 0.011612
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: -8498217049614706532
[12/29/2021-03:46:55] [V] [TRT] Tactic: -8498217049614706532 Time: 0.010452
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:46:55] [V] [TRT] Tactic: -7303593854972602201 Time: 0.010292
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:46:55] [V] [TRT] Tactic: -6585664687867083638 Time: 0.014012
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: -3326139578711341011
[12/29/2021-03:46:55] [V] [TRT] Tactic: -3326139578711341011 Time: 0.011432
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:46:55] [V] [TRT] Tactic: -683636008127039856 Time: 0.013936
[12/29/2021-03:46:55] [V] [TRT] Fastest Tactic: -7303593854972602201 Time: 0.010292
[12/29/2021-03:46:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7303593854972602201
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning format combination: Int8(512,16:4,4,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:55] [V] [TRT] --------------- Timing Runner: Conv_75 (CaskConvolution)
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:46:55] [V] [TRT] Tactic: 1100922622480907544 Time: 0.011456
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_c32_nn_v1 Tactic: 2855900226702061782
[12/29/2021-03:46:55] [V] [TRT] Tactic: 2855900226702061782 Time: 0.013348
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:46:55] [V] [TRT] Tactic: 3606311198834416176 Time: 0.010668
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:46:55] [V] [TRT] Tactic: 4325765560739862899 Time: 0.013404
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 8803458114157674373
[12/29/2021-03:46:55] [V] [TRT] Tactic: 8803458114157674373 Time: 0.0102
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: -6934773036503365000
[12/29/2021-03:46:55] [V] [TRT] Tactic: -6934773036503365000 Time: 0.011192
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: -4431642509665791294
[12/29/2021-03:46:55] [V] [TRT] Tactic: -4431642509665791294 Time: 0.010144
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:46:55] [V] [TRT] Tactic: -4255737803793506479 Time: 0.013324
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:46:55] [V] [TRT] Tactic: -3958182351168863467 Time: 0.010136
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:46:55] [V] [TRT] Tactic: -3111968753064955248 Time: 0.010772
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:46:55] [V] [TRT] Tactic: -1492575840277333548 Time: 0.011576
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:46:55] [V] [TRT] Tactic: -868495160148524802 Time: 0.01044
[12/29/2021-03:46:55] [V] [TRT] Fastest Tactic: -3958182351168863467 Time: 0.010136
[12/29/2021-03:46:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3958182351168863467
[12/29/2021-03:46:55] [V] [TRT] *************** Autotuning format combination: Int8(64,16:32,4,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:46:55] [V] [TRT] --------------- Timing Runner: Conv_75 (CaskConvolution)
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:46:55] [V] [TRT] Tactic: 2623576043214044314 Time: 0.006356
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 2818014835119698671
[12/29/2021-03:46:55] [V] [TRT] Tactic: 2818014835119698671 Time: 0.008076
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 3721599319722771137
[12/29/2021-03:46:55] [V] [TRT] Tactic: 3721599319722771137 Time: 0.006232
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_interior_nt_v1 Tactic: 4178917718361232468
[12/29/2021-03:46:55] [V] [TRT] Tactic: 4178917718361232468 Time: 0.009296
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:46:55] [V] [TRT] Tactic: 4551754795416974366 Time: 0.006508
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:46:55] [V] [TRT] Tactic: 4925112190271421402 Time: 0.006148
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:46:55] [V] [TRT] Tactic: 5012796702462679112 Time: 0.011056
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:46:55] [V] [TRT] Tactic: 6556170942941957134 Time: 0.009424
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 6618077155362058131
[12/29/2021-03:46:55] [V] [TRT] Tactic: 6618077155362058131 Time: 0.005904
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:46:55] [V] [TRT] Tactic: 6852868042694587230 Time: 0.007008
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 6969462133921577484
[12/29/2021-03:46:55] [V] [TRT] Tactic: 6969462133921577484 Time: 0.01554
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:46:55] [V] [TRT] Tactic: 8399092794516815300 Time: 0.015472
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:46:55] [V] [TRT] Tactic: -9132922677633967263 Time: 0.007868
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -8912999970161746151
[12/29/2021-03:46:55] [V] [TRT] Tactic: -8912999970161746151 Time: 0.007888
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -8893439100868426414
[12/29/2021-03:46:55] [V] [TRT] Tactic: -8893439100868426414 Time: 0.009068
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:46:55] [V] [TRT] Tactic: -7988637803896331454 Time: 0.009256
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_interior_nt_v1 Tactic: -7904635102498369361
[12/29/2021-03:46:55] [V] [TRT] Tactic: -7904635102498369361 Time: 0.010824
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:46:55] [V] [TRT] Tactic: -7606074703023778034 Time: 0.009148
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:46:55] [V] [TRT] Tactic: -7413564913826321357 Time: 0.009104
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:46:55] [V] [TRT] Tactic: -7282232519526877434 Time: 0.010876
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -6406011580107094428
[12/29/2021-03:46:55] [V] [TRT] Tactic: -6406011580107094428 Time: 0.006672
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:46:55] [V] [TRT] Tactic: -5603587790314027122 Time: 0.00928
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_interior_nt_v1 Tactic: -5416590980288859834
[12/29/2021-03:46:55] [V] [TRT] Tactic: -5416590980288859834 Time: 0.009352
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:46:55] [V] [TRT] Tactic: -5334776871777565833 Time: 0.012592
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:46:55] [V] [TRT] Tactic: -5157868397078537095 Time: 0.01042
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -3665201838779845683
[12/29/2021-03:46:55] [V] [TRT] Tactic: -3665201838779845683 Time: 0.012324
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_interior_nt_v1 Tactic: -3644377136375731441
[12/29/2021-03:46:55] [V] [TRT] Tactic: -3644377136375731441 Time: 0.009184
[12/29/2021-03:46:55] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -3502495740607894730
[12/29/2021-03:46:56] [V] [TRT] Tactic: -3502495740607894730 Time: 0.005968
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -2342404147487779225
[12/29/2021-03:46:56] [V] [TRT] Tactic: -2342404147487779225 Time: 0.010432
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:46:56] [V] [TRT] Tactic: -1782593837177056527 Time: 0.008168
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:46:56] [V] [TRT] Tactic: -1610768292520086910 Time: 0.009284
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:46:56] [V] [TRT] Tactic: -621838502160440068 Time: 0.009544
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 6618077155362058131 Time: 0.005904
[12/29/2021-03:46:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6618077155362058131
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning format combination: Int8(64,16:32,4,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Conv_75 (CudaGroupConvolution)
[12/29/2021-03:46:56] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Conv_75 (CudaDepthwiseConvolution)
[12/29/2021-03:46:56] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Conv_75 (FusedConvActConvolution)
[12/29/2021-03:46:56] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Conv_75 (CaskConvolution)
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 177040020707947851
[12/29/2021-03:46:56] [V] [TRT] Tactic: 177040020707947851 Time: 0.006604
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_interior_nt_v1 Tactic: 434957160407688216
[12/29/2021-03:46:56] [V] [TRT] Tactic: 434957160407688216 Time: 0.011476
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 805889586762897346
[12/29/2021-03:46:56] [V] [TRT] Tactic: 805889586762897346 Time: 0.010392
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 1550399266192842845
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1550399266192842845 Time: 0.006308
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:46:56] [V] [TRT] Tactic: 2325023763229477890 Time: 0.008476
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_interior_nt_v1 Tactic: 2346437292116182513
[12/29/2021-03:46:56] [V] [TRT] Tactic: 2346437292116182513 Time: 0.009244
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_interior_nt_v1 Tactic: 2522133112320625287
[12/29/2021-03:46:56] [V] [TRT] Tactic: 2522133112320625287 Time: 0.009304
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 2985940154541537814
[12/29/2021-03:46:56] [V] [TRT] Tactic: 2985940154541537814 Time: 0.009396
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 3538565962642681625
[12/29/2021-03:46:56] [V] [TRT] Tactic: 3538565962642681625 Time: 0.00638
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 3899284354987683408
[12/29/2021-03:46:56] [V] [TRT] Tactic: 3899284354987683408 Time: 0.011672
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:46:56] [V] [TRT] Tactic: 4042202769383439184 Time: 0.00722
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 4259547356717612415
[12/29/2021-03:46:56] [V] [TRT] Tactic: 4259547356717612415 Time: 0.007604
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: 4717285412741024953
[12/29/2021-03:46:56] [V] [TRT] Tactic: 4717285412741024953 Time: 0.00954
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:46:56] [V] [TRT] Tactic: 4734519122557206480 Time: 0.010928
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 5121596860264626879
[12/29/2021-03:46:56] [V] [TRT] Tactic: 5121596860264626879 Time: 0.0108
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_interior_nt_v1 Tactic: 5126565865931538390
[12/29/2021-03:46:56] [V] [TRT] Tactic: 5126565865931538390 Time: 0.00952
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 5158259316594207439
[12/29/2021-03:46:56] [V] [TRT] Tactic: 5158259316594207439 Time: 0.007308
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 5375256703210220108
[12/29/2021-03:46:56] [V] [TRT] Tactic: 5375256703210220108 Time: 0.007084
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 6433368103202497147
[12/29/2021-03:46:56] [V] [TRT] Tactic: 6433368103202497147 Time: 0.008328
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 6434020722187266170
[12/29/2021-03:46:56] [V] [TRT] Tactic: 6434020722187266170 Time: 0.010624
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 6441948709525127755
[12/29/2021-03:46:56] [V] [TRT] Tactic: 6441948709525127755 Time: 0.006072
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 6457435868048963632
[12/29/2021-03:46:56] [V] [TRT] Tactic: 6457435868048963632 Time: 0.007012
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:46:56] [V] [TRT] Tactic: 6781129591847482048 Time: 0.007296
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 6925201228918187099
[12/29/2021-03:46:56] [V] [TRT] Tactic: 6925201228918187099 Time: 0.00824
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 7504901284678552178
[12/29/2021-03:46:56] [V] [TRT] Tactic: 7504901284678552178 Time: 0.008208
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 7731430299029542276
[12/29/2021-03:46:56] [V] [TRT] Tactic: 7731430299029542276 Time: 0.008064
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 7738495016763012180
[12/29/2021-03:46:56] [V] [TRT] Tactic: 7738495016763012180 Time: 0.010496
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 8234775147403903473
[12/29/2021-03:46:56] [V] [TRT] Tactic: 8234775147403903473 Time: 0.010268
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:46:56] [V] [TRT] Tactic: -9165697322068360861 Time: 0.010688
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -9118785798277698619
[12/29/2021-03:46:56] [V] [TRT] Tactic: -9118785798277698619 Time: 0.009332
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -8556775352640313933
[12/29/2021-03:46:56] [V] [TRT] Tactic: -8556775352640313933 Time: 0.0082
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:46:56] [V] [TRT] Tactic: -8263994888336646547 Time: 0.008236
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:46:56] [V] [TRT] Tactic: -8205948405243401049 Time: 0.006208
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: -7842775553137511386
[12/29/2021-03:46:56] [V] [TRT] Tactic: -7842775553137511386 Time: 0.008328
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:46:56] [V] [TRT] Tactic: -7683887278997527517 Time: 0.00656
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -6527178416855951297
[12/29/2021-03:46:56] [V] [TRT] Tactic: -6527178416855951297 Time: 0.00624
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -6510232214299595844
[12/29/2021-03:46:56] [V] [TRT] Tactic: -6510232214299595844 Time: 0.006132
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -6400348606759295499
[12/29/2021-03:46:56] [V] [TRT] Tactic: -6400348606759295499 Time: 0.009248
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -5980889159865208399
[12/29/2021-03:46:56] [V] [TRT] Tactic: -5980889159865208399 Time: 0.01162
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5766140806760372989
[12/29/2021-03:46:56] [V] [TRT] Tactic: -5766140806760372989 Time: 0.009476
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -5170003087447722174
[12/29/2021-03:46:56] [V] [TRT] Tactic: -5170003087447722174 Time: 0.005928
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -4849712423393454704
[12/29/2021-03:46:56] [V] [TRT] Tactic: -4849712423393454704 Time: 0.007012
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -4516822589357530549
[12/29/2021-03:46:56] [V] [TRT] Tactic: -4516822589357530549 Time: 0.009716
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -3613322253849278738
[12/29/2021-03:46:56] [V] [TRT] Tactic: -3613322253849278738 Time: 0.005888
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -3577322188448771475
[12/29/2021-03:46:56] [V] [TRT] Tactic: -3577322188448771475 Time: 0.007092
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -2754311112012636251
[12/29/2021-03:46:56] [V] [TRT] Tactic: -2754311112012636251 Time: 0.007156
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: -2315453944962430928
[12/29/2021-03:46:56] [V] [TRT] Tactic: -2315453944962430928 Time: 0.010512
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -2083778562631872334
[12/29/2021-03:46:56] [V] [TRT] Tactic: -2083778562631872334 Time: 0.007108
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -1499578657823798783
[12/29/2021-03:46:56] [V] [TRT] Tactic: -1499578657823798783 Time: 0.00632
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:46:56] [V] [TRT] Tactic: -1498626619443284096 Time: 0.00752
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:46:56] [V] [TRT] Tactic: -1283580231568512025 Time: 0.006172
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: -1173968681844185579
[12/29/2021-03:46:56] [V] [TRT] Tactic: -1173968681844185579 Time: 0.006208
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:46:56] [V] [TRT] Tactic: -762222380308749469 Time: 0.006452
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -713022856474991236
[12/29/2021-03:46:56] [V] [TRT] Tactic: -713022856474991236 Time: 0.005848
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -556794153877490941
[12/29/2021-03:46:56] [V] [TRT] Tactic: -556794153877490941 Time: 0.006532
[12/29/2021-03:46:56] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -375949437730908730
[12/29/2021-03:46:56] [V] [TRT] Tactic: -375949437730908730 Time: 0.006932
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: -713022856474991236 Time: 0.005848
[12/29/2021-03:46:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -713022856474991236
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.009416
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.005032
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.005032
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.009464
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.00498
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.00498
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.008184
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.004544
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.004544
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.008192
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.005116
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.005116
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.009744
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.004792
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.004792
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.008196
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.004808
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.004808
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.008568
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.005204
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.005204
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.008356
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.005296
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.005296
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.009764
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.004944
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.004944
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.008424
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.005052
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.005052
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.009388
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.005092
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.005092
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.009372
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.00522
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.00522
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.009668
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.004804
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.004804
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.009952
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.004892
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.004892
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.008236
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.005012
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.005012
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.008916
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.005216
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.005216
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.0088
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.005116
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.005116
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.006864
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.004544
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.004544
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.009308
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.005828
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.005828
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.009528
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.005792
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.005792
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.0078
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.0048
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.0048
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.00696
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.00524
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.00524
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.008664
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.005856
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.005856
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.009516
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.005748
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.005748
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.007516
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.004532
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1 Time: 0.004936
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.004532
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.009448
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.004768
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.004768
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.009932
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.004812
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.004812
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.008264
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.004956
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.004956
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.009808
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.005292
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.005292
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1002 Time: 0.009084
[12/29/2021-03:46:56] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.005292
[12/29/2021-03:46:56] [V] [TRT] Fastest Tactic: 0 Time: 0.005292
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] *************** Autotuning format combination: Float(1024,4,2,1), Float(1024,4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CudaDepthwiseConvolution)
[12/29/2021-03:46:56] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (FusedConvActConvolution)
[12/29/2021-03:46:56] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:56] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CudnnConvolution)
[12/29/2021-03:46:56] [V] [TRT] Tactic: 0 Time: 0.106932
[12/29/2021-03:46:56] [V] [TRT] Tactic: 1 Time: 0.127296
[12/29/2021-03:46:56] [V] [TRT] Tactic: 2 Time: 0.11064
[12/29/2021-03:46:56] [V] [TRT] Tactic: 4 skipped. Scratch requested: 172228608, available: 16777216
[12/29/2021-03:46:56] [V] [TRT] Tactic: 5 skipped. Scratch requested: 356515840, available: 16777216
[12/29/2021-03:46:56] [V] [TRT] Tactic: 6 Time: 0.066716
[12/29/2021-03:46:56] [V] [TRT] Tactic: 56 Time: 0.106844
[12/29/2021-03:46:56] [V] [TRT] Tactic: 57 Time: 0.09684
[12/29/2021-03:46:56] [V] [TRT] Tactic: 58 Time: 0.110904
[12/29/2021-03:46:56] [V] [TRT] Tactic: 60 skipped. Scratch requested: 172228608, available: 16777216
[12/29/2021-03:46:56] [V] [TRT] Tactic: 61 skipped. Scratch requested: 356515840, available: 16777216
[12/29/2021-03:46:56] [V] [TRT] Tactic: 62 Time: 0.066644
[12/29/2021-03:46:56] [V] [TRT] Tactic: 112 Time: 0.10704
[12/29/2021-03:46:57] [V] [TRT] Tactic: 113 Time: 0.227228
[12/29/2021-03:46:57] [V] [TRT] Tactic: 114 Time: 0.1109
[12/29/2021-03:46:57] [V] [TRT] Tactic: 116 skipped. Scratch requested: 172228608, available: 16777216
[12/29/2021-03:46:57] [V] [TRT] Tactic: 117 skipped. Scratch requested: 356515840, available: 16777216
[12/29/2021-03:46:57] [V] [TRT] Tactic: 118 Time: 0.066776
[12/29/2021-03:46:57] [V] [TRT] Fastest Tactic: 62 Time: 0.066644
[12/29/2021-03:46:57] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CaskConvolution)
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:46:57] [V] [TRT] Tactic: 4549827808004681195 Time: 0.227544
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:46:57] [V] [TRT] Tactic: 5779835512569528575 Time: 0.3045
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[12/29/2021-03:46:57] [V] [TRT] Tactic: 6053873026024413720 Time: 0.318264
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[12/29/2021-03:46:57] [V] [TRT] Tactic: 6767548733843469815 Time: 0.234556
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:46:57] [V] [TRT] Tactic: -6313876406580483184 Time: 0.27122
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:46:57] [V] [TRT] Tactic: -1123676555321336786 Time: 0.31144
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:46:57] [V] [TRT] Tactic: -701551393537224327 Time: 0.261516
[12/29/2021-03:46:57] [V] [TRT] Fastest Tactic: 4549827808004681195 Time: 0.227544
[12/29/2021-03:46:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 62
[12/29/2021-03:46:57] [V] [TRT] *************** Autotuning format combination: Float(1024,1,512,256), Float(1024,1,512,256) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:57] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CudnnConvolution)
[12/29/2021-03:46:57] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:57] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CaskConvolution)
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:46:57] [V] [TRT] Tactic: 2860655430572478466 Time: 0.16978
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:46:57] [V] [TRT] Tactic: 4474630279712975759 Time: 0.099984
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:46:57] [V] [TRT] Tactic: 4479823862704990365 Time: 0.092872
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:46:57] [V] [TRT] Tactic: 4696204239951173149 Time: 0.176988
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:46:57] [V] [TRT] Tactic: 5778138195697110003 Time: 0.291028
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:46:57] [V] [TRT] Tactic: 7155825427510256858 Time: 0.286236
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:46:57] [V] [TRT] Tactic: 8918020581761223752 Time: 0.27996
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:46:57] [V] [TRT] Tactic: -4756382386362004279 Time: 0.172412
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:46:57] [V] [TRT] Tactic: -3855385237722507464 Time: 0.307908
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:46:57] [V] [TRT] Tactic: -2809379259463049391 Time: 0.303604
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:46:57] [V] [TRT] Tactic: -504296718212024303 Time: 0.27968
[12/29/2021-03:46:57] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.092872
[12/29/2021-03:46:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:46:57] [V] [TRT] *************** Autotuning format combination: Float(256,1:4,128,64), Float(256,1:4,128,64) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:57] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CudnnConvolution)
[12/29/2021-03:46:57] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:57] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CaskConvolution)
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:46:57] [V] [TRT] Tactic: 2860655430572478466 Time: 0.169948
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:46:57] [V] [TRT] Tactic: 4474630279712975759 Time: 0.099932
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:46:57] [V] [TRT] Tactic: 4479823862704990365 Time: 0.092924
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:46:57] [V] [TRT] Tactic: 4696204239951173149 Time: 0.177108
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:46:57] [V] [TRT] Tactic: 5778138195697110003 Time: 0.2909
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:46:57] [V] [TRT] Tactic: 7155825427510256858 Time: 0.286108
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:46:57] [V] [TRT] Tactic: 7342025736444949634 Time: 0.1951
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:46:57] [V] [TRT] Tactic: 8918020581761223752 Time: 0.279816
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:46:57] [V] [TRT] Tactic: -7377458734869418330 Time: 0.191884
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:46:57] [V] [TRT] Tactic: -5457304872213719461 Time: 0.193508
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:46:57] [V] [TRT] Tactic: -4756382386362004279 Time: 0.17228
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:46:57] [V] [TRT] Tactic: -3855385237722507464 Time: 0.307972
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:46:57] [V] [TRT] Tactic: -2809379259463049391 Time: 0.3038
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:46:57] [V] [TRT] Tactic: -504296718212024303 Time: 0.279672
[12/29/2021-03:46:57] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.092924
[12/29/2021-03:46:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:46:57] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1), Float(1024,4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:57] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CudaDepthwiseConvolution)
[12/29/2021-03:46:57] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:57] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CaskConvolution)
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 1332468635798226953
[12/29/2021-03:46:57] [V] [TRT] Tactic: 1332468635798226953 Time: 0.108264
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:46:57] [V] [TRT] Tactic: 1508480131241957639 Time: 0.104996
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 1947019689364377201
[12/29/2021-03:46:57] [V] [TRT] Tactic: 1947019689364377201 Time: 0.067516
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:46:57] [V] [TRT] Tactic: 3239257003214966313 Time: 0.107788
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:46:57] [V] [TRT] Tactic: 5592640619112287921 Time: 0.06178
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:46:57] [V] [TRT] Tactic: 7621465827583909090 Time: 0.065508
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:46:57] [V] [TRT] Tactic: -5576936487443445631 Time: 0.074048
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:46:57] [V] [TRT] Tactic: -2297737319934264721 Time: 0.08748
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:46:57] [V] [TRT] Tactic: -1425085658556684465 Time: 0.077564
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:46:57] [V] [TRT] Tactic: -108011214168778087 Time: 0.075644
[12/29/2021-03:46:57] [V] [TRT] Fastest Tactic: 5592640619112287921 Time: 0.06178
[12/29/2021-03:46:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5592640619112287921
[12/29/2021-03:46:57] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1), Int8(256,4:4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:57] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CudaDepthwiseConvolution)
[12/29/2021-03:46:57] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:57] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (FusedConvActConvolution)
[12/29/2021-03:46:57] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:57] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CaskConvolution)
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:46:57] [V] [TRT] Tactic: 175853789719975416 Time: 0.085988
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:46:57] [V] [TRT] Tactic: 2171150287007712632 Time: 0.075892
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:46:57] [V] [TRT] Tactic: 2234457234705232274 Time: 0.063684
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:46:57] [V] [TRT] Tactic: 5834048089706882838 Time: 0.07196
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:46:57] [V] [TRT] Tactic: -8626990807754934295 Time: 0.07414
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:46:57] [V] [TRT] Tactic: -7303593854972602201 Time: 0.0603
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:46:57] [V] [TRT] Tactic: -6585664687867083638 Time: 0.103332
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: -3730012925709297561
[12/29/2021-03:46:57] [V] [TRT] Tactic: -3730012925709297561 Time: 0.065708
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: -2277259417488004546
[12/29/2021-03:46:57] [V] [TRT] Tactic: -2277259417488004546 Time: 0.1042
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:46:57] [V] [TRT] Tactic: -683636008127039856 Time: 0.100528
[12/29/2021-03:46:57] [V] [TRT] Fastest Tactic: -7303593854972602201 Time: 0.0603
[12/29/2021-03:46:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7303593854972602201
[12/29/2021-03:46:57] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1), Int8(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:57] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CaskConvolution)
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 984309058095623735
[12/29/2021-03:46:57] [V] [TRT] Tactic: 984309058095623735 Time: 0.065628
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:46:57] [V] [TRT] Tactic: 1100922622480907544 Time: 0.074208
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 3238312825609165543
[12/29/2021-03:46:57] [V] [TRT] Tactic: 3238312825609165543 Time: 0.103568
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:46:57] [V] [TRT] Tactic: 3606311198834416176 Time: 0.071828
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:46:57] [V] [TRT] Tactic: 4325765560739862899 Time: 0.099728
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:46:57] [V] [TRT] Tactic: -4255737803793506479 Time: 0.102356
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:46:57] [V] [TRT] Tactic: -3958182351168863467 Time: 0.060196
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:46:57] [V] [TRT] Tactic: -3111968753064955248 Time: 0.075864
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:46:57] [V] [TRT] Tactic: -1492575840277333548 Time: 0.086008
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:46:57] [V] [TRT] Tactic: -868495160148524802 Time: 0.063448
[12/29/2021-03:46:57] [V] [TRT] Fastest Tactic: -3958182351168863467 Time: 0.060196
[12/29/2021-03:46:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3958182351168863467
[12/29/2021-03:46:57] [V] [TRT] *************** Autotuning format combination: Int8(32,4:32,2,1), Float(32,4:32,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:46:57] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CaskConvolution)
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:46:57] [V] [TRT] Tactic: 1011019097971850911 Time: 0.031456
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:46:57] [V] [TRT] Tactic: 1071114551801767124 Time: 0.019064
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:46:57] [V] [TRT] Tactic: 2623576043214044314 Time: 0.012456
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:46:57] [V] [TRT] Tactic: 3281631721811475881 Time: 0.014824
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:46:57] [V] [TRT] Tactic: 4551754795416974366 Time: 0.013908
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:46:57] [V] [TRT] Tactic: 4925112190271421402 Time: 0.011764
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:46:57] [V] [TRT] Tactic: 5012796702462679112 Time: 0.056984
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:46:57] [V] [TRT] Tactic: 5041593333398049019 Time: 0.011684
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:46:57] [V] [TRT] Tactic: 5166018662410176512 Time: 0.05478
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:46:57] [V] [TRT] Tactic: 6191867932654611882 Time: 0.031628
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:46:57] [V] [TRT] Tactic: 6556170942941957134 Time: 0.03718
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:46:57] [V] [TRT] Tactic: 6852868042694587230 Time: 0.014304
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:46:57] [V] [TRT] Tactic: 8399092794516815300 Time: 0.057828
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:46:57] [V] [TRT] Tactic: -9132922677633967263 Time: 0.019484
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:46:57] [V] [TRT] Tactic: -7988637803896331454 Time: 0.03466
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: -7865001268126363229
[12/29/2021-03:46:57] [V] [TRT] Tactic: -7865001268126363229 Time: 0.040172
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:46:57] [V] [TRT] Tactic: -7606074703023778034 Time: 0.03432
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:46:57] [V] [TRT] Tactic: -7413564913826321357 Time: 0.031684
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:46:57] [V] [TRT] Tactic: -7282232519526877434 Time: 0.05558
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:46:57] [V] [TRT] Tactic: -5942379529065248478 Time: 0.019308
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:46:57] [V] [TRT] Tactic: -5603587790314027122 Time: 0.037212
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:46:57] [V] [TRT] Tactic: -5334776871777565833 Time: 0.055244
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:46:57] [V] [TRT] Tactic: -5157868397078537095 Time: 0.031744
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:46:57] [V] [TRT] Tactic: -5100834417027499764 Time: 0.0131
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:46:57] [V] [TRT] Tactic: -3365360067423513506 Time: 0.01048
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2194148180068068313
[12/29/2021-03:46:57] [V] [TRT] Tactic: -2194148180068068313 Time: 0.055808
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:46:57] [V] [TRT] Tactic: -1782593837177056527 Time: 0.019484
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:46:57] [V] [TRT] Tactic: -1610768292520086910 Time: 0.036808
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:46:57] [V] [TRT] Tactic: -1573035963956198975 Time: 0.05722
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -1558762241666006941
[12/29/2021-03:46:57] [V] [TRT] Tactic: -1558762241666006941 Time: 0.039668
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -1365353082499976145
[12/29/2021-03:46:57] [V] [TRT] Tactic: -1365353082499976145 Time: 0.03902
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:46:57] [V] [TRT] Tactic: -621838502160440068 Time: 0.039056
[12/29/2021-03:46:57] [V] [TRT] Fastest Tactic: -3365360067423513506 Time: 0.01048
[12/29/2021-03:46:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3365360067423513506
[12/29/2021-03:46:57] [V] [TRT] *************** Autotuning format combination: Int8(32,4:32,2,1), Int8(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:57] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CudaGroupConvolution)
[12/29/2021-03:46:57] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:57] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CudaDepthwiseConvolution)
[12/29/2021-03:46:57] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:57] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (FusedConvActConvolution)
[12/29/2021-03:46:57] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:57] [V] [TRT] --------------- Timing Runner: Conv_72 + Add_76 + Relu_79 (CaskConvolution)
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:46:57] [V] [TRT] Tactic: 2325023763229477890 Time: 0.030384
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:46:57] [V] [TRT] Tactic: 3401614690060226673 Time: 0.01266
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:46:57] [V] [TRT] Tactic: 4042202769383439184 Time: 0.018384
[12/29/2021-03:46:57] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:46:58] [V] [TRT] Tactic: 4734519122557206480 Time: 0.053136
[12/29/2021-03:46:58] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:46:58] [V] [TRT] Tactic: 5136656982162849059 Time: 0.01044
[12/29/2021-03:46:58] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:46:58] [V] [TRT] Tactic: 6004789655466615912 Time: 0.019176
[12/29/2021-03:46:58] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:46:58] [V] [TRT] Tactic: 6146901278630392829 Time: 0.0527
[12/29/2021-03:46:58] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:46:58] [V] [TRT] Tactic: 6781129591847482048 Time: 0.018852
[12/29/2021-03:46:58] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:46:58] [V] [TRT] Tactic: 8096257414008860171 Time: 0.018532
[12/29/2021-03:46:58] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:46:58] [V] [TRT] Tactic: -9165697322068360861 Time: 0.053256
[12/29/2021-03:46:58] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:46:58] [V] [TRT] Tactic: -8263994888336646547 Time: 0.030152
[12/29/2021-03:46:58] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:46:58] [V] [TRT] Tactic: -8205948405243401049 Time: 0.011748
[12/29/2021-03:46:58] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:46:58] [V] [TRT] Tactic: -7683887278997527517 Time: 0.013608
[12/29/2021-03:46:58] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:46:58] [V] [TRT] Tactic: -4933563390723451692 Time: 0.014304
[12/29/2021-03:46:58] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:46:58] [V] [TRT] Tactic: -3238475748440751107 Time: 0.018024
[12/29/2021-03:46:58] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:46:58] [V] [TRT] Tactic: -3182884991006484042 Time: 0.030128
[12/29/2021-03:46:58] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:46:58] [V] [TRT] Tactic: -3173468756112541306 Time: 0.011516
[12/29/2021-03:46:58] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:46:58] [V] [TRT] Tactic: -1546787387293556842 Time: 0.029832
[12/29/2021-03:46:58] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:46:58] [V] [TRT] Tactic: -1498626619443284096 Time: 0.020684
[12/29/2021-03:46:58] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:46:58] [V] [TRT] Tactic: -1283580231568512025 Time: 0.011476
[12/29/2021-03:46:58] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:46:58] [V] [TRT] Tactic: -762222380308749469 Time: 0.013972
[12/29/2021-03:46:58] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:46:58] [V] [TRT] Tactic: -516725800067794372 Time: 0.052516
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 5136656982162849059 Time: 0.01044
[12/29/2021-03:46:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5136656982162849059
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.0095
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.005132
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.005132
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.009472
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.004984
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.004984
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.009388
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.004836
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.004836
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.008364
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.004696
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.004696
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.008196
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.005196
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.005196
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.009816
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.004776
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.004776
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.008432
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.004848
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.004848
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.010052
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.00494
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.00494
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.0086
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.005124
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.005124
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.00854
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.005092
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.005092
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.00988
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.004888
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.004888
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.008296
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.00494
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.00494
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.00822
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.004972
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.004972
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.009416
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.005156
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.005156
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.009424
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.005164
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.005164
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.009704
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.00486
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.00486
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.009956
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.004972
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.004972
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.00822
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.004996
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.004996
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.00896
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.005308
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.005308
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.008904
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.005244
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.005244
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.006944
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.004528
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.004528
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.009256
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.005748
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.005748
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.00964
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.005852
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.005852
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.009848
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.005328
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.005328
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.007744
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.00484
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.00484
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.006968
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.005112
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.005112
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.008512
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.00584
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.00584
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.009556
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.00574
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.00574
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.009048
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.00532
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.00532
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1002 Time: 0.00754
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.004608
[12/29/2021-03:46:58] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1 Time: 0.005044
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 0 Time: 0.004608
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning format combination: Float(1024,4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CudaDepthwiseConvolution)
[12/29/2021-03:46:58] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (FusedConvActConvolution)
[12/29/2021-03:46:58] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CudnnConvolution)
[12/29/2021-03:46:58] [V] [TRT] Tactic: 0 Time: 0.104404
[12/29/2021-03:46:58] [V] [TRT] Tactic: 1 Time: 0.075016
[12/29/2021-03:46:58] [V] [TRT] Tactic: 2 Time: 0.10812
[12/29/2021-03:46:58] [V] [TRT] Tactic: 4 skipped. Scratch requested: 172228608, available: 16777216
[12/29/2021-03:46:58] [V] [TRT] Tactic: 5 skipped. Scratch requested: 356515840, available: 16777216
[12/29/2021-03:46:58] [V] [TRT] Tactic: 6 Time: 0.06354
[12/29/2021-03:46:58] [V] [TRT] Tactic: 56 Time: 0.104288
[12/29/2021-03:46:58] [V] [TRT] Tactic: 57 Time: 0.066064
[12/29/2021-03:46:58] [V] [TRT] Tactic: 58 Time: 0.108256
[12/29/2021-03:46:58] [V] [TRT] Tactic: 60 skipped. Scratch requested: 172228608, available: 16777216
[12/29/2021-03:46:58] [V] [TRT] Tactic: 61 skipped. Scratch requested: 356515840, available: 16777216
[12/29/2021-03:46:58] [V] [TRT] Tactic: 62 Time: 0.0637
[12/29/2021-03:46:58] [V] [TRT] Tactic: 112 Time: 0.104272
[12/29/2021-03:46:58] [V] [TRT] Tactic: 113 Time: 0.146088
[12/29/2021-03:46:58] [V] [TRT] Tactic: 114 Time: 0.108172
[12/29/2021-03:46:58] [V] [TRT] Tactic: 116 skipped. Scratch requested: 172228608, available: 16777216
[12/29/2021-03:46:58] [V] [TRT] Tactic: 117 skipped. Scratch requested: 356515840, available: 16777216
[12/29/2021-03:46:58] [V] [TRT] Tactic: 118 Time: 0.063808
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 6 Time: 0.06354
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CaskConvolution)
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:46:58] [V] [TRT] Tactic: 4549827808004681195 Time: 0.22648
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:46:58] [V] [TRT] Tactic: 5779835512569528575 Time: 0.302
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[12/29/2021-03:46:58] [V] [TRT] Tactic: 6053873026024413720 Time: 0.316164
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[12/29/2021-03:46:58] [V] [TRT] Tactic: 6767548733843469815 Time: 0.233312
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:46:58] [V] [TRT] Tactic: -6313876406580483184 Time: 0.27028
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:46:58] [V] [TRT] Tactic: -1123676555321336786 Time: 0.3087
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:46:58] [V] [TRT] Tactic: -701551393537224327 Time: 0.260168
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 4549827808004681195 Time: 0.22648
[12/29/2021-03:46:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning format combination: Float(1024,1,512,256) -> Float(1024,1,512,256) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CudnnConvolution)
[12/29/2021-03:46:58] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CaskConvolution)
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:46:58] [V] [TRT] Tactic: 2860655430572478466 Time: 0.169148
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:46:58] [V] [TRT] Tactic: 4474630279712975759 Time: 0.099212
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:46:58] [V] [TRT] Tactic: 4479823862704990365 Time: 0.092012
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:46:58] [V] [TRT] Tactic: 4696204239951173149 Time: 0.176192
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:46:58] [V] [TRT] Tactic: 5778138195697110003 Time: 0.289988
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:46:58] [V] [TRT] Tactic: 7155825427510256858 Time: 0.285528
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:46:58] [V] [TRT] Tactic: 8918020581761223752 Time: 0.278892
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:46:58] [V] [TRT] Tactic: -4756382386362004279 Time: 0.171456
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:46:58] [V] [TRT] Tactic: -3855385237722507464 Time: 0.307024
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:46:58] [V] [TRT] Tactic: -2809379259463049391 Time: 0.302764
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:46:58] [V] [TRT] Tactic: -504296718212024303 Time: 0.278992
[12/29/2021-03:46:58] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.092012
[12/29/2021-03:46:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:46:58] [V] [TRT] *************** Autotuning format combination: Float(256,1:4,128,64) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CudnnConvolution)
[12/29/2021-03:46:58] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:58] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CaskConvolution)
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:46:58] [V] [TRT] Tactic: 2860655430572478466 Time: 0.16918
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:46:58] [V] [TRT] Tactic: 4474630279712975759 Time: 0.099144
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:46:58] [V] [TRT] Tactic: 4479823862704990365 Time: 0.092
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:46:58] [V] [TRT] Tactic: 4696204239951173149 Time: 0.176468
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:46:58] [V] [TRT] Tactic: 5778138195697110003 Time: 0.290096
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[12/29/2021-03:46:58] [V] [TRT] Tactic: 7155825427510256858 Time: 0.285432
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:46:58] [V] [TRT] Tactic: 7342025736444949634 Time: 0.193224
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:46:58] [V] [TRT] Tactic: 8918020581761223752 Time: 0.27894
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:46:58] [V] [TRT] Tactic: -7377458734869418330 Time: 0.190136
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:46:58] [V] [TRT] Tactic: -5457304872213719461 Time: 0.1917
[12/29/2021-03:46:58] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[12/29/2021-03:46:59] [V] [TRT] Tactic: -4756382386362004279 Time: 0.171264
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[12/29/2021-03:46:59] [V] [TRT] Tactic: -3855385237722507464 Time: 0.307024
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:46:59] [V] [TRT] Tactic: -2809379259463049391 Time: 0.3027
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:46:59] [V] [TRT] Tactic: -504296718212024303 Time: 0.278708
[12/29/2021-03:46:59] [V] [TRT] Fastest Tactic: 4479823862704990365 Time: 0.092
[12/29/2021-03:46:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4479823862704990365
[12/29/2021-03:46:59] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:46:59] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CudaDepthwiseConvolution)
[12/29/2021-03:46:59] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:59] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CaskConvolution)
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: 1332468635798226953
[12/29/2021-03:46:59] [V] [TRT] Tactic: 1332468635798226953 Time: 0.106068
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:46:59] [V] [TRT] Tactic: 1508480131241957639 Time: 0.102544
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: 1947019689364377201
[12/29/2021-03:46:59] [V] [TRT] Tactic: 1947019689364377201 Time: 0.066236
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:46:59] [V] [TRT] Tactic: 3239257003214966313 Time: 0.105068
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:46:59] [V] [TRT] Tactic: 5592640619112287921 Time: 0.060732
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:46:59] [V] [TRT] Tactic: 7621465827583909090 Time: 0.06414
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:46:59] [V] [TRT] Tactic: -5576936487443445631 Time: 0.072704
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:46:59] [V] [TRT] Tactic: -2297737319934264721 Time: 0.086564
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:46:59] [V] [TRT] Tactic: -1425085658556684465 Time: 0.076328
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:46:59] [V] [TRT] Tactic: -108011214168778087 Time: 0.074556
[12/29/2021-03:46:59] [V] [TRT] Fastest Tactic: 5592640619112287921 Time: 0.060732
[12/29/2021-03:46:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5592640619112287921
[12/29/2021-03:46:59] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:46:59] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CudaDepthwiseConvolution)
[12/29/2021-03:46:59] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:59] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (FusedConvActConvolution)
[12/29/2021-03:46:59] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:59] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CaskConvolution)
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:46:59] [V] [TRT] Tactic: 175853789719975416 Time: 0.084396
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:46:59] [V] [TRT] Tactic: 2171150287007712632 Time: 0.074172
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:46:59] [V] [TRT] Tactic: 2234457234705232274 Time: 0.061764
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:46:59] [V] [TRT] Tactic: 5834048089706882838 Time: 0.070348
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:46:59] [V] [TRT] Tactic: -8626990807754934295 Time: 0.072428
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:46:59] [V] [TRT] Tactic: -7303593854972602201 Time: 0.058628
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:46:59] [V] [TRT] Tactic: -6585664687867083638 Time: 0.100908
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_nn_v1 Tactic: -3730012925709297561
[12/29/2021-03:46:59] [V] [TRT] Tactic: -3730012925709297561 Time: 0.063784
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_nn_v1 Tactic: -2277259417488004546
[12/29/2021-03:46:59] [V] [TRT] Tactic: -2277259417488004546 Time: 0.101836
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:46:59] [V] [TRT] Tactic: -683636008127039856 Time: 0.09816
[12/29/2021-03:46:59] [V] [TRT] Fastest Tactic: -7303593854972602201 Time: 0.058628
[12/29/2021-03:46:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7303593854972602201
[12/29/2021-03:46:59] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:59] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CaskConvolution)
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_xregs_large_c32_nn_v1 Tactic: 984309058095623735
[12/29/2021-03:46:59] [V] [TRT] Tactic: 984309058095623735 Time: 0.063564
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:46:59] [V] [TRT] Tactic: 1100922622480907544 Time: 0.072296
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_xregs_large_c32_nn_v1 Tactic: 3238312825609165543
[12/29/2021-03:46:59] [V] [TRT] Tactic: 3238312825609165543 Time: 0.101392
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:46:59] [V] [TRT] Tactic: 3606311198834416176 Time: 0.070008
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:46:59] [V] [TRT] Tactic: 4325765560739862899 Time: 0.097696
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:46:59] [V] [TRT] Tactic: -4255737803793506479 Time: 0.100448
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:46:59] [V] [TRT] Tactic: -3958182351168863467 Time: 0.058492
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:46:59] [V] [TRT] Tactic: -3111968753064955248 Time: 0.073864
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:46:59] [V] [TRT] Tactic: -1492575840277333548 Time: 0.084176
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:46:59] [V] [TRT] Tactic: -868495160148524802 Time: 0.061456
[12/29/2021-03:46:59] [V] [TRT] Fastest Tactic: -3958182351168863467 Time: 0.058492
[12/29/2021-03:46:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3958182351168863467
[12/29/2021-03:46:59] [V] [TRT] *************** Autotuning format combination: Int8(32,4:32,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:46:59] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CaskConvolution)
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:46:59] [V] [TRT] Tactic: 1011019097971850911 Time: 0.030352
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:46:59] [V] [TRT] Tactic: 1071114551801767124 Time: 0.018452
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:46:59] [V] [TRT] Tactic: 2623576043214044314 Time: 0.012144
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:46:59] [V] [TRT] Tactic: 3281631721811475881 Time: 0.014316
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:46:59] [V] [TRT] Tactic: 4551754795416974366 Time: 0.013344
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:46:59] [V] [TRT] Tactic: 4925112190271421402 Time: 0.01158
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:46:59] [V] [TRT] Tactic: 5012796702462679112 Time: 0.055496
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:46:59] [V] [TRT] Tactic: 5041593333398049019 Time: 0.011364
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:46:59] [V] [TRT] Tactic: 5166018662410176512 Time: 0.053956
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:46:59] [V] [TRT] Tactic: 6191867932654611882 Time: 0.031068
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:46:59] [V] [TRT] Tactic: 6556170942941957134 Time: 0.035736
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:46:59] [V] [TRT] Tactic: 6852868042694587230 Time: 0.013984
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:46:59] [V] [TRT] Tactic: 8399092794516815300 Time: 0.057028
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:46:59] [V] [TRT] Tactic: -9132922677633967263 Time: 0.019008
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:46:59] [V] [TRT] Tactic: -7988637803896331454 Time: 0.033324
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_large_nt_v1 Tactic: -7865001268126363229
[12/29/2021-03:46:59] [V] [TRT] Tactic: -7865001268126363229 Time: 0.039432
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:46:59] [V] [TRT] Tactic: -7606074703023778034 Time: 0.033608
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:46:59] [V] [TRT] Tactic: -7413564913826321357 Time: 0.030868
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:46:59] [V] [TRT] Tactic: -7282232519526877434 Time: 0.0544
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:46:59] [V] [TRT] Tactic: -5942379529065248478 Time: 0.018572
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:46:59] [V] [TRT] Tactic: -5603587790314027122 Time: 0.03648
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:46:59] [V] [TRT] Tactic: -5334776871777565833 Time: 0.054604
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:46:59] [V] [TRT] Tactic: -5157868397078537095 Time: 0.031204
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:46:59] [V] [TRT] Tactic: -5100834417027499764 Time: 0.012524
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:46:59] [V] [TRT] Tactic: -3365360067423513506 Time: 0.01038
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_large_nt_v1 Tactic: -2194148180068068313
[12/29/2021-03:46:59] [V] [TRT] Tactic: -2194148180068068313 Time: 0.054424
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:46:59] [V] [TRT] Tactic: -1782593837177056527 Time: 0.019144
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:46:59] [V] [TRT] Tactic: -1610768292520086910 Time: 0.03594
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:46:59] [V] [TRT] Tactic: -1573035963956198975 Time: 0.056444
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_large_nt_v1 Tactic: -1558762241666006941
[12/29/2021-03:46:59] [V] [TRT] Tactic: -1558762241666006941 Time: 0.03858
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_large_nt_v1 Tactic: -1365353082499976145
[12/29/2021-03:46:59] [V] [TRT] Tactic: -1365353082499976145 Time: 0.038188
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:46:59] [V] [TRT] Tactic: -621838502160440068 Time: 0.038152
[12/29/2021-03:46:59] [V] [TRT] Fastest Tactic: -3365360067423513506 Time: 0.01038
[12/29/2021-03:46:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3365360067423513506
[12/29/2021-03:46:59] [V] [TRT] *************** Autotuning format combination: Int8(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:46:59] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CudaGroupConvolution)
[12/29/2021-03:46:59] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:59] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CudaDepthwiseConvolution)
[12/29/2021-03:46:59] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:59] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (FusedConvActConvolution)
[12/29/2021-03:46:59] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:46:59] [V] [TRT] --------------- Timing Runner: Conv_82 + Relu_85 (CaskConvolution)
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 177040020707947851
[12/29/2021-03:46:59] [V] [TRT] Tactic: 177040020707947851 Time: 0.013028
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 1550399266192842845
[12/29/2021-03:46:59] [V] [TRT] Tactic: 1550399266192842845 Time: 0.011604
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 1572887561103143487
[12/29/2021-03:46:59] [V] [TRT] Tactic: 1572887561103143487 Time: 0.018668
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:46:59] [V] [TRT] Tactic: 2325023763229477890 Time: 0.0294
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:46:59] [V] [TRT] Tactic: 3284282970967328046 Time: 0.010376
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:46:59] [V] [TRT] Tactic: 3401614690060226673 Time: 0.01234
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3512426920013359699
[12/29/2021-03:46:59] [V] [TRT] Tactic: 3512426920013359699 Time: 0.013868
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:46:59] [V] [TRT] Tactic: 4042202769383439184 Time: 0.01794
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 4259547356717612415
[12/29/2021-03:46:59] [V] [TRT] Tactic: 4259547356717612415 Time: 0.019304
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:46:59] [V] [TRT] Tactic: 4734519122557206480 Time: 0.051684
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 5121596860264626879
[12/29/2021-03:46:59] [V] [TRT] Tactic: 5121596860264626879 Time: 0.05186
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:46:59] [V] [TRT] Tactic: 5136656982162849059 Time: 0.010444
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 5158259316594207439
[12/29/2021-03:46:59] [V] [TRT] Tactic: 5158259316594207439 Time: 0.017888
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 5966973378912044513
[12/29/2021-03:46:59] [V] [TRT] Tactic: 5966973378912044513 Time: 0.029124
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:46:59] [V] [TRT] Tactic: 6004789655466615912 Time: 0.01866
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:46:59] [V] [TRT] Tactic: 6146901278630392829 Time: 0.051424
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 6434020722187266170
[12/29/2021-03:46:59] [V] [TRT] Tactic: 6434020722187266170 Time: 0.052176
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:46:59] [V] [TRT] Tactic: 6781129591847482048 Time: 0.018008
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7191893591576074000
[12/29/2021-03:46:59] [V] [TRT] Tactic: 7191893591576074000 Time: 0.011376
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7438984192263206338
[12/29/2021-03:46:59] [V] [TRT] Tactic: 7438984192263206338 Time: 0.017412
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 7504901284678552178
[12/29/2021-03:46:59] [V] [TRT] Tactic: 7504901284678552178 Time: 0.02894
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:46:59] [V] [TRT] Tactic: 8096257414008860171 Time: 0.017532
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 9143438935315839085
[12/29/2021-03:46:59] [V] [TRT] Tactic: 9143438935315839085 Time: 0.012564
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:46:59] [V] [TRT] Tactic: -9165697322068360861 Time: 0.052116
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:46:59] [V] [TRT] Tactic: -8263994888336646547 Time: 0.028908
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:46:59] [V] [TRT] Tactic: -8205948405243401049 Time: 0.011484
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -7992068592656168418
[12/29/2021-03:46:59] [V] [TRT] Tactic: -7992068592656168418 Time: 0.017768
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: -7842775553137511386
[12/29/2021-03:46:59] [V] [TRT] Tactic: -7842775553137511386 Time: 0.029464
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:46:59] [V] [TRT] Tactic: -7683887278997527517 Time: 0.013264
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5709079507616090666
[12/29/2021-03:46:59] [V] [TRT] Tactic: -5709079507616090666 Time: 0.028696
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5698636014239116282
[12/29/2021-03:46:59] [V] [TRT] Tactic: -5698636014239116282 Time: 0.051508
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:46:59] [V] [TRT] Tactic: -4933563390723451692 Time: 0.01384
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -3413217501222406256
[12/29/2021-03:46:59] [V] [TRT] Tactic: -3413217501222406256 Time: 0.051728
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:46:59] [V] [TRT] Tactic: -3238475748440751107 Time: 0.017488
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:46:59] [V] [TRT] Tactic: -3182884991006484042 Time: 0.029264
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:46:59] [V] [TRT] Tactic: -3173468756112541306 Time: 0.01134
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -2083778562631872334
[12/29/2021-03:46:59] [V] [TRT] Tactic: -2083778562631872334 Time: 0.017972
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:46:59] [V] [TRT] Tactic: -1546787387293556842 Time: 0.028548
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:46:59] [V] [TRT] Tactic: -1498626619443284096 Time: 0.020016
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:46:59] [V] [TRT] Tactic: -1283580231568512025 Time: 0.011108
[12/29/2021-03:46:59] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: -1173968681844185579
[12/29/2021-03:47:00] [V] [TRT] Tactic: -1173968681844185579 Time: 0.011028
[12/29/2021-03:47:00] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:47:00] [V] [TRT] Tactic: -762222380308749469 Time: 0.013552
[12/29/2021-03:47:00] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -556794153877490941
[12/29/2021-03:47:00] [V] [TRT] Tactic: -556794153877490941 Time: 0.013328
[12/29/2021-03:47:00] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:47:00] [V] [TRT] Tactic: -516725800067794372 Time: 0.0514
[12/29/2021-03:47:00] [V] [TRT] Fastest Tactic: 3284282970967328046 Time: 0.010376
[12/29/2021-03:47:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3284282970967328046
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning format combination: Float(1024,4,2,1), Float(1024,4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning format combination: Float(1024,1,512,256), Float(1024,1,512,256) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning format combination: Float(256,1:4,128,64), Float(256,1:4,128,64) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1), Float(1024,4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1), Int8(256,4:4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1), Int8(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning format combination: Int8(32,4:32,2,1), Float(32,4:32,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning format combination: Int8(32,4:32,2,1), Int8(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning format combination: Float(1024,4,2,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CudaDepthwiseConvolution)
[12/29/2021-03:47:00] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (FusedConvActConvolution)
[12/29/2021-03:47:00] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CudnnConvolution)
[12/29/2021-03:47:00] [V] [TRT] Tactic: 0 Time: 0.113232
[12/29/2021-03:47:00] [V] [TRT] Tactic: 1 Time: 0.07906
[12/29/2021-03:47:00] [V] [TRT] Tactic: 2 Time: 0.109612
[12/29/2021-03:47:00] [V] [TRT] Tactic: 5 skipped. Scratch requested: 677380096, available: 16777216
[12/29/2021-03:47:00] [V] [TRT] Tactic: 56 Time: 0.113204
[12/29/2021-03:47:00] [V] [TRT] Tactic: 57 Time: 0.07908
[12/29/2021-03:47:00] [V] [TRT] Tactic: 58 Time: 0.109336
[12/29/2021-03:47:00] [V] [TRT] Tactic: 61 skipped. Scratch requested: 677380096, available: 16777216
[12/29/2021-03:47:00] [V] [TRT] Tactic: 112 Time: 0.113316
[12/29/2021-03:47:00] [V] [TRT] Tactic: 113 Time: 0.113064
[12/29/2021-03:47:00] [V] [TRT] Tactic: 114 Time: 0.10952
[12/29/2021-03:47:00] [V] [TRT] Tactic: 117 skipped. Scratch requested: 677380096, available: 16777216
[12/29/2021-03:47:00] [V] [TRT] Fastest Tactic: 1 Time: 0.07906
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CaskConvolution)
[12/29/2021-03:47:00] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:00] [V] [TRT] Setting workspace to 677380096enables more tactics for profiling
[12/29/2021-03:47:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning format combination: Float(1024,1,512,256) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CudnnConvolution)
[12/29/2021-03:47:00] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CaskConvolution)
[12/29/2021-03:47:00] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning format combination: Float(256,1:4,128,64) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CudnnConvolution)
[12/29/2021-03:47:00] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CaskConvolution)
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:47:00] [V] [TRT] Tactic: 7342025736444949634 Time: 0.192948
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:47:00] [V] [TRT] Tactic: -7377458734869418330 Time: 0.190064
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:47:00] [V] [TRT] Tactic: -5457304872213719461 Time: 0.191636
[12/29/2021-03:47:00] [V] [TRT] Fastest Tactic: -7377458734869418330 Time: 0.190064
[12/29/2021-03:47:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7377458734869418330
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CudaDepthwiseConvolution)
[12/29/2021-03:47:00] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CaskConvolution)
[12/29/2021-03:47:00] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CudaDepthwiseConvolution)
[12/29/2021-03:47:00] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (FusedConvActConvolution)
[12/29/2021-03:47:00] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CaskConvolution)
[12/29/2021-03:47:00] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CaskConvolution)
[12/29/2021-03:47:00] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning format combination: Int8(32,4:32,2,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CaskConvolution)
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:47:00] [V] [TRT] Tactic: 1011019097971850911 Time: 0.029836
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:47:00] [V] [TRT] Tactic: 1071114551801767124 Time: 0.01766
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:47:00] [V] [TRT] Tactic: 2623576043214044314 Time: 0.012248
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:47:00] [V] [TRT] Tactic: 3281631721811475881 Time: 0.014336
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:47:00] [V] [TRT] Tactic: 4551754795416974366 Time: 0.013228
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:47:00] [V] [TRT] Tactic: 4925112190271421402 Time: 0.011488
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:47:00] [V] [TRT] Tactic: 5041593333398049019 Time: 0.011436
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:47:00] [V] [TRT] Tactic: 5166018662410176512 Time: 0.051596
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:47:00] [V] [TRT] Tactic: 6191867932654611882 Time: 0.029372
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:47:00] [V] [TRT] Tactic: 6852868042694587230 Time: 0.014096
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:47:00] [V] [TRT] Tactic: 8399092794516815300 Time: 0.052748
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:47:00] [V] [TRT] Tactic: -9132922677633967263 Time: 0.018336
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:47:00] [V] [TRT] Tactic: -7413564913826321357 Time: 0.031344
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:47:00] [V] [TRT] Tactic: -5942379529065248478 Time: 0.017972
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:47:00] [V] [TRT] Tactic: -5334776871777565833 Time: 0.052176
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:47:00] [V] [TRT] Tactic: -5157868397078537095 Time: 0.029624
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:47:00] [V] [TRT] Tactic: -5100834417027499764 Time: 0.012384
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:47:00] [V] [TRT] Tactic: -3365360067423513506 Time: 0.010352
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:47:00] [V] [TRT] Tactic: -1782593837177056527 Time: 0.018356
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:47:00] [V] [TRT] Tactic: -1573035963956198975 Time: 0.05238
[12/29/2021-03:47:00] [V] [TRT] Fastest Tactic: -3365360067423513506 Time: 0.010352
[12/29/2021-03:47:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3365360067423513506
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning format combination: Int8(32,4:32,2,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CudaGroupConvolution)
[12/29/2021-03:47:00] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CudaDepthwiseConvolution)
[12/29/2021-03:47:00] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (FusedConvActConvolution)
[12/29/2021-03:47:00] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_95 + Relu_98 (CaskConvolution)
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 177040020707947851
[12/29/2021-03:47:00] [V] [TRT] Tactic: 177040020707947851 Time: 0.013068
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 1550399266192842845
[12/29/2021-03:47:00] [V] [TRT] Tactic: 1550399266192842845 Time: 0.011816
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 1572887561103143487
[12/29/2021-03:47:00] [V] [TRT] Tactic: 1572887561103143487 Time: 0.021024
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:47:00] [V] [TRT] Tactic: 2325023763229477890 Time: 0.030148
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:47:00] [V] [TRT] Tactic: 3284282970967328046 Time: 0.010216
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:47:00] [V] [TRT] Tactic: 3401614690060226673 Time: 0.01234
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3512426920013359699
[12/29/2021-03:47:00] [V] [TRT] Tactic: 3512426920013359699 Time: 0.014252
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:47:00] [V] [TRT] Tactic: 4042202769383439184 Time: 0.017868
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 4259547356717612415
[12/29/2021-03:47:00] [V] [TRT] Tactic: 4259547356717612415 Time: 0.021996
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:47:00] [V] [TRT] Tactic: 4734519122557206480 Time: 0.052024
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 5121596860264626879
[12/29/2021-03:47:00] [V] [TRT] Tactic: 5121596860264626879 Time: 0.051748
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:47:00] [V] [TRT] Tactic: 5136656982162849059 Time: 0.010344
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 5158259316594207439
[12/29/2021-03:47:00] [V] [TRT] Tactic: 5158259316594207439 Time: 0.018048
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 5966973378912044513
[12/29/2021-03:47:00] [V] [TRT] Tactic: 5966973378912044513 Time: 0.029496
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:47:00] [V] [TRT] Tactic: 6004789655466615912 Time: 0.021156
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:47:00] [V] [TRT] Tactic: 6146901278630392829 Time: 0.051344
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 6434020722187266170
[12/29/2021-03:47:00] [V] [TRT] Tactic: 6434020722187266170 Time: 0.05226
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:47:00] [V] [TRT] Tactic: 6781129591847482048 Time: 0.018244
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7191893591576074000
[12/29/2021-03:47:00] [V] [TRT] Tactic: 7191893591576074000 Time: 0.01146
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7438984192263206338
[12/29/2021-03:47:00] [V] [TRT] Tactic: 7438984192263206338 Time: 0.017368
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 7504901284678552178
[12/29/2021-03:47:00] [V] [TRT] Tactic: 7504901284678552178 Time: 0.02916
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:47:00] [V] [TRT] Tactic: 8096257414008860171 Time: 0.01802
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 9143438935315839085
[12/29/2021-03:47:00] [V] [TRT] Tactic: 9143438935315839085 Time: 0.012544
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:47:00] [V] [TRT] Tactic: -9165697322068360861 Time: 0.052264
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:47:00] [V] [TRT] Tactic: -8263994888336646547 Time: 0.02914
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:47:00] [V] [TRT] Tactic: -8205948405243401049 Time: 0.011536
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -7992068592656168418
[12/29/2021-03:47:00] [V] [TRT] Tactic: -7992068592656168418 Time: 0.018192
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: -7842775553137511386
[12/29/2021-03:47:00] [V] [TRT] Tactic: -7842775553137511386 Time: 0.030496
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:47:00] [V] [TRT] Tactic: -7683887278997527517 Time: 0.013276
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5709079507616090666
[12/29/2021-03:47:00] [V] [TRT] Tactic: -5709079507616090666 Time: 0.0293
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5698636014239116282
[12/29/2021-03:47:00] [V] [TRT] Tactic: -5698636014239116282 Time: 0.051432
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:47:00] [V] [TRT] Tactic: -4933563390723451692 Time: 0.014396
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -3413217501222406256
[12/29/2021-03:47:00] [V] [TRT] Tactic: -3413217501222406256 Time: 0.051732
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:47:00] [V] [TRT] Tactic: -3238475748440751107 Time: 0.017688
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:47:00] [V] [TRT] Tactic: -3182884991006484042 Time: 0.03008
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:47:00] [V] [TRT] Tactic: -3173468756112541306 Time: 0.01164
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -2083778562631872334
[12/29/2021-03:47:00] [V] [TRT] Tactic: -2083778562631872334 Time: 0.018516
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:47:00] [V] [TRT] Tactic: -1546787387293556842 Time: 0.029516
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:47:00] [V] [TRT] Tactic: -1498626619443284096 Time: 0.0225
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:47:00] [V] [TRT] Tactic: -1283580231568512025 Time: 0.011476
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: -1173968681844185579
[12/29/2021-03:47:00] [V] [TRT] Tactic: -1173968681844185579 Time: 0.011136
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:47:00] [V] [TRT] Tactic: -762222380308749469 Time: 0.014264
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -556794153877490941
[12/29/2021-03:47:00] [V] [TRT] Tactic: -556794153877490941 Time: 0.01426
[12/29/2021-03:47:00] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:47:00] [V] [TRT] Tactic: -516725800067794372 Time: 0.0517
[12/29/2021-03:47:00] [V] [TRT] Fastest Tactic: 3284282970967328046 Time: 0.010216
[12/29/2021-03:47:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3284282970967328046
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(1024,1,512,256) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(256,1:4,128,64) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Float(32,4:32,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(256,4:4,2,1) -> Int8(32,4:32,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(1024,1,512,256) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Float(256,1:4,128,64) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning Reformat:Int8(32,4:32,2,1) -> Int8(256,4:4,2,1) ***************
[12/29/2021-03:47:00] [V] [TRT] *************** Autotuning format combination: Float(1024,4,2,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_104 (CudaDepthwiseConvolution)
[12/29/2021-03:47:00] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_104 (FusedConvActConvolution)
[12/29/2021-03:47:00] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_104 (CudnnConvolution)
[12/29/2021-03:47:00] [V] [TRT] Tactic: 0 Time: 0.047984
[12/29/2021-03:47:00] [V] [TRT] Tactic: 1 Time: 0.12586
[12/29/2021-03:47:00] [V] [TRT] Tactic: 2 Time: 0.110904
[12/29/2021-03:47:00] [V] [TRT] Tactic: 56 Time: 0.048028
[12/29/2021-03:47:00] [V] [TRT] Tactic: 57 Time: 0.114692
[12/29/2021-03:47:00] [V] [TRT] Tactic: 58 Time: 0.111092
[12/29/2021-03:47:00] [V] [TRT] Tactic: 112 Time: 0.047928
[12/29/2021-03:47:00] [V] [TRT] Tactic: 113 Time: 0.066692
[12/29/2021-03:47:00] [V] [TRT] Tactic: 114 Time: 0.11084
[12/29/2021-03:47:00] [V] [TRT] Fastest Tactic: 112 Time: 0.047928
[12/29/2021-03:47:00] [V] [TRT] --------------- Timing Runner: Conv_104 (CaskConvolution)
[12/29/2021-03:47:00] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:47:00] [V] [TRT] Tactic: 4549827808004681195 Time: 0.033876
[12/29/2021-03:47:00] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:47:01] [V] [TRT] Tactic: 5779835512569528575 Time: 0.044068
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 9151672657204310840
[12/29/2021-03:47:01] [V] [TRT] Tactic: 9151672657204310840 Time: 0.045832
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: -7491730084094677098
[12/29/2021-03:47:01] [V] [TRT] Tactic: -7491730084094677098 Time: 0.041024
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:47:01] [V] [TRT] Tactic: -6313876406580483184 Time: 0.04284
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: -6273689210331812572
[12/29/2021-03:47:01] [V] [TRT] Tactic: -6273689210331812572 Time: 0.043452
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: -4337126844824617177
[12/29/2021-03:47:01] [V] [TRT] Tactic: -4337126844824617177 Time: 0.031584
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:47:01] [V] [TRT] Tactic: -1123676555321336786 Time: 0.043476
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:47:01] [V] [TRT] Tactic: -701551393537224327 Time: 0.034608
[12/29/2021-03:47:01] [V] [TRT] Fastest Tactic: -4337126844824617177 Time: 0.031584
[12/29/2021-03:47:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4337126844824617177
[12/29/2021-03:47:01] [V] [TRT] *************** Autotuning format combination: Float(1024,1,512,256) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:01] [V] [TRT] --------------- Timing Runner: Conv_104 (CudnnConvolution)
[12/29/2021-03:47:01] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:01] [V] [TRT] --------------- Timing Runner: Conv_104 (CaskConvolution)
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 1663866669559596164
[12/29/2021-03:47:01] [V] [TRT] Tactic: 1663866669559596164 Time: 0.039296
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:47:01] [V] [TRT] Tactic: 2860655430572478466 Time: 0.026344
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:47:01] [V] [TRT] Tactic: 4474630279712975759 Time: 0.0179
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:47:01] [V] [TRT] Tactic: 4479823862704990365 Time: 0.017732
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:47:01] [V] [TRT] Tactic: 4696204239951173149 Time: 0.02606
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:47:01] [V] [TRT] Tactic: 5778138195697110003 Time: 0.039812
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:47:01] [V] [TRT] Tactic: 8918020581761223752 Time: 0.038284
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -5905193483742532701
[12/29/2021-03:47:01] [V] [TRT] Tactic: -5905193483742532701 Time: 0.02402
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -4035591156787122265
[12/29/2021-03:47:01] [V] [TRT] Tactic: -4035591156787122265 Time: 0.017516
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:47:01] [V] [TRT] Tactic: -2809379259463049391 Time: 0.039444
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -1985235291706575900
[12/29/2021-03:47:01] [V] [TRT] Tactic: -1985235291706575900 Time: 0.038248
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:47:01] [V] [TRT] Tactic: -504296718212024303 Time: 0.038688
[12/29/2021-03:47:01] [V] [TRT] Fastest Tactic: -4035591156787122265 Time: 0.017516
[12/29/2021-03:47:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4035591156787122265
[12/29/2021-03:47:01] [V] [TRT] *************** Autotuning format combination: Float(256,1:4,128,64) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:01] [V] [TRT] --------------- Timing Runner: Conv_104 (CudnnConvolution)
[12/29/2021-03:47:01] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:01] [V] [TRT] --------------- Timing Runner: Conv_104 (CaskConvolution)
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 1373022415249282411
[12/29/2021-03:47:01] [V] [TRT] Tactic: 1373022415249282411 Time: 0.027948
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 1663866669559596164
[12/29/2021-03:47:01] [V] [TRT] Tactic: 1663866669559596164 Time: 0.039424
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:47:01] [V] [TRT] Tactic: 2860655430572478466 Time: 0.026456
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:47:01] [V] [TRT] Tactic: 4474630279712975759 Time: 0.018024
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:47:01] [V] [TRT] Tactic: 4479823862704990365 Time: 0.017872
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:47:01] [V] [TRT] Tactic: 4696204239951173149 Time: 0.026184
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:47:01] [V] [TRT] Tactic: 5778138195697110003 Time: 0.039856
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:47:01] [V] [TRT] Tactic: 7342025736444949634 Time: 0.02806
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:47:01] [V] [TRT] Tactic: 8918020581761223752 Time: 0.038188
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -5905193483742532701
[12/29/2021-03:47:01] [V] [TRT] Tactic: -5905193483742532701 Time: 0.024036
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:47:01] [V] [TRT] Tactic: -5457304872213719461 Time: 0.0286
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -4035591156787122265
[12/29/2021-03:47:01] [V] [TRT] Tactic: -4035591156787122265 Time: 0.017508
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:47:01] [V] [TRT] Tactic: -2809379259463049391 Time: 0.03946
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -1985235291706575900
[12/29/2021-03:47:01] [V] [TRT] Tactic: -1985235291706575900 Time: 0.038152
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:47:01] [V] [TRT] Tactic: -504296718212024303 Time: 0.038548
[12/29/2021-03:47:01] [V] [TRT] Fastest Tactic: -4035591156787122265 Time: 0.017508
[12/29/2021-03:47:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4035591156787122265
[12/29/2021-03:47:01] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:01] [V] [TRT] --------------- Timing Runner: Conv_104 (CudaDepthwiseConvolution)
[12/29/2021-03:47:01] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:01] [V] [TRT] --------------- Timing Runner: Conv_104 (CaskConvolution)
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: 1508480131241957639
[12/29/2021-03:47:01] [V] [TRT] Tactic: 1508480131241957639 Time: 0.02196
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 2141154648944475104
[12/29/2021-03:47:01] [V] [TRT] Tactic: 2141154648944475104 Time: 0.0218
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: 3239257003214966313
[12/29/2021-03:47:01] [V] [TRT] Tactic: 3239257003214966313 Time: 0.022012
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: 5592640619112287921
[12/29/2021-03:47:01] [V] [TRT] Tactic: 5592640619112287921 Time: 0.01516
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 7621465827583909090
[12/29/2021-03:47:01] [V] [TRT] Tactic: 7621465827583909090 Time: 0.015972
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: -6580271968881459581
[12/29/2021-03:47:01] [V] [TRT] Tactic: -6580271968881459581 Time: 0.017168
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: -5576936487443445631
[12/29/2021-03:47:01] [V] [TRT] Tactic: -5576936487443445631 Time: 0.0164
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: -4443833619060044580
[12/29/2021-03:47:01] [V] [TRT] Tactic: -4443833619060044580 Time: 0.015304
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: -2297737319934264721
[12/29/2021-03:47:01] [V] [TRT] Tactic: -2297737319934264721 Time: 0.018184
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: -1425085658556684465
[12/29/2021-03:47:01] [V] [TRT] Tactic: -1425085658556684465 Time: 0.016224
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -108011214168778087
[12/29/2021-03:47:01] [V] [TRT] Tactic: -108011214168778087 Time: 0.017804
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: -42427192380281294
[12/29/2021-03:47:01] [V] [TRT] Tactic: -42427192380281294 Time: 0.015596
[12/29/2021-03:47:01] [V] [TRT] Fastest Tactic: 5592640619112287921 Time: 0.01516
[12/29/2021-03:47:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5592640619112287921
[12/29/2021-03:47:01] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:01] [V] [TRT] --------------- Timing Runner: Conv_104 (CudaDepthwiseConvolution)
[12/29/2021-03:47:01] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:01] [V] [TRT] --------------- Timing Runner: Conv_104 (FusedConvActConvolution)
[12/29/2021-03:47:01] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:01] [V] [TRT] --------------- Timing Runner: Conv_104 (CaskConvolution)
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_nn_v1 Tactic: 175853789719975416
[12/29/2021-03:47:01] [V] [TRT] Tactic: 175853789719975416 Time: 0.016332
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_nn_v1 Tactic: 2171150287007712632
[12/29/2021-03:47:01] [V] [TRT] Tactic: 2171150287007712632 Time: 0.014372
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_nn_v1 Tactic: 2234457234705232274
[12/29/2021-03:47:01] [V] [TRT] Tactic: 2234457234705232274 Time: 0.013908
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_nn_v1 Tactic: 5834048089706882838
[12/29/2021-03:47:01] [V] [TRT] Tactic: 5834048089706882838 Time: 0.01428
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_nn_v1 Tactic: 6299962968199310600
[12/29/2021-03:47:01] [V] [TRT] Tactic: 6299962968199310600 Time: 0.018584
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_nn_v1 Tactic: 6341572697076960911
[12/29/2021-03:47:01] [V] [TRT] Tactic: 6341572697076960911 Time: 0.013316
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_nn_v1 Tactic: -8626990807754934295
[12/29/2021-03:47:01] [V] [TRT] Tactic: -8626990807754934295 Time: 0.015808
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_nn_v1 Tactic: -8498217049614706532
[12/29/2021-03:47:01] [V] [TRT] Tactic: -8498217049614706532 Time: 0.013352
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_nn_v1 Tactic: -7303593854972602201
[12/29/2021-03:47:01] [V] [TRT] Tactic: -7303593854972602201 Time: 0.01324
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_nn_v1 Tactic: -6585664687867083638
[12/29/2021-03:47:01] [V] [TRT] Tactic: -6585664687867083638 Time: 0.018892
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_nn_v1 Tactic: -3326139578711341011
[12/29/2021-03:47:01] [V] [TRT] Tactic: -3326139578711341011 Time: 0.015364
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_nn_v1 Tactic: -683636008127039856
[12/29/2021-03:47:01] [V] [TRT] Tactic: -683636008127039856 Time: 0.018788
[12/29/2021-03:47:01] [V] [TRT] Fastest Tactic: -7303593854972602201 Time: 0.01324
[12/29/2021-03:47:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7303593854972602201
[12/29/2021-03:47:01] [V] [TRT] *************** Autotuning format combination: Int8(256,4:4,2,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:01] [V] [TRT] --------------- Timing Runner: Conv_104 (CaskConvolution)
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_small_c32_nn_v1 Tactic: 1100922622480907544
[12/29/2021-03:47:01] [V] [TRT] Tactic: 1100922622480907544 Time: 0.015548
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_interior_c32_nn_v1 Tactic: 2855900226702061782
[12/29/2021-03:47:01] [V] [TRT] Tactic: 2855900226702061782 Time: 0.018156
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_medium_c32_nn_v1 Tactic: 3606311198834416176
[12/29/2021-03:47:01] [V] [TRT] Tactic: 3606311198834416176 Time: 0.013976
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_small_c32_nn_v1 Tactic: 4325765560739862899
[12/29/2021-03:47:01] [V] [TRT] Tactic: 4325765560739862899 Time: 0.018268
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_interior_c32_nn_v1 Tactic: 8803458114157674373
[12/29/2021-03:47:01] [V] [TRT] Tactic: 8803458114157674373 Time: 0.01312
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_interior_c32_nn_v1 Tactic: -6934773036503365000
[12/29/2021-03:47:01] [V] [TRT] Tactic: -6934773036503365000 Time: 0.015284
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_interior_c32_nn_v1 Tactic: -4431642509665791294
[12/29/2021-03:47:01] [V] [TRT] Tactic: -4431642509665791294 Time: 0.013244
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x128_relu_medium_c32_nn_v1 Tactic: -4255737803793506479
[12/29/2021-03:47:01] [V] [TRT] Tactic: -4255737803793506479 Time: 0.018332
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_small_c32_nn_v1 Tactic: -3958182351168863467
[12/29/2021-03:47:01] [V] [TRT] Tactic: -3958182351168863467 Time: 0.01318
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_xregs_medium_c32_nn_v1 Tactic: -3111968753064955248
[12/29/2021-03:47:01] [V] [TRT] Tactic: -3111968753064955248 Time: 0.014348
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x32_relu_medium_c32_nn_v1 Tactic: -1492575840277333548
[12/29/2021-03:47:01] [V] [TRT] Tactic: -1492575840277333548 Time: 0.016172
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8x4_icudnn_int8x4_128x64_relu_small_c32_nn_v1 Tactic: -868495160148524802
[12/29/2021-03:47:01] [V] [TRT] Tactic: -868495160148524802 Time: 0.013636
[12/29/2021-03:47:01] [V] [TRT] Fastest Tactic: 8803458114157674373 Time: 0.01312
[12/29/2021-03:47:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8803458114157674373
[12/29/2021-03:47:01] [V] [TRT] *************** Autotuning format combination: Int8(32,4:32,2,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:47:01] [V] [TRT] --------------- Timing Runner: Conv_104 (CaskConvolution)
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:47:01] [V] [TRT] Tactic: 2623576043214044314 Time: 0.006872
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 2818014835119698671
[12/29/2021-03:47:01] [V] [TRT] Tactic: 2818014835119698671 Time: 0.00778
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 3721599319722771137
[12/29/2021-03:47:01] [V] [TRT] Tactic: 3721599319722771137 Time: 0.00676
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_interior_nt_v1 Tactic: 4178917718361232468
[12/29/2021-03:47:01] [V] [TRT] Tactic: 4178917718361232468 Time: 0.010796
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:47:01] [V] [TRT] Tactic: 4551754795416974366 Time: 0.007112
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:47:01] [V] [TRT] Tactic: 4925112190271421402 Time: 0.006792
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 5012796702462679112
[12/29/2021-03:47:01] [V] [TRT] Tactic: 5012796702462679112 Time: 0.013868
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 6556170942941957134
[12/29/2021-03:47:01] [V] [TRT] Tactic: 6556170942941957134 Time: 0.011044
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 6618077155362058131
[12/29/2021-03:47:01] [V] [TRT] Tactic: 6618077155362058131 Time: 0.00648
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:47:01] [V] [TRT] Tactic: 6852868042694587230 Time: 0.007348
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: 6969462133921577484
[12/29/2021-03:47:01] [V] [TRT] Tactic: 6969462133921577484 Time: 0.013452
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:47:01] [V] [TRT] Tactic: 8399092794516815300 Time: 0.01378
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:47:01] [V] [TRT] Tactic: -9132922677633967263 Time: 0.008236
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -8912999970161746151
[12/29/2021-03:47:01] [V] [TRT] Tactic: -8912999970161746151 Time: 0.007952
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -8893439100868426414
[12/29/2021-03:47:01] [V] [TRT] Tactic: -8893439100868426414 Time: 0.009608
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -7988637803896331454
[12/29/2021-03:47:01] [V] [TRT] Tactic: -7988637803896331454 Time: 0.010808
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_interior_nt_v1 Tactic: -7904635102498369361
[12/29/2021-03:47:01] [V] [TRT] Tactic: -7904635102498369361 Time: 0.013628
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -7606074703023778034
[12/29/2021-03:47:01] [V] [TRT] Tactic: -7606074703023778034 Time: 0.010876
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:47:01] [V] [TRT] Tactic: -7413564913826321357 Time: 0.010368
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -7282232519526877434
[12/29/2021-03:47:01] [V] [TRT] Tactic: -7282232519526877434 Time: 0.013652
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -6406011580107094428
[12/29/2021-03:47:01] [V] [TRT] Tactic: -6406011580107094428 Time: 0.00708
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5603587790314027122
[12/29/2021-03:47:01] [V] [TRT] Tactic: -5603587790314027122 Time: 0.011128
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_128x128_ldg16_relu_interior_nt_v1 Tactic: -5416590980288859834
[12/29/2021-03:47:01] [V] [TRT] Tactic: -5416590980288859834 Time: 0.011068
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:47:01] [V] [TRT] Tactic: -5334776871777565833 Time: 0.013484
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:47:01] [V] [TRT] Tactic: -5157868397078537095 Time: 0.010108
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -3665201838779845683
[12/29/2021-03:47:01] [V] [TRT] Tactic: -3665201838779845683 Time: 0.01272
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_interior_nt_v1 Tactic: -3644377136375731441
[12/29/2021-03:47:01] [V] [TRT] Tactic: -3644377136375731441 Time: 0.010944
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -3502495740607894730
[12/29/2021-03:47:01] [V] [TRT] Tactic: -3502495740607894730 Time: 0.006652
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -2342404147487779225
[12/29/2021-03:47:01] [V] [TRT] Tactic: -2342404147487779225 Time: 0.009576
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:47:01] [V] [TRT] Tactic: -1782593837177056527 Time: 0.008388
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: -1610768292520086910
[12/29/2021-03:47:01] [V] [TRT] Tactic: -1610768292520086910 Time: 0.011232
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_fp32_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -621838502160440068
[12/29/2021-03:47:01] [V] [TRT] Tactic: -621838502160440068 Time: 0.011524
[12/29/2021-03:47:01] [V] [TRT] Fastest Tactic: 6618077155362058131 Time: 0.00648
[12/29/2021-03:47:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6618077155362058131
[12/29/2021-03:47:01] [V] [TRT] *************** Autotuning format combination: Int8(32,4:32,2,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:01] [V] [TRT] --------------- Timing Runner: Conv_104 (CudaGroupConvolution)
[12/29/2021-03:47:01] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:01] [V] [TRT] --------------- Timing Runner: Conv_104 (CudaDepthwiseConvolution)
[12/29/2021-03:47:01] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:01] [V] [TRT] --------------- Timing Runner: Conv_104 (FusedConvActConvolution)
[12/29/2021-03:47:01] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:01] [V] [TRT] --------------- Timing Runner: Conv_104 (CaskConvolution)
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 177040020707947851
[12/29/2021-03:47:01] [V] [TRT] Tactic: 177040020707947851 Time: 0.00724
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_interior_nt_v1 Tactic: 434957160407688216
[12/29/2021-03:47:01] [V] [TRT] Tactic: 434957160407688216 Time: 0.014232
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 805889586762897346
[12/29/2021-03:47:01] [V] [TRT] Tactic: 805889586762897346 Time: 0.01282
[12/29/2021-03:47:01] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 1550399266192842845
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1550399266192842845 Time: 0.006784
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:47:02] [V] [TRT] Tactic: 2325023763229477890 Time: 0.0104
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_interior_nt_v1 Tactic: 2346437292116182513
[12/29/2021-03:47:02] [V] [TRT] Tactic: 2346437292116182513 Time: 0.01096
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_interior_nt_v1 Tactic: 2522133112320625287
[12/29/2021-03:47:02] [V] [TRT] Tactic: 2522133112320625287 Time: 0.01098
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_medium_nt_v1 Tactic: 2985940154541537814
[12/29/2021-03:47:02] [V] [TRT] Tactic: 2985940154541537814 Time: 0.01102
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 3538565962642681625
[12/29/2021-03:47:02] [V] [TRT] Tactic: 3538565962642681625 Time: 0.006912
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_medium_nt_v1 Tactic: 3899284354987683408
[12/29/2021-03:47:02] [V] [TRT] Tactic: 3899284354987683408 Time: 0.014488
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:47:02] [V] [TRT] Tactic: 4042202769383439184 Time: 0.008028
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 4259547356717612415
[12/29/2021-03:47:02] [V] [TRT] Tactic: 4259547356717612415 Time: 0.008868
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_small_nt_v1 Tactic: 4717285412741024953
[12/29/2021-03:47:02] [V] [TRT] Tactic: 4717285412741024953 Time: 0.011332
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:47:02] [V] [TRT] Tactic: 4734519122557206480 Time: 0.01318
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 5121596860264626879
[12/29/2021-03:47:02] [V] [TRT] Tactic: 5121596860264626879 Time: 0.013128
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_interior_nt_v1 Tactic: 5126565865931538390
[12/29/2021-03:47:02] [V] [TRT] Tactic: 5126565865931538390 Time: 0.011156
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 5158259316594207439
[12/29/2021-03:47:02] [V] [TRT] Tactic: 5158259316594207439 Time: 0.00802
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 5375256703210220108
[12/29/2021-03:47:02] [V] [TRT] Tactic: 5375256703210220108 Time: 0.007792
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: 6433368103202497147
[12/29/2021-03:47:02] [V] [TRT] Tactic: 6433368103202497147 Time: 0.009556
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 6434020722187266170
[12/29/2021-03:47:02] [V] [TRT] Tactic: 6434020722187266170 Time: 0.013696
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 6441948709525127755
[12/29/2021-03:47:02] [V] [TRT] Tactic: 6441948709525127755 Time: 0.006476
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 6457435868048963632
[12/29/2021-03:47:02] [V] [TRT] Tactic: 6457435868048963632 Time: 0.00778
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:47:02] [V] [TRT] Tactic: 6781129591847482048 Time: 0.008392
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 6925201228918187099
[12/29/2021-03:47:02] [V] [TRT] Tactic: 6925201228918187099 Time: 0.009492
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 7504901284678552178
[12/29/2021-03:47:02] [V] [TRT] Tactic: 7504901284678552178 Time: 0.009856
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 7731430299029542276
[12/29/2021-03:47:02] [V] [TRT] Tactic: 7731430299029542276 Time: 0.009424
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: 7738495016763012180
[12/29/2021-03:47:02] [V] [TRT] Tactic: 7738495016763012180 Time: 0.012792
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r1s1 Tactic: 8234775147403903473
[12/29/2021-03:47:02] [V] [TRT] Tactic: 8234775147403903473 Time: 0.012888
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:47:02] [V] [TRT] Tactic: -9165697322068360861 Time: 0.013568
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_small_nt_v1 Tactic: -9118785798277698619
[12/29/2021-03:47:02] [V] [TRT] Tactic: -9118785798277698619 Time: 0.011092
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -8556775352640313933
[12/29/2021-03:47:02] [V] [TRT] Tactic: -8556775352640313933 Time: 0.009604
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:47:02] [V] [TRT] Tactic: -8263994888336646547 Time: 0.009756
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:47:02] [V] [TRT] Tactic: -8205948405243401049 Time: 0.006808
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: -7842775553137511386
[12/29/2021-03:47:02] [V] [TRT] Tactic: -7842775553137511386 Time: 0.010468
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:47:02] [V] [TRT] Tactic: -7683887278997527517 Time: 0.00726
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -6527178416855951297
[12/29/2021-03:47:02] [V] [TRT] Tactic: -6527178416855951297 Time: 0.006964
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -6510232214299595844
[12/29/2021-03:47:02] [V] [TRT] Tactic: -6510232214299595844 Time: 0.007188
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_128x128_ldg16_relu_small_nt_v1 Tactic: -6400348606759295499
[12/29/2021-03:47:02] [V] [TRT] Tactic: -6400348606759295499 Time: 0.010988
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x128_ldg16_relu_small_nt_v1 Tactic: -5980889159865208399
[12/29/2021-03:47:02] [V] [TRT] Tactic: -5980889159865208399 Time: 0.014428
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_singleBuffer_medium_nt_v1 Tactic: -5766140806760372989
[12/29/2021-03:47:02] [V] [TRT] Tactic: -5766140806760372989 Time: 0.011276
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -5170003087447722174
[12/29/2021-03:47:02] [V] [TRT] Tactic: -5170003087447722174 Time: 0.006484
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -4849712423393454704
[12/29/2021-03:47:02] [V] [TRT] Tactic: -4849712423393454704 Time: 0.007716
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: ampere_int8_i8816cudnn_int8_256x64_ldg16_relu_medium_nt_v1 Tactic: -4516822589357530549
[12/29/2021-03:47:02] [V] [TRT] Tactic: -4516822589357530549 Time: 0.011604
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -3613322253849278738
[12/29/2021-03:47:02] [V] [TRT] Tactic: -3613322253849278738 Time: 0.006344
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -3577322188448771475
[12/29/2021-03:47:02] [V] [TRT] Tactic: -3577322188448771475 Time: 0.008028
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -2754311112012636251
[12/29/2021-03:47:02] [V] [TRT] Tactic: -2754311112012636251 Time: 0.008032
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r1s1 Tactic: -2315453944962430928
[12/29/2021-03:47:02] [V] [TRT] Tactic: -2315453944962430928 Time: 0.012988
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -2083778562631872334
[12/29/2021-03:47:02] [V] [TRT] Tactic: -2083778562631872334 Time: 0.008272
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -1499578657823798783
[12/29/2021-03:47:02] [V] [TRT] Tactic: -1499578657823798783 Time: 0.007168
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:47:02] [V] [TRT] Tactic: -1498626619443284096 Time: 0.008992
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:47:02] [V] [TRT] Tactic: -1283580231568512025 Time: 0.006676
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: -1173968681844185579
[12/29/2021-03:47:02] [V] [TRT] Tactic: -1173968681844185579 Time: 0.00672
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:47:02] [V] [TRT] Tactic: -762222380308749469 Time: 0.007324
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -713022856474991236
[12/29/2021-03:47:02] [V] [TRT] Tactic: -713022856474991236 Time: 0.006412
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -556794153877490941
[12/29/2021-03:47:02] [V] [TRT] Tactic: -556794153877490941 Time: 0.007216
[12/29/2021-03:47:02] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1 Tactic: -375949437730908730
[12/29/2021-03:47:02] [V] [TRT] Tactic: -375949437730908730 Time: 0.0079
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: -3613322253849278738 Time: 0.006344
[12/29/2021-03:47:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3613322253849278738
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.005944
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.004952
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.004952
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.006704
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.005272
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.005272
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.010944
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.004872
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.004872
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.01068
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.005264
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.005264
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.005996
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.005
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.005
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.00684
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.00526
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.00526
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.010904
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.00524
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.00524
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.010708
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.005328
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.005328
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.010288
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.004952
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.004952
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.00674
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.005064
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.005064
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.011892
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.005388
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.005388
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.011824
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.00552
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.00552
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.013172
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.005016
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.005016
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.006764
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.005224
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.005224
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.006844
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.005136
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.005136
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.011536
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.00554
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.00554
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.011384
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.005468
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.005468
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.011344
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.004832
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.004832
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.008492
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.005508
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.005508
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.008452
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.005476
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.005476
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.008768
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.004868
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.004868
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.010936
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.005432
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.005432
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.008444
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.0054
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.0054
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.008464
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.005496
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.005496
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.00876
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.00484
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1 Time: 0.004888
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.00484
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.012936
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.005116
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.005116
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.013008
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.005204
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.005204
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.01032
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.005236
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.005236
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.011708
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.00546
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.00546
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1002 Time: 0.011476
[12/29/2021-03:47:02] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.005448
[12/29/2021-03:47:02] [V] [TRT] Fastest Tactic: 0 Time: 0.005448
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] *************** Autotuning format combination: Float(512,1,1,1), Float(512,1,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CudaDepthwiseConvolution)
[12/29/2021-03:47:02] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (FusedConvActConvolution)
[12/29/2021-03:47:02] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:02] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CudnnConvolution)
[12/29/2021-03:47:02] [V] [TRT] Tactic: 0 Time: 0.641256
[12/29/2021-03:47:02] [V] [TRT] Tactic: 1 Time: 0.234328
[12/29/2021-03:47:02] [V] [TRT] Tactic: 2 Time: 0.294232
[12/29/2021-03:47:02] [V] [TRT] Tactic: 4 skipped. Scratch requested: 651165696, available: 16777216
[12/29/2021-03:47:02] [V] [TRT] Tactic: 5 skipped. Scratch requested: 1283457024, available: 16777216
[12/29/2021-03:47:02] [V] [TRT] Tactic: 6 skipped. Scratch requested: 26216448, available: 16777216
[12/29/2021-03:47:03] [V] [TRT] Tactic: 56 Time: 0.641164
[12/29/2021-03:47:03] [V] [TRT] Tactic: 57 Time: 0.204684
[12/29/2021-03:47:03] [V] [TRT] Tactic: 58 Time: 0.294308
[12/29/2021-03:47:03] [V] [TRT] Tactic: 60 skipped. Scratch requested: 651165696, available: 16777216
[12/29/2021-03:47:03] [V] [TRT] Tactic: 61 skipped. Scratch requested: 1283457024, available: 16777216
[12/29/2021-03:47:03] [V] [TRT] Tactic: 62 skipped. Scratch requested: 26216448, available: 16777216
[12/29/2021-03:47:03] [V] [TRT] Tactic: 112 Time: 0.640648
[12/29/2021-03:47:03] [V] [TRT] Tactic: 113 Time: 0.800736
[12/29/2021-03:47:03] [V] [TRT] Tactic: 114 Time: 0.293796
[12/29/2021-03:47:03] [V] [TRT] Tactic: 116 skipped. Scratch requested: 651165696, available: 16777216
[12/29/2021-03:47:03] [V] [TRT] Tactic: 117 skipped. Scratch requested: 1283457024, available: 16777216
[12/29/2021-03:47:03] [V] [TRT] Tactic: 118 skipped. Scratch requested: 26216448, available: 16777216
[12/29/2021-03:47:03] [V] [TRT] Fastest Tactic: 57 Time: 0.204684
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CaskConvolution)
[12/29/2021-03:47:03] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:03] [V] [TRT] Setting workspace to 26216448enables more tactics for profiling
[12/29/2021-03:47:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 57
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning format combination: Float(512,1,512,512), Float(512,1,512,512) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CudnnConvolution)
[12/29/2021-03:47:03] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CaskConvolution)
[12/29/2021-03:47:03] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning format combination: Float(128,1:4,128,128), Float(128,1:4,128,128) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CudnnConvolution)
[12/29/2021-03:47:03] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CaskConvolution)
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:47:03] [V] [TRT] Tactic: 7342025736444949634 Time: 0.379528
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:47:03] [V] [TRT] Tactic: -7377458734869418330 Time: 0.373376
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:47:03] [V] [TRT] Tactic: -5457304872213719461 Time: 0.376356
[12/29/2021-03:47:03] [V] [TRT] Fastest Tactic: -7377458734869418330 Time: 0.373376
[12/29/2021-03:47:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7377458734869418330
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning format combination: Int8(128,1:4,1,1), Float(512,1,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CudaDepthwiseConvolution)
[12/29/2021-03:47:03] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CaskConvolution)
[12/29/2021-03:47:03] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning format combination: Int8(128,1:4,1,1), Int8(128,1:4,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CudaDepthwiseConvolution)
[12/29/2021-03:47:03] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (FusedConvActConvolution)
[12/29/2021-03:47:03] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CaskConvolution)
[12/29/2021-03:47:03] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning format combination: Int8(128,1:4,1,1), Int8(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CaskConvolution)
[12/29/2021-03:47:03] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning format combination: Int8(16,1:32,1,1), Float(16,1:32,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CaskConvolution)
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:47:03] [V] [TRT] Tactic: 1011019097971850911 Time: 0.05262
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:47:03] [V] [TRT] Tactic: 1071114551801767124 Time: 0.029352
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:47:03] [V] [TRT] Tactic: 2623576043214044314 Time: 0.017964
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:47:03] [V] [TRT] Tactic: 3281631721811475881 Time: 0.022248
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:47:03] [V] [TRT] Tactic: 4551754795416974366 Time: 0.019992
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:47:03] [V] [TRT] Tactic: 4925112190271421402 Time: 0.016692
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:47:03] [V] [TRT] Tactic: 5041593333398049019 Time: 0.016736
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:47:03] [V] [TRT] Tactic: 5166018662410176512 Time: 0.096776
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:47:03] [V] [TRT] Tactic: 6191867932654611882 Time: 0.052064
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:47:03] [V] [TRT] Tactic: 6852868042694587230 Time: 0.020684
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:47:03] [V] [TRT] Tactic: 8399092794516815300 Time: 0.09714
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:47:03] [V] [TRT] Tactic: -9132922677633967263 Time: 0.029924
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:47:03] [V] [TRT] Tactic: -7413564913826321357 Time: 0.05388
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:47:03] [V] [TRT] Tactic: -5942379529065248478 Time: 0.029436
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:47:03] [V] [TRT] Tactic: -5334776871777565833 Time: 0.097616
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:47:03] [V] [TRT] Tactic: -5157868397078537095 Time: 0.052268
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:47:03] [V] [TRT] Tactic: -5100834417027499764 Time: 0.018816
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:47:03] [V] [TRT] Tactic: -3365360067423513506 Time: 0.014788
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:47:03] [V] [TRT] Tactic: -1782593837177056527 Time: 0.029732
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:47:03] [V] [TRT] Tactic: -1573035963956198975 Time: 0.096576
[12/29/2021-03:47:03] [V] [TRT] Fastest Tactic: -3365360067423513506 Time: 0.014788
[12/29/2021-03:47:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3365360067423513506
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning format combination: Int8(16,1:32,1,1), Int8(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CudaGroupConvolution)
[12/29/2021-03:47:03] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CudaDepthwiseConvolution)
[12/29/2021-03:47:03] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (FusedConvActConvolution)
[12/29/2021-03:47:03] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Conv_101 + Add_105 + Relu_108 (CaskConvolution)
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:47:03] [V] [TRT] Tactic: 2325023763229477890 Time: 0.053052
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:47:03] [V] [TRT] Tactic: 3401614690060226673 Time: 0.018724
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:47:03] [V] [TRT] Tactic: 4042202769383439184 Time: 0.029264
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:47:03] [V] [TRT] Tactic: 4734519122557206480 Time: 0.096528
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:47:03] [V] [TRT] Tactic: 5136656982162849059 Time: 0.014668
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:47:03] [V] [TRT] Tactic: 6004789655466615912 Time: 0.031932
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:47:03] [V] [TRT] Tactic: 6146901278630392829 Time: 0.09596
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:47:03] [V] [TRT] Tactic: 6781129591847482048 Time: 0.029592
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:47:03] [V] [TRT] Tactic: 8096257414008860171 Time: 0.029316
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:47:03] [V] [TRT] Tactic: -9165697322068360861 Time: 0.097292
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:47:03] [V] [TRT] Tactic: -8263994888336646547 Time: 0.05174
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:47:03] [V] [TRT] Tactic: -8205948405243401049 Time: 0.016944
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:47:03] [V] [TRT] Tactic: -7683887278997527517 Time: 0.019984
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:47:03] [V] [TRT] Tactic: -4933563390723451692 Time: 0.022176
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:47:03] [V] [TRT] Tactic: -3238475748440751107 Time: 0.028796
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:47:03] [V] [TRT] Tactic: -3182884991006484042 Time: 0.052456
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:47:03] [V] [TRT] Tactic: -3173468756112541306 Time: 0.016856
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:47:03] [V] [TRT] Tactic: -1546787387293556842 Time: 0.051804
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:47:03] [V] [TRT] Tactic: -1498626619443284096 Time: 0.034364
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:47:03] [V] [TRT] Tactic: -1283580231568512025 Time: 0.016072
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:47:03] [V] [TRT] Tactic: -762222380308749469 Time: 0.020488
[12/29/2021-03:47:03] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:47:03] [V] [TRT] Tactic: -516725800067794372 Time: 0.09602
[12/29/2021-03:47:03] [V] [TRT] Fastest Tactic: 5136656982162849059 Time: 0.014668
[12/29/2021-03:47:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5136656982162849059
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 1002 Time: 0.00558
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 0 Time: 0.004648
[12/29/2021-03:47:03] [V] [TRT] Fastest Tactic: 0 Time: 0.004648
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 1002 Time: 0.00662
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 0 Time: 0.004868
[12/29/2021-03:47:03] [V] [TRT] Fastest Tactic: 0 Time: 0.004868
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 1002 Time: 0.012696
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 0 Time: 0.004692
[12/29/2021-03:47:03] [V] [TRT] Fastest Tactic: 0 Time: 0.004692
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 1002 Time: 0.010592
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 0 Time: 0.004632
[12/29/2021-03:47:03] [V] [TRT] Fastest Tactic: 0 Time: 0.004632
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 1002 Time: 0.010452
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 0 Time: 0.005048
[12/29/2021-03:47:03] [V] [TRT] Fastest Tactic: 0 Time: 0.005048
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 1002 Time: 0.005712
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 0 Time: 0.004688
[12/29/2021-03:47:03] [V] [TRT] Fastest Tactic: 0 Time: 0.004688
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 1002 Time: 0.006412
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 0 Time: 0.00486
[12/29/2021-03:47:03] [V] [TRT] Fastest Tactic: 0 Time: 0.00486
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 1002 Time: 0.012576
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 0 Time: 0.004852
[12/29/2021-03:47:03] [V] [TRT] Fastest Tactic: 0 Time: 0.004852
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 1002 Time: 0.01052
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 0 Time: 0.005096
[12/29/2021-03:47:03] [V] [TRT] Fastest Tactic: 0 Time: 0.005096
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 1002 Time: 0.01042
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 0 Time: 0.005084
[12/29/2021-03:47:03] [V] [TRT] Fastest Tactic: 0 Time: 0.005084
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 1002 Time: 0.009996
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 0 Time: 0.004664
[12/29/2021-03:47:03] [V] [TRT] Fastest Tactic: 0 Time: 0.004664
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 1002 Time: 0.00646
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 0 Time: 0.004772
[12/29/2021-03:47:03] [V] [TRT] Fastest Tactic: 0 Time: 0.004772
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 1002 Time: 0.010012
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 0 Time: 0.004768
[12/29/2021-03:47:03] [V] [TRT] Fastest Tactic: 0 Time: 0.004768
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 1002 Time: 0.011664
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:03] [V] [TRT] Tactic: 0 Time: 0.005164
[12/29/2021-03:47:03] [V] [TRT] Fastest Tactic: 0 Time: 0.005164
[12/29/2021-03:47:03] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:03] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1002 Time: 0.011568
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 0 Time: 0.00516
[12/29/2021-03:47:04] [V] [TRT] Fastest Tactic: 0 Time: 0.00516
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1002 Time: 0.012856
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 0 Time: 0.004624
[12/29/2021-03:47:04] [V] [TRT] Fastest Tactic: 0 Time: 0.004624
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1002 Time: 0.00648
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 0 Time: 0.004948
[12/29/2021-03:47:04] [V] [TRT] Fastest Tactic: 0 Time: 0.004948
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1002 Time: 0.006484
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 0 Time: 0.004816
[12/29/2021-03:47:04] [V] [TRT] Fastest Tactic: 0 Time: 0.004816
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1002 Time: 0.011304
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 0 Time: 0.005224
[12/29/2021-03:47:04] [V] [TRT] Fastest Tactic: 0 Time: 0.005224
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1002 Time: 0.01104
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 0 Time: 0.005064
[12/29/2021-03:47:04] [V] [TRT] Fastest Tactic: 0 Time: 0.005064
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1002 Time: 0.010924
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 0 Time: 0.00452
[12/29/2021-03:47:04] [V] [TRT] Fastest Tactic: 0 Time: 0.00452
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1002 Time: 0.008236
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 0 Time: 0.005104
[12/29/2021-03:47:04] [V] [TRT] Fastest Tactic: 0 Time: 0.005104
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1002 Time: 0.008164
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 0 Time: 0.005072
[12/29/2021-03:47:04] [V] [TRT] Fastest Tactic: 0 Time: 0.005072
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1002 Time: 0.011444
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 0 Time: 0.00508
[12/29/2021-03:47:04] [V] [TRT] Fastest Tactic: 0 Time: 0.00508
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1002 Time: 0.00848
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 0 Time: 0.00454
[12/29/2021-03:47:04] [V] [TRT] Fastest Tactic: 0 Time: 0.00454
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1002 Time: 0.010704
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 0 Time: 0.00522
[12/29/2021-03:47:04] [V] [TRT] Fastest Tactic: 0 Time: 0.00522
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1002 Time: 0.008156
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 0 Time: 0.005216
[12/29/2021-03:47:04] [V] [TRT] Fastest Tactic: 0 Time: 0.005216
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1002 Time: 0.008176
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 0 Time: 0.005116
[12/29/2021-03:47:04] [V] [TRT] Fastest Tactic: 0 Time: 0.005116
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1002 Time: 0.011088
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 0 Time: 0.005144
[12/29/2021-03:47:04] [V] [TRT] Fastest Tactic: 0 Time: 0.005144
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1002 Time: 0.008476
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 0 Time: 0.00454
[12/29/2021-03:47:04] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1 Time: 0.00464
[12/29/2021-03:47:04] [V] [TRT] Fastest Tactic: 0 Time: 0.00454
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning format combination: Float(512,1,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CudaDepthwiseConvolution)
[12/29/2021-03:47:04] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (FusedConvActConvolution)
[12/29/2021-03:47:04] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CudnnConvolution)
[12/29/2021-03:47:04] [V] [TRT] Tactic: 0 Time: 0.638544
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1 Time: 0.202088
[12/29/2021-03:47:04] [V] [TRT] Tactic: 2 Time: 0.291756
[12/29/2021-03:47:04] [V] [TRT] Tactic: 4 skipped. Scratch requested: 651165696, available: 16777216
[12/29/2021-03:47:04] [V] [TRT] Tactic: 5 skipped. Scratch requested: 1283457024, available: 16777216
[12/29/2021-03:47:04] [V] [TRT] Tactic: 6 skipped. Scratch requested: 26216448, available: 16777216
[12/29/2021-03:47:04] [V] [TRT] Tactic: 56 Time: 0.63794
[12/29/2021-03:47:04] [V] [TRT] Tactic: 57 Time: 0.249808
[12/29/2021-03:47:04] [V] [TRT] Tactic: 58 Time: 0.290732
[12/29/2021-03:47:04] [V] [TRT] Tactic: 60 skipped. Scratch requested: 651165696, available: 16777216
[12/29/2021-03:47:04] [V] [TRT] Tactic: 61 skipped. Scratch requested: 1283457024, available: 16777216
[12/29/2021-03:47:04] [V] [TRT] Tactic: 62 skipped. Scratch requested: 26216448, available: 16777216
[12/29/2021-03:47:04] [V] [TRT] Tactic: 112 Time: 0.63838
[12/29/2021-03:47:04] [V] [TRT] Tactic: 113 Time: 0.86872
[12/29/2021-03:47:04] [V] [TRT] Tactic: 114 Time: 0.291228
[12/29/2021-03:47:04] [V] [TRT] Tactic: 116 skipped. Scratch requested: 651165696, available: 16777216
[12/29/2021-03:47:04] [V] [TRT] Tactic: 117 skipped. Scratch requested: 1283457024, available: 16777216
[12/29/2021-03:47:04] [V] [TRT] Tactic: 118 skipped. Scratch requested: 26216448, available: 16777216
[12/29/2021-03:47:04] [V] [TRT] Fastest Tactic: 1 Time: 0.202088
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CaskConvolution)
[12/29/2021-03:47:04] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:04] [V] [TRT] Setting workspace to 26216448enables more tactics for profiling
[12/29/2021-03:47:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning format combination: Float(512,1,512,512) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CudnnConvolution)
[12/29/2021-03:47:04] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CaskConvolution)
[12/29/2021-03:47:04] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning format combination: Float(128,1:4,128,128) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CudnnConvolution)
[12/29/2021-03:47:04] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CaskConvolution)
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[12/29/2021-03:47:04] [V] [TRT] Tactic: 7342025736444949634 Time: 0.378312
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[12/29/2021-03:47:04] [V] [TRT] Tactic: -7377458734869418330 Time: 0.372312
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[12/29/2021-03:47:04] [V] [TRT] Tactic: -5457304872213719461 Time: 0.375312
[12/29/2021-03:47:04] [V] [TRT] Fastest Tactic: -7377458734869418330 Time: 0.372312
[12/29/2021-03:47:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7377458734869418330
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning format combination: Int8(128,1:4,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CudaDepthwiseConvolution)
[12/29/2021-03:47:04] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CaskConvolution)
[12/29/2021-03:47:04] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning format combination: Int8(128,1:4,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CudaDepthwiseConvolution)
[12/29/2021-03:47:04] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (FusedConvActConvolution)
[12/29/2021-03:47:04] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CaskConvolution)
[12/29/2021-03:47:04] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning format combination: Int8(128,1:4,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CaskConvolution)
[12/29/2021-03:47:04] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning format combination: Int8(16,1:32,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CaskConvolution)
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 1011019097971850911
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1011019097971850911 Time: 0.051256
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 1071114551801767124
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1071114551801767124 Time: 0.028664
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 2623576043214044314
[12/29/2021-03:47:04] [V] [TRT] Tactic: 2623576043214044314 Time: 0.017616
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 3281631721811475881
[12/29/2021-03:47:04] [V] [TRT] Tactic: 3281631721811475881 Time: 0.021984
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4551754795416974366
[12/29/2021-03:47:04] [V] [TRT] Tactic: 4551754795416974366 Time: 0.019728
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: 4925112190271421402
[12/29/2021-03:47:04] [V] [TRT] Tactic: 4925112190271421402 Time: 0.016448
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5041593333398049019
[12/29/2021-03:47:04] [V] [TRT] Tactic: 5041593333398049019 Time: 0.016428
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 5166018662410176512
[12/29/2021-03:47:04] [V] [TRT] Tactic: 5166018662410176512 Time: 0.095196
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 6191867932654611882
[12/29/2021-03:47:04] [V] [TRT] Tactic: 6191867932654611882 Time: 0.051616
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6852868042694587230
[12/29/2021-03:47:04] [V] [TRT] Tactic: 6852868042694587230 Time: 0.020244
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 8399092794516815300
[12/29/2021-03:47:04] [V] [TRT] Tactic: 8399092794516815300 Time: 0.096572
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -9132922677633967263
[12/29/2021-03:47:04] [V] [TRT] Tactic: -9132922677633967263 Time: 0.029384
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -7413564913826321357
[12/29/2021-03:47:04] [V] [TRT] Tactic: -7413564913826321357 Time: 0.052952
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -5942379529065248478
[12/29/2021-03:47:04] [V] [TRT] Tactic: -5942379529065248478 Time: 0.028888
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -5334776871777565833
[12/29/2021-03:47:04] [V] [TRT] Tactic: -5334776871777565833 Time: 0.096148
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -5157868397078537095
[12/29/2021-03:47:04] [V] [TRT] Tactic: -5157868397078537095 Time: 0.05162
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -5100834417027499764
[12/29/2021-03:47:04] [V] [TRT] Tactic: -5100834417027499764 Time: 0.01868
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3365360067423513506
[12/29/2021-03:47:04] [V] [TRT] Tactic: -3365360067423513506 Time: 0.014652
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -1782593837177056527
[12/29/2021-03:47:04] [V] [TRT] Tactic: -1782593837177056527 Time: 0.029204
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8f32_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: -1573035963956198975
[12/29/2021-03:47:04] [V] [TRT] Tactic: -1573035963956198975 Time: 0.09616
[12/29/2021-03:47:04] [V] [TRT] Fastest Tactic: -3365360067423513506 Time: 0.014652
[12/29/2021-03:47:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3365360067423513506
[12/29/2021-03:47:04] [V] [TRT] *************** Autotuning format combination: Int8(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CudaGroupConvolution)
[12/29/2021-03:47:04] [V] [TRT] CudaGroupConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CudaDepthwiseConvolution)
[12/29/2021-03:47:04] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (FusedConvActConvolution)
[12/29/2021-03:47:04] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:04] [V] [TRT] --------------- Timing Runner: Conv_111 + Relu_114 (CaskConvolution)
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: 177040020707947851
[12/29/2021-03:47:04] [V] [TRT] Tactic: 177040020707947851 Time: 0.0196
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 1550399266192842845
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1550399266192842845 Time: 0.01666
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 1572887561103143487
[12/29/2021-03:47:04] [V] [TRT] Tactic: 1572887561103143487 Time: 0.031088
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: 2325023763229477890
[12/29/2021-03:47:04] [V] [TRT] Tactic: 2325023763229477890 Time: 0.052144
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:47:04] [V] [TRT] Tactic: 3284282970967328046 Time: 0.014476
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 3401614690060226673
[12/29/2021-03:47:04] [V] [TRT] Tactic: 3401614690060226673 Time: 0.018552
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3512426920013359699
[12/29/2021-03:47:04] [V] [TRT] Tactic: 3512426920013359699 Time: 0.021784
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 4042202769383439184
[12/29/2021-03:47:04] [V] [TRT] Tactic: 4042202769383439184 Time: 0.028816
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: 4259547356717612415
[12/29/2021-03:47:04] [V] [TRT] Tactic: 4259547356717612415 Time: 0.032816
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32 Tactic: 4734519122557206480
[12/29/2021-03:47:04] [V] [TRT] Tactic: 4734519122557206480 Time: 0.095208
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_epifadd Tactic: 5121596860264626879
[12/29/2021-03:47:04] [V] [TRT] Tactic: 5121596860264626879 Time: 0.09514
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:47:04] [V] [TRT] Tactic: 5136656982162849059 Time: 0.014512
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 5158259316594207439
[12/29/2021-03:47:04] [V] [TRT] Tactic: 5158259316594207439 Time: 0.028812
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 5966973378912044513
[12/29/2021-03:47:04] [V] [TRT] Tactic: 5966973378912044513 Time: 0.050976
[12/29/2021-03:47:04] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 6004789655466615912
[12/29/2021-03:47:04] [V] [TRT] Tactic: 6004789655466615912 Time: 0.031224
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3 Tactic: 6146901278630392829
[12/29/2021-03:47:05] [V] [TRT] Tactic: 6146901278630392829 Time: 0.095092
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_epifadd Tactic: 6434020722187266170
[12/29/2021-03:47:05] [V] [TRT] Tactic: 6434020722187266170 Time: 0.095992
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: 6781129591847482048
[12/29/2021-03:47:05] [V] [TRT] Tactic: 6781129591847482048 Time: 0.029064
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7191893591576074000
[12/29/2021-03:47:05] [V] [TRT] Tactic: 7191893591576074000 Time: 0.016476
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 7438984192263206338
[12/29/2021-03:47:05] [V] [TRT] Tactic: 7438984192263206338 Time: 0.02826
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: 7504901284678552178
[12/29/2021-03:47:05] [V] [TRT] Tactic: 7504901284678552178 Time: 0.051084
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: 8096257414008860171
[12/29/2021-03:47:05] [V] [TRT] Tactic: 8096257414008860171 Time: 0.028632
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 9143438935315839085
[12/29/2021-03:47:05] [V] [TRT] Tactic: 9143438935315839085 Time: 0.018864
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32 Tactic: -9165697322068360861
[12/29/2021-03:47:05] [V] [TRT] Tactic: -9165697322068360861 Time: 0.096048
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8263994888336646547
[12/29/2021-03:47:05] [V] [TRT] Tactic: -8263994888336646547 Time: 0.051108
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -8205948405243401049
[12/29/2021-03:47:05] [V] [TRT] Tactic: -8205948405243401049 Time: 0.01656
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -7992068592656168418
[12/29/2021-03:47:05] [V] [TRT] Tactic: -7992068592656168418 Time: 0.028848
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_epifadd Tactic: -7842775553137511386
[12/29/2021-03:47:05] [V] [TRT] Tactic: -7842775553137511386 Time: 0.052064
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -7683887278997527517
[12/29/2021-03:47:05] [V] [TRT] Tactic: -7683887278997527517 Time: 0.019712
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5709079507616090666
[12/29/2021-03:47:05] [V] [TRT] Tactic: -5709079507616090666 Time: 0.050984
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x256x64_stage4_warpsize2x4x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -5698636014239116282
[12/29/2021-03:47:05] [V] [TRT] Tactic: -5698636014239116282 Time: 0.095092
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -4933563390723451692
[12/29/2021-03:47:05] [V] [TRT] Tactic: -4933563390723451692 Time: 0.021848
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: -3413217501222406256
[12/29/2021-03:47:05] [V] [TRT] Tactic: -3413217501222406256 Time: 0.095292
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x128x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3238475748440751107
[12/29/2021-03:47:05] [V] [TRT] Tactic: -3238475748440751107 Time: 0.028288
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x64x64_stage4_warpsize4x1x1_g1_tensor16x8x32_t1r3s3 Tactic: -3182884991006484042
[12/29/2021-03:47:05] [V] [TRT] Tactic: -3182884991006484042 Time: 0.05154
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -3173468756112541306
[12/29/2021-03:47:05] [V] [TRT] Tactic: -3173468756112541306 Time: 0.016496
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -2083778562631872334
[12/29/2021-03:47:05] [V] [TRT] Tactic: -2083778562631872334 Time: 0.029184
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize128x128x64_stage4_warpsize2x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -1546787387293556842
[12/29/2021-03:47:05] [V] [TRT] Tactic: -1546787387293556842 Time: 0.051116
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x32x64_stage4_warpsize4x1x1_g1_tensor16x8x32 Tactic: -1498626619443284096
[12/29/2021-03:47:05] [V] [TRT] Tactic: -1498626619443284096 Time: 0.033412
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32 Tactic: -1283580231568512025
[12/29/2021-03:47:05] [V] [TRT] Tactic: -1283580231568512025 Time: 0.016004
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_epifadd Tactic: -1173968681844185579
[12/29/2021-03:47:05] [V] [TRT] Tactic: -1173968681844185579 Time: 0.015588
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32 Tactic: -762222380308749469
[12/29/2021-03:47:05] [V] [TRT] Tactic: -762222380308749469 Time: 0.020068
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_epifadd Tactic: -556794153877490941
[12/29/2021-03:47:05] [V] [TRT] Tactic: -556794153877490941 Time: 0.020164
[12/29/2021-03:47:05] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize256x128x64_stage4_warpsize4x2x1_g1_tensor16x8x32_t1r3s3 Tactic: -516725800067794372
[12/29/2021-03:47:05] [V] [TRT] Tactic: -516725800067794372 Time: 0.094908
[12/29/2021-03:47:05] [V] [TRT] Fastest Tactic: 3284282970967328046 Time: 0.014476
[12/29/2021-03:47:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3284282970967328046
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning format combination: Float(512,1,1,1), Float(512,1,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning format combination: Float(512,1,512,512), Float(512,1,512,512) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:05] [V] [TRT] --------------- Timing Runner: Conv_117 + Add_118 + Relu_121 (CudnnConvolution)
[12/29/2021-03:47:05] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:05] [V] [TRT] --------------- Timing Runner: Conv_117 + Add_118 + Relu_121 (CaskConvolution)
[12/29/2021-03:47:05] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning format combination: Float(128,1:4,128,128), Float(128,1:4,128,128) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning format combination: Int8(128,1:4,1,1), Float(512,1,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] --------------- Timing Runner: Conv_117 + Add_118 + Relu_121 (CudaDepthwiseConvolution)
[12/29/2021-03:47:05] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:05] [V] [TRT] --------------- Timing Runner: Conv_117 + Add_118 + Relu_121 (CaskConvolution)
[12/29/2021-03:47:05] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning format combination: Int8(128,1:4,1,1), Int8(128,1:4,1,1) -> Int8(128,1:4,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] --------------- Timing Runner: Conv_117 + Add_118 + Relu_121 (CudaDepthwiseConvolution)
[12/29/2021-03:47:05] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:05] [V] [TRT] --------------- Timing Runner: Conv_117 + Add_118 + Relu_121 (FusedConvActConvolution)
[12/29/2021-03:47:05] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:05] [V] [TRT] --------------- Timing Runner: Conv_117 + Add_118 + Relu_121 (CaskConvolution)
[12/29/2021-03:47:05] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning format combination: Int8(128,1:4,1,1), Int8(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] --------------- Timing Runner: Conv_117 + Add_118 + Relu_121 (CaskConvolution)
[12/29/2021-03:47:05] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning format combination: Int8(16,1:32,1,1), Float(16,1:32,1,1) -> Float(16,1:32,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning format combination: Int8(16,1:32,1,1), Int8(16,1:32,1,1) -> Int8(16,1:32,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Int8(128,1:4,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Int8(16,1:32,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning format combination: Float(512,1,1,1) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_122 (TiledPooling)
[12/29/2021-03:47:05] [V] [TRT] Tactic: 7209217 Time: 0.01594
[12/29/2021-03:47:05] [V] [TRT] Fastest Tactic: 7209217 Time: 0.01594
[12/29/2021-03:47:05] [V] [TRT] --------------- Timing Runner: GlobalAveragePool_122 (CudnnPooling)
[12/29/2021-03:47:05] [V] [TRT] Tactic: -1 Time: 0.00534
[12/29/2021-03:47:05] [V] [TRT] Fastest Tactic: -1 Time: 0.00534
[12/29/2021-03:47:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,1,1) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(512,1,512,512) -> Float(128,1:4,128,128) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning Reformat:Float(128,1:4,128,128) -> Float(512,1,512,512) ***************
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning format combination: Float(512,1,1,1) -> Float(10,1,1,1) ***************
[12/29/2021-03:47:05] [V] [TRT] --------------- Timing Runner: Gemm_126 (CudaDepthwiseConvolution)
[12/29/2021-03:47:05] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:05] [V] [TRT] --------------- Timing Runner: Gemm_126 (FusedConvActConvolution)
[12/29/2021-03:47:05] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:05] [V] [TRT] --------------- Timing Runner: Gemm_126 (CudnnConvolution)
[12/29/2021-03:47:05] [V] [TRT] Tactic: 0 Time: 0.0705
[12/29/2021-03:47:05] [V] [TRT] Tactic: 1 Time: 0.124208
[12/29/2021-03:47:05] [V] [TRT] Tactic: 2 Time: 0.099936
[12/29/2021-03:47:05] [V] [TRT] Tactic: 4 skipped. Scratch requested: 49565696, available: 16777216
[12/29/2021-03:47:05] [V] [TRT] Tactic: 5 Time: 0.05566
[12/29/2021-03:47:05] [V] [TRT] Tactic: 56 Time: 0.070492
[12/29/2021-03:47:05] [V] [TRT] Tactic: 57 Time: 0.089248
[12/29/2021-03:47:05] [V] [TRT] Tactic: 58 Time: 0.099988
[12/29/2021-03:47:05] [V] [TRT] Tactic: 60 skipped. Scratch requested: 49565696, available: 16777216
[12/29/2021-03:47:05] [V] [TRT] Tactic: 61 Time: 0.0558
[12/29/2021-03:47:05] [V] [TRT] Tactic: 112 Time: 0.070448
[12/29/2021-03:47:05] [V] [TRT] Tactic: 113 Time: 0.070596
[12/29/2021-03:47:05] [V] [TRT] Tactic: 114 Time: 0.09998
[12/29/2021-03:47:05] [V] [TRT] Tactic: 116 skipped. Scratch requested: 49565696, available: 16777216
[12/29/2021-03:47:05] [V] [TRT] Tactic: 117 Time: 0.055812
[12/29/2021-03:47:05] [V] [TRT] Fastest Tactic: 5 Time: 0.05566
[12/29/2021-03:47:05] [V] [TRT] --------------- Timing Runner: Gemm_126 (CublasConvolution)
[12/29/2021-03:47:05] [V] [TRT] Tactic: 0 Time: 0.012568
[12/29/2021-03:47:05] [V] [TRT] Tactic: 1 Time: 0.01674
[12/29/2021-03:47:05] [V] [TRT] Tactic: 2 Time: 0.013892
[12/29/2021-03:47:05] [V] [TRT] Tactic: 3 Time: 0.014144
[12/29/2021-03:47:05] [V] [TRT] Fastest Tactic: 0 Time: 0.012568
[12/29/2021-03:47:05] [V] [TRT] --------------- Timing Runner: Gemm_126 (CaskConvolution)
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[12/29/2021-03:47:05] [V] [TRT] Tactic: 4549827808004681195 Time: 0.056988
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[12/29/2021-03:47:05] [V] [TRT] Tactic: 5779835512569528575 Time: 0.072616
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 9151672657204310840
[12/29/2021-03:47:05] [V] [TRT] Tactic: 9151672657204310840 Time: 0.06632
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: -7491730084094677098
[12/29/2021-03:47:05] [V] [TRT] Tactic: -7491730084094677098 Time: 0.064016
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: -6622064180404051845
[12/29/2021-03:47:05] [V] [TRT] Tactic: -6622064180404051845 Time: 0.062516
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[12/29/2021-03:47:05] [V] [TRT] Tactic: -6313876406580483184 Time: 0.065464
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: -6273689210331812572
[12/29/2021-03:47:05] [V] [TRT] Tactic: -6273689210331812572 Time: 0.071332
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: -4337126844824617177
[12/29/2021-03:47:05] [V] [TRT] Tactic: -4337126844824617177 Time: 0.053004
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[12/29/2021-03:47:05] [V] [TRT] Tactic: -1123676555321336786 Time: 0.071392
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[12/29/2021-03:47:05] [V] [TRT] Tactic: -701551393537224327 Time: 0.061976
[12/29/2021-03:47:05] [V] [TRT] Fastest Tactic: -4337126844824617177 Time: 0.053004
[12/29/2021-03:47:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CublasConvolution Tactic: 0
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning format combination: Float(512,1,512,512) -> Float(10,1,10,10) ***************
[12/29/2021-03:47:05] [V] [TRT] --------------- Timing Runner: Gemm_126 (CudnnConvolution)
[12/29/2021-03:47:05] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:05] [V] [TRT] --------------- Timing Runner: Gemm_126 (CublasConvolution)
[12/29/2021-03:47:05] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:05] [V] [TRT] --------------- Timing Runner: Gemm_126 (CaskConvolution)
[12/29/2021-03:47:05] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:05] [V] [TRT] *************** Autotuning format combination: Float(128,1:4,128,128) -> Float(3,1:4,3,3) ***************
[12/29/2021-03:47:05] [V] [TRT] --------------- Timing Runner: Gemm_126 (CudnnConvolution)
[12/29/2021-03:47:05] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:05] [V] [TRT] --------------- Timing Runner: Gemm_126 (CublasConvolution)
[12/29/2021-03:47:05] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[12/29/2021-03:47:05] [V] [TRT] --------------- Timing Runner: Gemm_126 (CaskConvolution)
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 1373022415249282411
[12/29/2021-03:47:05] [V] [TRT] Tactic: 1373022415249282411 Time: 0.047656
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 1663866669559596164
[12/29/2021-03:47:05] [V] [TRT] Tactic: 1663866669559596164 Time: 0.069704
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[12/29/2021-03:47:05] [V] [TRT] Tactic: 2860655430572478466 Time: 0.044064
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[12/29/2021-03:47:05] [V] [TRT] Tactic: 4474630279712975759 Time: 0.02692
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[12/29/2021-03:47:05] [V] [TRT] Tactic: 4479823862704990365 Time: 0.02668
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[12/29/2021-03:47:05] [V] [TRT] Tactic: 4696204239951173149 Time: 0.043296
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[12/29/2021-03:47:05] [V] [TRT] Tactic: 5778138195697110003 Time: 0.070548
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[12/29/2021-03:47:05] [V] [TRT] Tactic: 8918020581761223752 Time: 0.06696
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: -7067026478815706014
[12/29/2021-03:47:05] [V] [TRT] Tactic: -7067026478815706014 Time: 0.047536
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -5905193483742532701
[12/29/2021-03:47:05] [V] [TRT] Tactic: -5905193483742532701 Time: 0.039216
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -4035591156787122265
[12/29/2021-03:47:05] [V] [TRT] Tactic: -4035591156787122265 Time: 0.026216
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[12/29/2021-03:47:05] [V] [TRT] Tactic: -2809379259463049391 Time: 0.069768
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -1985235291706575900
[12/29/2021-03:47:05] [V] [TRT] Tactic: -1985235291706575900 Time: 0.067496
[12/29/2021-03:47:05] [V] [TRT] Gemm_126 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[12/29/2021-03:47:06] [V] [TRT] Tactic: -504296718212024303 Time: 0.068448
[12/29/2021-03:47:06] [V] [TRT] Fastest Tactic: -4035591156787122265 Time: 0.026216
[12/29/2021-03:47:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4035591156787122265
[12/29/2021-03:47:06] [V] [TRT] *************** Autotuning Reformat:Float(10,1,10,10) -> Float(10,1,1,1) ***************
[12/29/2021-03:47:06] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:06] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:06] [V] [TRT] Tactic: 1002 Time: 0.006108
[12/29/2021-03:47:06] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:06] [V] [TRT] Tactic: 0 Time: 0.004424
[12/29/2021-03:47:06] [V] [TRT] Fastest Tactic: 0 Time: 0.004424
[12/29/2021-03:47:06] [V] [TRT] *************** Autotuning Reformat:Float(3,1:4,3,3) -> Float(10,1,1,1) ***************
[12/29/2021-03:47:06] [V] [TRT] --------------- Timing Runner: Optimizer Reformat (Reformat)
[12/29/2021-03:47:06] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:06] [V] [TRT] Tactic: 1002 Time: 0.006096
[12/29/2021-03:47:06] [V] [TRT] Setting a default quantization params because quantization data is missing for 
[12/29/2021-03:47:06] [V] [TRT] Tactic: 0 Time: 0.004528
[12/29/2021-03:47:06] [V] [TRT] Fastest Tactic: 0 Time: 0.004528
[12/29/2021-03:47:06] [V] [TRT] *************** Autotuning format combination: Float(10,1,1,1) -> Float(10,1) ***************
[12/29/2021-03:47:06] [V] [TRT] --------------- Timing Runner: (Unnamed Layer* 50) [Shuffle] (Shuffle)
[12/29/2021-03:47:06] [V] [TRT] Tactic: 0 Time: 0.004072
[12/29/2021-03:47:06] [V] [TRT] Tactic: 1 Time: 0.008828
[12/29/2021-03:47:06] [V] [TRT] Fastest Tactic: 0 Time: 0.004072
[12/29/2021-03:47:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0
[12/29/2021-03:47:06] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_2 + Relu_5 + MaxPool_8 (actual_input_1) from Float(3072,1024,32,1) to Int8(3072,1024,32,1)
[12/29/2021-03:47:06] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to GlobalAveragePool_122 (264) from Int8(16,1:32,1,1) to Float(512,1,1,1)
[12/29/2021-03:47:06] [V] [TRT] Formats and tactics selection completed in 22.7412 seconds.
[12/29/2021-03:47:06] [V] [TRT] After reformat layers: 25 layers
[12/29/2021-03:47:06] [V] [TRT] Block size 16777216
[12/29/2021-03:47:06] [V] [TRT] Block size 131072
[12/29/2021-03:47:06] [V] [TRT] Block size 131072
[12/29/2021-03:47:06] [V] [TRT] Block size 131072
[12/29/2021-03:47:06] [V] [TRT] Total Activation Memory: 17170432
[12/29/2021-03:47:06] [I] [TRT] Detected 1 inputs and 1 output network tensors.
[12/29/2021-03:47:06] [V] [TRT] Conv_11 + Relu_14 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 9143438935315839085
[12/29/2021-03:47:06] [V] [TRT] Conv_17 + Add_18 + Relu_21 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:47:06] [V] [TRT] Conv_24 + Relu_27 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize64x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 9143438935315839085
[12/29/2021-03:47:06] [V] [TRT] Conv_30 + Add_31 + Relu_34 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:47:06] [V] [TRT] Conv_37 + Relu_40 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:47:06] [V] [TRT] Conv_46 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x64x64_stage6_warpsize2x2x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -5170003087447722174
[12/29/2021-03:47:06] [V] [TRT] Conv_43 + Add_47 + Relu_50 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:47:06] [V] [TRT] Conv_53 + Relu_56 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:47:06] [V] [TRT] Conv_59 + Add_60 + Relu_63 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:47:06] [V] [TRT] Conv_66 + Relu_69 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:47:06] [V] [TRT] Conv_75 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1_epifadd Tactic: -713022856474991236
[12/29/2021-03:47:06] [V] [TRT] Conv_72 + Add_76 + Relu_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:47:06] [V] [TRT] Conv_82 + Relu_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:47:06] [V] [TRT] Conv_88 + Add_89 + Relu_92 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:47:06] [V] [TRT] Conv_95 + Relu_98 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:47:06] [V] [TRT] Conv_104 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r1s1 Tactic: -3613322253849278738
[12/29/2021-03:47:06] [V] [TRT] Conv_101 + Add_105 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:47:06] [V] [TRT] Conv_111 + Relu_114 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3_epifadd Tactic: 3284282970967328046
[12/29/2021-03:47:06] [V] [TRT] Conv_117 + Add_118 + Relu_121 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_interleaved_i8i8_i8i32_f32_nchw_vect_c_32kcrs_vect_c_32_nchw_vect_c_32_tilesize32x32x64_stage6_warpsize2x1x1_g1_tensor16x8x32_t1r3s3 Tactic: 5136656982162849059
[12/29/2021-03:47:06] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_2 + Relu_5 + MaxPool_8 HostPersistent: 0 DevicePersistent: 0
[12/29/2021-03:47:06] [V] [TRT] Layer: Conv_2 + Relu_5 + MaxPool_8 HostPersistent: 0 DevicePersistent: 0
[12/29/2021-03:47:06] [V] [TRT] Layer: Conv_11 + Relu_14 HostPersistent: 2976 DevicePersistent: 37888
[12/29/2021-03:47:06] [V] [TRT] Layer: Conv_17 + Add_18 + Relu_21 HostPersistent: 2976 DevicePersistent: 37888
[12/29/2021-03:47:06] [V] [TRT] Layer: Conv_24 + Relu_27 HostPersistent: 2976 DevicePersistent: 37888
[12/29/2021-03:47:06] [V] [TRT] Layer: Conv_30 + Add_31 + Relu_34 HostPersistent: 2976 DevicePersistent: 37888
[12/29/2021-03:47:06] [V] [TRT] Layer: Conv_37 + Relu_40 HostPersistent: 2976 DevicePersistent: 75264
[12/29/2021-03:47:06] [V] [TRT] Layer: Conv_46 HostPersistent: 2976 DevicePersistent: 9728
[12/29/2021-03:47:06] [V] [TRT] Layer: Conv_43 + Add_47 + Relu_50 HostPersistent: 2976 DevicePersistent: 148992
[12/29/2021-03:47:06] [V] [TRT] Layer: Conv_53 + Relu_56 HostPersistent: 2976 DevicePersistent: 148992
[12/29/2021-03:47:06] [V] [TRT] Layer: Conv_59 + Add_60 + Relu_63 HostPersistent: 2976 DevicePersistent: 148992
[12/29/2021-03:47:06] [V] [TRT] Layer: Conv_66 + Relu_69 HostPersistent: 2976 DevicePersistent: 297984
[12/29/2021-03:47:06] [V] [TRT] Layer: Conv_75 HostPersistent: 2976 DevicePersistent: 35840
[12/29/2021-03:47:06] [V] [TRT] Layer: Conv_72 + Add_76 + Relu_79 HostPersistent: 2976 DevicePersistent: 592896
[12/29/2021-03:47:06] [V] [TRT] Layer: Conv_82 + Relu_85 HostPersistent: 2976 DevicePersistent: 592896
[12/29/2021-03:47:06] [V] [TRT] Layer: Conv_88 + Add_89 + Relu_92 HostPersistent: 2976 DevicePersistent: 592896
[12/29/2021-03:47:06] [V] [TRT] Layer: Conv_95 + Relu_98 HostPersistent: 2976 DevicePersistent: 1185792
[12/29/2021-03:47:06] [V] [TRT] Layer: Conv_104 HostPersistent: 2976 DevicePersistent: 137216
[12/29/2021-03:47:06] [V] [TRT] Layer: Conv_101 + Add_105 + Relu_108 HostPersistent: 2976 DevicePersistent: 2365440
[12/29/2021-03:47:06] [V] [TRT] Layer: Conv_111 + Relu_114 HostPersistent: 2976 DevicePersistent: 2365440
[12/29/2021-03:47:06] [V] [TRT] Layer: Conv_117 + Add_118 + Relu_121 HostPersistent: 2976 DevicePersistent: 2365440
[12/29/2021-03:47:06] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to GlobalAveragePool_122 HostPersistent: 0 DevicePersistent: 0
[12/29/2021-03:47:06] [V] [TRT] Layer: GlobalAveragePool_122 HostPersistent: 48 DevicePersistent: 0
[12/29/2021-03:47:06] [V] [TRT] Layer: Gemm_126 HostPersistent: 340 DevicePersistent: 0
[12/29/2021-03:47:06] [I] [TRT] Total Host Persistent Memory: 56944
[12/29/2021-03:47:06] [I] [TRT] Total Device Persistent Memory: 11215360
[12/29/2021-03:47:06] [I] [TRT] Total Scratch Memory: 6144
[12/29/2021-03:47:06] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 13 MiB, GPU 4 MiB
[12/29/2021-03:47:06] [V] [TRT] Using cublasLt a tactic source
[12/29/2021-03:47:06] [12/29/2021-03:47:06] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +1, GPU +8, now: CPU 2079, GPU 4033 (MiB)
[12/29/2021-03:47:06] [V] [TRT] Using cuDNN as a tactic source
[12/29/2021-03:47:06] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2079, GPU 4041 (MiB)
[12/29/2021-03:47:06] [12/29/2021-03:47:06] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 2078, GPU 4025 (MiB)
[12/29/2021-03:47:06] [V] [TRT] Engine generation completed in 23.9779 seconds.
[12/29/2021-03:47:06] [V] [TRT] Deleting timing cache: 346 entries, 739 hits
[12/29/2021-03:47:06] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 2078, GPU 4007 (MiB)
[12/29/2021-03:47:06] [V] [TRT] Engine Layer Information:
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv_2 + Relu_5 + MaxPool_8, Tactic: 0, actual_input_1[Float(32,3,32,32)] -> Reformatted Input Tensor 0 to Conv_2 + Relu_5 + MaxPool_8[Int8(32,3,32,32)]
Layer(ConvActPool): Conv_2 + Relu_5 + MaxPool_8, Tactic: 1131, Reformatted Input Tensor 0 to Conv_2 + Relu_5 + MaxPool_8[Int8(32,3,32,32)] -> 132[Int8(32,64,8,8)]
Layer(CaskConvolution): Conv_11 + Relu_14, Tactic: 9143438935315839085, 132[Int8(32,64,8,8)] -> 139[Int8(32,64,8,8)]
Layer(CaskConvolution): Conv_17 + Add_18 + Relu_21, Tactic: 5136656982162849059, 139[Int8(32,64,8,8)], 132[Int8(32,64,8,8)] -> 147[Int8(32,64,8,8)]
Layer(CaskConvolution): Conv_24 + Relu_27, Tactic: 9143438935315839085, 147[Int8(32,64,8,8)] -> 154[Int8(32,64,8,8)]
Layer(CaskConvolution): Conv_30 + Add_31 + Relu_34, Tactic: 5136656982162849059, 154[Int8(32,64,8,8)], 147[Int8(32,64,8,8)] -> 162[Int8(32,64,8,8)]
Layer(CaskConvolution): Conv_37 + Relu_40, Tactic: 3284282970967328046, 162[Int8(32,64,8,8)] -> 169[Int8(32,128,4,4)]
Layer(CaskConvolution): Conv_46, Tactic: -5170003087447722174, 162[Int8(32,64,8,8)] -> 291[Int8(32,128,4,4)]
Layer(CaskConvolution): Conv_43 + Add_47 + Relu_50, Tactic: 5136656982162849059, 169[Int8(32,128,4,4)], 291[Int8(32,128,4,4)] -> 181[Int8(32,128,4,4)]
Layer(CaskConvolution): Conv_53 + Relu_56, Tactic: 3284282970967328046, 181[Int8(32,128,4,4)] -> 188[Int8(32,128,4,4)]
Layer(CaskConvolution): Conv_59 + Add_60 + Relu_63, Tactic: 5136656982162849059, 188[Int8(32,128,4,4)], 181[Int8(32,128,4,4)] -> 196[Int8(32,128,4,4)]
Layer(CaskConvolution): Conv_66 + Relu_69, Tactic: 5136656982162849059, 196[Int8(32,128,4,4)] -> 203[Int8(32,256,2,2)]
Layer(CaskConvolution): Conv_75, Tactic: -713022856474991236, 196[Int8(32,128,4,4)] -> 306[Int8(32,256,2,2)]
Layer(CaskConvolution): Conv_72 + Add_76 + Relu_79, Tactic: 5136656982162849059, 203[Int8(32,256,2,2)], 306[Int8(32,256,2,2)] -> 215[Int8(32,256,2,2)]
Layer(CaskConvolution): Conv_82 + Relu_85, Tactic: 3284282970967328046, 215[Int8(32,256,2,2)] -> 222[Int8(32,256,2,2)]
Layer(CaskConvolution): Conv_88 + Add_89 + Relu_92, Tactic: 5136656982162849059, 222[Int8(32,256,2,2)], 215[Int8(32,256,2,2)] -> 230[Int8(32,256,2,2)]
Layer(CaskConvolution): Conv_95 + Relu_98, Tactic: 3284282970967328046, 230[Int8(32,256,2,2)] -> 237[Int8(32,512,1,1)]
Layer(CaskConvolution): Conv_104, Tactic: -3613322253849278738, 230[Int8(32,256,2,2)] -> 321[Int8(32,512,1,1)]
Layer(CaskConvolution): Conv_101 + Add_105 + Relu_108, Tactic: 5136656982162849059, 237[Int8(32,512,1,1)], 321[Int8(32,512,1,1)] -> 249[Int8(32,512,1,1)]
Layer(CaskConvolution): Conv_111 + Relu_114, Tactic: 3284282970967328046, 249[Int8(32,512,1,1)] -> 256[Int8(32,512,1,1)]
Layer(CaskConvolution): Conv_117 + Add_118 + Relu_121, Tactic: 5136656982162849059, 256[Int8(32,512,1,1)], 249[Int8(32,512,1,1)] -> 264[Int8(32,512,1,1)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to GlobalAveragePool_122, Tactic: 0, 264[Int8(32,512,1,1)] -> Reformatted Input Tensor 0 to GlobalAveragePool_122[Float(32,512,1,1)]
Layer(CudnnPooling): GlobalAveragePool_122, Tactic: -1, Reformatted Input Tensor 0 to GlobalAveragePool_122[Float(32,512,1,1)] -> 265[Float(32,512,1,1)]
Layer(CublasConvolution): Gemm_126, Tactic: 0, 265[Float(32,512,1,1)] -> (Unnamed Layer* 49) [Fully Connected]_output[Float(32,10,1,1)]
[12/29/2021-03:47:06] [I] [TRT] [MemUsageSnapshot] Builder end: CPU 2078 MiB, GPU 4007 MiB
[12/29/2021-03:47:06] [I] [TRT] Loaded engine size: 10 MB
[12/29/2021-03:47:06] [I] [TRT] [MemUsageSnapshot] deserializeCudaEngine begin: CPU 2087 MiB, GPU 3995 MiB
[12/29/2021-03:47:06] [V] [TRT] Using cublasLt a tactic source
[12/29/2021-03:47:06] [12/29/2021-03:47:06] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2087, GPU 4017 (MiB)
[12/29/2021-03:47:06] [V] [TRT] Using cuDNN as a tactic source
[12/29/2021-03:47:06] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2087, GPU 4025 (MiB)
[12/29/2021-03:47:06] [12/29/2021-03:47:06] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 2087, GPU 4007 (MiB)
[12/29/2021-03:47:06] [V] [TRT] Deserialization required 32054 microseconds.
[12/29/2021-03:47:06] [I] [TRT] [MemUsageSnapshot] deserializeCudaEngine end: CPU 2087 MiB, GPU 4007 MiB
[12/29/2021-03:47:06] [I] Engine built in 24.8317 sec.
[12/29/2021-03:47:06] [I] [TRT] [MemUsageSnapshot] ExecutionContext creation begin: CPU 2048 MiB, GPU 4007 MiB
[12/29/2021-03:47:06] [V] [TRT] Using cublasLt a tactic source
[12/29/2021-03:47:06] [12/29/2021-03:47:06] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +1, GPU +10, now: CPU 2049, GPU 4017 (MiB)
[12/29/2021-03:47:06] [V] [TRT] Using cuDNN as a tactic source
[12/29/2021-03:47:06] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2049, GPU 4025 (MiB)
[12/29/2021-03:47:06] [12/29/2021-03:47:06] [V] [TRT] Total per-runner device memory is 11215360
[12/29/2021-03:47:06] [V] [TRT] Total per-runner host memory is 56944
[12/29/2021-03:47:06] [V] [TRT] Allocated activation device memory of size 393216
[12/29/2021-03:47:06] [I] [TRT] [MemUsageSnapshot] ExecutionContext creation end: CPU 2049 MiB, GPU 4037 MiB
[12/29/2021-03:47:06] [I] Created input binding for actual_input_1 with dimensions 32x3x32x32
[12/29/2021-03:47:06] [I] Created output binding for output1 with dimensions 32x10
[12/29/2021-03:47:06] [I] Starting inference
[12/29/2021-03:47:09] [I] Warmup completed 1024 queries over 200 ms
[12/29/2021-03:47:09] [I] Timing trace has 15933 queries over 3.00068 s
[12/29/2021-03:47:09] [I] 
[12/29/2021-03:47:09] [I] === Trace details ===
[12/29/2021-03:47:09] [I] Trace averages of 10 runs:
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1543 ms - Host latency: 0.195737 ms (end to end 0.282451 ms, enqueue 0.0909485 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154358 ms - Host latency: 0.195873 ms (end to end 0.279874 ms, enqueue 0.0924789 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153673 ms - Host latency: 0.195189 ms (end to end 0.285461 ms, enqueue 0.106953 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154999 ms - Host latency: 0.196857 ms (end to end 0.274864 ms, enqueue 0.114175 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154443 ms - Host latency: 0.196342 ms (end to end 0.271016 ms, enqueue 0.108948 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.222133 ms - Host latency: 0.269762 ms (end to end 0.30575 ms, enqueue 0.206519 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.187779 ms - Host latency: 0.234161 ms (end to end 0.257089 ms, enqueue 0.184125 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.163908 ms - Host latency: 0.208704 ms (end to end 0.263126 ms, enqueue 0.140794 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161165 ms - Host latency: 0.204608 ms (end to end 0.217296 ms, enqueue 0.149872 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157645 ms - Host latency: 0.205527 ms (end to end 0.214766 ms, enqueue 0.159178 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156514 ms - Host latency: 0.206918 ms (end to end 0.218468 ms, enqueue 0.16425 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160686 ms - Host latency: 0.208144 ms (end to end 0.221933 ms, enqueue 0.155035 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161833 ms - Host latency: 0.206483 ms (end to end 0.220753 ms, enqueue 0.151555 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155904 ms - Host latency: 0.198192 ms (end to end 0.264449 ms, enqueue 0.114345 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154697 ms - Host latency: 0.1972 ms (end to end 0.291316 ms, enqueue 0.109181 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154442 ms - Host latency: 0.19646 ms (end to end 0.288356 ms, enqueue 0.109482 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154375 ms - Host latency: 0.19623 ms (end to end 0.288794 ms, enqueue 0.107681 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154498 ms - Host latency: 0.196132 ms (end to end 0.286951 ms, enqueue 0.10643 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154955 ms - Host latency: 0.197287 ms (end to end 0.286919 ms, enqueue 0.109872 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.20128 ms - Host latency: 0.2476 ms (end to end 0.313251 ms, enqueue 0.169695 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.26572 ms - Host latency: 0.315865 ms (end to end 0.332797 ms, enqueue 0.290778 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.248157 ms - Host latency: 0.296021 ms (end to end 0.306439 ms, enqueue 0.274649 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.248174 ms - Host latency: 0.296259 ms (end to end 0.306946 ms, enqueue 0.27455 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.285088 ms - Host latency: 0.334805 ms (end to end 0.347942 ms, enqueue 0.311816 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.260468 ms - Host latency: 0.310043 ms (end to end 0.323819 ms, enqueue 0.28824 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.216316 ms - Host latency: 0.261935 ms (end to end 0.273151 ms, enqueue 0.232669 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.176001 ms - Host latency: 0.220029 ms (end to end 0.229959 ms, enqueue 0.200153 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.170566 ms - Host latency: 0.21535 ms (end to end 0.224493 ms, enqueue 0.184747 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.178738 ms - Host latency: 0.222723 ms (end to end 0.232806 ms, enqueue 0.207703 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.16225 ms - Host latency: 0.205954 ms (end to end 0.21774 ms, enqueue 0.153888 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154745 ms - Host latency: 0.19639 ms (end to end 0.275858 ms, enqueue 0.100037 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154541 ms - Host latency: 0.196454 ms (end to end 0.284756 ms, enqueue 0.100082 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155527 ms - Host latency: 0.198279 ms (end to end 0.271533 ms, enqueue 0.107916 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154636 ms - Host latency: 0.197534 ms (end to end 0.279834 ms, enqueue 0.100131 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154593 ms - Host latency: 0.196664 ms (end to end 0.28522 ms, enqueue 0.103033 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154385 ms - Host latency: 0.196121 ms (end to end 0.276709 ms, enqueue 0.0940796 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154865 ms - Host latency: 0.196765 ms (end to end 0.28114 ms, enqueue 0.0877655 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154285 ms - Host latency: 0.196072 ms (end to end 0.279657 ms, enqueue 0.0939606 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154077 ms - Host latency: 0.195575 ms (end to end 0.279691 ms, enqueue 0.0883911 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154877 ms - Host latency: 0.19642 ms (end to end 0.279755 ms, enqueue 0.0866394 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154184 ms - Host latency: 0.195511 ms (end to end 0.280933 ms, enqueue 0.0876678 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154443 ms - Host latency: 0.196124 ms (end to end 0.279828 ms, enqueue 0.087207 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154407 ms - Host latency: 0.195975 ms (end to end 0.279025 ms, enqueue 0.0915863 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15463 ms - Host latency: 0.196457 ms (end to end 0.283231 ms, enqueue 0.0983185 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154645 ms - Host latency: 0.19642 ms (end to end 0.281491 ms, enqueue 0.0965912 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154315 ms - Host latency: 0.195926 ms (end to end 0.278796 ms, enqueue 0.0957306 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154788 ms - Host latency: 0.196399 ms (end to end 0.280359 ms, enqueue 0.0976349 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154471 ms - Host latency: 0.195972 ms (end to end 0.280994 ms, enqueue 0.0969971 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154398 ms - Host latency: 0.195999 ms (end to end 0.279837 ms, enqueue 0.0960175 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154807 ms - Host latency: 0.197144 ms (end to end 0.283206 ms, enqueue 0.085965 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154227 ms - Host latency: 0.196011 ms (end to end 0.277759 ms, enqueue 0.0821472 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15463 ms - Host latency: 0.19639 ms (end to end 0.281342 ms, enqueue 0.0822022 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155005 ms - Host latency: 0.196762 ms (end to end 0.283539 ms, enqueue 0.0939301 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154984 ms - Host latency: 0.197076 ms (end to end 0.262521 ms, enqueue 0.123431 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154041 ms - Host latency: 0.196005 ms (end to end 0.293118 ms, enqueue 0.123047 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157581 ms - Host latency: 0.203345 ms (end to end 0.254199 ms, enqueue 0.144943 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160001 ms - Host latency: 0.208377 ms (end to end 0.224194 ms, enqueue 0.156781 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15885 ms - Host latency: 0.207336 ms (end to end 0.221881 ms, enqueue 0.156848 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.162399 ms - Host latency: 0.207828 ms (end to end 0.221701 ms, enqueue 0.152441 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161838 ms - Host latency: 0.207077 ms (end to end 0.220056 ms, enqueue 0.152634 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160876 ms - Host latency: 0.206558 ms (end to end 0.218945 ms, enqueue 0.148856 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15452 ms - Host latency: 0.196454 ms (end to end 0.281396 ms, enqueue 0.105939 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155289 ms - Host latency: 0.198312 ms (end to end 0.287881 ms, enqueue 0.109949 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153992 ms - Host latency: 0.195517 ms (end to end 0.284375 ms, enqueue 0.106879 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153882 ms - Host latency: 0.195486 ms (end to end 0.286292 ms, enqueue 0.10748 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153961 ms - Host latency: 0.195731 ms (end to end 0.285196 ms, enqueue 0.106439 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154077 ms - Host latency: 0.195993 ms (end to end 0.28472 ms, enqueue 0.106732 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153973 ms - Host latency: 0.195871 ms (end to end 0.280151 ms, enqueue 0.0935455 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153525 ms - Host latency: 0.195221 ms (end to end 0.273541 ms, enqueue 0.0845032 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153949 ms - Host latency: 0.195618 ms (end to end 0.27562 ms, enqueue 0.0845306 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153439 ms - Host latency: 0.194986 ms (end to end 0.275272 ms, enqueue 0.0840607 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153574 ms - Host latency: 0.195001 ms (end to end 0.276608 ms, enqueue 0.0838592 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153357 ms - Host latency: 0.195026 ms (end to end 0.275449 ms, enqueue 0.0836761 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153616 ms - Host latency: 0.195145 ms (end to end 0.274173 ms, enqueue 0.0850769 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153577 ms - Host latency: 0.19501 ms (end to end 0.274701 ms, enqueue 0.0818481 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153989 ms - Host latency: 0.19585 ms (end to end 0.270926 ms, enqueue 0.0837616 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153799 ms - Host latency: 0.19559 ms (end to end 0.274734 ms, enqueue 0.0841492 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154327 ms - Host latency: 0.195978 ms (end to end 0.278671 ms, enqueue 0.0831909 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1543 ms - Host latency: 0.195996 ms (end to end 0.278796 ms, enqueue 0.086795 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154184 ms - Host latency: 0.19595 ms (end to end 0.277609 ms, enqueue 0.0826508 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154001 ms - Host latency: 0.195554 ms (end to end 0.272028 ms, enqueue 0.0838501 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15386 ms - Host latency: 0.195657 ms (end to end 0.278571 ms, enqueue 0.0838654 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154666 ms - Host latency: 0.196228 ms (end to end 0.278406 ms, enqueue 0.0839142 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.208856 ms - Host latency: 0.25451 ms (end to end 0.300504 ms, enqueue 0.184558 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.188907 ms - Host latency: 0.232507 ms (end to end 0.275754 ms, enqueue 0.162338 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154868 ms - Host latency: 0.196646 ms (end to end 0.281528 ms, enqueue 0.090683 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155048 ms - Host latency: 0.196829 ms (end to end 0.283786 ms, enqueue 0.0893982 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155533 ms - Host latency: 0.197537 ms (end to end 0.276547 ms, enqueue 0.118161 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159177 ms - Host latency: 0.201727 ms (end to end 0.270941 ms, enqueue 0.129663 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156015 ms - Host latency: 0.197034 ms (end to end 0.240186 ms, enqueue 0.111597 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1561 ms - Host latency: 0.19772 ms (end to end 0.287738 ms, enqueue 0.0926056 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155804 ms - Host latency: 0.197342 ms (end to end 0.282892 ms, enqueue 0.0943878 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155667 ms - Host latency: 0.197354 ms (end to end 0.280927 ms, enqueue 0.092865 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15563 ms - Host latency: 0.19733 ms (end to end 0.286328 ms, enqueue 0.0931549 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155334 ms - Host latency: 0.196777 ms (end to end 0.285159 ms, enqueue 0.093692 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155887 ms - Host latency: 0.197794 ms (end to end 0.287054 ms, enqueue 0.0929657 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155215 ms - Host latency: 0.197098 ms (end to end 0.284506 ms, enqueue 0.0932922 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155658 ms - Host latency: 0.197446 ms (end to end 0.284451 ms, enqueue 0.0909454 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155502 ms - Host latency: 0.197183 ms (end to end 0.284415 ms, enqueue 0.0869843 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155414 ms - Host latency: 0.197348 ms (end to end 0.286725 ms, enqueue 0.0977905 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155121 ms - Host latency: 0.196692 ms (end to end 0.282431 ms, enqueue 0.0865021 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.209637 ms - Host latency: 0.257761 ms (end to end 0.29332 ms, enqueue 0.20993 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.206332 ms - Host latency: 0.251254 ms (end to end 0.261487 ms, enqueue 0.233115 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155374 ms - Host latency: 0.196542 ms (end to end 0.272247 ms, enqueue 0.0799713 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15531 ms - Host latency: 0.19679 ms (end to end 0.282333 ms, enqueue 0.0780121 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155582 ms - Host latency: 0.197107 ms (end to end 0.282434 ms, enqueue 0.0785248 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155377 ms - Host latency: 0.196909 ms (end to end 0.281772 ms, enqueue 0.0776031 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15513 ms - Host latency: 0.196603 ms (end to end 0.281702 ms, enqueue 0.0778961 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155719 ms - Host latency: 0.197366 ms (end to end 0.281274 ms, enqueue 0.0789429 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155579 ms - Host latency: 0.197147 ms (end to end 0.281387 ms, enqueue 0.0779633 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155161 ms - Host latency: 0.196527 ms (end to end 0.280023 ms, enqueue 0.0781403 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15473 ms - Host latency: 0.195831 ms (end to end 0.27926 ms, enqueue 0.0781403 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155338 ms - Host latency: 0.19697 ms (end to end 0.279868 ms, enqueue 0.0785797 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154846 ms - Host latency: 0.196613 ms (end to end 0.275113 ms, enqueue 0.081308 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.191324 ms - Host latency: 0.236649 ms (end to end 0.300088 ms, enqueue 0.149496 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.162497 ms - Host latency: 0.205417 ms (end to end 0.234161 ms, enqueue 0.1539 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.166562 ms - Host latency: 0.212985 ms (end to end 0.222968 ms, enqueue 0.184195 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155621 ms - Host latency: 0.206552 ms (end to end 0.218201 ms, enqueue 0.165991 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.164075 ms - Host latency: 0.213904 ms (end to end 0.225436 ms, enqueue 0.171503 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157019 ms - Host latency: 0.206573 ms (end to end 0.22085 ms, enqueue 0.160004 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160345 ms - Host latency: 0.202338 ms (end to end 0.21492 ms, enqueue 0.138885 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159631 ms - Host latency: 0.202802 ms (end to end 0.215012 ms, enqueue 0.146793 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156577 ms - Host latency: 0.197839 ms (end to end 0.208441 ms, enqueue 0.132721 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156363 ms - Host latency: 0.198978 ms (end to end 0.211179 ms, enqueue 0.136185 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158084 ms - Host latency: 0.199301 ms (end to end 0.214676 ms, enqueue 0.134546 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155814 ms - Host latency: 0.197021 ms (end to end 0.23212 ms, enqueue 0.124106 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15466 ms - Host latency: 0.196451 ms (end to end 0.278604 ms, enqueue 0.101465 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155905 ms - Host latency: 0.197705 ms (end to end 0.277765 ms, enqueue 0.106567 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.163202 ms - Host latency: 0.206064 ms (end to end 0.275836 ms, enqueue 0.118597 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154959 ms - Host latency: 0.19682 ms (end to end 0.28143 ms, enqueue 0.0988831 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155008 ms - Host latency: 0.196808 ms (end to end 0.28775 ms, enqueue 0.101486 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155222 ms - Host latency: 0.196652 ms (end to end 0.28208 ms, enqueue 0.101614 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.196994 ms (end to end 0.283325 ms, enqueue 0.0951477 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155508 ms - Host latency: 0.197156 ms (end to end 0.282217 ms, enqueue 0.0848083 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155231 ms - Host latency: 0.197186 ms (end to end 0.283105 ms, enqueue 0.0839935 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155286 ms - Host latency: 0.197513 ms (end to end 0.280023 ms, enqueue 0.0833008 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154919 ms - Host latency: 0.196979 ms (end to end 0.27933 ms, enqueue 0.0836945 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155151 ms - Host latency: 0.19668 ms (end to end 0.282706 ms, enqueue 0.0838867 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155249 ms - Host latency: 0.197034 ms (end to end 0.281137 ms, enqueue 0.0851562 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154874 ms - Host latency: 0.196576 ms (end to end 0.279999 ms, enqueue 0.0947815 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.254068 ms - Host latency: 0.302652 ms (end to end 0.333612 ms, enqueue 0.248236 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.253525 ms - Host latency: 0.302911 ms (end to end 0.315466 ms, enqueue 0.280777 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.23165 ms - Host latency: 0.280304 ms (end to end 0.292133 ms, enqueue 0.259274 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.24036 ms - Host latency: 0.289676 ms (end to end 0.300623 ms, enqueue 0.266614 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.237689 ms - Host latency: 0.285071 ms (end to end 0.295605 ms, enqueue 0.264102 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.208231 ms - Host latency: 0.254422 ms (end to end 0.263208 ms, enqueue 0.231802 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153867 ms - Host latency: 0.199622 ms (end to end 0.209427 ms, enqueue 0.169772 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159103 ms - Host latency: 0.202249 ms (end to end 0.210117 ms, enqueue 0.179428 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157669 ms - Host latency: 0.205072 ms (end to end 0.216092 ms, enqueue 0.174731 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15647 ms - Host latency: 0.201245 ms (end to end 0.212994 ms, enqueue 0.166779 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160706 ms - Host latency: 0.202716 ms (end to end 0.233578 ms, enqueue 0.132422 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155225 ms - Host latency: 0.197272 ms (end to end 0.286996 ms, enqueue 0.107239 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15466 ms - Host latency: 0.19639 ms (end to end 0.289441 ms, enqueue 0.122195 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155597 ms - Host latency: 0.199295 ms (end to end 0.248166 ms, enqueue 0.131805 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156 ms - Host latency: 0.198868 ms (end to end 0.264731 ms, enqueue 0.126294 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15531 ms - Host latency: 0.197525 ms (end to end 0.288477 ms, enqueue 0.120517 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155396 ms - Host latency: 0.197552 ms (end to end 0.288751 ms, enqueue 0.120032 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155002 ms - Host latency: 0.197165 ms (end to end 0.288324 ms, enqueue 0.125708 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155731 ms - Host latency: 0.198169 ms (end to end 0.294168 ms, enqueue 0.125168 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155591 ms - Host latency: 0.197488 ms (end to end 0.289044 ms, enqueue 0.12489 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155734 ms - Host latency: 0.197714 ms (end to end 0.29108 ms, enqueue 0.125238 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155087 ms - Host latency: 0.197125 ms (end to end 0.289838 ms, enqueue 0.122739 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.18602 ms - Host latency: 0.231467 ms (end to end 0.31236 ms, enqueue 0.169208 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.289136 ms - Host latency: 0.339972 ms (end to end 0.350241 ms, enqueue 0.311771 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.227197 ms - Host latency: 0.275122 ms (end to end 0.287274 ms, enqueue 0.255896 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.206073 ms - Host latency: 0.251831 ms (end to end 0.26311 ms, enqueue 0.235901 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.206226 ms - Host latency: 0.252496 ms (end to end 0.263104 ms, enqueue 0.234631 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.188824 ms - Host latency: 0.233881 ms (end to end 0.244788 ms, enqueue 0.21814 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.179535 ms - Host latency: 0.224048 ms (end to end 0.2328 ms, enqueue 0.207959 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.176013 ms - Host latency: 0.220746 ms (end to end 0.235645 ms, enqueue 0.170972 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158319 ms - Host latency: 0.202795 ms (end to end 0.221326 ms, enqueue 0.143762 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155505 ms - Host latency: 0.200562 ms (end to end 0.211041 ms, enqueue 0.170984 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154816 ms - Host latency: 0.204657 ms (end to end 0.215582 ms, enqueue 0.167011 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159387 ms - Host latency: 0.209991 ms (end to end 0.223114 ms, enqueue 0.17193 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155182 ms - Host latency: 0.204877 ms (end to end 0.214111 ms, enqueue 0.167474 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157727 ms - Host latency: 0.205762 ms (end to end 0.218481 ms, enqueue 0.154895 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155206 ms - Host latency: 0.196936 ms (end to end 0.282611 ms, enqueue 0.115833 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155652 ms - Host latency: 0.197504 ms (end to end 0.288538 ms, enqueue 0.113818 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155188 ms - Host latency: 0.196851 ms (end to end 0.289764 ms, enqueue 0.112469 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155414 ms - Host latency: 0.197321 ms (end to end 0.290637 ms, enqueue 0.111121 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154944 ms - Host latency: 0.196515 ms (end to end 0.289337 ms, enqueue 0.112482 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1547 ms - Host latency: 0.196289 ms (end to end 0.287378 ms, enqueue 0.111438 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155457 ms - Host latency: 0.197113 ms (end to end 0.283545 ms, enqueue 0.0912964 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.163507 ms - Host latency: 0.207062 ms (end to end 0.226892 ms, enqueue 0.146039 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.163879 ms - Host latency: 0.206024 ms (end to end 0.219702 ms, enqueue 0.148712 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157623 ms - Host latency: 0.203479 ms (end to end 0.248395 ms, enqueue 0.126581 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155536 ms - Host latency: 0.197528 ms (end to end 0.291119 ms, enqueue 0.10741 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155194 ms - Host latency: 0.197107 ms (end to end 0.282892 ms, enqueue 0.111975 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155353 ms - Host latency: 0.197064 ms (end to end 0.287018 ms, enqueue 0.0892761 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155267 ms - Host latency: 0.197015 ms (end to end 0.286151 ms, enqueue 0.09021 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155573 ms - Host latency: 0.197467 ms (end to end 0.282477 ms, enqueue 0.101727 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155615 ms - Host latency: 0.197455 ms (end to end 0.286993 ms, enqueue 0.109113 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155579 ms - Host latency: 0.197864 ms (end to end 0.290521 ms, enqueue 0.109772 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155432 ms - Host latency: 0.197284 ms (end to end 0.287091 ms, enqueue 0.10614 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155621 ms - Host latency: 0.197589 ms (end to end 0.290985 ms, enqueue 0.111536 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155206 ms - Host latency: 0.197174 ms (end to end 0.291748 ms, enqueue 0.119684 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15531 ms - Host latency: 0.197168 ms (end to end 0.288831 ms, enqueue 0.117419 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155341 ms - Host latency: 0.197211 ms (end to end 0.289124 ms, enqueue 0.117969 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155389 ms - Host latency: 0.197443 ms (end to end 0.29256 ms, enqueue 0.118805 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154968 ms - Host latency: 0.19704 ms (end to end 0.290552 ms, enqueue 0.118237 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155396 ms - Host latency: 0.197699 ms (end to end 0.290643 ms, enqueue 0.116022 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161969 ms - Host latency: 0.208527 ms (end to end 0.231445 ms, enqueue 0.152271 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.168518 ms - Host latency: 0.211304 ms (end to end 0.224249 ms, enqueue 0.158398 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156238 ms - Host latency: 0.198578 ms (end to end 0.222797 ms, enqueue 0.132758 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155499 ms - Host latency: 0.19707 ms (end to end 0.233667 ms, enqueue 0.132599 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156085 ms - Host latency: 0.197333 ms (end to end 0.221667 ms, enqueue 0.132538 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155768 ms - Host latency: 0.19801 ms (end to end 0.22533 ms, enqueue 0.131158 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.172388 ms - Host latency: 0.216821 ms (end to end 0.259308 ms, enqueue 0.153442 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.162701 ms - Host latency: 0.204102 ms (end to end 0.216107 ms, enqueue 0.143652 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161157 ms - Host latency: 0.205823 ms (end to end 0.218549 ms, enqueue 0.148254 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.163361 ms - Host latency: 0.205438 ms (end to end 0.218274 ms, enqueue 0.147675 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.164496 ms - Host latency: 0.208069 ms (end to end 0.221228 ms, enqueue 0.151379 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160168 ms - Host latency: 0.203607 ms (end to end 0.23609 ms, enqueue 0.128265 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.180237 ms - Host latency: 0.225677 ms (end to end 0.278345 ms, enqueue 0.149115 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155255 ms - Host latency: 0.197076 ms (end to end 0.288141 ms, enqueue 0.104181 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154773 ms - Host latency: 0.196722 ms (end to end 0.283801 ms, enqueue 0.103217 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155353 ms - Host latency: 0.197516 ms (end to end 0.2836 ms, enqueue 0.106 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154907 ms - Host latency: 0.196527 ms (end to end 0.28653 ms, enqueue 0.107037 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154962 ms - Host latency: 0.196808 ms (end to end 0.285187 ms, enqueue 0.105518 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155261 ms - Host latency: 0.197363 ms (end to end 0.275403 ms, enqueue 0.0922974 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154584 ms - Host latency: 0.196008 ms (end to end 0.278131 ms, enqueue 0.0917786 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15564 ms - Host latency: 0.19754 ms (end to end 0.280725 ms, enqueue 0.0921265 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15423 ms - Host latency: 0.195978 ms (end to end 0.277679 ms, enqueue 0.089917 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155511 ms - Host latency: 0.197064 ms (end to end 0.282416 ms, enqueue 0.0874512 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15556 ms - Host latency: 0.197058 ms (end to end 0.278931 ms, enqueue 0.0871338 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155176 ms - Host latency: 0.196692 ms (end to end 0.283075 ms, enqueue 0.0819458 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155823 ms - Host latency: 0.197217 ms (end to end 0.283051 ms, enqueue 0.079895 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155054 ms - Host latency: 0.196558 ms (end to end 0.280518 ms, enqueue 0.0815308 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155334 ms - Host latency: 0.197009 ms (end to end 0.282513 ms, enqueue 0.0801025 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15556 ms - Host latency: 0.197119 ms (end to end 0.282556 ms, enqueue 0.0802185 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155707 ms - Host latency: 0.197162 ms (end to end 0.282886 ms, enqueue 0.0800354 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155737 ms - Host latency: 0.197589 ms (end to end 0.282629 ms, enqueue 0.0789612 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155298 ms - Host latency: 0.196619 ms (end to end 0.280859 ms, enqueue 0.0796692 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155194 ms - Host latency: 0.196741 ms (end to end 0.281751 ms, enqueue 0.0787903 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154926 ms - Host latency: 0.196613 ms (end to end 0.279602 ms, enqueue 0.0794983 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155463 ms - Host latency: 0.196869 ms (end to end 0.280865 ms, enqueue 0.0800964 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15484 ms - Host latency: 0.196387 ms (end to end 0.278534 ms, enqueue 0.0870605 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155463 ms - Host latency: 0.19754 ms (end to end 0.281732 ms, enqueue 0.0838074 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.213257 ms - Host latency: 0.260406 ms (end to end 0.29671 ms, enqueue 0.209845 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.207446 ms - Host latency: 0.252258 ms (end to end 0.262006 ms, enqueue 0.235175 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.208319 ms - Host latency: 0.254608 ms (end to end 0.265839 ms, enqueue 0.234399 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.200934 ms - Host latency: 0.245905 ms (end to end 0.25838 ms, enqueue 0.23194 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.200793 ms - Host latency: 0.24585 ms (end to end 0.25708 ms, enqueue 0.230682 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.201837 ms - Host latency: 0.2474 ms (end to end 0.260724 ms, enqueue 0.231915 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.217426 ms - Host latency: 0.264239 ms (end to end 0.274646 ms, enqueue 0.245129 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.213892 ms - Host latency: 0.26297 ms (end to end 0.272589 ms, enqueue 0.239734 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.252972 ms - Host latency: 0.304492 ms (end to end 0.312537 ms, enqueue 0.274554 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.252747 ms - Host latency: 0.304816 ms (end to end 0.313245 ms, enqueue 0.275305 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.200098 ms - Host latency: 0.245746 ms (end to end 0.255103 ms, enqueue 0.222241 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157983 ms - Host latency: 0.199603 ms (end to end 0.20899 ms, enqueue 0.181592 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.16051 ms - Host latency: 0.202386 ms (end to end 0.210443 ms, enqueue 0.185284 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160577 ms - Host latency: 0.203625 ms (end to end 0.211163 ms, enqueue 0.185876 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157074 ms - Host latency: 0.198755 ms (end to end 0.207825 ms, enqueue 0.182361 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157867 ms - Host latency: 0.20014 ms (end to end 0.21297 ms, enqueue 0.138171 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156067 ms - Host latency: 0.197345 ms (end to end 0.210437 ms, enqueue 0.134167 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156238 ms - Host latency: 0.197528 ms (end to end 0.217712 ms, enqueue 0.135278 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156067 ms - Host latency: 0.197357 ms (end to end 0.21474 ms, enqueue 0.133807 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155615 ms - Host latency: 0.196906 ms (end to end 0.215082 ms, enqueue 0.134265 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15553 ms - Host latency: 0.196771 ms (end to end 0.217981 ms, enqueue 0.133588 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156415 ms - Host latency: 0.197986 ms (end to end 0.247943 ms, enqueue 0.118445 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155084 ms - Host latency: 0.197217 ms (end to end 0.284546 ms, enqueue 0.102496 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154767 ms - Host latency: 0.19776 ms (end to end 0.285242 ms, enqueue 0.111859 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.195227 ms - Host latency: 0.241138 ms (end to end 0.281274 ms, enqueue 0.182983 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.228094 ms - Host latency: 0.275281 ms (end to end 0.285834 ms, enqueue 0.253998 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.214685 ms - Host latency: 0.260571 ms (end to end 0.271289 ms, enqueue 0.243091 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154022 ms - Host latency: 0.202576 ms (end to end 0.212177 ms, enqueue 0.169397 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154645 ms - Host latency: 0.203326 ms (end to end 0.21297 ms, enqueue 0.172125 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154181 ms - Host latency: 0.200104 ms (end to end 0.209735 ms, enqueue 0.170764 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156995 ms - Host latency: 0.203607 ms (end to end 0.21369 ms, enqueue 0.172601 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155365 ms - Host latency: 0.208533 ms (end to end 0.220557 ms, enqueue 0.164709 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155902 ms - Host latency: 0.206976 ms (end to end 0.220544 ms, enqueue 0.166016 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155713 ms - Host latency: 0.207715 ms (end to end 0.218909 ms, enqueue 0.16134 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15614 ms - Host latency: 0.209454 ms (end to end 0.221405 ms, enqueue 0.163251 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.162415 ms - Host latency: 0.208771 ms (end to end 0.222278 ms, enqueue 0.150171 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.245129 ms - Host latency: 0.294415 ms (end to end 0.323871 ms, enqueue 0.249774 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.248322 ms - Host latency: 0.296313 ms (end to end 0.305371 ms, enqueue 0.272308 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.201904 ms - Host latency: 0.246973 ms (end to end 0.258728 ms, enqueue 0.23158 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.194006 ms - Host latency: 0.23938 ms (end to end 0.250226 ms, enqueue 0.223169 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.175916 ms - Host latency: 0.219958 ms (end to end 0.228687 ms, enqueue 0.204224 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.176331 ms - Host latency: 0.220178 ms (end to end 0.228522 ms, enqueue 0.20423 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.170782 ms - Host latency: 0.2146 ms (end to end 0.233209 ms, enqueue 0.174438 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155945 ms - Host latency: 0.19776 ms (end to end 0.255469 ms, enqueue 0.128461 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157959 ms - Host latency: 0.200934 ms (end to end 0.226398 ms, enqueue 0.14491 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160309 ms - Host latency: 0.201746 ms (end to end 0.213049 ms, enqueue 0.141638 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159064 ms - Host latency: 0.20213 ms (end to end 0.213074 ms, enqueue 0.142682 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.162573 ms - Host latency: 0.20567 ms (end to end 0.218164 ms, enqueue 0.145428 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.162518 ms - Host latency: 0.205774 ms (end to end 0.216736 ms, enqueue 0.145026 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.244135 ms - Host latency: 0.293591 ms (end to end 0.313501 ms, enqueue 0.251056 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.25285 ms - Host latency: 0.301886 ms (end to end 0.313153 ms, enqueue 0.278058 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.214514 ms - Host latency: 0.260065 ms (end to end 0.269086 ms, enqueue 0.241309 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.180835 ms - Host latency: 0.22926 ms (end to end 0.237421 ms, enqueue 0.198755 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157147 ms - Host latency: 0.208386 ms (end to end 0.22193 ms, enqueue 0.166724 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156244 ms - Host latency: 0.207019 ms (end to end 0.219714 ms, enqueue 0.164166 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154614 ms - Host latency: 0.206049 ms (end to end 0.216193 ms, enqueue 0.166742 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156006 ms - Host latency: 0.206378 ms (end to end 0.216998 ms, enqueue 0.162921 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157825 ms - Host latency: 0.204492 ms (end to end 0.228662 ms, enqueue 0.147345 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155414 ms - Host latency: 0.197174 ms (end to end 0.278137 ms, enqueue 0.103278 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155103 ms - Host latency: 0.19696 ms (end to end 0.286133 ms, enqueue 0.105798 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155396 ms - Host latency: 0.196826 ms (end to end 0.288397 ms, enqueue 0.103601 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155914 ms - Host latency: 0.198175 ms (end to end 0.285431 ms, enqueue 0.102417 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156091 ms - Host latency: 0.19801 ms (end to end 0.28584 ms, enqueue 0.100476 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155878 ms - Host latency: 0.198163 ms (end to end 0.286084 ms, enqueue 0.100458 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155914 ms - Host latency: 0.198059 ms (end to end 0.283484 ms, enqueue 0.101379 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155884 ms - Host latency: 0.197388 ms (end to end 0.285956 ms, enqueue 0.100592 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155682 ms - Host latency: 0.19751 ms (end to end 0.285278 ms, enqueue 0.0989136 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155261 ms - Host latency: 0.197522 ms (end to end 0.286237 ms, enqueue 0.0988953 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.189362 ms - Host latency: 0.235516 ms (end to end 0.29635 ms, enqueue 0.157336 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.183484 ms - Host latency: 0.226776 ms (end to end 0.273444 ms, enqueue 0.147772 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155792 ms - Host latency: 0.197485 ms (end to end 0.286243 ms, enqueue 0.078009 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155579 ms - Host latency: 0.19715 ms (end to end 0.287415 ms, enqueue 0.0778809 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156091 ms - Host latency: 0.198401 ms (end to end 0.286047 ms, enqueue 0.0787598 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155231 ms - Host latency: 0.196887 ms (end to end 0.284363 ms, enqueue 0.0785339 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15495 ms - Host latency: 0.196478 ms (end to end 0.282019 ms, enqueue 0.078949 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155701 ms - Host latency: 0.197717 ms (end to end 0.286401 ms, enqueue 0.0780518 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155328 ms - Host latency: 0.197321 ms (end to end 0.283429 ms, enqueue 0.0783691 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159448 ms - Host latency: 0.202515 ms (end to end 0.279529 ms, enqueue 0.0921448 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159991 ms - Host latency: 0.210931 ms (end to end 0.22514 ms, enqueue 0.159283 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161945 ms - Host latency: 0.212115 ms (end to end 0.226624 ms, enqueue 0.164172 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161951 ms - Host latency: 0.21026 ms (end to end 0.225555 ms, enqueue 0.157098 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.170874 ms - Host latency: 0.216345 ms (end to end 0.227692 ms, enqueue 0.1888 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.178033 ms - Host latency: 0.224512 ms (end to end 0.235413 ms, enqueue 0.19762 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154633 ms - Host latency: 0.19613 ms (end to end 0.269501 ms, enqueue 0.100079 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155609 ms - Host latency: 0.197406 ms (end to end 0.283899 ms, enqueue 0.0998169 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155963 ms - Host latency: 0.197723 ms (end to end 0.285193 ms, enqueue 0.0999268 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155603 ms - Host latency: 0.197369 ms (end to end 0.283667 ms, enqueue 0.101001 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155353 ms - Host latency: 0.196979 ms (end to end 0.284497 ms, enqueue 0.11272 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155524 ms - Host latency: 0.197504 ms (end to end 0.289716 ms, enqueue 0.117889 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155103 ms - Host latency: 0.197693 ms (end to end 0.291504 ms, enqueue 0.116687 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155713 ms - Host latency: 0.197748 ms (end to end 0.2883 ms, enqueue 0.117383 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155066 ms - Host latency: 0.197156 ms (end to end 0.287854 ms, enqueue 0.11601 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155499 ms - Host latency: 0.198059 ms (end to end 0.290887 ms, enqueue 0.117072 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155017 ms - Host latency: 0.196503 ms (end to end 0.286761 ms, enqueue 0.106116 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155353 ms - Host latency: 0.198071 ms (end to end 0.280853 ms, enqueue 0.0922546 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154419 ms - Host latency: 0.195667 ms (end to end 0.277643 ms, enqueue 0.0920044 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155048 ms - Host latency: 0.197015 ms (end to end 0.279175 ms, enqueue 0.0911194 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155048 ms - Host latency: 0.196698 ms (end to end 0.28017 ms, enqueue 0.0912903 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155353 ms - Host latency: 0.196893 ms (end to end 0.279266 ms, enqueue 0.0975525 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15451 ms - Host latency: 0.196259 ms (end to end 0.278021 ms, enqueue 0.0912842 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155481 ms - Host latency: 0.197784 ms (end to end 0.280713 ms, enqueue 0.0817383 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155518 ms - Host latency: 0.197681 ms (end to end 0.284485 ms, enqueue 0.0788269 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155652 ms - Host latency: 0.197437 ms (end to end 0.283606 ms, enqueue 0.0786194 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155658 ms - Host latency: 0.197406 ms (end to end 0.283374 ms, enqueue 0.0784729 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155347 ms - Host latency: 0.197357 ms (end to end 0.283478 ms, enqueue 0.0787903 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155731 ms - Host latency: 0.197424 ms (end to end 0.284131 ms, enqueue 0.0787964 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155719 ms - Host latency: 0.197559 ms (end to end 0.282715 ms, enqueue 0.0788879 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155591 ms - Host latency: 0.197296 ms (end to end 0.283466 ms, enqueue 0.0781433 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15592 ms - Host latency: 0.197986 ms (end to end 0.282745 ms, enqueue 0.0784424 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155707 ms - Host latency: 0.197742 ms (end to end 0.283575 ms, enqueue 0.077771 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155621 ms - Host latency: 0.197247 ms (end to end 0.282776 ms, enqueue 0.0781738 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155359 ms - Host latency: 0.19704 ms (end to end 0.284357 ms, enqueue 0.0788269 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155579 ms - Host latency: 0.197607 ms (end to end 0.283563 ms, enqueue 0.0780029 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155078 ms - Host latency: 0.196619 ms (end to end 0.286792 ms, enqueue 0.0799622 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155756 ms - Host latency: 0.198212 ms (end to end 0.273218 ms, enqueue 0.0813782 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155585 ms - Host latency: 0.197009 ms (end to end 0.279883 ms, enqueue 0.0787781 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155389 ms - Host latency: 0.196808 ms (end to end 0.28316 ms, enqueue 0.0799866 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15589 ms - Host latency: 0.197333 ms (end to end 0.284076 ms, enqueue 0.0809753 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155664 ms - Host latency: 0.198114 ms (end to end 0.283752 ms, enqueue 0.079834 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15542 ms - Host latency: 0.196783 ms (end to end 0.282404 ms, enqueue 0.0800598 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155585 ms - Host latency: 0.197101 ms (end to end 0.282892 ms, enqueue 0.0798584 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155432 ms - Host latency: 0.196765 ms (end to end 0.282654 ms, enqueue 0.0796509 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155463 ms - Host latency: 0.196918 ms (end to end 0.282385 ms, enqueue 0.0790039 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155444 ms - Host latency: 0.197168 ms (end to end 0.282178 ms, enqueue 0.0802063 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155725 ms - Host latency: 0.197345 ms (end to end 0.282513 ms, enqueue 0.0807434 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154974 ms - Host latency: 0.19679 ms (end to end 0.277765 ms, enqueue 0.0832459 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15484 ms - Host latency: 0.196252 ms (end to end 0.278333 ms, enqueue 0.08302 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.196552 ms - Host latency: 0.242047 ms (end to end 0.2849 ms, enqueue 0.1854 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.200531 ms - Host latency: 0.248505 ms (end to end 0.270087 ms, enqueue 0.200592 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.212628 ms - Host latency: 0.258673 ms (end to end 0.26875 ms, enqueue 0.239856 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.202124 ms - Host latency: 0.247144 ms (end to end 0.260516 ms, enqueue 0.233923 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.214398 ms - Host latency: 0.261127 ms (end to end 0.27038 ms, enqueue 0.241595 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.216748 ms - Host latency: 0.263165 ms (end to end 0.273969 ms, enqueue 0.244275 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1896 ms - Host latency: 0.236707 ms (end to end 0.248645 ms, enqueue 0.205383 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.162323 ms - Host latency: 0.208112 ms (end to end 0.224213 ms, enqueue 0.152734 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.165234 ms - Host latency: 0.210443 ms (end to end 0.224835 ms, enqueue 0.15661 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160107 ms - Host latency: 0.202124 ms (end to end 0.239722 ms, enqueue 0.135266 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155194 ms - Host latency: 0.197064 ms (end to end 0.288641 ms, enqueue 0.12525 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155688 ms - Host latency: 0.197467 ms (end to end 0.26546 ms, enqueue 0.134589 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156049 ms - Host latency: 0.200671 ms (end to end 0.24549 ms, enqueue 0.147803 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154712 ms - Host latency: 0.202051 ms (end to end 0.210529 ms, enqueue 0.168079 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160645 ms - Host latency: 0.211163 ms (end to end 0.224072 ms, enqueue 0.160297 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160114 ms - Host latency: 0.209906 ms (end to end 0.223297 ms, enqueue 0.159454 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160065 ms - Host latency: 0.211017 ms (end to end 0.225977 ms, enqueue 0.157983 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15882 ms - Host latency: 0.205505 ms (end to end 0.229974 ms, enqueue 0.144312 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154797 ms - Host latency: 0.196326 ms (end to end 0.28714 ms, enqueue 0.111951 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155066 ms - Host latency: 0.197076 ms (end to end 0.283514 ms, enqueue 0.121313 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155066 ms - Host latency: 0.197711 ms (end to end 0.281036 ms, enqueue 0.121027 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15592 ms - Host latency: 0.198279 ms (end to end 0.293042 ms, enqueue 0.119604 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154755 ms - Host latency: 0.196906 ms (end to end 0.29425 ms, enqueue 0.121741 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155475 ms - Host latency: 0.197217 ms (end to end 0.292865 ms, enqueue 0.1229 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154944 ms - Host latency: 0.196423 ms (end to end 0.278802 ms, enqueue 0.093457 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.201215 ms - Host latency: 0.246454 ms (end to end 0.298267 ms, enqueue 0.172302 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.241882 ms - Host latency: 0.287885 ms (end to end 0.299896 ms, enqueue 0.270734 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.238599 ms - Host latency: 0.284735 ms (end to end 0.296478 ms, enqueue 0.266772 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.217572 ms - Host latency: 0.262909 ms (end to end 0.273621 ms, enqueue 0.244482 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.209644 ms - Host latency: 0.257257 ms (end to end 0.267444 ms, enqueue 0.236597 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.176263 ms - Host latency: 0.222736 ms (end to end 0.23067 ms, enqueue 0.203009 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.190424 ms - Host latency: 0.237701 ms (end to end 0.248084 ms, enqueue 0.21908 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.213751 ms - Host latency: 0.262677 ms (end to end 0.273633 ms, enqueue 0.241016 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.200323 ms - Host latency: 0.248907 ms (end to end 0.260791 ms, enqueue 0.21535 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154749 ms - Host latency: 0.196124 ms (end to end 0.276819 ms, enqueue 0.0845154 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15509 ms - Host latency: 0.196875 ms (end to end 0.277124 ms, enqueue 0.0944702 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155316 ms - Host latency: 0.19707 ms (end to end 0.283716 ms, enqueue 0.0918152 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155133 ms - Host latency: 0.196716 ms (end to end 0.278033 ms, enqueue 0.0993774 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155188 ms - Host latency: 0.196716 ms (end to end 0.273901 ms, enqueue 0.0919739 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.224829 ms - Host latency: 0.272644 ms (end to end 0.30675 ms, enqueue 0.224335 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.221124 ms - Host latency: 0.267407 ms (end to end 0.277289 ms, enqueue 0.247479 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.181891 ms - Host latency: 0.227283 ms (end to end 0.238055 ms, enqueue 0.211444 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.172668 ms - Host latency: 0.217218 ms (end to end 0.226227 ms, enqueue 0.20144 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.178888 ms - Host latency: 0.22359 ms (end to end 0.232886 ms, enqueue 0.207806 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.191968 ms - Host latency: 0.236938 ms (end to end 0.245813 ms, enqueue 0.212146 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155444 ms - Host latency: 0.197449 ms (end to end 0.267993 ms, enqueue 0.107965 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155908 ms - Host latency: 0.198224 ms (end to end 0.278394 ms, enqueue 0.118506 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155212 ms - Host latency: 0.197119 ms (end to end 0.293103 ms, enqueue 0.112769 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155188 ms - Host latency: 0.19718 ms (end to end 0.293274 ms, enqueue 0.112909 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155298 ms - Host latency: 0.196899 ms (end to end 0.293286 ms, enqueue 0.112683 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154529 ms - Host latency: 0.195996 ms (end to end 0.28963 ms, enqueue 0.0879211 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155255 ms - Host latency: 0.197424 ms (end to end 0.290796 ms, enqueue 0.0799988 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154895 ms - Host latency: 0.196423 ms (end to end 0.28288 ms, enqueue 0.10946 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155664 ms - Host latency: 0.197803 ms (end to end 0.287048 ms, enqueue 0.126086 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155005 ms - Host latency: 0.196686 ms (end to end 0.290637 ms, enqueue 0.123877 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155243 ms - Host latency: 0.197131 ms (end to end 0.29425 ms, enqueue 0.126666 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155737 ms - Host latency: 0.198328 ms (end to end 0.29682 ms, enqueue 0.124323 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15509 ms - Host latency: 0.196985 ms (end to end 0.29483 ms, enqueue 0.124695 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155505 ms - Host latency: 0.197687 ms (end to end 0.293311 ms, enqueue 0.1151 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155695 ms - Host latency: 0.197699 ms (end to end 0.292578 ms, enqueue 0.110736 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155511 ms - Host latency: 0.197888 ms (end to end 0.242133 ms, enqueue 0.163849 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154022 ms - Host latency: 0.195935 ms (end to end 0.203522 ms, enqueue 0.173035 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155963 ms - Host latency: 0.200604 ms (end to end 0.210394 ms, enqueue 0.175183 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.163031 ms - Host latency: 0.207922 ms (end to end 0.216766 ms, enqueue 0.183276 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.182715 ms - Host latency: 0.227063 ms (end to end 0.235443 ms, enqueue 0.209021 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.179401 ms - Host latency: 0.224292 ms (end to end 0.232178 ms, enqueue 0.205536 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.178589 ms - Host latency: 0.223334 ms (end to end 0.231409 ms, enqueue 0.204626 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.177905 ms - Host latency: 0.223059 ms (end to end 0.231915 ms, enqueue 0.192578 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159863 ms - Host latency: 0.201184 ms (end to end 0.212488 ms, enqueue 0.139648 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159766 ms - Host latency: 0.201477 ms (end to end 0.212097 ms, enqueue 0.139478 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157043 ms - Host latency: 0.201331 ms (end to end 0.21593 ms, enqueue 0.14126 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160522 ms - Host latency: 0.203015 ms (end to end 0.213159 ms, enqueue 0.143079 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161243 ms - Host latency: 0.202783 ms (end to end 0.213025 ms, enqueue 0.141443 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158606 ms - Host latency: 0.200464 ms (end to end 0.236108 ms, enqueue 0.12439 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155835 ms - Host latency: 0.198022 ms (end to end 0.288208 ms, enqueue 0.105408 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155481 ms - Host latency: 0.197375 ms (end to end 0.285583 ms, enqueue 0.104224 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155701 ms - Host latency: 0.198083 ms (end to end 0.288452 ms, enqueue 0.105176 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155225 ms - Host latency: 0.197168 ms (end to end 0.286145 ms, enqueue 0.105066 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156079 ms - Host latency: 0.197803 ms (end to end 0.28761 ms, enqueue 0.105737 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155383 ms - Host latency: 0.197559 ms (end to end 0.288159 ms, enqueue 0.107605 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.193152 ms - Host latency: 0.238281 ms (end to end 0.302515 ms, enqueue 0.160168 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.266577 ms - Host latency: 0.316064 ms (end to end 0.32793 ms, enqueue 0.292895 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.236401 ms - Host latency: 0.283887 ms (end to end 0.295691 ms, enqueue 0.262683 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.213586 ms - Host latency: 0.259998 ms (end to end 0.270996 ms, enqueue 0.240735 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.191956 ms - Host latency: 0.238159 ms (end to end 0.247363 ms, enqueue 0.217969 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.190173 ms - Host latency: 0.236951 ms (end to end 0.246082 ms, enqueue 0.216199 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.187146 ms - Host latency: 0.232495 ms (end to end 0.240564 ms, enqueue 0.213184 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.164575 ms - Host latency: 0.208704 ms (end to end 0.218518 ms, enqueue 0.156067 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161157 ms - Host latency: 0.203137 ms (end to end 0.212415 ms, enqueue 0.140857 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159534 ms - Host latency: 0.201917 ms (end to end 0.214551 ms, enqueue 0.137769 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156104 ms - Host latency: 0.197363 ms (end to end 0.242615 ms, enqueue 0.128699 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154968 ms - Host latency: 0.19635 ms (end to end 0.264929 ms, enqueue 0.134631 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160217 ms - Host latency: 0.201709 ms (end to end 0.213049 ms, enqueue 0.140784 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157605 ms - Host latency: 0.199609 ms (end to end 0.240576 ms, enqueue 0.120532 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15564 ms - Host latency: 0.197644 ms (end to end 0.288867 ms, enqueue 0.105444 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15575 ms - Host latency: 0.197656 ms (end to end 0.287415 ms, enqueue 0.101807 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155652 ms - Host latency: 0.198254 ms (end to end 0.287964 ms, enqueue 0.102991 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15625 ms - Host latency: 0.198462 ms (end to end 0.288062 ms, enqueue 0.101501 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156055 ms - Host latency: 0.198535 ms (end to end 0.286951 ms, enqueue 0.101086 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155957 ms - Host latency: 0.19895 ms (end to end 0.291357 ms, enqueue 0.100635 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154907 ms - Host latency: 0.196497 ms (end to end 0.288257 ms, enqueue 0.0860107 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155249 ms - Host latency: 0.197156 ms (end to end 0.289111 ms, enqueue 0.0869629 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155029 ms - Host latency: 0.196741 ms (end to end 0.28905 ms, enqueue 0.0863403 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15509 ms - Host latency: 0.196606 ms (end to end 0.289807 ms, enqueue 0.0861084 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155176 ms - Host latency: 0.197034 ms (end to end 0.289099 ms, enqueue 0.0872314 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155176 ms - Host latency: 0.196631 ms (end to end 0.29071 ms, enqueue 0.0860352 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1552 ms - Host latency: 0.196912 ms (end to end 0.2896 ms, enqueue 0.086853 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15481 ms - Host latency: 0.196216 ms (end to end 0.28905 ms, enqueue 0.0850952 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155176 ms - Host latency: 0.196802 ms (end to end 0.289075 ms, enqueue 0.0854492 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15509 ms - Host latency: 0.196838 ms (end to end 0.289648 ms, enqueue 0.0887573 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155359 ms - Host latency: 0.197681 ms (end to end 0.283081 ms, enqueue 0.0823242 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155261 ms - Host latency: 0.197131 ms (end to end 0.280652 ms, enqueue 0.0866943 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1552 ms - Host latency: 0.197046 ms (end to end 0.286023 ms, enqueue 0.0825684 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155554 ms - Host latency: 0.197424 ms (end to end 0.287134 ms, enqueue 0.0824585 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1552 ms - Host latency: 0.19696 ms (end to end 0.28645 ms, enqueue 0.0849243 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155798 ms - Host latency: 0.197925 ms (end to end 0.283643 ms, enqueue 0.0855347 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155444 ms - Host latency: 0.196948 ms (end to end 0.283948 ms, enqueue 0.0862915 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155872 ms - Host latency: 0.197656 ms (end to end 0.28208 ms, enqueue 0.0839844 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155652 ms - Host latency: 0.197681 ms (end to end 0.282837 ms, enqueue 0.0820801 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157935 ms - Host latency: 0.202979 ms (end to end 0.271033 ms, enqueue 0.10647 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.18938 ms - Host latency: 0.235486 ms (end to end 0.249011 ms, enqueue 0.193494 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.162354 ms - Host latency: 0.205176 ms (end to end 0.217017 ms, enqueue 0.146228 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.16344 ms - Host latency: 0.20553 ms (end to end 0.215918 ms, enqueue 0.144507 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.162598 ms - Host latency: 0.204456 ms (end to end 0.215723 ms, enqueue 0.148621 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160144 ms - Host latency: 0.202429 ms (end to end 0.240173 ms, enqueue 0.129004 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155103 ms - Host latency: 0.196985 ms (end to end 0.290173 ms, enqueue 0.110913 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155823 ms - Host latency: 0.198425 ms (end to end 0.293542 ms, enqueue 0.120203 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1552 ms - Host latency: 0.197021 ms (end to end 0.286462 ms, enqueue 0.116846 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155212 ms - Host latency: 0.196777 ms (end to end 0.288538 ms, enqueue 0.117224 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155151 ms - Host latency: 0.197095 ms (end to end 0.288147 ms, enqueue 0.113245 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15498 ms - Host latency: 0.196533 ms (end to end 0.285645 ms, enqueue 0.108594 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157617 ms - Host latency: 0.199829 ms (end to end 0.268323 ms, enqueue 0.0993286 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155286 ms - Host latency: 0.196887 ms (end to end 0.282861 ms, enqueue 0.0868896 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155408 ms - Host latency: 0.196924 ms (end to end 0.282275 ms, enqueue 0.0873169 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155664 ms - Host latency: 0.19762 ms (end to end 0.281751 ms, enqueue 0.0860474 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155603 ms - Host latency: 0.197266 ms (end to end 0.282935 ms, enqueue 0.0855225 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15553 ms - Host latency: 0.197412 ms (end to end 0.284253 ms, enqueue 0.0848511 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.173767 ms - Host latency: 0.219006 ms (end to end 0.232275 ms, enqueue 0.206506 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.162024 ms - Host latency: 0.20542 ms (end to end 0.213416 ms, enqueue 0.191089 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.163757 ms - Host latency: 0.207349 ms (end to end 0.216089 ms, enqueue 0.193408 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158875 ms - Host latency: 0.203723 ms (end to end 0.21344 ms, enqueue 0.186572 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161853 ms - Host latency: 0.206836 ms (end to end 0.221094 ms, enqueue 0.152063 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.163708 ms - Host latency: 0.207458 ms (end to end 0.221411 ms, enqueue 0.150696 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161597 ms - Host latency: 0.204956 ms (end to end 0.230957 ms, enqueue 0.140491 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15531 ms - Host latency: 0.197571 ms (end to end 0.290442 ms, enqueue 0.10885 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155664 ms - Host latency: 0.197998 ms (end to end 0.289062 ms, enqueue 0.108911 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155261 ms - Host latency: 0.197339 ms (end to end 0.290625 ms, enqueue 0.117896 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155688 ms - Host latency: 0.197009 ms (end to end 0.26095 ms, enqueue 0.136511 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159082 ms - Host latency: 0.200623 ms (end to end 0.221497 ms, enqueue 0.141626 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157874 ms - Host latency: 0.199304 ms (end to end 0.211023 ms, enqueue 0.137 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156091 ms - Host latency: 0.197449 ms (end to end 0.209924 ms, enqueue 0.134998 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158081 ms - Host latency: 0.199438 ms (end to end 0.209851 ms, enqueue 0.135986 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156213 ms - Host latency: 0.197754 ms (end to end 0.211035 ms, enqueue 0.133997 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156006 ms - Host latency: 0.198035 ms (end to end 0.252441 ms, enqueue 0.109717 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155884 ms - Host latency: 0.197461 ms (end to end 0.284155 ms, enqueue 0.0965698 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155591 ms - Host latency: 0.197217 ms (end to end 0.283997 ms, enqueue 0.0966553 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155688 ms - Host latency: 0.197595 ms (end to end 0.283887 ms, enqueue 0.0976318 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155774 ms - Host latency: 0.197339 ms (end to end 0.285095 ms, enqueue 0.0961182 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15592 ms - Host latency: 0.197644 ms (end to end 0.283777 ms, enqueue 0.0955444 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155518 ms - Host latency: 0.197034 ms (end to end 0.283057 ms, enqueue 0.0965088 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155542 ms - Host latency: 0.197107 ms (end to end 0.284998 ms, enqueue 0.0867798 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155505 ms - Host latency: 0.196997 ms (end to end 0.28595 ms, enqueue 0.0847168 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155457 ms - Host latency: 0.197107 ms (end to end 0.284497 ms, enqueue 0.0843994 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155359 ms - Host latency: 0.196924 ms (end to end 0.285999 ms, enqueue 0.0854126 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15542 ms - Host latency: 0.197058 ms (end to end 0.284827 ms, enqueue 0.0840332 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154968 ms - Host latency: 0.196558 ms (end to end 0.281006 ms, enqueue 0.0849243 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156604 ms - Host latency: 0.198474 ms (end to end 0.268518 ms, enqueue 0.0884766 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155725 ms - Host latency: 0.197681 ms (end to end 0.285059 ms, enqueue 0.0788452 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155554 ms - Host latency: 0.197168 ms (end to end 0.28374 ms, enqueue 0.0784424 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155066 ms - Host latency: 0.196533 ms (end to end 0.283667 ms, enqueue 0.0794678 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155737 ms - Host latency: 0.197876 ms (end to end 0.284082 ms, enqueue 0.0780762 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155212 ms - Host latency: 0.196936 ms (end to end 0.28302 ms, enqueue 0.0790283 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155554 ms - Host latency: 0.1979 ms (end to end 0.283887 ms, enqueue 0.078418 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155737 ms - Host latency: 0.197388 ms (end to end 0.285144 ms, enqueue 0.0778931 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.197522 ms (end to end 0.284106 ms, enqueue 0.0779053 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155847 ms - Host latency: 0.197595 ms (end to end 0.285669 ms, enqueue 0.0780518 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155811 ms - Host latency: 0.197766 ms (end to end 0.284229 ms, enqueue 0.0794434 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155615 ms - Host latency: 0.197705 ms (end to end 0.285095 ms, enqueue 0.0786499 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155151 ms - Host latency: 0.197107 ms (end to end 0.28291 ms, enqueue 0.0797607 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155408 ms - Host latency: 0.197119 ms (end to end 0.281982 ms, enqueue 0.0801636 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155725 ms - Host latency: 0.197534 ms (end to end 0.284607 ms, enqueue 0.0779175 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.199988 ms - Host latency: 0.245959 ms (end to end 0.283533 ms, enqueue 0.199011 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.205432 ms - Host latency: 0.250317 ms (end to end 0.259778 ms, enqueue 0.23324 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.198059 ms - Host latency: 0.242847 ms (end to end 0.256213 ms, enqueue 0.230005 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.204846 ms - Host latency: 0.249719 ms (end to end 0.259155 ms, enqueue 0.232361 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.210693 ms - Host latency: 0.256055 ms (end to end 0.265906 ms, enqueue 0.238428 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.307288 ms - Host latency: 0.359692 ms (end to end 0.369141 ms, enqueue 0.325342 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.163147 ms - Host latency: 0.206628 ms (end to end 0.221375 ms, enqueue 0.152698 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161658 ms - Host latency: 0.205188 ms (end to end 0.217273 ms, enqueue 0.148792 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155859 ms - Host latency: 0.197083 ms (end to end 0.253552 ms, enqueue 0.126147 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155249 ms - Host latency: 0.197205 ms (end to end 0.290833 ms, enqueue 0.129065 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155151 ms - Host latency: 0.198047 ms (end to end 0.294165 ms, enqueue 0.130835 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15575 ms - Host latency: 0.197644 ms (end to end 0.226672 ms, enqueue 0.138647 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156787 ms - Host latency: 0.198279 ms (end to end 0.21637 ms, enqueue 0.137195 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15592 ms - Host latency: 0.196973 ms (end to end 0.208374 ms, enqueue 0.132837 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155957 ms - Host latency: 0.197131 ms (end to end 0.208496 ms, enqueue 0.13269 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156616 ms - Host latency: 0.197937 ms (end to end 0.209106 ms, enqueue 0.133057 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157153 ms - Host latency: 0.198865 ms (end to end 0.217981 ms, enqueue 0.133203 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156726 ms - Host latency: 0.198315 ms (end to end 0.219971 ms, enqueue 0.135046 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155811 ms - Host latency: 0.197327 ms (end to end 0.230408 ms, enqueue 0.117603 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154639 ms - Host latency: 0.196753 ms (end to end 0.280652 ms, enqueue 0.0974731 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154163 ms - Host latency: 0.195947 ms (end to end 0.280749 ms, enqueue 0.0976196 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154602 ms - Host latency: 0.19668 ms (end to end 0.279541 ms, enqueue 0.0966675 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.183813 ms - Host latency: 0.228503 ms (end to end 0.287134 ms, enqueue 0.149963 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.204102 ms - Host latency: 0.249805 ms (end to end 0.260571 ms, enqueue 0.233447 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.226013 ms - Host latency: 0.272742 ms (end to end 0.284399 ms, enqueue 0.254333 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.217712 ms - Host latency: 0.263489 ms (end to end 0.27356 ms, enqueue 0.245593 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.203735 ms - Host latency: 0.249146 ms (end to end 0.25929 ms, enqueue 0.232178 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.172388 ms - Host latency: 0.223633 ms (end to end 0.237122 ms, enqueue 0.181873 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160498 ms - Host latency: 0.210779 ms (end to end 0.227087 ms, enqueue 0.159485 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159448 ms - Host latency: 0.210413 ms (end to end 0.225732 ms, enqueue 0.159766 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158594 ms - Host latency: 0.211975 ms (end to end 0.226282 ms, enqueue 0.159875 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.162622 ms - Host latency: 0.212207 ms (end to end 0.22345 ms, enqueue 0.172778 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15918 ms - Host latency: 0.208496 ms (end to end 0.222974 ms, enqueue 0.149316 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155957 ms - Host latency: 0.197876 ms (end to end 0.280078 ms, enqueue 0.114978 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155786 ms - Host latency: 0.197949 ms (end to end 0.286694 ms, enqueue 0.115173 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15542 ms - Host latency: 0.197351 ms (end to end 0.287463 ms, enqueue 0.115466 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155627 ms - Host latency: 0.197217 ms (end to end 0.287988 ms, enqueue 0.115247 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155566 ms - Host latency: 0.197388 ms (end to end 0.286487 ms, enqueue 0.116699 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155103 ms - Host latency: 0.196948 ms (end to end 0.287073 ms, enqueue 0.114355 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155359 ms - Host latency: 0.196997 ms (end to end 0.28092 ms, enqueue 0.0975708 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15498 ms - Host latency: 0.19679 ms (end to end 0.277991 ms, enqueue 0.0896973 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155261 ms - Host latency: 0.196912 ms (end to end 0.271252 ms, enqueue 0.0886353 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155774 ms - Host latency: 0.197681 ms (end to end 0.279053 ms, enqueue 0.089917 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154919 ms - Host latency: 0.196814 ms (end to end 0.27666 ms, enqueue 0.0942749 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155054 ms - Host latency: 0.19696 ms (end to end 0.280103 ms, enqueue 0.0891968 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.170312 ms - Host latency: 0.2146 ms (end to end 0.26792 ms, enqueue 0.154529 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.184546 ms - Host latency: 0.228931 ms (end to end 0.239917 ms, enqueue 0.214587 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.187537 ms - Host latency: 0.232043 ms (end to end 0.242603 ms, enqueue 0.216907 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.185181 ms - Host latency: 0.229541 ms (end to end 0.239954 ms, enqueue 0.214258 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.177197 ms - Host latency: 0.222668 ms (end to end 0.235779 ms, enqueue 0.195166 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.162659 ms - Host latency: 0.207568 ms (end to end 0.221289 ms, enqueue 0.151794 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.163904 ms - Host latency: 0.206628 ms (end to end 0.221472 ms, enqueue 0.150879 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.162231 ms - Host latency: 0.205652 ms (end to end 0.221826 ms, enqueue 0.151599 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.163855 ms - Host latency: 0.208398 ms (end to end 0.221509 ms, enqueue 0.151025 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.162146 ms - Host latency: 0.205212 ms (end to end 0.218359 ms, enqueue 0.157959 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156384 ms - Host latency: 0.199219 ms (end to end 0.253577 ms, enqueue 0.12644 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155151 ms - Host latency: 0.197058 ms (end to end 0.281055 ms, enqueue 0.112329 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155359 ms - Host latency: 0.197192 ms (end to end 0.282959 ms, enqueue 0.117346 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155237 ms - Host latency: 0.197668 ms (end to end 0.290454 ms, enqueue 0.114807 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155591 ms - Host latency: 0.197791 ms (end to end 0.287769 ms, enqueue 0.120703 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155762 ms - Host latency: 0.197485 ms (end to end 0.271973 ms, enqueue 0.119751 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155652 ms - Host latency: 0.197571 ms (end to end 0.283374 ms, enqueue 0.106934 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155811 ms - Host latency: 0.197791 ms (end to end 0.269495 ms, enqueue 0.0885498 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.196924 ms (end to end 0.27439 ms, enqueue 0.0825073 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.21781 ms - Host latency: 0.265845 ms (end to end 0.278259 ms, enqueue 0.246899 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.213684 ms - Host latency: 0.259985 ms (end to end 0.271033 ms, enqueue 0.24198 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.223438 ms - Host latency: 0.270361 ms (end to end 0.280054 ms, enqueue 0.249341 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.175562 ms - Host latency: 0.226038 ms (end to end 0.239697 ms, enqueue 0.185547 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159851 ms - Host latency: 0.21156 ms (end to end 0.226355 ms, enqueue 0.159607 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159961 ms - Host latency: 0.210339 ms (end to end 0.22605 ms, enqueue 0.160791 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159814 ms - Host latency: 0.210767 ms (end to end 0.224719 ms, enqueue 0.157764 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159338 ms - Host latency: 0.200964 ms (end to end 0.21355 ms, enqueue 0.140283 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15946 ms - Host latency: 0.201807 ms (end to end 0.21167 ms, enqueue 0.138379 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159155 ms - Host latency: 0.201379 ms (end to end 0.212781 ms, enqueue 0.138831 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158398 ms - Host latency: 0.200366 ms (end to end 0.212634 ms, enqueue 0.138342 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159314 ms - Host latency: 0.201111 ms (end to end 0.213269 ms, enqueue 0.13855 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161218 ms - Host latency: 0.203699 ms (end to end 0.225513 ms, enqueue 0.133215 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155518 ms - Host latency: 0.196948 ms (end to end 0.280566 ms, enqueue 0.105054 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155811 ms - Host latency: 0.197388 ms (end to end 0.280017 ms, enqueue 0.105701 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154749 ms - Host latency: 0.196631 ms (end to end 0.282336 ms, enqueue 0.104065 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154749 ms - Host latency: 0.196704 ms (end to end 0.285107 ms, enqueue 0.107471 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154968 ms - Host latency: 0.196667 ms (end to end 0.282581 ms, enqueue 0.107605 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154517 ms - Host latency: 0.196265 ms (end to end 0.284082 ms, enqueue 0.106018 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154932 ms - Host latency: 0.196497 ms (end to end 0.278357 ms, enqueue 0.0977661 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154883 ms - Host latency: 0.196545 ms (end to end 0.27345 ms, enqueue 0.0903687 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154968 ms - Host latency: 0.196472 ms (end to end 0.272925 ms, enqueue 0.0898926 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155273 ms - Host latency: 0.197144 ms (end to end 0.275195 ms, enqueue 0.0912231 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155542 ms - Host latency: 0.197827 ms (end to end 0.278967 ms, enqueue 0.0925903 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154883 ms - Host latency: 0.196582 ms (end to end 0.274268 ms, enqueue 0.0880493 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.213232 ms - Host latency: 0.259937 ms (end to end 0.302832 ms, enqueue 0.204932 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.207153 ms - Host latency: 0.252563 ms (end to end 0.269458 ms, enqueue 0.20697 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155176 ms - Host latency: 0.196643 ms (end to end 0.285742 ms, enqueue 0.114832 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155835 ms - Host latency: 0.197717 ms (end to end 0.288367 ms, enqueue 0.114063 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155322 ms - Host latency: 0.199036 ms (end to end 0.289685 ms, enqueue 0.114111 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155176 ms - Host latency: 0.197058 ms (end to end 0.288135 ms, enqueue 0.109814 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1552 ms - Host latency: 0.196887 ms (end to end 0.286804 ms, enqueue 0.102454 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155029 ms - Host latency: 0.196692 ms (end to end 0.2849 ms, enqueue 0.102429 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155811 ms - Host latency: 0.197607 ms (end to end 0.285706 ms, enqueue 0.10459 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155151 ms - Host latency: 0.196997 ms (end to end 0.288037 ms, enqueue 0.105493 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156519 ms - Host latency: 0.200366 ms (end to end 0.290149 ms, enqueue 0.106165 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155554 ms - Host latency: 0.197656 ms (end to end 0.289502 ms, enqueue 0.105591 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15625 ms - Host latency: 0.198889 ms (end to end 0.284924 ms, enqueue 0.102234 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155713 ms - Host latency: 0.197437 ms (end to end 0.286157 ms, enqueue 0.10166 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15553 ms - Host latency: 0.197461 ms (end to end 0.284302 ms, enqueue 0.100867 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155579 ms - Host latency: 0.19751 ms (end to end 0.283862 ms, enqueue 0.100623 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155969 ms - Host latency: 0.197461 ms (end to end 0.27533 ms, enqueue 0.104993 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155774 ms - Host latency: 0.198218 ms (end to end 0.284363 ms, enqueue 0.100989 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15564 ms - Host latency: 0.198096 ms (end to end 0.285913 ms, enqueue 0.10072 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156055 ms - Host latency: 0.198059 ms (end to end 0.285266 ms, enqueue 0.100964 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156128 ms - Host latency: 0.198022 ms (end to end 0.285144 ms, enqueue 0.0986816 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155945 ms - Host latency: 0.19762 ms (end to end 0.280701 ms, enqueue 0.101904 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155957 ms - Host latency: 0.198145 ms (end to end 0.283569 ms, enqueue 0.100085 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155725 ms - Host latency: 0.198364 ms (end to end 0.286035 ms, enqueue 0.099353 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156567 ms - Host latency: 0.198462 ms (end to end 0.27428 ms, enqueue 0.102747 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155396 ms - Host latency: 0.197522 ms (end to end 0.285413 ms, enqueue 0.083667 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155627 ms - Host latency: 0.197815 ms (end to end 0.286743 ms, enqueue 0.0881958 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15564 ms - Host latency: 0.197583 ms (end to end 0.284644 ms, enqueue 0.0843628 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155603 ms - Host latency: 0.197937 ms (end to end 0.28678 ms, enqueue 0.0844727 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156824 ms - Host latency: 0.199207 ms (end to end 0.287781 ms, enqueue 0.0911499 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155518 ms - Host latency: 0.197412 ms (end to end 0.284363 ms, enqueue 0.0907471 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156592 ms - Host latency: 0.198547 ms (end to end 0.252478 ms, enqueue 0.119214 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155981 ms - Host latency: 0.197913 ms (end to end 0.269238 ms, enqueue 0.126953 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15531 ms - Host latency: 0.197742 ms (end to end 0.290515 ms, enqueue 0.122961 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155078 ms - Host latency: 0.19696 ms (end to end 0.289966 ms, enqueue 0.124158 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1547 ms - Host latency: 0.19668 ms (end to end 0.29054 ms, enqueue 0.120215 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155261 ms - Host latency: 0.196997 ms (end to end 0.278882 ms, enqueue 0.123145 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156165 ms - Host latency: 0.198462 ms (end to end 0.28822 ms, enqueue 0.0955689 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155432 ms - Host latency: 0.197095 ms (end to end 0.287463 ms, enqueue 0.104529 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155493 ms - Host latency: 0.197925 ms (end to end 0.289197 ms, enqueue 0.106323 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155554 ms - Host latency: 0.197375 ms (end to end 0.288318 ms, enqueue 0.108313 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.233398 ms - Host latency: 0.282129 ms (end to end 0.320239 ms, enqueue 0.238867 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.214478 ms - Host latency: 0.260242 ms (end to end 0.26925 ms, enqueue 0.241418 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.208203 ms - Host latency: 0.254541 ms (end to end 0.263806 ms, enqueue 0.235425 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.208679 ms - Host latency: 0.254871 ms (end to end 0.263074 ms, enqueue 0.234338 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.212231 ms - Host latency: 0.257654 ms (end to end 0.267712 ms, enqueue 0.23999 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161646 ms - Host latency: 0.208813 ms (end to end 0.224097 ms, enqueue 0.158972 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.170569 ms - Host latency: 0.216479 ms (end to end 0.228638 ms, enqueue 0.174255 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155493 ms - Host latency: 0.196692 ms (end to end 0.205029 ms, enqueue 0.178015 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155286 ms - Host latency: 0.197632 ms (end to end 0.207886 ms, enqueue 0.176196 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153857 ms - Host latency: 0.20271 ms (end to end 0.212305 ms, enqueue 0.168591 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158313 ms - Host latency: 0.209631 ms (end to end 0.225049 ms, enqueue 0.161963 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158008 ms - Host latency: 0.210339 ms (end to end 0.224548 ms, enqueue 0.162695 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.162158 ms - Host latency: 0.210266 ms (end to end 0.246619 ms, enqueue 0.143835 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154932 ms - Host latency: 0.196362 ms (end to end 0.288098 ms, enqueue 0.111523 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154675 ms - Host latency: 0.196387 ms (end to end 0.286194 ms, enqueue 0.1151 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154797 ms - Host latency: 0.196423 ms (end to end 0.291003 ms, enqueue 0.10918 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15498 ms - Host latency: 0.196655 ms (end to end 0.278113 ms, enqueue 0.0924561 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154724 ms - Host latency: 0.196448 ms (end to end 0.276917 ms, enqueue 0.088501 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15481 ms - Host latency: 0.196912 ms (end to end 0.277844 ms, enqueue 0.0866455 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154712 ms - Host latency: 0.196667 ms (end to end 0.275989 ms, enqueue 0.0858765 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154639 ms - Host latency: 0.195911 ms (end to end 0.273914 ms, enqueue 0.0876953 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155066 ms - Host latency: 0.197009 ms (end to end 0.277722 ms, enqueue 0.0918091 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155505 ms - Host latency: 0.19762 ms (end to end 0.274634 ms, enqueue 0.0824829 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15509 ms - Host latency: 0.196423 ms (end to end 0.273706 ms, enqueue 0.0802368 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155359 ms - Host latency: 0.197131 ms (end to end 0.276404 ms, enqueue 0.0844605 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154468 ms - Host latency: 0.196082 ms (end to end 0.261084 ms, enqueue 0.0857666 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155408 ms - Host latency: 0.19718 ms (end to end 0.274597 ms, enqueue 0.0844116 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155627 ms - Host latency: 0.197668 ms (end to end 0.269531 ms, enqueue 0.0869141 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154736 ms - Host latency: 0.196106 ms (end to end 0.276038 ms, enqueue 0.0914185 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155066 ms - Host latency: 0.196667 ms (end to end 0.281531 ms, enqueue 0.0862305 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155066 ms - Host latency: 0.197034 ms (end to end 0.280176 ms, enqueue 0.0918457 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155017 ms - Host latency: 0.196472 ms (end to end 0.276282 ms, enqueue 0.0919189 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155359 ms - Host latency: 0.197058 ms (end to end 0.277686 ms, enqueue 0.0852295 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154382 ms - Host latency: 0.195837 ms (end to end 0.274036 ms, enqueue 0.0831055 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1547 ms - Host latency: 0.196729 ms (end to end 0.278284 ms, enqueue 0.0919922 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155176 ms - Host latency: 0.196667 ms (end to end 0.27207 ms, enqueue 0.102625 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154797 ms - Host latency: 0.196375 ms (end to end 0.281751 ms, enqueue 0.0877319 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.172803 ms - Host latency: 0.217261 ms (end to end 0.29502 ms, enqueue 0.126538 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.199805 ms - Host latency: 0.244873 ms (end to end 0.256006 ms, enqueue 0.229529 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.192871 ms - Host latency: 0.238916 ms (end to end 0.249988 ms, enqueue 0.222815 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.182837 ms - Host latency: 0.226611 ms (end to end 0.237134 ms, enqueue 0.212781 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.184375 ms - Host latency: 0.228638 ms (end to end 0.238025 ms, enqueue 0.213196 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.18302 ms - Host latency: 0.226953 ms (end to end 0.237158 ms, enqueue 0.212854 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.191675 ms - Host latency: 0.238831 ms (end to end 0.250427 ms, enqueue 0.203125 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.264307 ms - Host latency: 0.313757 ms (end to end 0.323718 ms, enqueue 0.288721 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155847 ms - Host latency: 0.197607 ms (end to end 0.206238 ms, enqueue 0.17998 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159668 ms - Host latency: 0.20946 ms (end to end 0.225012 ms, enqueue 0.161621 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160278 ms - Host latency: 0.207922 ms (end to end 0.222217 ms, enqueue 0.156885 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.164624 ms - Host latency: 0.207056 ms (end to end 0.220618 ms, enqueue 0.149011 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.164087 ms - Host latency: 0.209326 ms (end to end 0.222974 ms, enqueue 0.151074 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.163904 ms - Host latency: 0.207629 ms (end to end 0.219812 ms, enqueue 0.149768 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156665 ms - Host latency: 0.206543 ms (end to end 0.218359 ms, enqueue 0.163257 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154858 ms - Host latency: 0.203577 ms (end to end 0.215454 ms, enqueue 0.165039 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157288 ms - Host latency: 0.202124 ms (end to end 0.225244 ms, enqueue 0.146387 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.171057 ms - Host latency: 0.216223 ms (end to end 0.278406 ms, enqueue 0.14375 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.240515 ms - Host latency: 0.287878 ms (end to end 0.298389 ms, enqueue 0.265869 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.236499 ms - Host latency: 0.283423 ms (end to end 0.294885 ms, enqueue 0.262964 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.167139 ms - Host latency: 0.210791 ms (end to end 0.223462 ms, enqueue 0.180237 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157544 ms - Host latency: 0.206824 ms (end to end 0.217664 ms, enqueue 0.170715 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156726 ms - Host latency: 0.203674 ms (end to end 0.214819 ms, enqueue 0.175208 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15741 ms - Host latency: 0.208801 ms (end to end 0.220752 ms, enqueue 0.16449 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157385 ms - Host latency: 0.210449 ms (end to end 0.222974 ms, enqueue 0.160754 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156641 ms - Host latency: 0.204053 ms (end to end 0.230225 ms, enqueue 0.135925 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.20437 ms - Host latency: 0.251367 ms (end to end 0.295422 ms, enqueue 0.197583 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.240784 ms - Host latency: 0.287964 ms (end to end 0.300183 ms, enqueue 0.268396 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.26051 ms - Host latency: 0.308386 ms (end to end 0.320557 ms, enqueue 0.288037 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154907 ms - Host latency: 0.196191 ms (end to end 0.206335 ms, enqueue 0.178247 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153918 ms - Host latency: 0.195032 ms (end to end 0.203992 ms, enqueue 0.173303 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157288 ms - Host latency: 0.199915 ms (end to end 0.254187 ms, enqueue 0.109033 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155554 ms - Host latency: 0.19751 ms (end to end 0.283459 ms, enqueue 0.079187 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155652 ms - Host latency: 0.197852 ms (end to end 0.281238 ms, enqueue 0.0794434 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154907 ms - Host latency: 0.19751 ms (end to end 0.277673 ms, enqueue 0.0897583 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155225 ms - Host latency: 0.197241 ms (end to end 0.280493 ms, enqueue 0.0973389 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154651 ms - Host latency: 0.196436 ms (end to end 0.280249 ms, enqueue 0.0928711 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154895 ms - Host latency: 0.196252 ms (end to end 0.280029 ms, enqueue 0.0902344 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155127 ms - Host latency: 0.196472 ms (end to end 0.280908 ms, enqueue 0.091687 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154639 ms - Host latency: 0.196582 ms (end to end 0.278931 ms, enqueue 0.0908081 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155029 ms - Host latency: 0.196533 ms (end to end 0.280457 ms, enqueue 0.0871216 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155432 ms - Host latency: 0.19729 ms (end to end 0.280859 ms, enqueue 0.082019 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155688 ms - Host latency: 0.196863 ms (end to end 0.282202 ms, enqueue 0.0811523 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154883 ms - Host latency: 0.196399 ms (end to end 0.280115 ms, enqueue 0.0823853 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154822 ms - Host latency: 0.196387 ms (end to end 0.278076 ms, enqueue 0.0821289 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155212 ms - Host latency: 0.197021 ms (end to end 0.276807 ms, enqueue 0.082019 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155786 ms - Host latency: 0.19762 ms (end to end 0.249243 ms, enqueue 0.111401 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155725 ms - Host latency: 0.197327 ms (end to end 0.267603 ms, enqueue 0.126636 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155188 ms - Host latency: 0.196484 ms (end to end 0.269885 ms, enqueue 0.129858 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155237 ms - Host latency: 0.19967 ms (end to end 0.221753 ms, enqueue 0.167004 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155151 ms - Host latency: 0.201453 ms (end to end 0.213208 ms, enqueue 0.176306 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153821 ms - Host latency: 0.202905 ms (end to end 0.215186 ms, enqueue 0.172522 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155847 ms - Host latency: 0.196899 ms (end to end 0.207251 ms, enqueue 0.155933 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156909 ms - Host latency: 0.198389 ms (end to end 0.220666 ms, enqueue 0.133887 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156006 ms - Host latency: 0.197192 ms (end to end 0.221265 ms, enqueue 0.134253 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157117 ms - Host latency: 0.198621 ms (end to end 0.215369 ms, enqueue 0.137061 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160986 ms - Host latency: 0.204041 ms (end to end 0.215991 ms, enqueue 0.1427 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.16178 ms - Host latency: 0.204053 ms (end to end 0.216821 ms, enqueue 0.142981 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156873 ms - Host latency: 0.198901 ms (end to end 0.209729 ms, enqueue 0.135425 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.236816 ms - Host latency: 0.286157 ms (end to end 0.315234 ms, enqueue 0.235864 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.228723 ms - Host latency: 0.276074 ms (end to end 0.28501 ms, enqueue 0.253455 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.253479 ms - Host latency: 0.303296 ms (end to end 0.314392 ms, enqueue 0.278491 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.188049 ms - Host latency: 0.233386 ms (end to end 0.261365 ms, enqueue 0.193274 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1672 ms - Host latency: 0.211963 ms (end to end 0.222473 ms, enqueue 0.197632 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155786 ms - Host latency: 0.196863 ms (end to end 0.208752 ms, enqueue 0.179517 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15874 ms - Host latency: 0.200281 ms (end to end 0.210889 ms, enqueue 0.171545 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155212 ms - Host latency: 0.196802 ms (end to end 0.27843 ms, enqueue 0.10957 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157324 ms - Host latency: 0.199683 ms (end to end 0.272363 ms, enqueue 0.134961 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157227 ms - Host latency: 0.200049 ms (end to end 0.222229 ms, enqueue 0.144958 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161255 ms - Host latency: 0.20459 ms (end to end 0.217847 ms, enqueue 0.145374 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160889 ms - Host latency: 0.204297 ms (end to end 0.216992 ms, enqueue 0.148987 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159399 ms - Host latency: 0.205371 ms (end to end 0.218494 ms, enqueue 0.153418 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.162183 ms - Host latency: 0.204224 ms (end to end 0.21814 ms, enqueue 0.138709 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154651 ms - Host latency: 0.196362 ms (end to end 0.282886 ms, enqueue 0.110901 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155774 ms - Host latency: 0.197522 ms (end to end 0.286938 ms, enqueue 0.110266 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154932 ms - Host latency: 0.196655 ms (end to end 0.286072 ms, enqueue 0.111389 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155786 ms - Host latency: 0.1979 ms (end to end 0.264343 ms, enqueue 0.113416 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.197131 ms (end to end 0.284888 ms, enqueue 0.111047 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155164 ms - Host latency: 0.196973 ms (end to end 0.280457 ms, enqueue 0.120984 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154834 ms - Host latency: 0.196826 ms (end to end 0.281372 ms, enqueue 0.0907837 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155688 ms - Host latency: 0.197485 ms (end to end 0.279187 ms, enqueue 0.0863281 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15564 ms - Host latency: 0.197412 ms (end to end 0.283459 ms, enqueue 0.0863403 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155359 ms - Host latency: 0.197424 ms (end to end 0.283521 ms, enqueue 0.0794067 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154687 ms - Host latency: 0.196252 ms (end to end 0.281165 ms, enqueue 0.0789795 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154749 ms - Host latency: 0.196436 ms (end to end 0.278809 ms, enqueue 0.0783325 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154822 ms - Host latency: 0.19668 ms (end to end 0.279846 ms, enqueue 0.0805542 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155261 ms - Host latency: 0.19668 ms (end to end 0.283337 ms, enqueue 0.0796875 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155347 ms - Host latency: 0.196826 ms (end to end 0.278113 ms, enqueue 0.0865601 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155164 ms - Host latency: 0.196997 ms (end to end 0.285425 ms, enqueue 0.0805786 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154822 ms - Host latency: 0.196399 ms (end to end 0.288 ms, enqueue 0.0965088 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.197522 ms (end to end 0.289014 ms, enqueue 0.0918701 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155994 ms - Host latency: 0.197961 ms (end to end 0.266699 ms, enqueue 0.118115 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155652 ms - Host latency: 0.197424 ms (end to end 0.291943 ms, enqueue 0.116882 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155566 ms - Host latency: 0.197327 ms (end to end 0.281958 ms, enqueue 0.10365 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155237 ms - Host latency: 0.196851 ms (end to end 0.287402 ms, enqueue 0.0843262 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155408 ms - Host latency: 0.197058 ms (end to end 0.285937 ms, enqueue 0.0846558 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155261 ms - Host latency: 0.196704 ms (end to end 0.289465 ms, enqueue 0.07771 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155017 ms - Host latency: 0.196716 ms (end to end 0.287683 ms, enqueue 0.0819946 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154907 ms - Host latency: 0.196362 ms (end to end 0.286926 ms, enqueue 0.102649 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154883 ms - Host latency: 0.19668 ms (end to end 0.284656 ms, enqueue 0.104687 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154749 ms - Host latency: 0.196484 ms (end to end 0.283765 ms, enqueue 0.102417 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155286 ms - Host latency: 0.196582 ms (end to end 0.283862 ms, enqueue 0.102124 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155566 ms - Host latency: 0.197778 ms (end to end 0.283472 ms, enqueue 0.108557 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157153 ms - Host latency: 0.199805 ms (end to end 0.26261 ms, enqueue 0.129492 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155322 ms - Host latency: 0.197058 ms (end to end 0.264844 ms, enqueue 0.0888062 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154089 ms - Host latency: 0.19563 ms (end to end 0.274878 ms, enqueue 0.080603 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154639 ms - Host latency: 0.196411 ms (end to end 0.273694 ms, enqueue 0.106055 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154358 ms - Host latency: 0.195972 ms (end to end 0.278284 ms, enqueue 0.0841797 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.203857 ms - Host latency: 0.250757 ms (end to end 0.297192 ms, enqueue 0.181958 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.283313 ms - Host latency: 0.333081 ms (end to end 0.344824 ms, enqueue 0.308276 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.302075 ms - Host latency: 0.351831 ms (end to end 0.364172 ms, enqueue 0.327075 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.316406 ms - Host latency: 0.367163 ms (end to end 0.377441 ms, enqueue 0.338672 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.213562 ms - Host latency: 0.258752 ms (end to end 0.269861 ms, enqueue 0.242114 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.186121 ms - Host latency: 0.230688 ms (end to end 0.242627 ms, enqueue 0.217065 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.184448 ms - Host latency: 0.228308 ms (end to end 0.239575 ms, enqueue 0.214697 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.182739 ms - Host latency: 0.226904 ms (end to end 0.238196 ms, enqueue 0.213245 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157129 ms - Host latency: 0.199255 ms (end to end 0.266528 ms, enqueue 0.110461 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155164 ms - Host latency: 0.196997 ms (end to end 0.285913 ms, enqueue 0.103967 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15625 ms - Host latency: 0.19928 ms (end to end 0.260156 ms, enqueue 0.124829 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155786 ms - Host latency: 0.197156 ms (end to end 0.20874 ms, enqueue 0.133325 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155847 ms - Host latency: 0.197168 ms (end to end 0.221362 ms, enqueue 0.131909 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155408 ms - Host latency: 0.196484 ms (end to end 0.218469 ms, enqueue 0.133301 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156445 ms - Host latency: 0.197949 ms (end to end 0.224072 ms, enqueue 0.136121 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161121 ms - Host latency: 0.202991 ms (end to end 0.214539 ms, enqueue 0.142395 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.16106 ms - Host latency: 0.203259 ms (end to end 0.215332 ms, enqueue 0.140222 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161389 ms - Host latency: 0.203845 ms (end to end 0.215662 ms, enqueue 0.143689 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.196765 ms - Host latency: 0.24176 ms (end to end 0.251367 ms, enqueue 0.213525 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.189868 ms - Host latency: 0.236584 ms (end to end 0.245764 ms, enqueue 0.216919 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.209314 ms - Host latency: 0.255688 ms (end to end 0.267419 ms, enqueue 0.236755 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.206152 ms - Host latency: 0.252905 ms (end to end 0.264929 ms, enqueue 0.234241 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.2099 ms - Host latency: 0.256934 ms (end to end 0.268689 ms, enqueue 0.23772 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.177161 ms - Host latency: 0.226648 ms (end to end 0.240063 ms, enqueue 0.192126 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160583 ms - Host latency: 0.210718 ms (end to end 0.226343 ms, enqueue 0.160413 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161816 ms - Host latency: 0.212463 ms (end to end 0.226477 ms, enqueue 0.159485 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161133 ms - Host latency: 0.208594 ms (end to end 0.222644 ms, enqueue 0.159351 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161169 ms - Host latency: 0.2099 ms (end to end 0.225928 ms, enqueue 0.158948 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158984 ms - Host latency: 0.207556 ms (end to end 0.222583 ms, enqueue 0.148511 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154968 ms - Host latency: 0.196423 ms (end to end 0.28197 ms, enqueue 0.113599 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155115 ms - Host latency: 0.196851 ms (end to end 0.287793 ms, enqueue 0.114172 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1552 ms - Host latency: 0.197339 ms (end to end 0.292505 ms, enqueue 0.113391 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15509 ms - Host latency: 0.196887 ms (end to end 0.290015 ms, enqueue 0.112634 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155005 ms - Host latency: 0.196521 ms (end to end 0.287524 ms, enqueue 0.113977 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155042 ms - Host latency: 0.196729 ms (end to end 0.290454 ms, enqueue 0.112598 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154858 ms - Host latency: 0.196265 ms (end to end 0.282068 ms, enqueue 0.0890137 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.240173 ms - Host latency: 0.289722 ms (end to end 0.334668 ms, enqueue 0.230347 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.230151 ms - Host latency: 0.276941 ms (end to end 0.287878 ms, enqueue 0.257666 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.233997 ms - Host latency: 0.280981 ms (end to end 0.290833 ms, enqueue 0.260229 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.278967 ms - Host latency: 0.329858 ms (end to end 0.340698 ms, enqueue 0.30354 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.26947 ms - Host latency: 0.320251 ms (end to end 0.331201 ms, enqueue 0.293311 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.224231 ms - Host latency: 0.27179 ms (end to end 0.282727 ms, enqueue 0.250916 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.244897 ms - Host latency: 0.293091 ms (end to end 0.301392 ms, enqueue 0.267517 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.224109 ms - Host latency: 0.270642 ms (end to end 0.280322 ms, enqueue 0.250598 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.201221 ms - Host latency: 0.246143 ms (end to end 0.25896 ms, enqueue 0.231799 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.163037 ms - Host latency: 0.208276 ms (end to end 0.222693 ms, enqueue 0.151807 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.16228 ms - Host latency: 0.208105 ms (end to end 0.223438 ms, enqueue 0.15437 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.163818 ms - Host latency: 0.20791 ms (end to end 0.222717 ms, enqueue 0.1521 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157874 ms - Host latency: 0.205725 ms (end to end 0.21731 ms, enqueue 0.161157 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15658 ms - Host latency: 0.208972 ms (end to end 0.220862 ms, enqueue 0.163025 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156311 ms - Host latency: 0.203381 ms (end to end 0.230298 ms, enqueue 0.142224 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155396 ms - Host latency: 0.197107 ms (end to end 0.278796 ms, enqueue 0.120142 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15614 ms - Host latency: 0.198328 ms (end to end 0.260693 ms, enqueue 0.124976 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160266 ms - Host latency: 0.205176 ms (end to end 0.221008 ms, enqueue 0.156653 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1578 ms - Host latency: 0.19967 ms (end to end 0.212976 ms, enqueue 0.137537 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1604 ms - Host latency: 0.203223 ms (end to end 0.215015 ms, enqueue 0.145166 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156995 ms - Host latency: 0.201428 ms (end to end 0.211841 ms, enqueue 0.15575 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154138 ms - Host latency: 0.199561 ms (end to end 0.208972 ms, enqueue 0.175671 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155469 ms - Host latency: 0.201782 ms (end to end 0.211072 ms, enqueue 0.174121 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159583 ms - Host latency: 0.202063 ms (end to end 0.211865 ms, enqueue 0.18457 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.174805 ms - Host latency: 0.222876 ms (end to end 0.235278 ms, enqueue 0.188623 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.16012 ms - Host latency: 0.202271 ms (end to end 0.237219 ms, enqueue 0.139319 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155493 ms - Host latency: 0.198328 ms (end to end 0.286938 ms, enqueue 0.123804 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155579 ms - Host latency: 0.198047 ms (end to end 0.27085 ms, enqueue 0.126074 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15553 ms - Host latency: 0.197571 ms (end to end 0.288953 ms, enqueue 0.120361 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155542 ms - Host latency: 0.197595 ms (end to end 0.292175 ms, enqueue 0.123926 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156738 ms - Host latency: 0.20011 ms (end to end 0.248157 ms, enqueue 0.14447 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156262 ms - Host latency: 0.197888 ms (end to end 0.267554 ms, enqueue 0.111194 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.213171 ms - Host latency: 0.260083 ms (end to end 0.325696 ms, enqueue 0.179834 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156018 ms - Host latency: 0.198108 ms (end to end 0.267383 ms, enqueue 0.105518 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155457 ms - Host latency: 0.197278 ms (end to end 0.287756 ms, enqueue 0.100024 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155505 ms - Host latency: 0.197253 ms (end to end 0.289404 ms, enqueue 0.101367 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155676 ms - Host latency: 0.197473 ms (end to end 0.287488 ms, enqueue 0.101245 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155798 ms - Host latency: 0.198157 ms (end to end 0.283728 ms, enqueue 0.105896 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155322 ms - Host latency: 0.197498 ms (end to end 0.284021 ms, enqueue 0.0818848 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15498 ms - Host latency: 0.196924 ms (end to end 0.290088 ms, enqueue 0.0808472 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158704 ms - Host latency: 0.202173 ms (end to end 0.264124 ms, enqueue 0.121045 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157141 ms - Host latency: 0.200171 ms (end to end 0.244409 ms, enqueue 0.119763 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155481 ms - Host latency: 0.197339 ms (end to end 0.285901 ms, enqueue 0.102808 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155408 ms - Host latency: 0.197473 ms (end to end 0.290906 ms, enqueue 0.107751 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155139 ms - Host latency: 0.197168 ms (end to end 0.296741 ms, enqueue 0.129004 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155579 ms - Host latency: 0.197827 ms (end to end 0.277051 ms, enqueue 0.139392 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158325 ms - Host latency: 0.200208 ms (end to end 0.21842 ms, enqueue 0.138562 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156067 ms - Host latency: 0.197888 ms (end to end 0.253809 ms, enqueue 0.131104 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155054 ms - Host latency: 0.196191 ms (end to end 0.269189 ms, enqueue 0.130933 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155762 ms - Host latency: 0.197803 ms (end to end 0.276392 ms, enqueue 0.130859 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154834 ms - Host latency: 0.196692 ms (end to end 0.291187 ms, enqueue 0.113367 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155017 ms - Host latency: 0.196875 ms (end to end 0.288562 ms, enqueue 0.096582 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154834 ms - Host latency: 0.196838 ms (end to end 0.286926 ms, enqueue 0.096875 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1552 ms - Host latency: 0.197205 ms (end to end 0.286633 ms, enqueue 0.106567 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154968 ms - Host latency: 0.196375 ms (end to end 0.288745 ms, enqueue 0.101257 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155115 ms - Host latency: 0.196826 ms (end to end 0.288672 ms, enqueue 0.10094 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154724 ms - Host latency: 0.196521 ms (end to end 0.289258 ms, enqueue 0.0943481 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154956 ms - Host latency: 0.196484 ms (end to end 0.2849 ms, enqueue 0.0833496 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155408 ms - Host latency: 0.197034 ms (end to end 0.286194 ms, enqueue 0.0917603 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.218945 ms - Host latency: 0.266772 ms (end to end 0.314319 ms, enqueue 0.207556 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.207776 ms - Host latency: 0.253784 ms (end to end 0.263574 ms, enqueue 0.235571 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.258643 ms - Host latency: 0.307898 ms (end to end 0.31781 ms, enqueue 0.2828 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.257507 ms - Host latency: 0.30708 ms (end to end 0.318982 ms, enqueue 0.283032 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.224011 ms - Host latency: 0.270251 ms (end to end 0.280298 ms, enqueue 0.250916 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.190588 ms - Host latency: 0.240588 ms (end to end 0.251038 ms, enqueue 0.206665 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161365 ms - Host latency: 0.208716 ms (end to end 0.220007 ms, enqueue 0.172681 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.168921 ms - Host latency: 0.216577 ms (end to end 0.228772 ms, enqueue 0.178247 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.167358 ms - Host latency: 0.21709 ms (end to end 0.227637 ms, enqueue 0.17782 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161255 ms - Host latency: 0.210425 ms (end to end 0.223279 ms, enqueue 0.162122 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157349 ms - Host latency: 0.199817 ms (end to end 0.231714 ms, enqueue 0.133923 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155603 ms - Host latency: 0.197314 ms (end to end 0.278052 ms, enqueue 0.115247 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.195007 ms - Host latency: 0.241724 ms (end to end 0.277722 ms, enqueue 0.198926 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.167053 ms - Host latency: 0.210828 ms (end to end 0.218762 ms, enqueue 0.195435 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.184534 ms - Host latency: 0.230505 ms (end to end 0.23905 ms, enqueue 0.212354 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.16665 ms - Host latency: 0.21062 ms (end to end 0.222974 ms, enqueue 0.170862 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.165369 ms - Host latency: 0.207581 ms (end to end 0.220264 ms, enqueue 0.150195 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.164478 ms - Host latency: 0.20686 ms (end to end 0.22052 ms, enqueue 0.150684 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.163293 ms - Host latency: 0.207532 ms (end to end 0.221033 ms, enqueue 0.151489 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160938 ms - Host latency: 0.208972 ms (end to end 0.22207 ms, enqueue 0.156226 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.16062 ms - Host latency: 0.207166 ms (end to end 0.22002 ms, enqueue 0.147388 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155322 ms - Host latency: 0.196899 ms (end to end 0.284375 ms, enqueue 0.109094 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155457 ms - Host latency: 0.197253 ms (end to end 0.286523 ms, enqueue 0.112524 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155786 ms - Host latency: 0.197644 ms (end to end 0.291675 ms, enqueue 0.109778 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155261 ms - Host latency: 0.197791 ms (end to end 0.288586 ms, enqueue 0.113672 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155383 ms - Host latency: 0.197412 ms (end to end 0.29071 ms, enqueue 0.114832 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154773 ms - Host latency: 0.196143 ms (end to end 0.289685 ms, enqueue 0.110547 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155603 ms - Host latency: 0.19762 ms (end to end 0.280688 ms, enqueue 0.0939819 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156653 ms - Host latency: 0.198547 ms (end to end 0.258044 ms, enqueue 0.111658 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155042 ms - Host latency: 0.196936 ms (end to end 0.287451 ms, enqueue 0.118091 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155518 ms - Host latency: 0.197388 ms (end to end 0.284387 ms, enqueue 0.122522 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155383 ms - Host latency: 0.197156 ms (end to end 0.292871 ms, enqueue 0.112634 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15531 ms - Host latency: 0.197058 ms (end to end 0.290759 ms, enqueue 0.115649 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156018 ms - Host latency: 0.19978 ms (end to end 0.289392 ms, enqueue 0.124695 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154883 ms - Host latency: 0.196704 ms (end to end 0.289673 ms, enqueue 0.116418 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156482 ms - Host latency: 0.199841 ms (end to end 0.267541 ms, enqueue 0.124365 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155823 ms - Host latency: 0.198022 ms (end to end 0.265161 ms, enqueue 0.11864 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155505 ms - Host latency: 0.197351 ms (end to end 0.286438 ms, enqueue 0.114624 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155396 ms - Host latency: 0.197156 ms (end to end 0.290149 ms, enqueue 0.109485 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157642 ms - Host latency: 0.199878 ms (end to end 0.273206 ms, enqueue 0.126367 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1573 ms - Host latency: 0.198755 ms (end to end 0.211169 ms, enqueue 0.135266 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157617 ms - Host latency: 0.199512 ms (end to end 0.216504 ms, enqueue 0.135449 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157678 ms - Host latency: 0.198901 ms (end to end 0.211499 ms, enqueue 0.136633 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156836 ms - Host latency: 0.198071 ms (end to end 0.212073 ms, enqueue 0.133997 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15741 ms - Host latency: 0.198792 ms (end to end 0.212854 ms, enqueue 0.136182 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15697 ms - Host latency: 0.199268 ms (end to end 0.241541 ms, enqueue 0.120105 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155469 ms - Host latency: 0.197473 ms (end to end 0.288782 ms, enqueue 0.110168 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154883 ms - Host latency: 0.19635 ms (end to end 0.28927 ms, enqueue 0.110791 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155432 ms - Host latency: 0.197046 ms (end to end 0.285767 ms, enqueue 0.105859 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156665 ms - Host latency: 0.198779 ms (end to end 0.273755 ms, enqueue 0.107483 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155261 ms - Host latency: 0.196899 ms (end to end 0.28562 ms, enqueue 0.0911865 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154919 ms - Host latency: 0.196887 ms (end to end 0.278674 ms, enqueue 0.105615 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155835 ms - Host latency: 0.198193 ms (end to end 0.249402 ms, enqueue 0.128369 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157385 ms - Host latency: 0.19978 ms (end to end 0.237109 ms, enqueue 0.124402 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154956 ms - Host latency: 0.196912 ms (end to end 0.278308 ms, enqueue 0.094751 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154749 ms - Host latency: 0.196399 ms (end to end 0.288074 ms, enqueue 0.0837524 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.170483 ms - Host latency: 0.21488 ms (end to end 0.270093 ms, enqueue 0.153662 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.213171 ms - Host latency: 0.260535 ms (end to end 0.270435 ms, enqueue 0.240002 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.247168 ms - Host latency: 0.295789 ms (end to end 0.307349 ms, enqueue 0.273462 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.242712 ms - Host latency: 0.290613 ms (end to end 0.300977 ms, enqueue 0.268469 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.219507 ms - Host latency: 0.266833 ms (end to end 0.27699 ms, enqueue 0.238416 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15697 ms - Host latency: 0.210706 ms (end to end 0.224463 ms, enqueue 0.162305 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1573 ms - Host latency: 0.211169 ms (end to end 0.222827 ms, enqueue 0.161096 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159082 ms - Host latency: 0.210156 ms (end to end 0.223108 ms, enqueue 0.161304 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160095 ms - Host latency: 0.212329 ms (end to end 0.226843 ms, enqueue 0.16167 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157117 ms - Host latency: 0.210315 ms (end to end 0.222876 ms, enqueue 0.15896 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15575 ms - Host latency: 0.197839 ms (end to end 0.274536 ms, enqueue 0.111621 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155408 ms - Host latency: 0.197375 ms (end to end 0.288562 ms, enqueue 0.114172 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.186646 ms - Host latency: 0.231445 ms (end to end 0.267944 ms, enqueue 0.198926 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.186499 ms - Host latency: 0.232642 ms (end to end 0.241968 ms, enqueue 0.215137 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.177319 ms - Host latency: 0.222314 ms (end to end 0.231152 ms, enqueue 0.206201 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.193774 ms - Host latency: 0.23916 ms (end to end 0.248584 ms, enqueue 0.222021 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.184521 ms - Host latency: 0.229761 ms (end to end 0.241187 ms, enqueue 0.214111 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.188525 ms - Host latency: 0.233081 ms (end to end 0.243115 ms, enqueue 0.21792 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.17207 ms - Host latency: 0.216479 ms (end to end 0.226855 ms, enqueue 0.179688 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158008 ms - Host latency: 0.199976 ms (end to end 0.211646 ms, enqueue 0.13938 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160376 ms - Host latency: 0.202344 ms (end to end 0.213672 ms, enqueue 0.140674 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158301 ms - Host latency: 0.199731 ms (end to end 0.211353 ms, enqueue 0.138696 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160376 ms - Host latency: 0.202148 ms (end to end 0.212964 ms, enqueue 0.140747 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161865 ms - Host latency: 0.203345 ms (end to end 0.214551 ms, enqueue 0.143359 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158301 ms - Host latency: 0.200195 ms (end to end 0.222388 ms, enqueue 0.127197 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155762 ms - Host latency: 0.197949 ms (end to end 0.268555 ms, enqueue 0.103198 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155444 ms - Host latency: 0.197217 ms (end to end 0.288696 ms, enqueue 0.10564 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155298 ms - Host latency: 0.196924 ms (end to end 0.286987 ms, enqueue 0.105762 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15542 ms - Host latency: 0.196997 ms (end to end 0.288843 ms, enqueue 0.105054 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155542 ms - Host latency: 0.197266 ms (end to end 0.280542 ms, enqueue 0.103687 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155249 ms - Host latency: 0.197485 ms (end to end 0.287451 ms, enqueue 0.10647 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.169897 ms - Host latency: 0.21311 ms (end to end 0.294141 ms, enqueue 0.113184 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155835 ms - Host latency: 0.197607 ms (end to end 0.26853 ms, enqueue 0.104541 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155298 ms - Host latency: 0.197144 ms (end to end 0.284058 ms, enqueue 0.0998047 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155835 ms - Host latency: 0.197852 ms (end to end 0.28457 ms, enqueue 0.101489 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15625 ms - Host latency: 0.198315 ms (end to end 0.285718 ms, enqueue 0.102271 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155396 ms - Host latency: 0.197021 ms (end to end 0.284595 ms, enqueue 0.0993652 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15564 ms - Host latency: 0.197266 ms (end to end 0.284131 ms, enqueue 0.100781 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155347 ms - Host latency: 0.196973 ms (end to end 0.285352 ms, enqueue 0.100146 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15564 ms - Host latency: 0.197656 ms (end to end 0.281934 ms, enqueue 0.0993164 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155713 ms - Host latency: 0.197559 ms (end to end 0.285425 ms, enqueue 0.0990479 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.197119 ms (end to end 0.283398 ms, enqueue 0.0990234 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155249 ms - Host latency: 0.196826 ms (end to end 0.286548 ms, enqueue 0.100098 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155591 ms - Host latency: 0.197437 ms (end to end 0.285278 ms, enqueue 0.100537 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156104 ms - Host latency: 0.198486 ms (end to end 0.287646 ms, enqueue 0.0996826 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155396 ms - Host latency: 0.197534 ms (end to end 0.282324 ms, enqueue 0.100098 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.180884 ms - Host latency: 0.222241 ms (end to end 0.260791 ms, enqueue 0.137573 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1677 ms - Host latency: 0.210522 ms (end to end 0.224927 ms, enqueue 0.15188 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157104 ms - Host latency: 0.198218 ms (end to end 0.21123 ms, enqueue 0.133569 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157056 ms - Host latency: 0.200317 ms (end to end 0.231299 ms, enqueue 0.124609 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155298 ms - Host latency: 0.197095 ms (end to end 0.287598 ms, enqueue 0.115601 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.258252 ms - Host latency: 0.308276 ms (end to end 0.338892 ms, enqueue 0.270703 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.221582 ms - Host latency: 0.268872 ms (end to end 0.279883 ms, enqueue 0.248389 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.220557 ms - Host latency: 0.267065 ms (end to end 0.278247 ms, enqueue 0.248413 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.181885 ms - Host latency: 0.226636 ms (end to end 0.236084 ms, enqueue 0.210205 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.206226 ms - Host latency: 0.251929 ms (end to end 0.262695 ms, enqueue 0.234692 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.164404 ms - Host latency: 0.207153 ms (end to end 0.255811 ms, enqueue 0.13374 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161743 ms - Host latency: 0.204297 ms (end to end 0.267334 ms, enqueue 0.152856 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154102 ms - Host latency: 0.208374 ms (end to end 0.216968 ms, enqueue 0.165649 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156982 ms - Host latency: 0.203979 ms (end to end 0.215234 ms, enqueue 0.173169 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15459 ms - Host latency: 0.196069 ms (end to end 0.204541 ms, enqueue 0.178052 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161182 ms - Host latency: 0.209473 ms (end to end 0.219434 ms, enqueue 0.178296 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153857 ms - Host latency: 0.204858 ms (end to end 0.213818 ms, enqueue 0.166968 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156299 ms - Host latency: 0.198413 ms (end to end 0.261523 ms, enqueue 0.119922 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155542 ms - Host latency: 0.197729 ms (end to end 0.286035 ms, enqueue 0.0903564 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155322 ms - Host latency: 0.197144 ms (end to end 0.283813 ms, enqueue 0.0848877 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155493 ms - Host latency: 0.197168 ms (end to end 0.284692 ms, enqueue 0.085376 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15603 ms - Host latency: 0.198022 ms (end to end 0.283691 ms, enqueue 0.0844238 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155688 ms - Host latency: 0.197461 ms (end to end 0.2854 ms, enqueue 0.0842529 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155322 ms - Host latency: 0.197021 ms (end to end 0.28396 ms, enqueue 0.0846436 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.197363 ms (end to end 0.284375 ms, enqueue 0.0838867 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155591 ms - Host latency: 0.197559 ms (end to end 0.284033 ms, enqueue 0.0843506 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156104 ms - Host latency: 0.198755 ms (end to end 0.261816 ms, enqueue 0.12063 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159351 ms - Host latency: 0.207886 ms (end to end 0.222705 ms, enqueue 0.158496 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160938 ms - Host latency: 0.210107 ms (end to end 0.223364 ms, enqueue 0.155591 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.169824 ms - Host latency: 0.212842 ms (end to end 0.222656 ms, enqueue 0.184424 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.175439 ms - Host latency: 0.219165 ms (end to end 0.227905 ms, enqueue 0.203467 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.195288 ms - Host latency: 0.240234 ms (end to end 0.24939 ms, enqueue 0.222363 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.201782 ms - Host latency: 0.247388 ms (end to end 0.256909 ms, enqueue 0.229077 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.163623 ms - Host latency: 0.206152 ms (end to end 0.217456 ms, enqueue 0.154761 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158521 ms - Host latency: 0.201587 ms (end to end 0.221997 ms, enqueue 0.140625 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156274 ms - Host latency: 0.198242 ms (end to end 0.222144 ms, enqueue 0.134131 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156299 ms - Host latency: 0.197461 ms (end to end 0.218726 ms, enqueue 0.132471 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156616 ms - Host latency: 0.197876 ms (end to end 0.242725 ms, enqueue 0.130396 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155127 ms - Host latency: 0.196753 ms (end to end 0.270312 ms, enqueue 0.128735 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155835 ms - Host latency: 0.197705 ms (end to end 0.284375 ms, enqueue 0.114355 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155249 ms - Host latency: 0.196802 ms (end to end 0.283472 ms, enqueue 0.0949219 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156201 ms - Host latency: 0.19834 ms (end to end 0.284521 ms, enqueue 0.0940918 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15625 ms - Host latency: 0.19834 ms (end to end 0.27522 ms, enqueue 0.105444 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154736 ms - Host latency: 0.196167 ms (end to end 0.277197 ms, enqueue 0.110986 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155615 ms - Host latency: 0.197827 ms (end to end 0.288013 ms, enqueue 0.109155 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155493 ms - Host latency: 0.197559 ms (end to end 0.290186 ms, enqueue 0.113599 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154956 ms - Host latency: 0.196802 ms (end to end 0.28877 ms, enqueue 0.113843 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15498 ms - Host latency: 0.196606 ms (end to end 0.286743 ms, enqueue 0.112817 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15498 ms - Host latency: 0.196655 ms (end to end 0.29043 ms, enqueue 0.109741 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155127 ms - Host latency: 0.19707 ms (end to end 0.287988 ms, enqueue 0.111108 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155273 ms - Host latency: 0.19707 ms (end to end 0.2927 ms, enqueue 0.112231 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155811 ms - Host latency: 0.198267 ms (end to end 0.287842 ms, enqueue 0.110767 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.197339 ms (end to end 0.28728 ms, enqueue 0.107446 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155347 ms - Host latency: 0.197363 ms (end to end 0.282373 ms, enqueue 0.101367 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155737 ms - Host latency: 0.198218 ms (end to end 0.284033 ms, enqueue 0.099707 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155103 ms - Host latency: 0.196777 ms (end to end 0.285742 ms, enqueue 0.100342 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155396 ms - Host latency: 0.197095 ms (end to end 0.283618 ms, enqueue 0.0981934 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155664 ms - Host latency: 0.197314 ms (end to end 0.284302 ms, enqueue 0.0982178 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.196899 ms (end to end 0.284863 ms, enqueue 0.0991211 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15542 ms - Host latency: 0.196924 ms (end to end 0.285107 ms, enqueue 0.0989014 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155737 ms - Host latency: 0.197705 ms (end to end 0.275562 ms, enqueue 0.109351 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155908 ms - Host latency: 0.19812 ms (end to end 0.268164 ms, enqueue 0.11897 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157178 ms - Host latency: 0.198413 ms (end to end 0.214258 ms, enqueue 0.133374 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156348 ms - Host latency: 0.1979 ms (end to end 0.222095 ms, enqueue 0.134253 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159766 ms - Host latency: 0.202271 ms (end to end 0.212524 ms, enqueue 0.153564 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158716 ms - Host latency: 0.200195 ms (end to end 0.213721 ms, enqueue 0.137256 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157739 ms - Host latency: 0.201465 ms (end to end 0.231445 ms, enqueue 0.125659 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156665 ms - Host latency: 0.199365 ms (end to end 0.223022 ms, enqueue 0.137915 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155981 ms - Host latency: 0.197461 ms (end to end 0.251514 ms, enqueue 0.125098 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155322 ms - Host latency: 0.197949 ms (end to end 0.294385 ms, enqueue 0.125342 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.19812 ms (end to end 0.297778 ms, enqueue 0.125708 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155396 ms - Host latency: 0.197437 ms (end to end 0.290869 ms, enqueue 0.123877 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155127 ms - Host latency: 0.197583 ms (end to end 0.293799 ms, enqueue 0.125391 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155542 ms - Host latency: 0.197681 ms (end to end 0.284326 ms, enqueue 0.128101 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.197119 ms - Host latency: 0.243823 ms (end to end 0.278833 ms, enqueue 0.189429 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.232495 ms - Host latency: 0.279077 ms (end to end 0.289111 ms, enqueue 0.258374 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.186475 ms - Host latency: 0.230127 ms (end to end 0.270142 ms, enqueue 0.16897 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.199902 ms - Host latency: 0.245801 ms (end to end 0.278198 ms, enqueue 0.208594 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.211353 ms - Host latency: 0.256836 ms (end to end 0.269556 ms, enqueue 0.242358 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.178052 ms - Host latency: 0.222803 ms (end to end 0.256714 ms, enqueue 0.15918 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155322 ms - Host latency: 0.196802 ms (end to end 0.284668 ms, enqueue 0.0805664 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154541 ms - Host latency: 0.195947 ms (end to end 0.279175 ms, enqueue 0.0827393 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155127 ms - Host latency: 0.196436 ms (end to end 0.252759 ms, enqueue 0.0817627 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156372 ms - Host latency: 0.197681 ms (end to end 0.24729 ms, enqueue 0.0971924 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1552 ms - Host latency: 0.197119 ms (end to end 0.279858 ms, enqueue 0.105688 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155127 ms - Host latency: 0.197095 ms (end to end 0.285034 ms, enqueue 0.100732 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155176 ms - Host latency: 0.196973 ms (end to end 0.272046 ms, enqueue 0.100659 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154712 ms - Host latency: 0.19646 ms (end to end 0.284326 ms, enqueue 0.103711 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154883 ms - Host latency: 0.196948 ms (end to end 0.287061 ms, enqueue 0.101953 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155298 ms - Host latency: 0.196973 ms (end to end 0.278271 ms, enqueue 0.102344 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.197095 ms (end to end 0.283447 ms, enqueue 0.10022 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154517 ms - Host latency: 0.196045 ms (end to end 0.276563 ms, enqueue 0.0906982 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155225 ms - Host latency: 0.197144 ms (end to end 0.278638 ms, enqueue 0.0935547 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155151 ms - Host latency: 0.197192 ms (end to end 0.264087 ms, enqueue 0.0936279 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155029 ms - Host latency: 0.196729 ms (end to end 0.281738 ms, enqueue 0.0877441 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155591 ms - Host latency: 0.197461 ms (end to end 0.284277 ms, enqueue 0.086377 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155151 ms - Host latency: 0.196851 ms (end to end 0.280273 ms, enqueue 0.0866943 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.227563 ms - Host latency: 0.275342 ms (end to end 0.316138 ms, enqueue 0.218018 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.260645 ms - Host latency: 0.309668 ms (end to end 0.320776 ms, enqueue 0.28584 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.203564 ms - Host latency: 0.248877 ms (end to end 0.284229 ms, enqueue 0.19812 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.182227 ms - Host latency: 0.226343 ms (end to end 0.235669 ms, enqueue 0.210913 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.172217 ms - Host latency: 0.216504 ms (end to end 0.224658 ms, enqueue 0.200366 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.184741 ms - Host latency: 0.228931 ms (end to end 0.238135 ms, enqueue 0.213208 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.173462 ms - Host latency: 0.217627 ms (end to end 0.225586 ms, enqueue 0.201758 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.162598 ms - Host latency: 0.205957 ms (end to end 0.216504 ms, enqueue 0.15835 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157471 ms - Host latency: 0.198682 ms (end to end 0.210645 ms, enqueue 0.135669 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158447 ms - Host latency: 0.201318 ms (end to end 0.212305 ms, enqueue 0.137622 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160303 ms - Host latency: 0.203613 ms (end to end 0.214624 ms, enqueue 0.141187 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.163379 ms - Host latency: 0.206372 ms (end to end 0.218433 ms, enqueue 0.147412 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15625 ms - Host latency: 0.199414 ms (end to end 0.24812 ms, enqueue 0.12146 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155396 ms - Host latency: 0.19729 ms (end to end 0.281836 ms, enqueue 0.0790283 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.196777 ms (end to end 0.282544 ms, enqueue 0.078125 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155298 ms - Host latency: 0.197217 ms (end to end 0.280908 ms, enqueue 0.0794189 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155762 ms - Host latency: 0.197437 ms (end to end 0.282178 ms, enqueue 0.0780273 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155542 ms - Host latency: 0.197046 ms (end to end 0.28208 ms, enqueue 0.0777588 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155176 ms - Host latency: 0.196631 ms (end to end 0.281934 ms, enqueue 0.0779785 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155078 ms - Host latency: 0.196826 ms (end to end 0.280737 ms, enqueue 0.0779297 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154663 ms - Host latency: 0.19624 ms (end to end 0.278687 ms, enqueue 0.0803711 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155762 ms - Host latency: 0.197778 ms (end to end 0.284717 ms, enqueue 0.07854 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.196875 ms (end to end 0.286768 ms, enqueue 0.0790527 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1552 ms - Host latency: 0.196973 ms (end to end 0.285669 ms, enqueue 0.0780029 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155493 ms - Host latency: 0.197241 ms (end to end 0.287378 ms, enqueue 0.0770752 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155786 ms - Host latency: 0.197778 ms (end to end 0.285425 ms, enqueue 0.0780762 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15564 ms - Host latency: 0.197314 ms (end to end 0.283862 ms, enqueue 0.0777832 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155225 ms - Host latency: 0.197192 ms (end to end 0.280347 ms, enqueue 0.0800049 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154932 ms - Host latency: 0.196338 ms (end to end 0.275 ms, enqueue 0.0820557 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155151 ms - Host latency: 0.196875 ms (end to end 0.276416 ms, enqueue 0.0833984 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15481 ms - Host latency: 0.19624 ms (end to end 0.276416 ms, enqueue 0.0842773 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155786 ms - Host latency: 0.19812 ms (end to end 0.283594 ms, enqueue 0.0845947 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15542 ms - Host latency: 0.19707 ms (end to end 0.283789 ms, enqueue 0.0848877 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.197046 ms (end to end 0.28457 ms, enqueue 0.0845947 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15564 ms - Host latency: 0.197559 ms (end to end 0.28523 ms, enqueue 0.0838623 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155664 ms - Host latency: 0.197681 ms (end to end 0.283276 ms, enqueue 0.0850098 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.173779 ms - Host latency: 0.21582 ms (end to end 0.320923 ms, enqueue 0.0841553 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155566 ms - Host latency: 0.197314 ms (end to end 0.285693 ms, enqueue 0.0841553 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155444 ms - Host latency: 0.196948 ms (end to end 0.284619 ms, enqueue 0.0847656 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155493 ms - Host latency: 0.19729 ms (end to end 0.283936 ms, enqueue 0.0844971 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155737 ms - Host latency: 0.198291 ms (end to end 0.283081 ms, enqueue 0.0845703 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155615 ms - Host latency: 0.197314 ms (end to end 0.282129 ms, enqueue 0.0835449 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155225 ms - Host latency: 0.196851 ms (end to end 0.273242 ms, enqueue 0.0838379 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1927 ms - Host latency: 0.238525 ms (end to end 0.290161 ms, enqueue 0.171069 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.215796 ms - Host latency: 0.261572 ms (end to end 0.272729 ms, enqueue 0.244409 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.217139 ms - Host latency: 0.26438 ms (end to end 0.273413 ms, enqueue 0.242993 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.215332 ms - Host latency: 0.260718 ms (end to end 0.270044 ms, enqueue 0.241455 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.217603 ms - Host latency: 0.263403 ms (end to end 0.273071 ms, enqueue 0.242627 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.172827 ms - Host latency: 0.223901 ms (end to end 0.236157 ms, enqueue 0.18335 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161914 ms - Host latency: 0.211133 ms (end to end 0.228271 ms, enqueue 0.159888 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160889 ms - Host latency: 0.209473 ms (end to end 0.226147 ms, enqueue 0.158569 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160718 ms - Host latency: 0.211157 ms (end to end 0.226465 ms, enqueue 0.159326 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160913 ms - Host latency: 0.209766 ms (end to end 0.226416 ms, enqueue 0.158691 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160742 ms - Host latency: 0.209912 ms (end to end 0.225854 ms, enqueue 0.159521 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155078 ms - Host latency: 0.196558 ms (end to end 0.26958 ms, enqueue 0.110889 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155273 ms - Host latency: 0.196655 ms (end to end 0.28313 ms, enqueue 0.112817 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1552 ms - Host latency: 0.19624 ms (end to end 0.28064 ms, enqueue 0.11106 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155249 ms - Host latency: 0.196582 ms (end to end 0.280371 ms, enqueue 0.112988 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155688 ms - Host latency: 0.197119 ms (end to end 0.286377 ms, enqueue 0.113159 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155151 ms - Host latency: 0.196997 ms (end to end 0.282251 ms, enqueue 0.11665 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155151 ms - Host latency: 0.196753 ms (end to end 0.284375 ms, enqueue 0.095459 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155176 ms - Host latency: 0.196851 ms (end to end 0.280127 ms, enqueue 0.0836914 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15498 ms - Host latency: 0.196533 ms (end to end 0.279565 ms, enqueue 0.0812012 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154639 ms - Host latency: 0.196338 ms (end to end 0.271704 ms, enqueue 0.103174 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154932 ms - Host latency: 0.196631 ms (end to end 0.285474 ms, enqueue 0.100073 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154858 ms - Host latency: 0.196289 ms (end to end 0.284277 ms, enqueue 0.100537 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155176 ms - Host latency: 0.197412 ms (end to end 0.28269 ms, enqueue 0.108179 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155273 ms - Host latency: 0.197119 ms (end to end 0.290356 ms, enqueue 0.125293 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155322 ms - Host latency: 0.196997 ms (end to end 0.286206 ms, enqueue 0.129248 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15564 ms - Host latency: 0.197314 ms (end to end 0.26687 ms, enqueue 0.132324 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155298 ms - Host latency: 0.197021 ms (end to end 0.284717 ms, enqueue 0.128003 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155322 ms - Host latency: 0.197412 ms (end to end 0.287964 ms, enqueue 0.127002 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15498 ms - Host latency: 0.197388 ms (end to end 0.291162 ms, enqueue 0.127563 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155859 ms - Host latency: 0.197339 ms (end to end 0.286743 ms, enqueue 0.0947998 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154858 ms - Host latency: 0.196875 ms (end to end 0.28894 ms, enqueue 0.0886719 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.166943 ms - Host latency: 0.210352 ms (end to end 0.298315 ms, enqueue 0.112305 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.218091 ms - Host latency: 0.264404 ms (end to end 0.274658 ms, enqueue 0.244971 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.180054 ms - Host latency: 0.229736 ms (end to end 0.241309 ms, enqueue 0.174316 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158789 ms - Host latency: 0.201562 ms (end to end 0.210596 ms, enqueue 0.187207 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154907 ms - Host latency: 0.195825 ms (end to end 0.205835 ms, enqueue 0.175928 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15415 ms - Host latency: 0.195142 ms (end to end 0.204565 ms, enqueue 0.174365 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154468 ms - Host latency: 0.195703 ms (end to end 0.205762 ms, enqueue 0.176123 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15437 ms - Host latency: 0.195361 ms (end to end 0.206104 ms, enqueue 0.164819 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159985 ms - Host latency: 0.207202 ms (end to end 0.217383 ms, enqueue 0.180249 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154565 ms - Host latency: 0.205762 ms (end to end 0.215771 ms, enqueue 0.168921 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153955 ms - Host latency: 0.205762 ms (end to end 0.215332 ms, enqueue 0.168164 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154297 ms - Host latency: 0.203516 ms (end to end 0.213965 ms, enqueue 0.172949 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154736 ms - Host latency: 0.200293 ms (end to end 0.209937 ms, enqueue 0.160522 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155469 ms - Host latency: 0.197144 ms (end to end 0.268018 ms, enqueue 0.124438 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155347 ms - Host latency: 0.19707 ms (end to end 0.295142 ms, enqueue 0.126392 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155396 ms - Host latency: 0.19751 ms (end to end 0.296045 ms, enqueue 0.126001 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154834 ms - Host latency: 0.196899 ms (end to end 0.29563 ms, enqueue 0.127271 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.197827 ms (end to end 0.297192 ms, enqueue 0.127148 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155688 ms - Host latency: 0.197729 ms (end to end 0.290479 ms, enqueue 0.12666 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155103 ms - Host latency: 0.197266 ms (end to end 0.281177 ms, enqueue 0.108301 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155078 ms - Host latency: 0.196851 ms (end to end 0.27749 ms, enqueue 0.0938721 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154687 ms - Host latency: 0.196436 ms (end to end 0.275537 ms, enqueue 0.0916992 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15481 ms - Host latency: 0.196655 ms (end to end 0.278662 ms, enqueue 0.0928955 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155493 ms - Host latency: 0.19729 ms (end to end 0.279639 ms, enqueue 0.0953125 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155005 ms - Host latency: 0.196411 ms (end to end 0.283936 ms, enqueue 0.100415 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155396 ms - Host latency: 0.197021 ms (end to end 0.280835 ms, enqueue 0.094165 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155225 ms - Host latency: 0.196729 ms (end to end 0.271997 ms, enqueue 0.0858154 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155518 ms - Host latency: 0.196973 ms (end to end 0.27439 ms, enqueue 0.0850342 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154883 ms - Host latency: 0.196631 ms (end to end 0.2771 ms, enqueue 0.0914795 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155078 ms - Host latency: 0.197266 ms (end to end 0.277148 ms, enqueue 0.0896728 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155273 ms - Host latency: 0.196875 ms (end to end 0.274365 ms, enqueue 0.0874756 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155566 ms - Host latency: 0.197559 ms (end to end 0.276025 ms, enqueue 0.0866943 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154956 ms - Host latency: 0.196729 ms (end to end 0.274512 ms, enqueue 0.0874756 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154834 ms - Host latency: 0.196411 ms (end to end 0.275854 ms, enqueue 0.088501 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155054 ms - Host latency: 0.19668 ms (end to end 0.27666 ms, enqueue 0.0866455 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155078 ms - Host latency: 0.196533 ms (end to end 0.280835 ms, enqueue 0.0862061 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155127 ms - Host latency: 0.196655 ms (end to end 0.282568 ms, enqueue 0.0857422 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.250244 ms - Host latency: 0.298853 ms (end to end 0.311133 ms, enqueue 0.277295 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.245093 ms - Host latency: 0.292773 ms (end to end 0.302344 ms, enqueue 0.269946 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.203345 ms - Host latency: 0.250854 ms (end to end 0.261523 ms, enqueue 0.232397 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.203369 ms - Host latency: 0.248071 ms (end to end 0.258423 ms, enqueue 0.231714 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.189111 ms - Host latency: 0.233594 ms (end to end 0.241943 ms, enqueue 0.216333 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.171973 ms - Host latency: 0.215625 ms (end to end 0.226514 ms, enqueue 0.181226 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155176 ms - Host latency: 0.196899 ms (end to end 0.279712 ms, enqueue 0.110718 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155347 ms - Host latency: 0.197217 ms (end to end 0.288037 ms, enqueue 0.112964 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155591 ms - Host latency: 0.197119 ms (end to end 0.285645 ms, enqueue 0.117041 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155103 ms - Host latency: 0.196753 ms (end to end 0.284399 ms, enqueue 0.119214 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157104 ms - Host latency: 0.198755 ms (end to end 0.242578 ms, enqueue 0.140015 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159277 ms - Host latency: 0.200879 ms (end to end 0.212158 ms, enqueue 0.133325 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155933 ms - Host latency: 0.197241 ms (end to end 0.240723 ms, enqueue 0.12854 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15564 ms - Host latency: 0.197021 ms (end to end 0.26394 ms, enqueue 0.132007 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155786 ms - Host latency: 0.197461 ms (end to end 0.274365 ms, enqueue 0.129736 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155151 ms - Host latency: 0.196484 ms (end to end 0.296899 ms, enqueue 0.129907 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155078 ms - Host latency: 0.196655 ms (end to end 0.280176 ms, enqueue 0.102881 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155005 ms - Host latency: 0.196582 ms (end to end 0.279224 ms, enqueue 0.0964844 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155151 ms - Host latency: 0.197363 ms (end to end 0.282056 ms, enqueue 0.103491 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154907 ms - Host latency: 0.196094 ms (end to end 0.28103 ms, enqueue 0.0985596 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154883 ms - Host latency: 0.196484 ms (end to end 0.28269 ms, enqueue 0.101196 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155054 ms - Host latency: 0.196704 ms (end to end 0.278662 ms, enqueue 0.0981689 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154956 ms - Host latency: 0.197314 ms (end to end 0.280005 ms, enqueue 0.0915283 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.204639 ms - Host latency: 0.250586 ms (end to end 0.292627 ms, enqueue 0.193433 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.203027 ms - Host latency: 0.247559 ms (end to end 0.258228 ms, enqueue 0.231909 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.200488 ms - Host latency: 0.245288 ms (end to end 0.254834 ms, enqueue 0.227954 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.167065 ms - Host latency: 0.209424 ms (end to end 0.254785 ms, enqueue 0.149536 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160962 ms - Host latency: 0.202637 ms (end to end 0.226611 ms, enqueue 0.144702 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.163892 ms - Host latency: 0.206421 ms (end to end 0.219751 ms, enqueue 0.146851 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.163232 ms - Host latency: 0.206836 ms (end to end 0.220776 ms, enqueue 0.148169 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161694 ms - Host latency: 0.205762 ms (end to end 0.217041 ms, enqueue 0.146167 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.162988 ms - Host latency: 0.205005 ms (end to end 0.21521 ms, enqueue 0.142749 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159546 ms - Host latency: 0.200952 ms (end to end 0.228369 ms, enqueue 0.125269 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155493 ms - Host latency: 0.198291 ms (end to end 0.28208 ms, enqueue 0.101978 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155225 ms - Host latency: 0.197192 ms (end to end 0.280493 ms, enqueue 0.102344 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155029 ms - Host latency: 0.196484 ms (end to end 0.284888 ms, enqueue 0.102783 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154736 ms - Host latency: 0.196387 ms (end to end 0.282227 ms, enqueue 0.101855 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155225 ms - Host latency: 0.196606 ms (end to end 0.282422 ms, enqueue 0.102271 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155762 ms - Host latency: 0.197168 ms (end to end 0.281348 ms, enqueue 0.105127 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155908 ms - Host latency: 0.197681 ms (end to end 0.284717 ms, enqueue 0.0824219 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1552 ms - Host latency: 0.196729 ms (end to end 0.280981 ms, enqueue 0.0828613 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154883 ms - Host latency: 0.196655 ms (end to end 0.276416 ms, enqueue 0.0843506 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154834 ms - Host latency: 0.196289 ms (end to end 0.275391 ms, enqueue 0.0815186 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154321 ms - Host latency: 0.195923 ms (end to end 0.274585 ms, enqueue 0.081958 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154468 ms - Host latency: 0.196094 ms (end to end 0.275854 ms, enqueue 0.0816162 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154858 ms - Host latency: 0.196289 ms (end to end 0.275977 ms, enqueue 0.0808838 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154541 ms - Host latency: 0.196411 ms (end to end 0.276221 ms, enqueue 0.0789063 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155151 ms - Host latency: 0.19668 ms (end to end 0.275049 ms, enqueue 0.0804443 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155054 ms - Host latency: 0.196387 ms (end to end 0.269971 ms, enqueue 0.0816162 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154907 ms - Host latency: 0.196436 ms (end to end 0.26875 ms, enqueue 0.0820801 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15498 ms - Host latency: 0.196216 ms (end to end 0.270776 ms, enqueue 0.0814941 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155078 ms - Host latency: 0.196313 ms (end to end 0.273413 ms, enqueue 0.0811279 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1552 ms - Host latency: 0.196655 ms (end to end 0.277637 ms, enqueue 0.0789551 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15437 ms - Host latency: 0.195874 ms (end to end 0.278174 ms, enqueue 0.0784424 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15459 ms - Host latency: 0.196191 ms (end to end 0.276001 ms, enqueue 0.0777588 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154883 ms - Host latency: 0.196558 ms (end to end 0.278882 ms, enqueue 0.0776123 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154761 ms - Host latency: 0.196265 ms (end to end 0.277515 ms, enqueue 0.0785156 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155322 ms - Host latency: 0.197119 ms (end to end 0.280737 ms, enqueue 0.0775635 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155249 ms - Host latency: 0.197144 ms (end to end 0.282422 ms, enqueue 0.078125 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155444 ms - Host latency: 0.196802 ms (end to end 0.281348 ms, enqueue 0.0777832 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154834 ms - Host latency: 0.196631 ms (end to end 0.278809 ms, enqueue 0.0775146 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.218994 ms - Host latency: 0.265894 ms (end to end 0.293433 ms, enqueue 0.226562 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.233691 ms - Host latency: 0.282007 ms (end to end 0.292944 ms, enqueue 0.260522 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.232837 ms - Host latency: 0.280078 ms (end to end 0.289746 ms, enqueue 0.257373 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.22793 ms - Host latency: 0.275659 ms (end to end 0.28645 ms, enqueue 0.254687 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.224316 ms - Host latency: 0.271533 ms (end to end 0.281836 ms, enqueue 0.251343 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157886 ms - Host latency: 0.203564 ms (end to end 0.213086 ms, enqueue 0.174658 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154346 ms - Host latency: 0.205054 ms (end to end 0.215479 ms, enqueue 0.166895 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154834 ms - Host latency: 0.206372 ms (end to end 0.217554 ms, enqueue 0.164087 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155786 ms - Host latency: 0.208667 ms (end to end 0.219727 ms, enqueue 0.164185 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154639 ms - Host latency: 0.207104 ms (end to end 0.218335 ms, enqueue 0.164941 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.197485 ms (end to end 0.249707 ms, enqueue 0.127344 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.180664 ms - Host latency: 0.224316 ms (end to end 0.28208 ms, enqueue 0.146509 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.23252 ms - Host latency: 0.279883 ms (end to end 0.289868 ms, enqueue 0.257739 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.268066 ms - Host latency: 0.319995 ms (end to end 0.32937 ms, enqueue 0.290259 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.242969 ms - Host latency: 0.293701 ms (end to end 0.304004 ms, enqueue 0.266943 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.228296 ms - Host latency: 0.278711 ms (end to end 0.290674 ms, enqueue 0.251392 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.227124 ms - Host latency: 0.277759 ms (end to end 0.289014 ms, enqueue 0.253955 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.172485 ms - Host latency: 0.21582 ms (end to end 0.226782 ms, enqueue 0.19436 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156812 ms - Host latency: 0.199072 ms (end to end 0.208813 ms, enqueue 0.178027 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154541 ms - Host latency: 0.195728 ms (end to end 0.207666 ms, enqueue 0.175439 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156787 ms - Host latency: 0.198145 ms (end to end 0.207568 ms, enqueue 0.178296 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.196631 ms (end to end 0.205835 ms, enqueue 0.175464 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157178 ms - Host latency: 0.198291 ms (end to end 0.218579 ms, enqueue 0.131616 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155933 ms - Host latency: 0.197046 ms (end to end 0.229224 ms, enqueue 0.135767 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155713 ms - Host latency: 0.197339 ms (end to end 0.231665 ms, enqueue 0.13584 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156079 ms - Host latency: 0.197534 ms (end to end 0.237842 ms, enqueue 0.133984 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155981 ms - Host latency: 0.197681 ms (end to end 0.247192 ms, enqueue 0.136011 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15603 ms - Host latency: 0.197803 ms (end to end 0.2479 ms, enqueue 0.135718 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155444 ms - Host latency: 0.197266 ms (end to end 0.268774 ms, enqueue 0.111157 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155664 ms - Host latency: 0.197339 ms (end to end 0.282227 ms, enqueue 0.0973877 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155322 ms - Host latency: 0.197437 ms (end to end 0.283618 ms, enqueue 0.0994629 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155469 ms - Host latency: 0.197095 ms (end to end 0.281055 ms, enqueue 0.0976318 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155713 ms - Host latency: 0.197607 ms (end to end 0.287207 ms, enqueue 0.0974121 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15481 ms - Host latency: 0.196411 ms (end to end 0.288062 ms, enqueue 0.0965332 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155322 ms - Host latency: 0.197168 ms (end to end 0.287354 ms, enqueue 0.0968018 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.22124 ms - Host latency: 0.268628 ms (end to end 0.305005 ms, enqueue 0.224707 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.227002 ms - Host latency: 0.273755 ms (end to end 0.282349 ms, enqueue 0.252686 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.238599 ms - Host latency: 0.287573 ms (end to end 0.299561 ms, enqueue 0.266602 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161841 ms - Host latency: 0.203101 ms (end to end 0.211572 ms, enqueue 0.183154 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154761 ms - Host latency: 0.195801 ms (end to end 0.204468 ms, enqueue 0.17644 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153955 ms - Host latency: 0.195581 ms (end to end 0.205566 ms, enqueue 0.17373 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158545 ms - Host latency: 0.202588 ms (end to end 0.214111 ms, enqueue 0.184277 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.162598 ms - Host latency: 0.206641 ms (end to end 0.228149 ms, enqueue 0.168701 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.165991 ms - Host latency: 0.211084 ms (end to end 0.237793 ms, enqueue 0.153296 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157471 ms - Host latency: 0.199854 ms (end to end 0.243481 ms, enqueue 0.137402 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156323 ms - Host latency: 0.199634 ms (end to end 0.238281 ms, enqueue 0.136475 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156592 ms - Host latency: 0.2073 ms (end to end 0.219873 ms, enqueue 0.162183 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159399 ms - Host latency: 0.209253 ms (end to end 0.225562 ms, enqueue 0.161182 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.164429 ms - Host latency: 0.208228 ms (end to end 0.222754 ms, enqueue 0.153101 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.165527 ms - Host latency: 0.208423 ms (end to end 0.220654 ms, enqueue 0.152393 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155615 ms - Host latency: 0.197729 ms (end to end 0.26897 ms, enqueue 0.109131 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155518 ms - Host latency: 0.197461 ms (end to end 0.29021 ms, enqueue 0.112109 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158252 ms - Host latency: 0.201465 ms (end to end 0.261987 ms, enqueue 0.160645 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156201 ms - Host latency: 0.198364 ms (end to end 0.20625 ms, enqueue 0.184448 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160669 ms - Host latency: 0.202173 ms (end to end 0.212378 ms, enqueue 0.185889 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153662 ms - Host latency: 0.195142 ms (end to end 0.204883 ms, enqueue 0.173584 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157764 ms - Host latency: 0.198926 ms (end to end 0.208252 ms, enqueue 0.179834 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153906 ms - Host latency: 0.194775 ms (end to end 0.204272 ms, enqueue 0.173608 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154248 ms - Host latency: 0.19519 ms (end to end 0.203687 ms, enqueue 0.174805 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15542 ms - Host latency: 0.197461 ms (end to end 0.25791 ms, enqueue 0.124194 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156079 ms - Host latency: 0.197925 ms (end to end 0.284302 ms, enqueue 0.122583 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155469 ms - Host latency: 0.197217 ms (end to end 0.287378 ms, enqueue 0.119775 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156274 ms - Host latency: 0.197656 ms (end to end 0.268188 ms, enqueue 0.121265 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155469 ms - Host latency: 0.197119 ms (end to end 0.275 ms, enqueue 0.121606 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.197095 ms (end to end 0.285547 ms, enqueue 0.124512 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154956 ms - Host latency: 0.196851 ms (end to end 0.291919 ms, enqueue 0.118945 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154468 ms - Host latency: 0.195972 ms (end to end 0.281128 ms, enqueue 0.0993408 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155176 ms - Host latency: 0.196631 ms (end to end 0.274951 ms, enqueue 0.0908203 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154907 ms - Host latency: 0.196265 ms (end to end 0.276587 ms, enqueue 0.0908203 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154956 ms - Host latency: 0.196387 ms (end to end 0.279126 ms, enqueue 0.0949463 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.187256 ms - Host latency: 0.232739 ms (end to end 0.294019 ms, enqueue 0.153296 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.237598 ms - Host latency: 0.28667 ms (end to end 0.297339 ms, enqueue 0.263208 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.196021 ms - Host latency: 0.241113 ms (end to end 0.25166 ms, enqueue 0.224658 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.222583 ms - Host latency: 0.269385 ms (end to end 0.279126 ms, enqueue 0.249316 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.206348 ms - Host latency: 0.251294 ms (end to end 0.2604 ms, enqueue 0.234253 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.166138 ms - Host latency: 0.209302 ms (end to end 0.228784 ms, enqueue 0.168701 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.197998 ms - Host latency: 0.246899 ms (end to end 0.267969 ms, enqueue 0.219116 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156812 ms - Host latency: 0.199902 ms (end to end 0.264331 ms, enqueue 0.0998047 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.218848 ms - Host latency: 0.266528 ms (end to end 0.305884 ms, enqueue 0.206885 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.250684 ms - Host latency: 0.298975 ms (end to end 0.310181 ms, enqueue 0.276563 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.236328 ms - Host latency: 0.286353 ms (end to end 0.297241 ms, enqueue 0.262671 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.176953 ms - Host latency: 0.221313 ms (end to end 0.232886 ms, enqueue 0.166187 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158936 ms - Host latency: 0.202563 ms (end to end 0.213989 ms, enqueue 0.141528 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157788 ms - Host latency: 0.20249 ms (end to end 0.238452 ms, enqueue 0.133936 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155615 ms - Host latency: 0.19895 ms (end to end 0.237158 ms, enqueue 0.132422 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155127 ms - Host latency: 0.196777 ms (end to end 0.282959 ms, enqueue 0.099292 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155029 ms - Host latency: 0.196606 ms (end to end 0.279858 ms, enqueue 0.105273 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1552 ms - Host latency: 0.196753 ms (end to end 0.281836 ms, enqueue 0.107935 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155249 ms - Host latency: 0.196924 ms (end to end 0.28291 ms, enqueue 0.104175 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.243799 ms - Host latency: 0.297485 ms (end to end 0.309082 ms, enqueue 0.2698 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.219116 ms - Host latency: 0.269019 ms (end to end 0.279834 ms, enqueue 0.24563 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.214282 ms - Host latency: 0.263477 ms (end to end 0.274023 ms, enqueue 0.241138 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.188794 ms - Host latency: 0.236816 ms (end to end 0.24563 ms, enqueue 0.215723 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.167139 ms - Host latency: 0.210596 ms (end to end 0.221118 ms, enqueue 0.19541 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.17207 ms - Host latency: 0.216821 ms (end to end 0.224609 ms, enqueue 0.198804 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.171387 ms - Host latency: 0.213818 ms (end to end 0.222119 ms, enqueue 0.198071 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.164478 ms - Host latency: 0.208594 ms (end to end 0.217871 ms, enqueue 0.176611 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.170508 ms - Host latency: 0.214307 ms (end to end 0.227051 ms, enqueue 0.155493 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158838 ms - Host latency: 0.200317 ms (end to end 0.218628 ms, enqueue 0.136353 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158838 ms - Host latency: 0.200342 ms (end to end 0.21228 ms, enqueue 0.136987 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158374 ms - Host latency: 0.199927 ms (end to end 0.213306 ms, enqueue 0.134058 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155591 ms - Host latency: 0.196948 ms (end to end 0.243237 ms, enqueue 0.126196 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155054 ms - Host latency: 0.196631 ms (end to end 0.277881 ms, enqueue 0.132397 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154834 ms - Host latency: 0.196826 ms (end to end 0.285962 ms, enqueue 0.110522 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160229 ms - Host latency: 0.202905 ms (end to end 0.227563 ms, enqueue 0.152075 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157764 ms - Host latency: 0.199219 ms (end to end 0.210278 ms, enqueue 0.135229 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157178 ms - Host latency: 0.200293 ms (end to end 0.227783 ms, enqueue 0.122729 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160425 ms - Host latency: 0.205103 ms (end to end 0.221655 ms, enqueue 0.159937 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.160083 ms - Host latency: 0.204102 ms (end to end 0.218213 ms, enqueue 0.149756 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155933 ms - Host latency: 0.196875 ms (end to end 0.206079 ms, enqueue 0.173779 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153906 ms - Host latency: 0.194702 ms (end to end 0.203833 ms, enqueue 0.173779 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15415 ms - Host latency: 0.194922 ms (end to end 0.20498 ms, enqueue 0.175293 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153979 ms - Host latency: 0.194434 ms (end to end 0.204565 ms, enqueue 0.174463 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15769 ms - Host latency: 0.199268 ms (end to end 0.257275 ms, enqueue 0.104321 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154932 ms - Host latency: 0.196973 ms (end to end 0.27666 ms, enqueue 0.0784424 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154565 ms - Host latency: 0.196313 ms (end to end 0.273486 ms, enqueue 0.0787109 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154883 ms - Host latency: 0.196362 ms (end to end 0.276123 ms, enqueue 0.0781006 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.194019 ms - Host latency: 0.239844 ms (end to end 0.280908 ms, enqueue 0.182812 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.199585 ms - Host latency: 0.244409 ms (end to end 0.253711 ms, enqueue 0.226733 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.233008 ms - Host latency: 0.279687 ms (end to end 0.290454 ms, enqueue 0.259473 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.261621 ms - Host latency: 0.311084 ms (end to end 0.322974 ms, enqueue 0.288184 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.325391 ms - Host latency: 0.379224 ms (end to end 0.389966 ms, enqueue 0.346069 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.270703 ms - Host latency: 0.320557 ms (end to end 0.332422 ms, enqueue 0.295459 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.225464 ms - Host latency: 0.273267 ms (end to end 0.283765 ms, enqueue 0.25061 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.161328 ms - Host latency: 0.208032 ms (end to end 0.219189 ms, enqueue 0.180542 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.185498 ms - Host latency: 0.232178 ms (end to end 0.242358 ms, enqueue 0.197266 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155762 ms - Host latency: 0.198242 ms (end to end 0.259595 ms, enqueue 0.136499 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158569 ms - Host latency: 0.204736 ms (end to end 0.218066 ms, enqueue 0.152026 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15564 ms - Host latency: 0.197632 ms (end to end 0.267627 ms, enqueue 0.125269 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155981 ms - Host latency: 0.1979 ms (end to end 0.264111 ms, enqueue 0.137988 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155493 ms - Host latency: 0.197192 ms (end to end 0.204712 ms, enqueue 0.179565 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155322 ms - Host latency: 0.197046 ms (end to end 0.2125 ms, enqueue 0.1479 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155933 ms - Host latency: 0.197852 ms (end to end 0.247266 ms, enqueue 0.122388 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155566 ms - Host latency: 0.19707 ms (end to end 0.241895 ms, enqueue 0.129272 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156616 ms - Host latency: 0.198364 ms (end to end 0.257056 ms, enqueue 0.129297 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155225 ms - Host latency: 0.196753 ms (end to end 0.27627 ms, enqueue 0.126294 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154883 ms - Host latency: 0.196924 ms (end to end 0.294849 ms, enqueue 0.128516 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155981 ms - Host latency: 0.198315 ms (end to end 0.268066 ms, enqueue 0.129224 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155713 ms - Host latency: 0.198096 ms (end to end 0.285254 ms, enqueue 0.123779 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.198267 ms (end to end 0.292505 ms, enqueue 0.123218 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155127 ms - Host latency: 0.196558 ms (end to end 0.28418 ms, enqueue 0.0989014 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.25481 ms - Host latency: 0.303931 ms (end to end 0.330566 ms, enqueue 0.261987 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.245239 ms - Host latency: 0.293384 ms (end to end 0.304736 ms, enqueue 0.271558 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.25022 ms - Host latency: 0.297705 ms (end to end 0.307983 ms, enqueue 0.275146 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.215186 ms - Host latency: 0.26062 ms (end to end 0.27124 ms, enqueue 0.243237 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.174072 ms - Host latency: 0.217163 ms (end to end 0.248804 ms, enqueue 0.168066 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154785 ms - Host latency: 0.196191 ms (end to end 0.273145 ms, enqueue 0.0850342 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154761 ms - Host latency: 0.19646 ms (end to end 0.276123 ms, enqueue 0.0788818 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154858 ms - Host latency: 0.196216 ms (end to end 0.271802 ms, enqueue 0.0870605 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154858 ms - Host latency: 0.196484 ms (end to end 0.274463 ms, enqueue 0.0792236 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154443 ms - Host latency: 0.195972 ms (end to end 0.277905 ms, enqueue 0.0843506 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154834 ms - Host latency: 0.196191 ms (end to end 0.275244 ms, enqueue 0.0810059 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155127 ms - Host latency: 0.19668 ms (end to end 0.281348 ms, enqueue 0.088501 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.19668 ms (end to end 0.281396 ms, enqueue 0.0791992 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155566 ms - Host latency: 0.197046 ms (end to end 0.282788 ms, enqueue 0.0783447 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155566 ms - Host latency: 0.196851 ms (end to end 0.282422 ms, enqueue 0.0812988 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155444 ms - Host latency: 0.196655 ms (end to end 0.282275 ms, enqueue 0.0804688 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155322 ms - Host latency: 0.196851 ms (end to end 0.280054 ms, enqueue 0.0818359 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155225 ms - Host latency: 0.196826 ms (end to end 0.277979 ms, enqueue 0.0859375 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155542 ms - Host latency: 0.19729 ms (end to end 0.286694 ms, enqueue 0.0878662 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154639 ms - Host latency: 0.196289 ms (end to end 0.277954 ms, enqueue 0.0845703 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15481 ms - Host latency: 0.19646 ms (end to end 0.278979 ms, enqueue 0.0881104 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155029 ms - Host latency: 0.196655 ms (end to end 0.280591 ms, enqueue 0.0795898 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155615 ms - Host latency: 0.197339 ms (end to end 0.282593 ms, enqueue 0.0798584 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155347 ms - Host latency: 0.197046 ms (end to end 0.281104 ms, enqueue 0.0780762 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.196753 ms (end to end 0.282495 ms, enqueue 0.0867188 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155713 ms - Host latency: 0.197485 ms (end to end 0.280884 ms, enqueue 0.0806152 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155298 ms - Host latency: 0.196704 ms (end to end 0.281641 ms, enqueue 0.0812256 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155469 ms - Host latency: 0.197339 ms (end to end 0.284082 ms, enqueue 0.0848633 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155151 ms - Host latency: 0.197192 ms (end to end 0.287012 ms, enqueue 0.0881592 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.164355 ms - Host latency: 0.208374 ms (end to end 0.257715 ms, enqueue 0.137134 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.197998 ms - Host latency: 0.245508 ms (end to end 0.256274 ms, enqueue 0.222119 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.176099 ms - Host latency: 0.220166 ms (end to end 0.26626 ms, enqueue 0.132812 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157568 ms - Host latency: 0.200708 ms (end to end 0.269092 ms, enqueue 0.111157 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15603 ms - Host latency: 0.198193 ms (end to end 0.287305 ms, enqueue 0.105127 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155737 ms - Host latency: 0.197412 ms (end to end 0.283813 ms, enqueue 0.0993408 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155542 ms - Host latency: 0.197241 ms (end to end 0.284351 ms, enqueue 0.0844727 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155615 ms - Host latency: 0.196997 ms (end to end 0.284619 ms, enqueue 0.0822022 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155225 ms - Host latency: 0.196948 ms (end to end 0.284033 ms, enqueue 0.0822266 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155811 ms - Host latency: 0.197681 ms (end to end 0.28374 ms, enqueue 0.0835449 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155957 ms - Host latency: 0.197656 ms (end to end 0.284644 ms, enqueue 0.0834717 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155542 ms - Host latency: 0.197339 ms (end to end 0.282788 ms, enqueue 0.0869629 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.197046 ms (end to end 0.280664 ms, enqueue 0.0889648 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155688 ms - Host latency: 0.1979 ms (end to end 0.275024 ms, enqueue 0.106128 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156006 ms - Host latency: 0.197974 ms (end to end 0.292432 ms, enqueue 0.113062 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155542 ms - Host latency: 0.197827 ms (end to end 0.289038 ms, enqueue 0.112769 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.185449 ms - Host latency: 0.231006 ms (end to end 0.293628 ms, enqueue 0.17522 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.223877 ms - Host latency: 0.271191 ms (end to end 0.281763 ms, enqueue 0.250122 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.218701 ms - Host latency: 0.264502 ms (end to end 0.275 ms, enqueue 0.244312 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.222827 ms - Host latency: 0.270215 ms (end to end 0.282739 ms, enqueue 0.24856 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.222681 ms - Host latency: 0.271655 ms (end to end 0.282227 ms, enqueue 0.24856 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157324 ms - Host latency: 0.207202 ms (end to end 0.219604 ms, enqueue 0.164185 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156934 ms - Host latency: 0.210498 ms (end to end 0.221753 ms, enqueue 0.163403 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15752 ms - Host latency: 0.204248 ms (end to end 0.217041 ms, enqueue 0.164697 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154785 ms - Host latency: 0.201147 ms (end to end 0.210791 ms, enqueue 0.171997 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156421 ms - Host latency: 0.211914 ms (end to end 0.223145 ms, enqueue 0.163354 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155957 ms - Host latency: 0.200684 ms (end to end 0.256787 ms, enqueue 0.127808 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154346 ms - Host latency: 0.195825 ms (end to end 0.290234 ms, enqueue 0.11521 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155005 ms - Host latency: 0.197388 ms (end to end 0.287524 ms, enqueue 0.114819 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155322 ms - Host latency: 0.197339 ms (end to end 0.286816 ms, enqueue 0.117432 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155249 ms - Host latency: 0.197241 ms (end to end 0.287842 ms, enqueue 0.113403 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155615 ms - Host latency: 0.197485 ms (end to end 0.288672 ms, enqueue 0.116089 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154907 ms - Host latency: 0.196826 ms (end to end 0.28938 ms, enqueue 0.105518 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.231616 ms - Host latency: 0.280298 ms (end to end 0.296777 ms, enqueue 0.261694 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.196851 ms - Host latency: 0.241821 ms (end to end 0.254834 ms, enqueue 0.228857 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.202319 ms - Host latency: 0.247729 ms (end to end 0.259448 ms, enqueue 0.232812 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.184546 ms - Host latency: 0.230737 ms (end to end 0.241919 ms, enqueue 0.209521 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.153833 ms - Host latency: 0.204419 ms (end to end 0.214648 ms, enqueue 0.169556 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.164136 ms - Host latency: 0.208496 ms (end to end 0.218872 ms, enqueue 0.167334 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156104 ms - Host latency: 0.197119 ms (end to end 0.216626 ms, enqueue 0.133765 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.1573 ms - Host latency: 0.198584 ms (end to end 0.216992 ms, enqueue 0.136133 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155444 ms - Host latency: 0.196558 ms (end to end 0.216431 ms, enqueue 0.1323 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155859 ms - Host latency: 0.197021 ms (end to end 0.258936 ms, enqueue 0.104248 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155273 ms - Host latency: 0.197461 ms (end to end 0.281763 ms, enqueue 0.0982422 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155249 ms - Host latency: 0.197095 ms (end to end 0.28147 ms, enqueue 0.0985107 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155469 ms - Host latency: 0.196753 ms (end to end 0.271704 ms, enqueue 0.110962 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156494 ms - Host latency: 0.199023 ms (end to end 0.230396 ms, enqueue 0.171655 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.163477 ms - Host latency: 0.205469 ms (end to end 0.216187 ms, enqueue 0.186841 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156323 ms - Host latency: 0.197607 ms (end to end 0.20769 ms, enqueue 0.176294 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156128 ms - Host latency: 0.197144 ms (end to end 0.206958 ms, enqueue 0.175244 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157861 ms - Host latency: 0.199536 ms (end to end 0.208862 ms, enqueue 0.176392 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158203 ms - Host latency: 0.199414 ms (end to end 0.208008 ms, enqueue 0.176953 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158911 ms - Host latency: 0.202148 ms (end to end 0.213281 ms, enqueue 0.16521 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159912 ms - Host latency: 0.201611 ms (end to end 0.212817 ms, enqueue 0.141187 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159839 ms - Host latency: 0.201099 ms (end to end 0.21438 ms, enqueue 0.141357 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159521 ms - Host latency: 0.200952 ms (end to end 0.212524 ms, enqueue 0.140967 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.16106 ms - Host latency: 0.202637 ms (end to end 0.214282 ms, enqueue 0.143213 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159741 ms - Host latency: 0.201025 ms (end to end 0.212842 ms, enqueue 0.141577 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158276 ms - Host latency: 0.199438 ms (end to end 0.222314 ms, enqueue 0.129785 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155566 ms - Host latency: 0.198071 ms (end to end 0.289307 ms, enqueue 0.109326 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155664 ms - Host latency: 0.197803 ms (end to end 0.289429 ms, enqueue 0.106006 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.219189 ms - Host latency: 0.266895 ms (end to end 0.313086 ms, enqueue 0.217822 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.229395 ms - Host latency: 0.275977 ms (end to end 0.285815 ms, enqueue 0.256274 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.206152 ms - Host latency: 0.251099 ms (end to end 0.261304 ms, enqueue 0.234351 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.20061 ms - Host latency: 0.24541 ms (end to end 0.256006 ms, enqueue 0.229614 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.202832 ms - Host latency: 0.247681 ms (end to end 0.258228 ms, enqueue 0.231641 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.197119 ms - Host latency: 0.24126 ms (end to end 0.250928 ms, enqueue 0.219165 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158789 ms - Host latency: 0.210767 ms (end to end 0.225024 ms, enqueue 0.159619 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159058 ms - Host latency: 0.206787 ms (end to end 0.220557 ms, enqueue 0.159863 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156421 ms - Host latency: 0.208057 ms (end to end 0.222021 ms, enqueue 0.16001 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159204 ms - Host latency: 0.210815 ms (end to end 0.222632 ms, enqueue 0.163477 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159302 ms - Host latency: 0.210693 ms (end to end 0.225439 ms, enqueue 0.15647 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158447 ms - Host latency: 0.202026 ms (end to end 0.24751 ms, enqueue 0.125488 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.184863 ms - Host latency: 0.230322 ms (end to end 0.266333 ms, enqueue 0.207471 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.184473 ms - Host latency: 0.228613 ms (end to end 0.239038 ms, enqueue 0.214355 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.181714 ms - Host latency: 0.225732 ms (end to end 0.236377 ms, enqueue 0.211865 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.168335 ms - Host latency: 0.210791 ms (end to end 0.220801 ms, enqueue 0.19397 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154053 ms - Host latency: 0.19502 ms (end to end 0.20437 ms, enqueue 0.175562 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.16748 ms - Host latency: 0.210083 ms (end to end 0.221411 ms, enqueue 0.192554 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159766 ms - Host latency: 0.202319 ms (end to end 0.212573 ms, enqueue 0.18457 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.167896 ms - Host latency: 0.210962 ms (end to end 0.219482 ms, enqueue 0.197437 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158667 ms - Host latency: 0.200781 ms (end to end 0.213403 ms, enqueue 0.143726 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156592 ms - Host latency: 0.197998 ms (end to end 0.212695 ms, enqueue 0.134546 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155884 ms - Host latency: 0.196899 ms (end to end 0.223755 ms, enqueue 0.13335 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157422 ms - Host latency: 0.198779 ms (end to end 0.23645 ms, enqueue 0.130591 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155029 ms - Host latency: 0.196948 ms (end to end 0.287793 ms, enqueue 0.120703 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15564 ms - Host latency: 0.197363 ms (end to end 0.288184 ms, enqueue 0.127905 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155737 ms - Host latency: 0.197095 ms (end to end 0.269312 ms, enqueue 0.113916 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155396 ms - Host latency: 0.197192 ms (end to end 0.283154 ms, enqueue 0.0990723 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155029 ms - Host latency: 0.196851 ms (end to end 0.279614 ms, enqueue 0.0968506 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155542 ms - Host latency: 0.197559 ms (end to end 0.281592 ms, enqueue 0.0978272 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155664 ms - Host latency: 0.19751 ms (end to end 0.286401 ms, enqueue 0.100439 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15564 ms - Host latency: 0.197583 ms (end to end 0.274048 ms, enqueue 0.0882568 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154858 ms - Host latency: 0.196436 ms (end to end 0.272534 ms, enqueue 0.0886475 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.154419 ms - Host latency: 0.196265 ms (end to end 0.274536 ms, enqueue 0.0795898 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157104 ms - Host latency: 0.199976 ms (end to end 0.273706 ms, enqueue 0.0944824 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157861 ms - Host latency: 0.203442 ms (end to end 0.214966 ms, enqueue 0.15415 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156543 ms - Host latency: 0.198267 ms (end to end 0.222607 ms, enqueue 0.135767 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157251 ms - Host latency: 0.199316 ms (end to end 0.222363 ms, enqueue 0.138281 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156763 ms - Host latency: 0.19834 ms (end to end 0.231958 ms, enqueue 0.127661 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156079 ms - Host latency: 0.197998 ms (end to end 0.266528 ms, enqueue 0.135937 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156348 ms - Host latency: 0.197705 ms (end to end 0.220215 ms, enqueue 0.136011 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155908 ms - Host latency: 0.196973 ms (end to end 0.209375 ms, enqueue 0.133154 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15625 ms - Host latency: 0.19729 ms (end to end 0.209155 ms, enqueue 0.133398 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.158105 ms - Host latency: 0.199878 ms (end to end 0.213623 ms, enqueue 0.135425 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157031 ms - Host latency: 0.198755 ms (end to end 0.214795 ms, enqueue 0.134375 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156934 ms - Host latency: 0.198926 ms (end to end 0.233716 ms, enqueue 0.117139 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155737 ms - Host latency: 0.197485 ms (end to end 0.278784 ms, enqueue 0.0971436 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.20498 ms - Host latency: 0.251563 ms (end to end 0.294971 ms, enqueue 0.200635 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.179712 ms - Host latency: 0.226123 ms (end to end 0.234229 ms, enqueue 0.206787 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.166382 ms - Host latency: 0.210986 ms (end to end 0.252832 ms, enqueue 0.144458 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155615 ms - Host latency: 0.197095 ms (end to end 0.281079 ms, enqueue 0.100537 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156226 ms - Host latency: 0.199121 ms (end to end 0.295093 ms, enqueue 0.129688 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155127 ms - Host latency: 0.197119 ms (end to end 0.286133 ms, enqueue 0.127441 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155371 ms - Host latency: 0.197559 ms (end to end 0.291919 ms, enqueue 0.12561 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155664 ms - Host latency: 0.198437 ms (end to end 0.293359 ms, enqueue 0.122827 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155005 ms - Host latency: 0.196851 ms (end to end 0.292139 ms, enqueue 0.121094 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155347 ms - Host latency: 0.197119 ms (end to end 0.291797 ms, enqueue 0.122192 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155469 ms - Host latency: 0.197192 ms (end to end 0.289771 ms, enqueue 0.101025 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.15564 ms - Host latency: 0.197314 ms (end to end 0.288379 ms, enqueue 0.087793 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155688 ms - Host latency: 0.197632 ms (end to end 0.287988 ms, enqueue 0.087207 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155469 ms - Host latency: 0.197461 ms (end to end 0.287891 ms, enqueue 0.0875244 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156445 ms - Host latency: 0.198828 ms (end to end 0.285815 ms, enqueue 0.101367 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157593 ms - Host latency: 0.198389 ms (end to end 0.210547 ms, enqueue 0.134985 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156226 ms - Host latency: 0.197217 ms (end to end 0.215112 ms, enqueue 0.136914 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.159253 ms - Host latency: 0.20144 ms (end to end 0.212012 ms, enqueue 0.13772 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.157593 ms - Host latency: 0.198853 ms (end to end 0.210352 ms, enqueue 0.137329 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.183618 ms - Host latency: 0.227783 ms (end to end 0.256226 ms, enqueue 0.167627 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.226465 ms - Host latency: 0.27334 ms (end to end 0.282666 ms, enqueue 0.252539 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.197192 ms - Host latency: 0.243213 ms (end to end 0.272241 ms, enqueue 0.193091 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.156323 ms - Host latency: 0.197974 ms (end to end 0.242725 ms, enqueue 0.121875 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155005 ms - Host latency: 0.196509 ms (end to end 0.279053 ms, enqueue 0.101245 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.155298 ms - Host latency: 0.19668 ms (end to end 0.285303 ms, enqueue 0.0818359 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.205493 ms - Host latency: 0.251514 ms (end to end 0.28125 ms, enqueue 0.21748 ms)
[12/29/2021-03:47:09] [I] Average on 10 runs - GPU latency: 0.228345 ms - Host latency: 0.274805 ms (end to end 0.284351 ms, enqueue 0.254028 ms)
[12/29/2021-03:47:09] [I] 
[12/29/2021-03:47:09] [I] === Performance summary ===
[12/29/2021-03:47:09] [I] Throughput: 5309.79 qps
[12/29/2021-03:47:09] [I] Latency: min = 0.192139 ms, max = 0.515625 ms, mean = 0.210061 ms, median = 0.197754 ms, percentile(99%) = 0.340332 ms
[12/29/2021-03:47:09] [I] End-to-End Host Latency: min = 0.197327 ms, max = 0.552979 ms, mean = 0.264168 ms, median = 0.276489 ms, percentile(99%) = 0.354492 ms
[12/29/2021-03:47:09] [I] Enqueue Time: min = 0.0756836 ms, max = 0.480713 ms, mean = 0.137503 ms, median = 0.118896 ms, percentile(99%) = 0.31543 ms
[12/29/2021-03:47:09] [I] H2D Latency: min = 0.0358887 ms, max = 0.0778809 ms, mean = 0.0378632 ms, median = 0.0375977 ms, percentile(99%) = 0.0430908 ms
[12/29/2021-03:47:09] [I] GPU Compute Time: min = 0.152252 ms, max = 0.443359 ms, mean = 0.166633 ms, median = 0.155762 ms, percentile(99%) = 0.288452 ms
[12/29/2021-03:47:09] [I] D2H Latency: min = 0.00268555 ms, max = 0.0517578 ms, mean = 0.00556481 ms, median = 0.00439453 ms, percentile(99%) = 0.0185547 ms
[12/29/2021-03:47:09] [I] Total Host Walltime: 3.00068 s
[12/29/2021-03:47:09] [I] Total GPU Compute Time: 2.65496 s
[12/29/2021-03:47:09] [I] Explanations of the performance metrics are printed in the verbose logs.
[12/29/2021-03:47:09] [V] 
[12/29/2021-03:47:09] [V] === Explanations of the performance metrics ===
[12/29/2021-03:47:09] [V] Total Host Walltime: the host walltime from when the first query (after warmups) is enqueued to when the last query is completed.
[12/29/2021-03:47:09] [V] GPU Compute Time: the GPU latency to execute the kernels for a query.
[12/29/2021-03:47:09] [V] Total GPU Compute Time: the summation of the GPU Compute Time of all the queries. If this is significantly shorter than Total Host Walltime, the GPU may be under-utilized because of host-side overheads or data transfers.
[12/29/2021-03:47:09] [V] Throughput: the observed throughput computed by dividing the number of queries by the Total Host Walltime. If this is significantly lower than the reciprocal of GPU Compute Time, the GPU may be under-utilized because of host-side overheads or data transfers.
[12/29/2021-03:47:09] [V] Enqueue Time: the host latency to enqueue a query. If this is longer than GPU Compute Time, the GPU may be under-utilized.
[12/29/2021-03:47:09] [V] H2D Latency: the latency for host-to-device data transfers for input tensors of a single query.
[12/29/2021-03:47:09] [V] D2H Latency: the latency for device-to-host data transfers for output tensors of a single query.
[12/29/2021-03:47:09] [V] Latency: the summation of H2D Latency, GPU Compute Time, and D2H Latency. This is the latency to infer a single query.
[12/29/2021-03:47:09] [V] End-to-End Host Latency: the duration from when the H2D of a query is called to when the D2H of the same query is completed, which includes the latency to wait for the completion of the previous query. This is the latency of a query if multiple queries are enqueued consecutively.
[12/29/2021-03:47:09] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8001] # trtexec --onnx=default_model.onnx --saveEngine=tmp.trt --verbose --calib=model.calib --int8
[12/29/2021-03:47:09] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 2051, GPU 4009 (MiB)
